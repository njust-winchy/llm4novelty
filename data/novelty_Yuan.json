[
  [
    "and I find the methodological contribution to be limited .",
    "NOVELTY"
  ],
  [
    "The proposed approach is a variation of a fairly well-known heuristic .",
    "NOVELTY"
  ],
  [
    "2 .The proposed approach is not novel .",
    "NOVELTY"
  ],
  [
    "The masking and using causal attention for the transformer has been proposed in previous works",
    "NOVELTY"
  ],
  [
    "Overall the contributions are limited .",
    "NOVELTY"
  ],
  [
    "While the concept proposed is not exactly ground breaking",
    "NOVELTY"
  ],
  [
    "I like the idea in general",
    "NOVELTY"
  ],
  [
    "the theorems are very interesting",
    "NOVELTY"
  ],
  [
    "In contrast , this aspect is missing from other work on ML for optimization .",
    "NOVELTY"
  ],
  [
    "Overall , I believe that the idea of using a probabilistic model to capture polysemy is an interesting idea .",
    "NOVELTY"
  ],
  [
    "I like the main idea of the paper , which is to represent word senses by latent variables in a probabilistic model .",
    "NOVELTY"
  ],
  [
    "as far as I am aware , the idea of adversarial *model * manipulation is a new one ,",
    "NOVELTY"
  ],
  [
    "and the approach is interesting",
    "NOVELTY"
  ],
  [
    "The idea of using a structure on the latent prior of a VAE to learn a clustering of the data is not new ,",
    "NOVELTY"
  ],
  [
    "but the authors propose here an interesting approach to it , with a clearly described algorithm",
    "NOVELTY"
  ],
  [
    "While the technical contribution is not necessarily huge , the conceptual contribution of the paper would definitely make it a valuable addition to the existing literature on the topic .",
    "NOVELTY"
  ],
  [
    "The overall notion of learning a Hamiltonian network directly is a great one",
    "NOVELTY"
  ],
  [
    "Theoretical and technical novelty is rather minimal .",
    "NOVELTY"
  ],
  [
    "The paper presents some interesting contributions .",
    "NOVELTY"
  ],
  [
    "However , the technical contribution is rather incremental .",
    "NOVELTY"
  ],
  [
    "This seems to be the first work ( afaik ) to tackle this problem of automatically learning the order of composition the given domain specific transformations . The approach proposed is also natural and makes sense . So there is novelty in this aspect .",
    "NOVELTY"
  ],
  [
    "The contributions of this paper seem to me to be significant and surprising .",
    "NOVELTY"
  ],
  [
    "The novelty seems a bit limited",
    "NOVELTY"
  ],
  [
    "The paper proposes a new loss for training deep latent variable models .",
    "NOVELTY"
  ],
  [
    "I think the technical contributions of this paper is not significant enough for the publication .",
    "NOVELTY"
  ],
  [
    "However , the work is only incremental and does not propose a new perspective to robust RL .",
    "NOVELTY"
  ],
  [
    "The idea of using the methods from natural language processing to graph mining is quite interesting .",
    "NOVELTY"
  ],
  [
    "my main issue is with both the originality and significance of this work",
    "NOVELTY"
  ],
  [
    "Overall , it is novel and well written .",
    "NOVELTY"
  ],
  [
    "The idea of sweeping temperature during beam search decoding is not new in the NLP community , which limits the novelty of this paper . What \u2019 s more , some parts of the experiment results is also somehow not new",
    "NOVELTY"
  ],
  [
    "The method is both novel and interesting .",
    "NOVELTY"
  ],
  [
    "and presents an interesting take on solving this problem .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting and believe that it is a good contribution to the community detection literature .",
    "NOVELTY"
  ],
  [
    "The results are new",
    "NOVELTY"
  ],
  [
    ", and the analysis in this setting seems nontrivial .",
    "NOVELTY"
  ],
  [
    "Nevertheless , I find studying this approach to be one of the most significant contributions of the paper .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel neural network compression technique .",
    "NOVELTY"
  ],
  [
    "although the technical novelty seems limited",
    "NOVELTY"
  ],
  [
    "Unsupervised feature learning is an interesting area in computer vision and ML and this paper tries to tackle this problem for objects seen from different viewpoints",
    "NOVELTY"
  ],
  [
    "-Not enough technical novelty compared to current unsupervised feature learning approaches .",
    "NOVELTY"
  ],
  [
    "The view of putting existing multi-task learning algorithms in a read-write framework is quite intriguing and inspiring .",
    "NOVELTY"
  ],
  [
    "Nevertheless the paper is a little lacking of novelty in the sense that it brings together many existing ideas and provides an analysis of the effect of bringing them together but none of the theory significantly improves over the existing theory .",
    "NOVELTY"
  ],
  [
    "The approach and losses proposed in Section 2 have also not been proposed before , and given that an external language model is available , are very natural choices .",
    "NOVELTY"
  ],
  [
    "Originality As the proposed methods is an extension of a previous method it is , by nature , somewhat incremental .",
    "NOVELTY"
  ],
  [
    "However , the proposed new , decoupled basis and the following derivations of natural parameters and natural gradient descent update rules makes for a solid and novel work .",
    "NOVELTY"
  ],
  [
    "While the idea is novel and I do agree that I have not seen other works along these lines",
    "NOVELTY"
  ],
  [
    "The problem tackled is in itself original",
    "NOVELTY"
  ],
  [
    "research , combining the best of semantic segmentation and zero-shot learning",
    "NOVELTY"
  ],
  [
    "The supervised facility learning approach described in this paper appears to be novel ,",
    "NOVELTY"
  ],
  [
    "The idea is interesting and new .",
    "NOVELTY"
  ],
  [
    "The framework appears to be closely related to the CNMF method , but with a robust loss function . I 'm not confident in assessing the novelty or validity of the statistical framework",
    "NOVELTY"
  ],
  [
    "The idea of using distribution of small patches to guide the training of kernel estimator is interesting .",
    "NOVELTY"
  ],
  [
    "In this sense , the paper is a bit incremental .",
    "NOVELTY"
  ],
  [
    "One novel idea behind the proof is to make use of the variance of the optimal value function under the next state distribution , which effectively helps to improve over the previous analysis .",
    "NOVELTY"
  ],
  [
    "To summarize , I liked the main idea behind the paper .",
    "NOVELTY"
  ],
  [
    "So , from a scientific point of view my feeling is that the significance of this study for the NeurIPS audience might be low .",
    "NOVELTY"
  ],
  [
    "Novel addressing scheme as an extension to NTM .",
    "NOVELTY"
  ],
  [
    "Some interesting theory about the novel addressing scheme based on Lie groups .",
    "NOVELTY"
  ],
  [
    "The pruning approach is too simplistic .",
    "NOVELTY"
  ],
  [
    "Lack of novel insights .",
    "NOVELTY"
  ],
  [
    "The results that this paper get to",
    "NOVELTY"
  ],
  [
    ", are not necessarily new knowledge to the community . In terms of the result analysis , mostly simple correlation analysis was used which presented no novelty nor insights .",
    "NOVELTY"
  ],
  [
    "This paper alone does not seem to have enough novel ML contributions for acceptance .",
    "NOVELTY"
  ],
  [
    "The work is novel and the algorithm proposed for empirical minimization is novel .",
    "NOVELTY"
  ],
  [
    "2 .Theorem 3.1 is interesting in itself , because it applies to vectors which are not in the range of the generative",
    "NOVELTY"
  ],
  [
    "The conditions proposed for Theorem 3.3 are novel and could be used for future results",
    "NOVELTY"
  ],
  [
    "The novelty of the method is relatively minor",
    "NOVELTY"
  ],
  [
    "The approach is very original and well illustrated and I think that this approach has the potential to become a standard practice in Bayesian optimization alternatively to current approaches that are not even well formalized",
    "NOVELTY"
  ],
  [
    "The method to reparametrize the acquisition is know but its application to this domain is new",
    "NOVELTY"
  ],
  [
    "I would say that the paper does progress towards this goal but does n't quite reach it .",
    "NOVELTY"
  ],
  [
    "This work effectively narrows down the gap of achievable regret in online convex optimization problem under dynamic environment upto a $ O ( sqrt loglog ( T ) ) $ factor in terms of path length $ P_T $ . This improves the gap by $ sqrt P_T $ .",
    "NOVELTY"
  ],
  [
    "Novelty ] I feel this is just a natural extension of adversarial training .",
    "NOVELTY"
  ],
  [
    "I find the idea of combining variance reduction with coordinate descent very interesting .",
    "NOVELTY"
  ],
  [
    "Given that , the novelty of the paper is fairly incremental as it uses NerveNet to evaluate fitness and ES for the main design search .",
    "NOVELTY"
  ],
  [
    "The idea proposed in the article is very interesting .",
    "NOVELTY"
  ],
  [
    "and proposes a novel approach . The local visualization idea is interesting .",
    "NOVELTY"
  ],
  [
    "The novely of this work is not enough as R4 pointed out",
    "NOVELTY"
  ],
  [
    "While I find the overall approach of the paper interesting",
    "NOVELTY"
  ],
  [
    "given previous literature , I do not find the presented results novel nor fundamentally very interesting",
    "NOVELTY"
  ],
  [
    "Originality Although other papers might have noted undesirability of randomness , it seems to be the first paper to formulate the question by providing a metric as to how close a deterministic classifier is to a stochastic classifier .",
    "NOVELTY"
  ],
  [
    "The idea of doing dynamic pruning of neural networks by learning the decision to prune using RL is fairly novel .",
    "NOVELTY"
  ],
  [
    "However , in my eyes , it 's almost like an extension of VaDE which combines VIB and GMM too .",
    "NOVELTY"
  ],
  [
    "All of those make sense but may not contribute much to the research field .",
    "NOVELTY"
  ],
  [
    "The main strength of the paper is the originality of use of RNN for this task",
    "NOVELTY"
  ],
  [
    "Overall , this is an excellent paper with a novel method and",
    "NOVELTY"
  ],
  [
    "The approach of the paper is a sounding one .",
    "NOVELTY"
  ],
  [
    "the architecture and approach is far from novel",
    "NOVELTY"
  ],
  [
    "Of course , using explicit contextual information is not a new idea",
    "NOVELTY"
  ],
  [
    "but the specific method used here is original ,",
    "NOVELTY"
  ],
  [
    "I believe this paper offers little novelty",
    "NOVELTY"
  ],
  [
    "The paper introduces a nice general framework for several of existing known results for several bandit problems such as linear , lipschitz , unimodal , combinatorial , dueling bandits .",
    "NOVELTY"
  ],
  [
    "The method presented is novel",
    "NOVELTY"
  ],
  [
    "Overall , this paper gives a novel option learning framework that results in some improvement in multi-task learning .",
    "NOVELTY"
  ],
  [
    "the main contribution , metric-softmax loss , is not novel",
    "NOVELTY"
  ],
  [
    "the metric-softmax is actually not novel and can be found in several other contributions from last year",
    "NOVELTY"
  ],
  [
    "I found the paper to be a nice theoretical discussion of generalized sorting , quantiles , and CDFs .",
    "NOVELTY"
  ],
  [
    "I think the basic idea of generalizing sorting is quite fundamental and interesting to consider , so I quite liked this part .",
    "NOVELTY"
  ],
  [
    "The applications did not seem overly original .",
    "NOVELTY"
  ],
  [
    "While the proposed algorithm is interesting from a RL perspective and",
    "NOVELTY"
  ],
  [
    "The model is novel to my knowledge , and uses GANs in an intriguing way .",
    "NOVELTY"
  ],
  [
    "I think the paper could be improved by including more tests of generalization to novel classes",
    "NOVELTY"
  ],
  [
    "Limited contributions in terms of novelty .",
    "NOVELTY"
  ],
  [
    "The advantages of this work over existing work are that it does not require ( i ) causal graphs as input , ( ii ) interventions to be perfect and ( iii ) targets of interventions to be known .",
    "NOVELTY"
  ],
  [
    "I do not think the approach is sufficiently novel .",
    "NOVELTY"
  ],
  [
    "two main issues are ( a ) lack of novelty (",
    "NOVELTY"
  ],
  [
    "The approach is not very novel .",
    "NOVELTY"
  ],
  [
    "to facilitate transfer has been done before",
    "NOVELTY"
  ],
  [
    "Since the novelty is limited and",
    "NOVELTY"
  ],
  [
    "The proposed technique seems to be very similar to SVD of learned representations .",
    "NOVELTY"
  ],
  [
    "Novelty is not clear .",
    "NOVELTY"
  ],
  [
    "I am not an expert in this area , but as far as I am concerned the contributions are sufficient to accept it .",
    "NOVELTY"
  ],
  [
    "And , with this assumtion I 'm not sure if the proposed solution is solving difficult enough problem with novel enough idea .",
    "NOVELTY"
  ],
  [
    "Even without the CycleGAN , the use of CQT- > WaveNet for time stretching and pitch shifting of a single piece is an interesting and valuable contribution .",
    "NOVELTY"
  ],
  [
    ", the idea in this paper is interesting",
    "NOVELTY"
  ],
  [
    "As such , the originality and significance of the work is high .",
    "NOVELTY"
  ],
  [
    "Although this measure may not be available in practice , the theoretical contribution is more than what I expected before .",
    "NOVELTY"
  ],
  [
    "The proposed method in Section 4.2 appears to be a straightforward modification to MCA for NN",
    "NOVELTY"
  ],
  [
    "Bad === \u00e2\u0080\u0093\u00c2 Incremental , with no real conceptual contributions \u00e2\u0080\u0093\u00c2 Missing related work",
    "NOVELTY"
  ],
  [
    "The proof techniques are claimed to be novel -- that 's fine",
    "NOVELTY"
  ],
  [
    "so it is not clear that this really is particularly new",
    "NOVELTY"
  ],
  [
    "There are no significant new contributions other than the application to this very narrow field .",
    "NOVELTY"
  ],
  [
    "I find the technical novelty of the paper is somewhat limited , as the proposed method consists of a mostly straightforward combination of existing methods .",
    "NOVELTY"
  ],
  [
    "although I find the proposed study very interesting and enlightening",
    "NOVELTY"
  ],
  [
    "The proposed Saccader model is original",
    "NOVELTY"
  ],
  [
    "However , it is not clear from the paper what are the main technical difference ( s ) between Saccader and its main competitor DRAM .",
    "NOVELTY"
  ],
  [
    "interesting ideas",
    "NOVELTY"
  ],
  [
    "It 's a new model and I 'm not aware of a similar model .",
    "NOVELTY"
  ],
  [
    "Conclusion This paper brings in an interesting idea",
    "NOVELTY"
  ],
  [
    "Although the idea of adaptive computation is not novel",
    "NOVELTY"
  ],
  [
    "and has been explored , their application to the domain adaptation problem is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "There is very little methodological novelty and the key contribution seems to be the application-specific formulation of the generative process , which I believe might be of limited interest to the ICLR community .",
    "NOVELTY"
  ],
  [
    "however the results present in the section 3 are trivial and does not provide any new insights on understanding GAN .",
    "NOVELTY"
  ],
  [
    "The extension of [ 1 ] to the adaptive case is natural and interesting .",
    "NOVELTY"
  ],
  [
    "Also , the result is , to the best of my knowledge , quite novel .",
    "NOVELTY"
  ],
  [
    "The proposed approach of minimizing the gof statistic between generated data and an energy distribution seems novel .",
    "NOVELTY"
  ],
  [
    "The model is not novel .",
    "NOVELTY"
  ],
  [
    "Overall , the paper has some incremental improvements on the existing methods that dealing with the nonuniform time series data .",
    "NOVELTY"
  ],
  [
    "The paper lacks novelty , just reports some results without proper analysis or insights .",
    "NOVELTY"
  ],
  [
    "The proposed framework is fairly novel and provides an interesting perspective on learning data manipulation .",
    "NOVELTY"
  ],
  [
    "Overall , the paper proposes a novel and elegant approach to build policy networks and validates it experimentaly .",
    "NOVELTY"
  ],
  [
    "The paper also proposed a novel multiagent natural policy gradient algorithm that addresses the high variance issue .",
    "NOVELTY"
  ],
  [
    "The results are new and apply to a couple very well known methods .",
    "NOVELTY"
  ],
  [
    "although I find the novelty a bit limited",
    "NOVELTY"
  ],
  [
    "The new contribution of the paper is limited .",
    "NOVELTY"
  ],
  [
    "plenty of interesting insights , a novel algorithm",
    "NOVELTY"
  ],
  [
    "2 .I think Section 3 and Theorem 1 are interesting and insightful .",
    "NOVELTY"
  ],
  [
    "The analysis and insight provided in section 4 is interesting and insightful .",
    "NOVELTY"
  ],
  [
    "On the bright side , I like the idea of relaxing the ( sometimes strict ) assumptions underlying topic models such as LDA .",
    "NOVELTY"
  ],
  [
    "Although not significantly novel",
    "NOVELTY"
  ],
  [
    "2 .The paper has reasonable novelty that proposes a novel approach for choosing network input and volumetric pyramid for pooling .",
    "NOVELTY"
  ],
  [
    "The architecture has already been proposed in another paper .",
    "NOVELTY"
  ],
  [
    "the proposed method lacks novelty",
    "NOVELTY"
  ],
  [
    "DPP based Monte Carlo algorithms are certainly new and might represent a major improvement in this domain",
    "NOVELTY"
  ],
  [
    "The idea of building 3D adversarial objects is novel so the study is interesting .",
    "NOVELTY"
  ],
  [
    "the main originality of the paper is both in how the intentions are discovered",
    "NOVELTY"
  ],
  [
    "Novel idea that makes sense for learning a more robust representation for predicting the future and prevent only local temporal correlations learned .",
    "NOVELTY"
  ],
  [
    "However , the paper presents a novel efficient way to compute the convolutional kernel , which I",
    "NOVELTY"
  ],
  [
    "To begin with , I am not entirely sure how this differs from the `` REINFORCEMENT LEARNING WITH UNSUPERVISED AUXILIARY TASKS `` paper .",
    "NOVELTY"
  ],
  [
    "interesting but somewhat incremental",
    "NOVELTY"
  ],
  [
    "It 's novel , interesting",
    "NOVELTY"
  ],
  [
    "I am still not convinced it will generalize and all other components of the paper are largely minor tweaks to existing work .",
    "NOVELTY"
  ],
  [
    "As far as I can tell , the use of a distillation error as an exploration reward is novel .",
    "NOVELTY"
  ],
  [
    "I liked the idea to use two value heads to evaluate intrinsic and extrinsic values with different discounts .",
    "NOVELTY"
  ],
  [
    "The theory for optimization of VIs with stochastic gradients ( though only in monotone setting ) was very interesting to me and contains some novel results",
    "NOVELTY"
  ],
  [
    "and the idea to be elegant",
    "NOVELTY"
  ],
  [
    "The major flaw of this paper is that its contribution is not really clear .",
    "NOVELTY"
  ],
  [
    "The idea of using pairwise comparison information to learn permutations is interesting .",
    "NOVELTY"
  ],
  [
    "I think the contributions in this paper is novel and significant .",
    "NOVELTY"
  ],
  [
    "They idea of using ConvNets for local output prediction is new .",
    "NOVELTY"
  ],
  [
    "The basic idea of making local prediction and harmonising local outputs to get a consistent global estimation is not new .",
    "NOVELTY"
  ],
  [
    ".Therefore , novelty , is quite limited , especially for NIPS standard .",
    "NOVELTY"
  ],
  [
    "The theoretical contributions are largely based on well-known ideas ( Sipser and Spielman , 1996 ) .",
    "NOVELTY"
  ],
  [
    "However , the adaptation of these ideas to Hopfield nets is interesting and original .",
    "NOVELTY"
  ],
  [
    "I personally find the idea exciting",
    "NOVELTY"
  ],
  [
    "interesting ideas",
    "NOVELTY"
  ],
  [
    "Strengths To some extent , I think the proposed method is novel",
    "NOVELTY"
  ],
  [
    "However , since Su et al. , 2018 , already presented similar findings , I do not see any major contribution in this paper .",
    "NOVELTY"
  ],
  [
    "However , it comes across as three papers stapled together , that were submitted to some journal and have now been put into ICLR format .",
    "NOVELTY"
  ],
  [
    "The idea is novel and seems to be relatively effective in practice although I do believe that it has a lot of moving parts and introduces a considerable amount of hyperameters ( which generally are problematic to tune in causal inference tasks ) .",
    "NOVELTY"
  ],
  [
    "The paper has some nice novel ideas for estimating parameters in models where the normalization constant may not be known .",
    "NOVELTY"
  ],
  [
    "Rating I find the paper and the advanced ideas of interest for the community and I consider they are novel .",
    "NOVELTY"
  ],
  [
    "The flexible masking technique that is advanced here is novel and experimentally seems effective .",
    "NOVELTY"
  ],
  [
    "The idea of using the backward pass necessary for training to also compute adversarial samples seems indeed novel .",
    "NOVELTY"
  ],
  [
    ": adding dropout and recurrent training do not seem particularly novel",
    "NOVELTY"
  ],
  [
    "Generally , if the main contribution is actually only the `` stochastic `` part and not improved performance , then just adding dropout does not seem like a particularly novel approach to me",
    "NOVELTY"
  ],
  [
    "field .",
    "NOVELTY"
  ],
  [
    "I found the paper provides a significant contribution to the literature on policy evaluation .",
    "NOVELTY"
  ],
  [
    "The idea of using discriminators for separating the labeled samples from unlabeled ones that most likely belong to extra classes is interesting . - A new generalization bound for MDL is introduced .",
    "NOVELTY"
  ],
  [
    "The paper does not seem to have enough original contribution .",
    "NOVELTY"
  ],
  [
    "The difference between this work and prior works is multi-concept ; while this is an important contribution , it is not a fundamental one .",
    "NOVELTY"
  ],
  [
    "2 .I like the theoretical contributions",
    "NOVELTY"
  ],
  [
    "As far as the reviewer is aware this work is novel \u2013",
    "NOVELTY"
  ],
  [
    "Good sound paper providing a novel basis for flexible maximum entropy models .",
    "NOVELTY"
  ],
  [
    "Refreshing .",
    "NOVELTY"
  ],
  [
    "I found the contribution of this paper insufficient to meet the standard of a NIPS paper .",
    "NOVELTY"
  ],
  [
    "Overall I think the idea is novel and interesting",
    "NOVELTY"
  ],
  [
    "The star-convexity assumption is very interesting which provides new insights about the landscape of the loss function and the trajectory of SGD .",
    "NOVELTY"
  ],
  [
    "Overall this paper makes several interesting contributions on a challenging problem",
    "NOVELTY"
  ],
  [
    "The theoretical analysis is claimed to be novel , and should have an impact for real world problems in the long run .",
    "NOVELTY"
  ],
  [
    "The proposed framework is original and interesting but it was recently introduced by authors of",
    "NOVELTY"
  ],
  [
    "so it is not a contribution of this paper . It 's an incremental work from ( 23 ) which provides enough improvement",
    "NOVELTY"
  ],
  [
    "I am not sure if this paper has any additional insights to warrant itself as a conference paper .",
    "NOVELTY"
  ],
  [
    "Overall the two main ideas in this paper -- A3C and curriculums -- are not really novel but the authors do make use of them in a real system",
    "NOVELTY"
  ],
  [
    "it does use existing SRL work but in a different context of NLP problems , this makes novelty a bit weak",
    "NOVELTY"
  ],
  [
    "However , the improvement over existing methods is marginal .",
    "NOVELTY"
  ],
  [
    "Weaknesses The idea seems to be known .",
    "NOVELTY"
  ],
  [
    "this paper raises an interesting point about missing data imputation via generative models",
    "NOVELTY"
  ],
  [
    "The main concern with this work is originality ; the paper declares introducing the targeted attack method while it was introduced in the previous literature",
    "NOVELTY"
  ],
  [
    "Given the originality concern , I am afraid that the current contributions of the paper , overall , are not enough for a venue like NeurIPS .",
    "NOVELTY"
  ],
  [
    "It appears that the basic model is not original",
    "NOVELTY"
  ],
  [
    "The proposed gradient penalty method that penalizes the unseen samples is novel and reasonable from the explanation",
    "NOVELTY"
  ],
  [
    "-- The idea behind the paper is novel : translating language modeling into a matrix factorization problem is new as far as I know .",
    "NOVELTY"
  ],
  [
    "the paper has very strong contributions and deserves acceptance at ICLR",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work that applies GAN to ITE estimation .",
    "NOVELTY"
  ],
  [
    "The authors provide a novel stochastic algorithm for Online AUC Maximization ( non-adversarial setting ) . The challenge this paper addresses is that AUC is defined over a pair of examples and past approaches have required use of buffers in the online setting . The authors ' main contribution is a new formulation of AUC maximization as a convex-concave saddle point problem . By using stochastic gradient descent/ascent , the authors achieve a per-iteration complexity to one example . Further , they go on to show that the error falls as O ( 1 / \\sqrt T ) for T iterations ( up to log factors ) . Experiments are performed to compare the proposed method against existing methods . The idea of formulating AUC Maximization as SPP is novel",
    "NOVELTY"
  ],
  [
    "The connection between binary stochastic activation and normalization seems novel",
    "NOVELTY"
  ],
  [
    "This paper 's view is novel and relatively solid .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this is the first paper that considers adversarial examples for generative models .",
    "NOVELTY"
  ],
  [
    "I did n't find the ideas of this paper very original .",
    "NOVELTY"
  ],
  [
    "but the novelty and the presentation of the paper is",
    "NOVELTY"
  ],
  [
    "Very neat and original approach .",
    "NOVELTY"
  ],
  [
    "paper",
    "NOVELTY"
  ],
  [
    "of spiking neural networks or for large and distributed architectures",
    "NOVELTY"
  ],
  [
    "data-deficient domains , the main contribution of this work , the ROCK architecture , comes across as a little incremental .",
    "NOVELTY"
  ],
  [
    "and the novelty is limited",
    "NOVELTY"
  ],
  [
    "In spite of some concern about novelty",
    "NOVELTY"
  ],
  [
    "Even though this idea in not new the authors propose a simple and robust approach for doing it by using the value function estimation network of A3C",
    "NOVELTY"
  ],
  [
    "The method is a combination of existing techniques",
    "NOVELTY"
  ],
  [
    "The paper is incremental to previous work .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- The idea of using the medians of means estimator to obtain stronger PAC guarantees for reinforcement learning algorithms seems very appealing to me",
    "NOVELTY"
  ],
  [
    "But comparing to [ 1 ] , this paper has limited contribution .",
    "NOVELTY"
  ],
  [
    "The paper , however , constructs the ELBO in such a way that distance it from many key ideas of the VAE .",
    "NOVELTY"
  ],
  [
    "the novel contributions of this paper are left unclear",
    "NOVELTY"
  ],
  [
    "Incorporating landmark/spatial information into autoencoders is not a new idea .",
    "NOVELTY"
  ],
  [
    "The paper includes a likelihood model which also throws away key ideas from VAE .",
    "NOVELTY"
  ],
  [
    "Cons 1 .The novelty is not good enough",
    "NOVELTY"
  ],
  [
    "The main idea of predicting weights over multiple experts is not novel",
    "NOVELTY"
  ],
  [
    "The redundancy claims do not provide any novel intuition ( and looks trivial )",
    "NOVELTY"
  ],
  [
    "I found the paper interesting .",
    "NOVELTY"
  ],
  [
    "In addition to these issues with the proposed benchmark , the baseline results don \u2019 t provide any new insights .",
    "NOVELTY"
  ],
  [
    "To me , this is a very interesting , solid contribution , clearly worth presenting at NIPS",
    "NOVELTY"
  ],
  [
    "I honestly think that on the conceptual side , this work does not make that many really interesting contributions .",
    "NOVELTY"
  ],
  [
    "The temporal regularized matrix factorization ( TRMF ) framework proposed by the paper sounds interesting .",
    "NOVELTY"
  ],
  [
    "Not a huge technical innovation , but a rather incremental modification based on existing techniques .",
    "NOVELTY"
  ],
  [
    "while the lower-bound is novel and technically interesting",
    "NOVELTY"
  ],
  [
    ", the algorithm and its analysis seem to be an incremental variation on a well-known technique",
    "NOVELTY"
  ],
  [
    "The components of the proposed model mainly include Hilbert curve theory and CNN which are existing technologies .",
    "NOVELTY"
  ],
  [
    "That being said , the model itself is not overly unique ( not the worst thing ) and the quantitative / qualitative results do n't really cement",
    "NOVELTY"
  ],
  [
    "I like the idea overall",
    "NOVELTY"
  ],
  [
    "I want to like the paper and I think the authors approach is a potentially very good one",
    "NOVELTY"
  ],
  [
    "The paper is mildly original",
    "NOVELTY"
  ],
  [
    "and the paper is theoretically strong , novel in its approach and touches on all the important points .",
    "NOVELTY"
  ],
  [
    "I do n't understand how the definition of the problem in Section 3 differs from standard Bayesian optimization augmented with an additional input that describes the tasks .",
    "NOVELTY"
  ],
  [
    "Given that the difference in the fusion simulation experiments between the proposed method and standard Thompson sampling with randomly picked tasks seems to be relative small , I am afraid that the contributions of the paper are not sufficient for acceptance .",
    "NOVELTY"
  ],
  [
    "This is a paper with scattered potentially interesting ideas .",
    "NOVELTY"
  ],
  [
    "I agree with the authors regarding the originality and the soundness of assortment optimization as opposed to cascading/position-based model",
    "NOVELTY"
  ],
  [
    "To my knowledge , the method proposed in the paper in novel",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first paper to carefully address and propose an algorithm ( with guarantees ) for distributionally robust learning in the overparametrized regime , which is typical of modern large deep neural networks .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is novel work",
    "NOVELTY"
  ],
  [
    "The paper clearly delivers an improved automatic theorist system which learns and represents music concepts as well as thoroughly interprets and compares the learned rules with music theory",
    "NOVELTY"
  ],
  [
    "the paper investigate the topic in a novel way",
    "NOVELTY"
  ],
  [
    "Overall , the paper has some interesting ideas about proving unique recovery for a pretty difficult matrix problem",
    "NOVELTY"
  ],
  [
    "Novel problem + solution",
    "NOVELTY"
  ],
  [
    "given the limited novelty of the technical contribution",
    "NOVELTY"
  ],
  [
    "While the work achieves a bound that is superior than a previous work , I personally find the work less inspiring and somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The idea seems rather novel even if it 's an extension of graph-based regularization for Matrix Factorization .",
    "NOVELTY"
  ],
  [
    "Novel and state-of-the-art question answering approach .",
    "NOVELTY"
  ],
  [
    "This is a novel combination of existing techniques that appears well-formulated with intriguing experimental results .",
    "NOVELTY"
  ],
  [
    "I think overall it is a good idea .",
    "NOVELTY"
  ],
  [
    "I think the idea of the paper is interesting and I 'm willing to increase",
    "NOVELTY"
  ],
  [
    "The methods are technically similar to the \u201c exemplar network \u201d",
    "NOVELTY"
  ],
  [
    ", a new implementation of CPC with dramatically-improved ability is presented in this paper .",
    "NOVELTY"
  ],
  [
    "It is a cool idea and I enjoyed the paper .",
    "NOVELTY"
  ],
  [
    "The paper present a novel family of relational machine learning models .",
    "NOVELTY"
  ],
  [
    "a weighting factor in front of likelihood is not new",
    "NOVELTY"
  ],
  [
    "In my opinion the proposed algorithm is original and elegant , and --",
    "NOVELTY"
  ],
  [
    "Generating class-level interpretations is an interesting idea but its novelty is somewhat unclear",
    "NOVELTY"
  ],
  [
    "The use of tree models for model based optimization have been considered before ( e.g. , SMAC ) , although the MCTS acquisition with a single tree surrogate is novel as far as I am aware .",
    "NOVELTY"
  ],
  [
    "The idea is itself new",
    "NOVELTY"
  ],
  [
    "The pro is that this paper proposes a novel way to create an ensemble by applying random linear transformations and rescaling to the input .",
    "NOVELTY"
  ],
  [
    "The idea of assigning different learning rates to different types of parameters is old .",
    "NOVELTY"
  ],
  [
    "I like the idea of learning an `` output stochastic `` model -- it is much simpler to train than an `` input stochastic `` model that is more standard in the literature",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "Although",
    "NOVELTY"
  ],
  [
    "the contribution is rather simple ( can be describe in less than a page ) , I can see myself using the SCE/ACE metrics in the near future .",
    "NOVELTY"
  ],
  [
    "Contributions relative to , e.g .Bell et al. , are minor .",
    "NOVELTY"
  ],
  [
    "I actually do like the idea and am also impressed that this model can work well .",
    "NOVELTY"
  ],
  [
    "However , the novelty is limited and the developed algorithm is not yet scalable to genome-wide analysis .",
    "NOVELTY"
  ],
  [
    "but appealing method",
    "NOVELTY"
  ],
  [
    "by working on the topic of noisy input data at all , they are guaranteed novelty",
    "NOVELTY"
  ],
  [
    "Section 7.2 on the richness of natural noise is extremely interesting",
    "NOVELTY"
  ],
  [
    "I find the idea of using a surrogate objective instead of the expected reward very interesting and novel .",
    "NOVELTY"
  ],
  [
    "but its underlying idea is not novel",
    "NOVELTY"
  ],
  [
    "the insight obtained in this paper is a bit weak .",
    "NOVELTY"
  ],
  [
    "Pros The paper delivers some interesting theoretical findings about the embeddings learned in hyperbolic space",
    "NOVELTY"
  ],
  [
    "Learning graph embeddings have already been explored in",
    "NOVELTY"
  ],
  [
    "These changes provide significant improvements on the results but still the novelty of the approach is in that sense limited compared to [ 1 ] .",
    "NOVELTY"
  ],
  [
    "to a slimmable",
    "NOVELTY"
  ],
  [
    "The proposed method is incremental and improvements are marginal .",
    "NOVELTY"
  ],
  [
    "I think the idea looks novel",
    "NOVELTY"
  ],
  [
    "and but the technical contribution seems incremental",
    "NOVELTY"
  ],
  [
    "Nice overview of adversarial techniques in natural language classification",
    "NOVELTY"
  ],
  [
    "The idea of using a diverse summary to do robust policy optimization is interesting .",
    "NOVELTY"
  ],
  [
    "From a machine learning perspective , I find the ideas presented in this paper new , interesting and thought-provoking .",
    "NOVELTY"
  ],
  [
    "My score does not change since the proposed method does not seem to improve much compared to a simple weight decay ( baseline + l2 regularization ) .",
    "NOVELTY"
  ],
  [
    "there are some nicely presented ideas",
    "NOVELTY"
  ],
  [
    "While the separation into private and shared subspaces has been reported before , I am convinced by the originality of the approach , which combines this separation with the gradient reversal in a way , which makes sense .",
    "NOVELTY"
  ],
  [
    "One could eventually object that adversarial domain adaptation is not new , and neither are projections into shared and private spaces and orthogonality constraints",
    "NOVELTY"
  ],
  [
    "I still think that the whole package is sufficiently novel even for a high level conference as NIPS .",
    "NOVELTY"
  ],
  [
    "With regards to multimodal learning , this paper offers incremental advancements since it primarily uses a novel combination of input modalities",
    "NOVELTY"
  ],
  [
    "I think these are not major issues and the paper make a good contribution towards scene generation",
    "NOVELTY"
  ],
  [
    "I have really enjoyed the paper and believe it is an amazing one .",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed approach",
    "NOVELTY"
  ],
  [
    "Overall , I believe this is a clear and significant contribution with respect to the existing literature .",
    "NOVELTY"
  ],
  [
    "and innovative",
    "NOVELTY"
  ],
  [
    "Certainly , there are some interesting ideas in this paper .",
    "NOVELTY"
  ],
  [
    "Overall , I thus think the paper makes a good contribution .",
    "NOVELTY"
  ],
  [
    "The architecture of the proposed model looks natural and all components seem to have clear contribution to the model .",
    "NOVELTY"
  ],
  [
    "and the contribution is clear",
    "NOVELTY"
  ],
  [
    "The result is novel and can potentially have a high impact on non-convex optimization .",
    "NOVELTY"
  ],
  [
    "The primary criticism I have of this paper is that it is somewhat incremental in nature",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the presented theoretical convergence analysis of the f-divergence estimators is novel work .",
    "NOVELTY"
  ],
  [
    "The method provides another way that allows the model to learn an adaptive clustering of vocabulary .",
    "NOVELTY"
  ],
  [
    "The relationship between the joint M best diverse and parametric submodular minimization is an interesting theoretical contribution .",
    "NOVELTY"
  ],
  [
    "The methods used and results obtained are very interesting . To my knowledge they are novel and may prove useful in other work .",
    "NOVELTY"
  ],
  [
    "Although an interesting variant on a ( somewhat niche ) existing problem , I do feel that some aspects of this paper are a little dated -- claiming that the method is more useful for interpretability",
    "NOVELTY"
  ],
  [
    "and is a nice update on previous techniques for multi-aspect sentiment analysis .",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are rather on the thin side .",
    "NOVELTY"
  ],
  [
    "And the idea of formulating the problem is nice",
    "NOVELTY"
  ],
  [
    "Quality The algorithms and corresponding analysis are nontrivial but straightforward technically .",
    "NOVELTY"
  ],
  [
    "Originality Interlacing idea appears to be novel",
    "NOVELTY"
  ],
  [
    ", but the proof techniques build on previous work .",
    "NOVELTY"
  ],
  [
    "The idea of \u201c hard-coded \u201d constraints is interesting and constitutes an alternative approach to utilizing either quantized values in the VAE ( VQ-VAE ) or a constrained family of variational posteriors ( e.g. , Hyperspherical VAE ) .",
    "NOVELTY"
  ],
  [
    "1 .Authors propose a new loss function in Eqn.17 which simply combines lifted structure loss and binomial deviance loss .",
    "NOVELTY"
  ],
  [
    "as the algorithm is not new",
    "NOVELTY"
  ],
  [
    "The paper elegantly deals with these issues by introducing a new varying mixing time level analysis , without adding artificial assumptions .",
    "NOVELTY"
  ],
  [
    "I do like the general idea of the paper .",
    "NOVELTY"
  ],
  [
    "The algorithms introduced are pretty intuitive and the formulations and problem statement novel .",
    "NOVELTY"
  ],
  [
    "Novel/Sound future frame prediction formulation and training for modeling the stochasticity of future prediction .",
    "NOVELTY"
  ],
  [
    "Conclusion This paper proposes an interesting novel approach for predicting multiple futures in videos",
    "NOVELTY"
  ],
  [
    "point ( 2 ) is original and non-trivial . All in all , I think this paper makes a significant contribution that I believe will spark interesting follow-up work",
    "NOVELTY"
  ],
  [
    "This is an elegant , intuitive algorithm that to my knowledge has not appeared in previous literature . The technical contribution combines previous results in a straightforward but novel way .",
    "NOVELTY"
  ],
  [
    "Demonstrate a novel architecture TP-Transformer in details",
    "NOVELTY"
  ],
  [
    "This paper presents a novel model for unsupervised segmentation and classification of time series data . A recurrent hidden semi-markov model is proposed . This extends regular hidden semi-markov models to include a recurrent neural network ( RNN ) for observations . Each latent class has its own RNN for modeling observations for that category . Further , an efficient training procedure based on a variational approximation . Experiments demonstrate the effectiveness of the approach for modeling synthetic and real time series data . This is an interesting and novel paper .",
    "NOVELTY"
  ],
  [
    "Another major issue with this paper is that the theoretical analysis is not novel in terms of bringing new insights and results to the field given many other papers including global convergence of policy gradient",
    "NOVELTY"
  ],
  [
    "the actor-critic scheme in this paper is just a trivial modification of the nonlinear policy gradient method by calling existing result for TD learning in Cai et al . ( 2019 ) . Therefore , the contribution of this paper is not so clear given existing papers .",
    "NOVELTY"
  ],
  [
    "In my opinion this is an interesting theoretical contribution to RL",
    "NOVELTY"
  ],
  [
    "The originality is not high as the application of neural networks for graph classification has already been studied elsewhere and the proposed method is a direct combination of three existing methods , community detection , graph kernels , and CNNs .",
    "NOVELTY"
  ],
  [
    "the paper proposes a novel method which",
    "NOVELTY"
  ],
  [
    "The problem formulation is interesting .",
    "NOVELTY"
  ],
  [
    "While I 'm still not super convinced of its potential for application , I find the idea original and worth discussing at the conference .",
    "NOVELTY"
  ],
  [
    "Pretty original problem formulation",
    "NOVELTY"
  ],
  [
    "it seems that this work is incremental to [ 1 ] , which limits the originality and contributions .",
    "NOVELTY"
  ],
  [
    "I like this idea of structuring the computation based on the task as this adds priors which make the learning problem more tractable .",
    "NOVELTY"
  ],
  [
    "Nonetheless , the ideas presented are novel and the paper",
    "NOVELTY"
  ],
  [
    "The co-learning strategy idea is interesting",
    "NOVELTY"
  ],
  [
    ", the novelty contribution of the paper is marginally incremental as the model structure is largely unchanged from BERT . The other techniques applied also are somewhat trivial .",
    "NOVELTY"
  ],
  [
    "It proposes an interesting novel approach to pooling that leads favorable gains in performance .",
    "NOVELTY"
  ],
  [
    "I think connecting it to probabilistic models is not trivial and can be regarded as a satisfactory technical contribution",
    "NOVELTY"
  ],
  [
    ", with no major technical contribution , or novelty",
    "NOVELTY"
  ],
  [
    "Principled approach that marries the best aspects of deep learning with classic principles from multi-view geometry .",
    "NOVELTY"
  ],
  [
    "This paper presents a well-engineered and non-trivial system that leverages principles from different fields in a very reasonable way",
    "NOVELTY"
  ],
  [
    "The model seems to be new",
    "NOVELTY"
  ],
  [
    "The formulation proposed in the paper",
    "NOVELTY"
  ],
  [
    "is not new and consists in solving the optimal entropy-transport problem",
    "NOVELTY"
  ],
  [
    "The idea of explicitly modeling the relational structure via GCNs is interesting .",
    "NOVELTY"
  ],
  [
    "To this end I believe that the Online Tensor Power Method ( Algorithm 2 ) is the most important contribution of the paper .",
    "NOVELTY"
  ],
  [
    "My main criticism of the paper as a whole is that many of the results on their own feel somewhat incremental ,",
    "NOVELTY"
  ],
  [
    "the paper is similar to previously published works and lacks methodological novelty",
    "NOVELTY"
  ],
  [
    "Lack of novelty .",
    "NOVELTY"
  ],
  [
    "observations are interesting",
    "NOVELTY"
  ],
  [
    "The proposed approach seems interesting .",
    "NOVELTY"
  ],
  [
    "I have concerns with the novelty of the proposed method because `` joint retraining `` and replay alignments are already employed in two papers referenced in each sections and application of the method in this problem seems",
    "NOVELTY"
  ],
  [
    "Other than that , the paper has limited technical innovations",
    "NOVELTY"
  ],
  [
    "`` To the best of our knowledge , this is the first algorithm for BoN that can simultaneously learn the network structures and parameters from training data . `` is over-claimed",
    "NOVELTY"
  ],
  [
    "Limited novelty of methods . Ideas similar to the model variants discussed in this work have been considered in other work ( Eg",
    "NOVELTY"
  ],
  [
    "the methods presented have limited novelty and impact",
    "NOVELTY"
  ],
  [
    "Unfortunately , the novelty of these generalization bounds are very limited as they are a direct application of known generalization bounds in the supervised settings . Therefore , the authors contributions are very limited here .",
    "NOVELTY"
  ],
  [
    "here the novelty and final result is very limited since the bounds achieved by a union bound arguments and does not really go beyond that",
    "NOVELTY"
  ],
  [
    "and I find it very interesting",
    "NOVELTY"
  ],
  [
    ".The algorithm proposed is a classical neural net without any insight",
    "NOVELTY"
  ],
  [
    "I do feel that",
    "NOVELTY"
  ],
  [
    "I would rate the ideas low on originality , as the idea of using Taylor expansion and Nystrom approximation has been extensively explored for online learning with kernels",
    "NOVELTY"
  ],
  [
    "Originality The idea of generating videos by predicting motion has been used previously .",
    "NOVELTY"
  ],
  [
    "However the exact implementation in this paper",
    "NOVELTY"
  ],
  [
    "is new . The proposed evaluation protocol is novel .",
    "NOVELTY"
  ],
  [
    "Technically , the paper is very similar to previous works by Gittens and Halko et al .The proofs are fairly simple",
    "NOVELTY"
  ],
  [
    "The new algorithm is a small modification of previous algorithms and uses the same sketch",
    "NOVELTY"
  ],
  [
    "However , I am a bit concerned that the method itself seems like a trivial extension of the prior work , and does not really provide much addition insight .",
    "NOVELTY"
  ],
  [
    "Despite the generalization , the design and analysis of the algorithm appears to be very similar to the paper by Chen , Wang , Yuan and Wang ( 2016 ) .",
    "NOVELTY"
  ],
  [
    "but the techniques behind appear similar to those in the existing literature .",
    "NOVELTY"
  ],
  [
    "The ideas in this paper are novel and interesting .",
    "NOVELTY"
  ],
  [
    "The paper has some interesting points and novelties",
    "NOVELTY"
  ],
  [
    "The exploration on the layer division is really insightful .",
    "NOVELTY"
  ],
  [
    "3 .The proposed MDM method seems to be incremental .",
    "NOVELTY"
  ],
  [
    "Interesting paper - the reduction of GLM to OLE is striking .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is very rich with ideas so I think it would be a great contribution to the conference .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel approach to interactive visual content retrieval .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is the first dialog-based interactive image retrieval system where the system and user communicate using natural language .",
    "NOVELTY"
  ],
  [
    "2 .The idea of using a user simulator for relative image captioning is interesting .",
    "NOVELTY"
  ],
  [
    "most of them are already known results , and hence provide little novel theoretical knowledge .",
    "NOVELTY"
  ],
  [
    "The paper presents a very interesting idea",
    "NOVELTY"
  ],
  [
    "and this appears to be one of the first successful attempts at this problem .",
    "NOVELTY"
  ],
  [
    "but because its lack of rigorous analysis and explanation for the observations , I personally think these observations alone are not novel enough to be an ICLR paper .",
    "NOVELTY"
  ],
  [
    "The paper gives off a feeling that this method is not novel .",
    "NOVELTY"
  ],
  [
    "The idea of solving classification problems as regression problem is not new .",
    "NOVELTY"
  ],
  [
    "However , to the best of my knowledge , the idea of representing the multi-class classification likelihood in terms of independent gamma distributions and then approximating each gamma distribution using a lognormal distribution is indeed original and novel .",
    "NOVELTY"
  ],
  [
    "Generally , I think the paper studies an interesting novel problem setting .",
    "NOVELTY"
  ],
  [
    "This Bayesian model is rather simple and intuitive .",
    "NOVELTY"
  ],
  [
    "In overall , I liked its novel motivation and simplicity of the method",
    "NOVELTY"
  ],
  [
    "I still think the paper is not novel enough so I 'm leaving the rating untouched .",
    "NOVELTY"
  ],
  [
    "The novelty of the approach is relatively low : it \u2019 s just a straightforward fusion of the existing techniques .",
    "NOVELTY"
  ],
  [
    "it seems that an important part of the work has already been done before",
    "NOVELTY"
  ],
  [
    "and that the differences from there are very ad-hoc and intuition for why they work is not present",
    "NOVELTY"
  ],
  [
    "The proposed methods are interesting",
    "NOVELTY"
  ],
  [
    "they have shown more classes of problems",
    "NOVELTY"
  ],
  [
    "The proposed method for choosing bandwidth seems novel and interesting .",
    "NOVELTY"
  ],
  [
    ", and has some interesting discussion/insight into attacking deep RL agents in continuous actions spaces .",
    "NOVELTY"
  ],
  [
    "The idea is not novel enough",
    "NOVELTY"
  ],
  [
    "The idea of adversarial attacks with spatial distortion is not the innovation of this paper and has been proposed and extensively studied by many previous papers . This paper does not have additional innovation and does not lead to additional insight that can warrant an acceptance at ICLR .",
    "NOVELTY"
  ],
  [
    "The conditions in Remark 3 are very interesting .",
    "NOVELTY"
  ],
  [
    "Overall I think there is limited novelty in the approach",
    "NOVELTY"
  ],
  [
    "This is a nice approach that brings continuous optimization ideas to a field that is often studied from a discrete viewpoint , which I think is timely and relevant .",
    "NOVELTY"
  ],
  [
    "I found the proposed approach interesting . It definitely feels that solves pathogenies observed in previous methodologies and adds only an incremental contribution .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , CVEs are novel and of wide applicability ;",
    "NOVELTY"
  ],
  [
    "The paper pursues interesting ideas",
    "NOVELTY"
  ],
  [
    "Regarding novelty : The general idea of Ego-CNN seems to be quite closely related to the model of Kipf and Welling [ 2 ] .",
    "NOVELTY"
  ],
  [
    "and the novelty of the contribution is remarkable .",
    "NOVELTY"
  ],
  [
    "Proposition 2 seems to be the main novel observation of this work . Although it is straightforward , it is nice to point out that the monotone treatment response assumption",
    "NOVELTY"
  ],
  [
    "allows for identification in this case",
    "NOVELTY"
  ],
  [
    "The insight seems to be present in previous work [ 32 ] , so extending it to give expressions for TPR/FPR is not particularly original though still useful .",
    "NOVELTY"
  ],
  [
    "The partial identification results are quite novel",
    "NOVELTY"
  ],
  [
    "Unfortunately , that in and of itself is not original .",
    "NOVELTY"
  ],
  [
    "The idea of quantizing a continuous distribution over activations using a multinomial is interesting .",
    "NOVELTY"
  ],
  [
    "Even though the authors seem propose a novel approach to knowledge extraction",
    "NOVELTY"
  ],
  [
    "The proposed method sounds interesting and promising",
    "NOVELTY"
  ],
  [
    "The contribution seems incremental , given that Tsang et al ( 2018 ) already explored explanations based on interactions .",
    "NOVELTY"
  ],
  [
    "I find the novelty aspect of it quite limited",
    "NOVELTY"
  ],
  [
    "Overall , I think that the model proposed in this work is barely novel and",
    "NOVELTY"
  ],
  [
    "and the unifying link to the dynamics of a natural system is insightful .",
    "NOVELTY"
  ],
  [
    "The methodological novelties seem more-or-less limited",
    "NOVELTY"
  ],
  [
    "The idea of planning using TDMs over a latent representation is novel , and a promising direction for goal-directed planning in high-dimensional observation spaces .",
    "NOVELTY"
  ],
  [
    "while the idea proposed is interesting",
    "NOVELTY"
  ],
  [
    "but it is still a novel , elegant piece of work",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , I agree with the authors when they claim to be the first to inspect the problem to give bounds under the setting they have considered .",
    "NOVELTY"
  ],
  [
    "but somehow incremental in nature as the improvement is limited to slightly changing the reward and transition representations .",
    "NOVELTY"
  ],
  [
    "I think the theory proposed in section 2 is quite interesting and a novel way of computing a Markov transition matrix given sampled transitions .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the motivation for such dual-pathway design is not new .",
    "NOVELTY"
  ],
  [
    "But the particular design of this paper , CM polling in particular , is definitely novel .",
    "NOVELTY"
  ],
  [
    "I still think that the paper presents an important enough contribution to warrant publications in",
    "NOVELTY"
  ],
  [
    "The methods seem interesting and novel",
    "NOVELTY"
  ],
  [
    "As far as I know , learning a divergence for VI using meta-learning is new .",
    "NOVELTY"
  ],
  [
    "However , the approach appears very similar to previous work , making it less relevant for the NIPS community .",
    "NOVELTY"
  ],
  [
    "A novel Bayesian variant of MAML is proposed , with a two-fold technical contribution",
    "NOVELTY"
  ],
  [
    "The benefit of increased stability by adding Jacobian norm regularization term to the discriminator 's loss is nice .",
    "NOVELTY"
  ],
  [
    "This paper explores an interesting new research area for learning theory . Based on traditional technique for sample complexity analysis , the results reveals new insights on the structure of auction class hierarchy .",
    "NOVELTY"
  ],
  [
    "Interesting and novel idea",
    "NOVELTY"
  ],
  [
    "Unclear what the advantages of the presented framework are The presented idea is clearly new and a deviation from standard GAN architectures",
    "NOVELTY"
  ],
  [
    "and the proposed method is quite novel for automated theorem proving .",
    "NOVELTY"
  ],
  [
    "This paper provides the best analysis of this method to date in the finite sample regime and thus is a nice contribution",
    "NOVELTY"
  ],
  [
    "The data is rather novel",
    "NOVELTY"
  ],
  [
    "The model architectures are not of theoretical novelty .",
    "NOVELTY"
  ],
  [
    "Yes , it is true that there are no enough studies that has studied this problem in a principled way .",
    "NOVELTY"
  ],
  [
    "There is not much novelty in this work .",
    "NOVELTY"
  ],
  [
    "This is already proposed . The rest of the paper is mere brute force .",
    "NOVELTY"
  ],
  [
    "I kinda like the idea of using chart , and the attention over chart cells .",
    "NOVELTY"
  ],
  [
    "My only concern about the novelty of the paper is that the idea of using CYK chart-based mechanism is already explored in Le and Zuidema ( 2015 ) .",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting and novel",
    "NOVELTY"
  ],
  [
    "This paper presents a novel , theoretically well-justified idea",
    "NOVELTY"
  ],
  [
    "Technical contribution of the paper is very limited .",
    "NOVELTY"
  ],
  [
    "The methods appear to be new",
    "NOVELTY"
  ],
  [
    ", but they are mostly a collection of pretrained components with minor novelty linking the visual and linguistic components .",
    "NOVELTY"
  ],
  [
    "The results are not particularly surprising , and they do not seem particularly revolutionary .",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper ,",
    "NOVELTY"
  ],
  [
    "While the geometric approach looks interesting",
    "NOVELTY"
  ],
  [
    "Using an internal model to correct the user 's actions is novel to my knowledge",
    "NOVELTY"
  ],
  [
    "in my opinion , the method itself is not the main contribution of the paper anyway .",
    "NOVELTY"
  ],
  [
    "While these aspects may be important in practice they are somewhat incremental",
    "NOVELTY"
  ],
  [
    "I like the main modeling idea ,",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel way to address the well studied system identification problem .",
    "NOVELTY"
  ],
  [
    "The connection between DAE , mean-shift and the distribution of natural data points apparently comes from prior work , though",
    "NOVELTY"
  ],
  [
    "is used in a novel way here",
    "NOVELTY"
  ],
  [
    "The author should provide more insight for this contribution .",
    "NOVELTY"
  ],
  [
    "I could not find any novelty in the approach .",
    "NOVELTY"
  ],
  [
    "and the proposed idea seems interesting .",
    "NOVELTY"
  ],
  [
    "The architecture of the action value estimator does not seem novel",
    "NOVELTY"
  ],
  [
    "but the synthetic experiments around which much of the paper is based may not be sufficiently novel and give little indication of broader implications .",
    "NOVELTY"
  ],
  [
    "This is a nice idea but",
    "NOVELTY"
  ],
  [
    "The idea itself is interesting .",
    "NOVELTY"
  ],
  [
    "The paper is both original and significant because at least to my knowledge",
    "NOVELTY"
  ],
  [
    "This paper could be accepted as it presents an interesting idea",
    "NOVELTY"
  ],
  [
    "I like the approach , however",
    "NOVELTY"
  ],
  [
    "the proposed approach seems like a relatively minor modification of SPAIR ( Crawford & Pineau )",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "While applying policy gradients to symbolic regression is a great idea",
    "NOVELTY"
  ],
  [
    "This paper considers a new problem which is to learn OT given `` subset correspondence `` information .",
    "NOVELTY"
  ],
  [
    "The idea of parameterizing the transport cost using a neural network is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "This paper seems to present a neat and sensible idea for learning OT with neural networks given subset correspondence information . The problem and method are new",
    "NOVELTY"
  ],
  [
    "I overall think that the ideas presented in this paper are useful and interesting",
    "NOVELTY"
  ],
  [
    "Overall I believe this is a paper that tackles an important topic area and provides a novel and persuasive potential solution to many of the issues it highlights .",
    "NOVELTY"
  ],
  [
    "The paper introduces a kernel variant for IV regression that combines 2SLS with RKHSs that is novel ,",
    "NOVELTY"
  ],
  [
    "I do n't see any contribution in this paper ,",
    "NOVELTY"
  ],
  [
    "However , there are novelty concerns with the proposed methods .",
    "NOVELTY"
  ],
  [
    "the novelty of the actual RL methods is not entirely clear .",
    "NOVELTY"
  ],
  [
    "A major concern with regard to novelty is that this greedy local search procedure is analogous to gradient descent",
    "NOVELTY"
  ],
  [
    "and the paper is fairly incremental in terms of technical novelty .",
    "NOVELTY"
  ],
  [
    "The authors show sample complexity results for FDR control and for pool-based active learning in terms of novel complexity measures",
    "NOVELTY"
  ],
  [
    "and the presents novel theoretical results and techniques",
    "NOVELTY"
  ],
  [
    "I think this is original and novel work .",
    "NOVELTY"
  ],
  [
    "The general concept is nice",
    "NOVELTY"
  ],
  [
    "and might have the potential to be pioneering .",
    "NOVELTY"
  ],
  [
    "The paper is densely packed with valuable novel analysis of a very popular algorithm : distributed SGD .",
    "NOVELTY"
  ],
  [
    "It is hard to see a lot of novelty in this paper .",
    "NOVELTY"
  ],
  [
    "Overall , this seems for the most part too close to off-the-shelf existing embedding to be acceptable .",
    "NOVELTY"
  ],
  [
    "I am not sure whether the paper adds any significant on top of what we know from Bartlett et al . , Elsayed et al .since",
    "NOVELTY"
  ],
  [
    "The only novelty here seems to be that the authors use the margin distribution at each layer",
    "NOVELTY"
  ],
  [
    "The contribution of the paper seems a bit small given the work of XGBoost and GreedyMiser .",
    "NOVELTY"
  ],
  [
    "Though I do n't believe the metrics are particularly novel , I believe this work would be useful to the broader community and was evaluated on a",
    "NOVELTY"
  ],
  [
    "though I 'm not sure I would call them novel",
    "NOVELTY"
  ],
  [
    "their approach is not novel",
    "NOVELTY"
  ],
  [
    "I generally think the community will like and use these ideas .",
    "NOVELTY"
  ],
  [
    "The method for estimating impact appears novel .",
    "NOVELTY"
  ],
  [
    "The method is novel :",
    "NOVELTY"
  ],
  [
    "The meta-sampler architecture is new but improved upon NAF so I consider the architectural novelty to be minor .",
    "NOVELTY"
  ],
  [
    "This appears to be an very interesting higher-order generalization of copulas -- representing a joint density of interest as a multivariate ( not coordinatwise ) transformation of a jointly Gaussian density .",
    "NOVELTY"
  ],
  [
    "I think this is a very exciting paper , providing a new ( at least for the machine learning community ) approach to deal with high-dimensional non-Gaussian undirected graphical models .",
    "NOVELTY"
  ],
  [
    "Also it appears that the authors refer to a nontrivial amount of existing work -- but this literature is new to me -- and as far as I know it has not been presented to the ML community -- appearing in physics and geoscience journals and the like",
    "NOVELTY"
  ],
  [
    "The main contribution from the paper seems to be two novel benchmark problems with characteristics that reflect natural environments and an exhaustive evaluation of the performance of standard algorithms on them .",
    "NOVELTY"
  ],
  [
    "the paper does not contain any methodological contributions",
    "NOVELTY"
  ],
  [
    "it is hard to assess the novelty of the work .",
    "NOVELTY"
  ],
  [
    "I think the task is original and important for computational chemistry .",
    "NOVELTY"
  ],
  [
    "Conceptually , the novelty of the proposed approach is limited .",
    "NOVELTY"
  ],
  [
    "this paper is not the first to achieve that",
    "NOVELTY"
  ],
  [
    "This contribution is quite orthogonal",
    "NOVELTY"
  ],
  [
    "and the idea of coupling the gradient descent and mirror descent is very interesting .",
    "NOVELTY"
  ],
  [
    "My main issue is that while the authors argue about novelty , the first application of CLT for sampling neuron pre-activations at neural networks with discrete r.v.s is performed at [ 1 ] .",
    "NOVELTY"
  ],
  [
    "Section 3.1. is not novel .",
    "NOVELTY"
  ],
  [
    "Nothing ground-breaking but definitely novel enough for acceptance .",
    "NOVELTY"
  ],
  [
    "I think it 's originality is at least decent .",
    "NOVELTY"
  ],
  [
    "The paper is n't technically especially novel but that does n't bother me at all",
    "NOVELTY"
  ],
  [
    "I like the idea of imposing a class-specific gated structure for disentangling the representation",
    "NOVELTY"
  ],
  [
    "the theoretical analysis seem fairly mechanical and without theoretical innovation .",
    "NOVELTY"
  ],
  [
    "the work presented falls short of",
    "NOVELTY"
  ],
  [
    "I personally like this manuscript a lot , considering the novelty and the thoroughness of the manuscript .",
    "NOVELTY"
  ],
  [
    "2 .The current theoretical contribution seems incrementally .",
    "NOVELTY"
  ],
  [
    "3 .The integrating of Adam and OMD in the experiments is very interesting .",
    "NOVELTY"
  ],
  [
    "The paper advances the state of the art in network compression .",
    "NOVELTY"
  ],
  [
    "The paper addresses a difficult problem in a better way and it advances the state of the art in demonstrable ways . It provides a unique conclusion and unique practical approach .",
    "NOVELTY"
  ],
  [
    "this is a nice idea",
    "NOVELTY"
  ],
  [
    "The paper explores a relatively new idea",
    "NOVELTY"
  ],
  [
    "While the idea of multifidelity has been explored in previous work the current work provides an important step forward in providing a formal regret and in particular derives a regret bound for the specific procedure",
    "NOVELTY"
  ],
  [
    "yet I find that it has a suitable mix of novel models , theoretical/numerical analysis and experimental results to make it of general interest to the NISP community .",
    "NOVELTY"
  ],
  [
    "The idea of introducing an additional kernel working on some augmented data in the form of the evaluation of an indicator function is a clever one that skirts the issue that certain contributions would otherwise be undefined . I believe such a kernel could be used in other applications and as such is , as far as I am aware , a novel and useful contribution .",
    "NOVELTY"
  ],
  [
    "Overall , I think the theoretical results are novel .",
    "NOVELTY"
  ],
  [
    "The novelty of the modifications to the algorithm may be minor ,",
    "NOVELTY"
  ],
  [
    "The paper is definitely very investing . The idea of reducing MLC to sequential prediction problem is a natural extension of chaining commonly used for solving MLC under 0/1 loss .",
    "NOVELTY"
  ],
  [
    "I suppose",
    "NOVELTY"
  ],
  [
    "that some similar ideas have been already considered",
    "NOVELTY"
  ],
  [
    "My main concern with the paper is that the contribution is unclear , as the authors failed from my point of view in establishing the novely w.r.t .the state of the art regarding uncertainty in neural networks .",
    "NOVELTY"
  ],
  [
    "To my knowledge the use of SBN for posterior distribution of trees inference is knew , and the results are certainly encouraging .",
    "NOVELTY"
  ],
  [
    "proposed a new Newton-based method using adaptive sample sizes , which is novel in the field of Newton-based algorithms",
    "NOVELTY"
  ],
  [
    "It presents several interesting findings",
    "NOVELTY"
  ],
  [
    "The technical contribution of the paper is minor : it is a simple modification to an existing methodology .",
    "NOVELTY"
  ],
  [
    "Simple but useful extension of the existing super-node idea",
    "NOVELTY"
  ],
  [
    "Recommendation This is a nice contribution of minor novelty",
    "NOVELTY"
  ],
  [
    "my major concern is the novelty of this paper or the contribution .",
    "NOVELTY"
  ],
  [
    "This paper lacks novelty .",
    "NOVELTY"
  ],
  [
    "and I found the discussion insightful .",
    "NOVELTY"
  ],
  [
    "The novelty may be a bit weak in this aspect .",
    "NOVELTY"
  ],
  [
    "Although the algorithms used to synthesize the metamers themselves are nothing new",
    "NOVELTY"
  ],
  [
    ", the work is a novel combination of previous approaches and techniques , and the analysis approach gives these methods a fresh perspective that leads to good insights .",
    "NOVELTY"
  ],
  [
    "2 .The contribution of the paper seems not significant , as the idea of utilizing anchors to reduce the number of parameters to be inferred has been widely studies in the related work",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting and novel .",
    "NOVELTY"
  ],
  [
    "the overall framework is still conditional GAN framework",
    "NOVELTY"
  ],
  [
    "The multiple -generators-discriminators structure has been used in many other works ( see the references ) . The global-local design is not new . Finally , compared with Reed et al . [ 2016 ] , the novelty is limit .",
    "NOVELTY"
  ],
  [
    "Thus , the theoretical contribution of this paper is limited .",
    "NOVELTY"
  ],
  [
    "The algorithm proposed in this paper is interesting .",
    "NOVELTY"
  ],
  [
    "The paper proposes a new theoretical upper-bound based on the prior works , the upper-bound and its derivation are interesting and heuristic to the domain adaptation research community .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is incremental as the theoretical results are extended from Cortes et al ( 2019 ) and Zhao et al",
    "NOVELTY"
  ],
  [
    "The universality for smooth and non-smooth problems , and ability to converge on stochastic problems are very appealing properties of the algorithm . Not having to tune the smoothness parameter seems especially attractive since it makes practical deployment of the algorithm much simpler . To the best of my knowledge , no other algorithm combines all of these properties in one package .",
    "NOVELTY"
  ],
  [
    "The main results seem original .",
    "NOVELTY"
  ],
  [
    "the idea of regularizing the optimization using the density of real trajectories used to train the dynamics model is not new",
    "NOVELTY"
  ],
  [
    "However I found the",
    "NOVELTY"
  ],
  [
    "the method of proof to be different from burer-monteiro",
    "NOVELTY"
  ],
  [
    "While the framework and the performance of the proposed method are interesting and promising",
    "NOVELTY"
  ],
  [
    "The variance bound for the gradient estimator is novel and understanding the technical condition would be helpful in analyzing the stochastic gradient descent method",
    "NOVELTY"
  ],
  [
    "Overall , the newly proposed method is a minor update , and novelty is limited .",
    "NOVELTY"
  ],
  [
    "It is not completely clear what this paper contributes over those other existing papers",
    "NOVELTY"
  ],
  [
    "Let me first comment that the approximate MPE method is NOT novel",
    "NOVELTY"
  ],
  [
    "claiming novelty of APME , or even renaming it as APME ,",
    "NOVELTY"
  ],
  [
    "The method appears new",
    "NOVELTY"
  ],
  [
    "It is a simple and creative",
    "NOVELTY"
  ],
  [
    "the paper does not produce any clear novel results .",
    "NOVELTY"
  ],
  [
    "This is a",
    "NOVELTY"
  ],
  [
    "There is basic novelty in applying the base model to a new task",
    "NOVELTY"
  ],
  [
    "The embedding-enhancing method has low originality but is effective on this particular combination of model architecture",
    "NOVELTY"
  ],
  [
    "and the contribution , while somewhat incremental , seems original to this reviewer .",
    "NOVELTY"
  ],
  [
    "the novelty of the approach is somewhat limited Justification for score",
    "NOVELTY"
  ],
  [
    "This is on the whole a great thing , but perhaps not especially surprising from an originality/novelty perspective .",
    "NOVELTY"
  ],
  [
    "This work is a novel extension of the preceding distortion-perception tradeoff in image restoration tasks .",
    "NOVELTY"
  ],
  [
    "Although the novelty of this paper is a little incremental",
    "NOVELTY"
  ],
  [
    ", it combined all the stuff in",
    "NOVELTY"
  ],
  [
    "Its contribution is definitely novel and provides new perspectives on PAC Bayesian bound analysis .",
    "NOVELTY"
  ],
  [
    "The paper lacks novelty .",
    "NOVELTY"
  ],
  [
    "I did not see that the contribution from the paper is sufficiently original .",
    "NOVELTY"
  ],
  [
    "This is a nice idea .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- Technical Quality -- -- -- -- -- The use of ResNet is commendable",
    "NOVELTY"
  ],
  [
    "Unfortunately the paper falls short in two main areas",
    "NOVELTY"
  ],
  [
    "novelty : the additions proposed are small modifications to existing algorithms and there are other methods of attention on graphs which have been discussed in the paper but not directly compared to",
    "NOVELTY"
  ],
  [
    "I find the contribution of this paper minimal .",
    "NOVELTY"
  ],
  [
    "Their 's nothing new about the flows used in this paper",
    "NOVELTY"
  ],
  [
    "The KL term ( Eq .3 ) gives interesting insights and the authors exploit the insights",
    "NOVELTY"
  ],
  [
    "As for the novelty , I still believe the proposed interpretation of the KL term in the ELBO is original and gives interesting insights to the online bayesian learning frameworks .",
    "NOVELTY"
  ],
  [
    "but the approach rather superficial",
    "NOVELTY"
  ],
  [
    "Applying vector-valued RKHSs to multiple outputs regression problem itself is not really that original ; however",
    "NOVELTY"
  ],
  [
    "Its originality lies in putting all the pieces together and giving a rigorous analysis of the resulting algorithm .",
    "NOVELTY"
  ],
  [
    "Strictly technically speaking the proofs use heavy machinery from known results in complexity theory but are non very technical themselves",
    "NOVELTY"
  ],
  [
    "The work proposes an interesting approach with a factorized policy to perform RL by performing iterative improvement over the current solution until convergence is",
    "NOVELTY"
  ],
  [
    "Using RL for combinatorial optimization is not new",
    "NOVELTY"
  ],
  [
    "loss functions for session-based recommendations",
    "NOVELTY"
  ],
  [
    "Based on the result of these analysis the authors propose two novel losses functions which add a weighting to existing ranking-based loss functions .",
    "NOVELTY"
  ],
  [
    ".Still , simply augmenting previous work with LSTM-based conditioning is not enough of a contribution to justify an entire paper .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- The paper is to the best of my knowledge , wholly original .",
    "NOVELTY"
  ],
  [
    "this is the first theoretical result ( to my knowledge ) that supports the idea of using adversarial training to find robust neural networks , amplifying its originality .",
    "NOVELTY"
  ],
  [
    "Is the teaching MDP formulation of Sec .3.2 a novel contribution",
    "NOVELTY"
  ],
  [
    "In my opinion both contributions suffer from some significant limitations .",
    "NOVELTY"
  ],
  [
    "I liked the",
    "NOVELTY"
  ],
  [
    "paper but I believe the contribution to be incremental in its current state .",
    "NOVELTY"
  ],
  [
    "The presentation suggests that somehow the proposed approach is novel in its end-to-end framework .",
    "NOVELTY"
  ],
  [
    "However , the central idea is very similar to Dawid-Skene ( 1979 ) , and its subsequent augmentations like the ones in Carpenter",
    "NOVELTY"
  ],
  [
    "that model both image difficulty and worker competence",
    "NOVELTY"
  ],
  [
    "I am not convinced that the contribution is substantial or the experiments very insightful .",
    "NOVELTY"
  ],
  [
    "While this appears to obtain interesting results in the reported experiments , I find this proposal very straightforward and poorly innovative , as it corresponds to a quiet classical neural network structure .",
    "NOVELTY"
  ],
  [
    "The overall idea is nevertheless interesting ( even if not completely new ) ,",
    "NOVELTY"
  ],
  [
    "The paper presents interesting ideas",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , they all need the information of the transition matrix , learning which could be challenging",
    "NOVELTY"
  ],
  [
    "The idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Despite the idea looks pretty simple and present some advantages",
    "NOVELTY"
  ],
  [
    ", especially because the idea is not so novel",
    "NOVELTY"
  ],
  [
    "The main potential issue with the paper is the degree of ( effective ) novelty .",
    "NOVELTY"
  ],
  [
    "the approach is interesting",
    "NOVELTY"
  ],
  [
    "on the other hand the article seems to me not mature enough and strong enough from the point of view of organization , contents and experimental results shown .",
    "NOVELTY"
  ],
  [
    "1.The proposed module and the message passing style computation is quite similar to other graph neural networks , so not sure this is very novel .",
    "NOVELTY"
  ],
  [
    "The idea of taking advantage of data in many languages is natural and powerful .",
    "NOVELTY"
  ],
  [
    "and the proposed ideas quite appealing",
    "NOVELTY"
  ],
  [
    "I found the approach to be novel and",
    "NOVELTY"
  ],
  [
    "I think the idea is nice and useful ( I 'm surprised people have n't thought of this before )",
    "NOVELTY"
  ],
  [
    "While I like the idea",
    "NOVELTY"
  ],
  [
    "Regarding the method itself , the contribution over prior work is unfortunately not entirely clear to me .",
    "NOVELTY"
  ],
  [
    "The idea of combining GAIL reward and extrinsic reward is not really new and quite straight forward so I would n't consider this as a contribution . Also , using state only demonstration in the framework of GAIL is not new as the authors also acknowledge in the paper",
    "NOVELTY"
  ],
  [
    "Although the idea of applying deep learning for temporal clustering is novel and interesting",
    "NOVELTY"
  ],
  [
    "This paper is very intriguing .",
    "NOVELTY"
  ],
  [
    "this innovative perspective to represent learning is good for us to understand the learning process",
    "NOVELTY"
  ],
  [
    "A novel way to evaluate the quality of heterogeneous data sources .",
    "NOVELTY"
  ],
  [
    "The paper presents interesting and novel observations .",
    "NOVELTY"
  ],
  [
    "I like the proposed architecture and I think the idea can be of interest for the community .",
    "NOVELTY"
  ],
  [
    "The paper is quite incremental , due to its similarities with Path-SGD .",
    "NOVELTY"
  ],
  [
    "Quite incremental ( close to Path-SGD / Weight Normalization ) , and missing actual comparison with Weight Normalization",
    "NOVELTY"
  ],
  [
    "All in all , I find that this work is a bit too incremental , missing some important comparisons with other techniques and its experimental setup could definitely",
    "NOVELTY"
  ],
  [
    ".2.1 .The way of solving both the learning from partial labels and the sampling strategies are not particularly insightful .",
    "NOVELTY"
  ],
  [
    "My concern is primarily on the novelty and originality of the idea , as it is mainly based on the work of Guo etal 2018",
    "NOVELTY"
  ],
  [
    "Each model component is not novel .",
    "NOVELTY"
  ],
  [
    "Although there is difference from ( Yu et al. , 2017 ) , the contribution of this paper is still incremental .",
    "NOVELTY"
  ],
  [
    "4 .This general idea is somewhat similar to a June 2018 Arxiv paper (",
    "NOVELTY"
  ],
  [
    "//arxiv.org/abs/1807.00053 but this is a novel contribution as it is uses the Brain-Score dataset",
    "NOVELTY"
  ],
  [
    "The paper presents a novel adversarial training setup , based on distance based loss of the feature embedding .",
    "NOVELTY"
  ],
  [
    "The distance based loss is novel , and significantly different from prior work",
    "NOVELTY"
  ],
  [
    "The experiments are somewhat rudimentary",
    "NOVELTY"
  ],
  [
    "The work seems significantly novel and can have quite a large impact since it generalizes and unifies several previous heuristic results",
    "NOVELTY"
  ],
  [
    "This is a very nice paper contributing to what I consider a relatively underexplored but potentially very promising research direction",
    "NOVELTY"
  ],
  [
    "but insightful experiments",
    "NOVELTY"
  ],
  [
    "Unfortunately",
    "NOVELTY"
  ],
  [
    "I have fundamental issues with novelty .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is relatively limited . The idea to use a high-to-low network to model distribution of real-world low resolution images has already been investigated in several works",
    "NOVELTY"
  ],
  [
    "Besides , the network structures are very similar to SRGAN and ESRGAN , which again shows little novelty .",
    "NOVELTY"
  ],
  [
    "In general , I am inclined to think that this paper has made an important contribution with very promising results but I still have doubts in the proposed solution technique",
    "NOVELTY"
  ],
  [
    "the paper might present some interesting and effective ideas",
    "NOVELTY"
  ],
  [
    "This paper presents a novel method for explaining black-box models .",
    "NOVELTY"
  ],
  [
    "In general , I think this paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "theoretical standpoint , it is an interesting general approach of exploiting sharpness .",
    "NOVELTY"
  ],
  [
    "the paper seems to contribute to the study of restarting mechanisms schemes only incrementally .",
    "NOVELTY"
  ],
  [
    "* proposes a novel architecture *",
    "NOVELTY"
  ],
  [
    "A possible downside is the relative lack of novelty , since the method seems like a reasonable extension of the existing work .",
    "NOVELTY"
  ],
  [
    "I find the proposed method interesting",
    "NOVELTY"
  ],
  [
    "Overall , I find the idea of the paper interesting , I am",
    "NOVELTY"
  ],
  [
    "I found this to be an interesting approach .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed decoder , leveraging a low-dimensional , task-independent moulatory signal shared across a population is novel . I find this idea intriguing",
    "NOVELTY"
  ],
  [
    "I find the ideas in the paper to be interesting",
    "NOVELTY"
  ],
  [
    "I think the idea is nice overall because it allows network designers to better understand",
    "NOVELTY"
  ],
  [
    "Unfortunately ,",
    "NOVELTY"
  ],
  [
    ", I do n't think we have enough novelty to justify accepting this work in the conference .",
    "NOVELTY"
  ],
  [
    "Originality Using low-rank representation is not something new and has already been explored in [ 1 ]",
    "NOVELTY"
  ],
  [
    "even though",
    "NOVELTY"
  ],
  [
    "the main idea is novel ( to the best of my knowledge )",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    ", introduces a novel combination of well-established architecture/agent building blocks and introduces a novel regularizer .",
    "NOVELTY"
  ],
  [
    "The novelty and significance of the contributions , however is limited , as many recent works have explored using graph-structured representations and attention in multi-agent domains",
    "NOVELTY"
  ],
  [
    "The combination of these blocks and the considered problem setting is novel , but",
    "NOVELTY"
  ],
  [
    "otherwise incremental",
    "NOVELTY"
  ],
  [
    "Novelty is incremental , but if the paper would otherwise be very well written",
    "NOVELTY"
  ],
  [
    "In this large collection this paper feels somewhat incremental for this conference .",
    "NOVELTY"
  ],
  [
    "the paper follows the idea of previous works , but uses Thompson sampling in a novel way ( to the best of my knowledge ) for efficient task selection in contextual BO .",
    "NOVELTY"
  ],
  [
    "This work is largely derivative of the Pixel RNN work , and without the conditional model there would not be sufficient novelty .",
    "NOVELTY"
  ],
  [
    "and interesting on an engineering point of view because it makes sense to use keypoints and bounding boxes as an intermediary step before generating the whole image",
    "NOVELTY"
  ],
  [
    "the novelty of the the work is interesting",
    "NOVELTY"
  ],
  [
    "but it might not be strong or generic enough for the broad audience at NIPS .",
    "NOVELTY"
  ],
  [
    "I like the idea of \u00e2\u0080\u009cwhat-where\u00e2\u0080\u009d network",
    "NOVELTY"
  ],
  [
    "I think the idea proposed here of using RBFI units is very interesting and intuitive .",
    "NOVELTY"
  ],
  [
    "3 .Even though the technique is novel , the contributions of this paper is not very significant .",
    "NOVELTY"
  ],
  [
    "It seems novel",
    "NOVELTY"
  ],
  [
    "Using RL in this specific application setting seems relatively new ( though also explored by RL-LS in https",
    "NOVELTY"
  ],
  [
    "the approach used does n't seem to be substantially different than anything else typically used for policy gradient RL .",
    "NOVELTY"
  ],
  [
    "There is not much of novelty in the algorithm and architecture .",
    "NOVELTY"
  ],
  [
    "I 'm leaning towards accepting as it seems to be an original concept and has fairly extensive empirical results that are somewhat promising . The idea of a sleep phase as an alternative to explicit adversarial or generalization training is interesting .",
    "NOVELTY"
  ],
  [
    "but overall I think this is an interesting paper with a reasonable contribution",
    "NOVELTY"
  ],
  [
    "An interesting aspect of the contribution is to revisit a",
    "NOVELTY"
  ],
  [
    "training classifiers",
    "NOVELTY"
  ],
  [
    "The proposed framework makes modification on the existing work , which is a good extension but the novelty is limited .",
    "NOVELTY"
  ],
  [
    "Merits The idea of using bootstrapping , as a replacement of methods like posterior sampling , is interesting and promising .",
    "NOVELTY"
  ],
  [
    "This is an interesting idea .",
    "NOVELTY"
  ],
  [
    "paper which proposes a novel and effective method for the task of visual dialog generation .",
    "NOVELTY"
  ],
  [
    "the work appears original and a useful extension to previous mean field approximations .",
    "NOVELTY"
  ],
  [
    "The simple combination of the results from two published articles is not that interesting",
    "NOVELTY"
  ],
  [
    "The design of the architecture is novel",
    "NOVELTY"
  ],
  [
    ", but it is also not groundbreaking .",
    "NOVELTY"
  ],
  [
    "and the contributions are clear",
    "NOVELTY"
  ],
  [
    "2 .To the best of my knowledge this paper is the first to consider deep semi-supervised regression .",
    "NOVELTY"
  ],
  [
    "There",
    "NOVELTY"
  ],
  [
    "but the alternating optimization approach in this paper appears to be new and significant to me . While the idea of the paper is exciting",
    "NOVELTY"
  ],
  [
    "The idea in this paper is relatively simple despite the many lines of equations",
    "NOVELTY"
  ],
  [
    "The idea is natural ,",
    "NOVELTY"
  ],
  [
    "though not novel .",
    "NOVELTY"
  ],
  [
    "Therefore the paper is quite thin in technical novelty .",
    "NOVELTY"
  ],
  [
    "I think the paper lacks both in terms of technical novelty as well as",
    "NOVELTY"
  ],
  [
    "however the novelty is low .",
    "NOVELTY"
  ],
  [
    "I think the idea of using MCMC methods to approximate D^2-sampling scheme is great .",
    "NOVELTY"
  ],
  [
    "But since this paper is not the first to propose this approach , and the theoretical analysis seems incremental to that of Banchem 16",
    "NOVELTY"
  ],
  [
    "In terms of highlighting their",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "This paper is interesting",
    "NOVELTY"
  ],
  [
    "this paper is interesting",
    "NOVELTY"
  ],
  [
    "The result is a simple and straightforward application of an existing technique - not greatly original .",
    "NOVELTY"
  ],
  [
    "General notes ============ The general idea of measuring the distribution divergence for a set of classes is interesting and seems to be novel .",
    "NOVELTY"
  ],
  [
    "Overall , I really like the main idea of the paper . The use of `` syntactic distances `` to parametrize the trees is clever",
    "NOVELTY"
  ],
  [
    "While the experimental results are interesting they are not striking especially when viewed in the context of the tremendous amount of work on auto-encoders",
    "NOVELTY"
  ],
  [
    "Training the classification-features along with reconstruction-features does not seem to give any significantly new insights .",
    "NOVELTY"
  ],
  [
    "I believe the main algorithmic contribution is nicely original",
    "NOVELTY"
  ],
  [
    "though the approach is probably not that surprising to experts in hindsight",
    "NOVELTY"
  ],
  [
    "The work is quite ( conceptually ) similar to `` Neural voice cloning with a few samples ``",
    "NOVELTY"
  ],
  [
    "While the manuscript gives",
    "NOVELTY"
  ],
  [
    "I found this paper to be interesting",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is pretty low .",
    "NOVELTY"
  ],
  [
    "My assessment stays the same since I still think that the technical contribution of this paper is quite limited .",
    "NOVELTY"
  ],
  [
    "This pape is a nice application of Gaussian process mechanism .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting",
    "NOVELTY"
  ],
  [
    "Unfortunately I can not see any novelty in the relationship the authors draw to LASSO style super-resolution and dictionary learning beyond what is already in the literature",
    "NOVELTY"
  ],
  [
    "Given that much of the main result seems to already be known , I feel that this work is not novel enough at this time .",
    "NOVELTY"
  ],
  [
    "The idea of using directed information for GAIL is novel and very interesting .",
    "NOVELTY"
  ],
  [
    "one could argue that the findings in the paper are not particularly novel .",
    "NOVELTY"
  ],
  [
    "Comparison to existing approaches I think the approach presented by the authors is interesting as it offers some improvements over past approaches .",
    "NOVELTY"
  ],
  [
    "The proposed deep learning architecture is novel for solving the matrix completion problem in recommender systems with the relationships between users and the relationships between items represented as two graphs .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the proposed combination is novel .",
    "NOVELTY"
  ],
  [
    "it can be seen as a small modification of previous methods resulting from the structure imposed in",
    "NOVELTY"
  ],
  [
    "This paper presents a novel algorithm for robust PCA that is interesting both in theory and in practice .",
    "NOVELTY"
  ],
  [
    "There is no prior work that attempts HER in visual domains without explicit goal conditioning",
    "NOVELTY"
  ],
  [
    "The designing and training on HALGAN seem rather standard and similar to InfoGAN .",
    "NOVELTY"
  ],
  [
    "The paper feels incremental as it combines existing techniques/ideas in a ( perhaps ) novel fashion",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "The contribution itself is slightly incremental , as several different parameterization of orthogonal or almost-orthogonal weight matrices for RNN have been introduced .",
    "NOVELTY"
  ],
  [
    "Technical novelty is somewhat limited 2",
    "NOVELTY"
  ],
  [
    "I find the work to be interesting",
    "NOVELTY"
  ],
  [
    "== From theoretical point of view , finding a proper generalization for the momentum term ( so as to be able to implement AGD ) which maintains the same convergence rate for any Riemannian space is novel and very interesting .",
    "NOVELTY"
  ],
  [
    "Strictly speaking , the proposed formulation is novel as far as I am aware .",
    "NOVELTY"
  ],
  [
    "but it 's all together neither here or there in terms of an overall contribution .",
    "NOVELTY"
  ],
  [
    "The contribution is incremental yet significant .",
    "NOVELTY"
  ],
  [
    "The methods utilized in this paper is different from other existing papers about SGD without-replacement sampling",
    "NOVELTY"
  ],
  [
    "gives a novel proofs and presents several interesting results",
    "NOVELTY"
  ],
  [
    "the approach in the paper is novel and one that I have n't seen before .",
    "NOVELTY"
  ],
  [
    "The problem studied is not new",
    "NOVELTY"
  ],
  [
    ", but to my knowledge the presented bounds are novel and the concepts of capacity and impact are new .",
    "NOVELTY"
  ],
  [
    "From a technical perspective , the contribution of the paper is rather incremental . The detection of adversarial examples by training a classifier on saliency maps has already been studied in prior work",
    "NOVELTY"
  ],
  [
    "the technical and conceptual contribution of this paper is insufficient for publication at ICLR",
    "NOVELTY"
  ],
  [
    "and proposes a novel biologically inspired model for spike localization .",
    "NOVELTY"
  ],
  [
    "and provides new paths for exploring the link between individual neurons and electrophysiological properties .",
    "NOVELTY"
  ],
  [
    "Overall , I believe the idea of the paper is novel and interesting",
    "NOVELTY"
  ],
  [
    "While the idea of defining fairness based on equal error treatment of groups is not new",
    "NOVELTY"
  ],
  [
    "I think the ideas here are quite nice and have a lot of promise .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , conducting human psychophysics and comparing their performance to computational models has not been done for the precise problem formulation examined by the authors",
    "NOVELTY"
  ],
  [
    "and the algorithm is intuitive to some extent",
    "NOVELTY"
  ],
  [
    "Originality* To my knowledge , the idea of designing deletion efficient machine learning algorithms is novel .",
    "NOVELTY"
  ],
  [
    "My main concerns are the",
    "NOVELTY"
  ],
  [
    "novelty of the work",
    "NOVELTY"
  ],
  [
    "I liked the idea of proposing a hypothesis testing approach for finding OOD samples generated from a model",
    "NOVELTY"
  ],
  [
    "However , this idea had already been proposed and explored in Choi .",
    "NOVELTY"
  ],
  [
    "The idea of delegating generation order to the latent variables seems interesting",
    "NOVELTY"
  ],
  [
    "it seems to me that the paper is limited both in theoretical novelty and practical usefulness of these results . Especially , I could not see any novel contribution for GAN literature or adversarial divergences .",
    "NOVELTY"
  ],
  [
    "Relevance The result itself does not feel very novel because variants of it were already available .",
    "NOVELTY"
  ],
  [
    "I could not even figure out if this was an original result or just stating some prior tensor-unfolding-based technique does not work",
    "NOVELTY"
  ],
  [
    "Moreover , it also provides new characterization for shallow ReLU nonlinear networks , which is not discussed in previous work .",
    "NOVELTY"
  ],
  [
    "seems similar in spirit to this line of work",
    "NOVELTY"
  ],
  [
    "The idea present is interesting",
    "NOVELTY"
  ],
  [
    "The idea is original ,",
    "NOVELTY"
  ],
  [
    "I am not particularly well informed about the area , but the work appears to be novel .",
    "NOVELTY"
  ],
  [
    "The proposed two stream architecture ( static background / moving foreground + mask ) for video generation is novel (",
    "NOVELTY"
  ],
  [
    "albeit somewhat incremental over the previous static image generation GANs )",
    "NOVELTY"
  ],
  [
    "The paper is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "While somewhat incremental , the paper seems to have enough novelty for a poster .",
    "NOVELTY"
  ],
  [
    "I am not sure if this contributes substantially on top of existing literature",
    "NOVELTY"
  ],
  [
    "it does n't provide substantial algorithmic insight",
    "NOVELTY"
  ],
  [
    "In this sense , this paper has novel technical contribution compared to prior literature .",
    "NOVELTY"
  ],
  [
    "Overall I find this paper interesting",
    "NOVELTY"
  ],
  [
    "The paper mainly uses existing ideas , but with some incremental improvements . It lacks novelty .",
    "NOVELTY"
  ],
  [
    "In light of this , I see very little novelty in this paper .",
    "NOVELTY"
  ],
  [
    ".The evolutionary search algorithm was not wildly original or a huge breakthough in the general context of previous work",
    "NOVELTY"
  ],
  [
    "but seems appropriate",
    "NOVELTY"
  ],
  [
    "The use of graph neural networks appears novel ( concurrent with Paliwal ) , as does the sweep order",
    "NOVELTY"
  ],
  [
    "The trick of using architecture search as a dataset also seems novel , and I 'm quite happy with this idea .",
    "NOVELTY"
  ],
  [
    "I really liked the application of the perturbation trick , which has appeared in the literature before , but which I had not seen and is applied nicely here .",
    "NOVELTY"
  ],
  [
    "While the presented results are novel to the best of my knowledge ,",
    "NOVELTY"
  ],
  [
    "they are hardly surprising",
    "NOVELTY"
  ],
  [
    "insights around the problem",
    "NOVELTY"
  ],
  [
    ", highly novel and significant not only in a theoretical sense but also in a practical sense .",
    "NOVELTY"
  ],
  [
    "Overall I do like the approach and love that EP is beating neural nets .",
    "NOVELTY"
  ],
  [
    "The `` group `` idea and the `` sum of l2 norm `` idea are not new",
    "NOVELTY"
  ],
  [
    "the study of the generalization bounds with the presence of ( 1 ) kernels , and ( 2 ) the hinge loss ( as opposed to squared loss ) is new",
    "NOVELTY"
  ],
  [
    "The proposed method is novel , and",
    "NOVELTY"
  ],
  [
    "The combination of techniques is novel .",
    "NOVELTY"
  ],
  [
    "and the proposed algorithm looks novel .",
    "NOVELTY"
  ],
  [
    "thus reducing the novelty of the paper",
    "NOVELTY"
  ],
  [
    "I like the paper -- node differential privacy has been shown to be extremely challenging to achieve -- and consequently , this work is a solid algorithmic advance",
    "NOVELTY"
  ],
  [
    "I still think the contribution of this paper is overstated and the statements for corollary 4.2/4.3 are not entirely valid",
    "NOVELTY"
  ],
  [
    "The proof technique is interesting",
    "NOVELTY"
  ],
  [
    "While the paper includes some interesting ideas about representation of relative pitch",
    "NOVELTY"
  ],
  [
    "Novelty is minimal and is well below the level required by ICLR .",
    "NOVELTY"
  ],
  [
    "The use of von Neumann divergence as a loss for this task is perhaps novel . 2 .The use of \\alpha-derivatives , while computationally demanding , is perhaps novel in this context as well .",
    "NOVELTY"
  ],
  [
    "I do not think the problem setting or the proposed framework is entirely new or is the best choice of its ingredients",
    "NOVELTY"
  ],
  [
    "it is not clear how the proposed setup is novel ,",
    "NOVELTY"
  ],
  [
    "While , there are some components in the model that are perhaps new",
    "NOVELTY"
  ],
  [
    "This is a paper for the application of GAN and there are limited contribution to the technical aspect of machine learning .",
    "NOVELTY"
  ],
  [
    "The concept behind this term continuum learning is not a novel idea .",
    "NOVELTY"
  ],
  [
    "I definitely do not think this is novel .",
    "NOVELTY"
  ],
  [
    "Although the algorithmic idea of interactive proof is not new",
    "NOVELTY"
  ],
  [
    "Pros Their evaluation framework is public and is definitely a nice contribution to the community",
    "NOVELTY"
  ],
  [
    "The paper also introduces a new language modelling dataset , which overcomes some of the shortcomings of previous datasets",
    "NOVELTY"
  ],
  [
    "It is interesting to see how doubly robust can be related to primal-dual relations and the connections between these approaches , which is a novel contribution to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "This stands out in itself as a novel contribution of the paper .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper has a neat and elegant theoretical contribution , exploiting the connection of OPE with primal-dual frameworks that seems quite novel to me .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    ", and this paper has significantly novel theoretical contribution .",
    "NOVELTY"
  ],
  [
    "To me this paper is very interesting",
    "NOVELTY"
  ],
  [
    ".However , in terms of the proposed architecture , it seems to lack some novelty .",
    "NOVELTY"
  ],
  [
    "The different variants of the scheme and sparse selection of the frames to be perturbed are interesting .",
    "NOVELTY"
  ],
  [
    "I think the main weakness of this paper is the lack of any surprise/significant novelty in the presented approach .",
    "NOVELTY"
  ],
  [
    "it lacks novelty",
    "NOVELTY"
  ],
  [
    "the paper is an extension of Kim & Bengio 2016",
    "NOVELTY"
  ],
  [
    "-The effort made on designing the confidence penalty for asymmetric noise is interesting .",
    "NOVELTY"
  ],
  [
    "My only concern is about the novelty since the small loss trick in label noise and the MixMatch approach in SSL are already explored by many recent studies",
    "NOVELTY"
  ],
  [
    "but to the best of my knowledge , this paper is the first to unify them to solve label noise problems",
    "NOVELTY"
  ],
  [
    "The idea of importing concepts from functional programming into neural programming looks very promising , helping to address a bit the somewhat naive approach taken so far in the deep learning community towards program induction .",
    "NOVELTY"
  ],
  [
    "Originality This methods proposed in this paper are quite novel and start to bridge an important gap between neural program induction and functional programming , by importing the concept of combinator abstraction into NPI .",
    "NOVELTY"
  ],
  [
    "Learns new programs without catastrophic forgetting in the NPI core , in particular where previous NPI models fail .",
    "NOVELTY"
  ],
  [
    "The idea of using nearest neighbor regression is not new",
    "NOVELTY"
  ],
  [
    "but",
    "NOVELTY"
  ],
  [
    "the proposed method uses an online setting which makes this work novel compared with previous methods",
    "NOVELTY"
  ],
  [
    "interesting algorithm",
    "NOVELTY"
  ],
  [
    "The authors propose a novel , end-to-end trainable deep architecture for finding dense correspondences between pairs of images .",
    "NOVELTY"
  ],
  [
    "and the proposed approach is interesting and novel",
    "NOVELTY"
  ],
  [
    "To my knowledge the paper is novel , and",
    "NOVELTY"
  ],
  [
    "A novel study on quantifying the difficulty of meta-learning .",
    "NOVELTY"
  ],
  [
    "The proposed method is original and means a sufficient contribution .",
    "NOVELTY"
  ],
  [
    "This work is one of the first that tackles the problem described .",
    "NOVELTY"
  ],
  [
    "Regarding the trace set inference , the loss function during training and the subsequent use of SMC during test time",
    "NOVELTY"
  ],
  [
    "is pretty unconventional",
    "NOVELTY"
  ],
  [
    "The application of WGAN to modeling financial market microstructure is novel and appropriate",
    "NOVELTY"
  ],
  [
    "Quality The method combines an interesting set of ideas .",
    "NOVELTY"
  ],
  [
    "As far as I know , the combination proposed in this work is original .",
    "NOVELTY"
  ],
  [
    "The content is clearly novel and the result is far from",
    "NOVELTY"
  ],
  [
    "trivial",
    "NOVELTY"
  ],
  [
    "I find the paper interesting and novel , as it is the first to my knowledge to study the implicit bias of optimization for such generator-based denoising approaches , and provides interesting theoretical and empirical denoising",
    "NOVELTY"
  ],
  [
    "the novelty of this part is limited .",
    "NOVELTY"
  ],
  [
    "that makes a number of contributions",
    "NOVELTY"
  ],
  [
    ", it is not very original , at least in my subjective eyes .",
    "NOVELTY"
  ],
  [
    "IMO it is quite straight forward and builds on ideas that have been recently been proposed in many other works",
    "NOVELTY"
  ],
  [
    "The closed form derivations of the loss surface were interesting to see , and the clarity of tone on the advantages * and* disadvantages was educational .",
    "NOVELTY"
  ],
  [
    "The fact that a node-DP polynomial time algorithm is available and with almost the same error guarantees as the non-DP algorithm is quite an achievement",
    "NOVELTY"
  ],
  [
    "Even though personalization in federated learning",
    "NOVELTY"
  ],
  [
    "I find the contribution and novelty of this paper limited",
    "NOVELTY"
  ],
  [
    "Although the idea seems to be interesting",
    "NOVELTY"
  ],
  [
    "the paper seems to be a bit incremental and is a simple application of existing GAN techniques .",
    "NOVELTY"
  ],
  [
    "the method looks incremental",
    "NOVELTY"
  ],
  [
    "This is where I learned something new .",
    "NOVELTY"
  ],
  [
    "The contribution is somewhat limited .",
    "NOVELTY"
  ],
  [
    "2 .The theoretical results given in this paper is slightly incremental .",
    "NOVELTY"
  ],
  [
    "While the approach seems novel",
    "NOVELTY"
  ],
  [
    "My main concern with regards to the paper is novelty .",
    "NOVELTY"
  ],
  [
    "An advantage of the branch and bound framework is that there are already numerous methods for both branching and bounding .",
    "NOVELTY"
  ],
  [
    "this in itself is not sufficiently novel for publication at ICLR .",
    "NOVELTY"
  ],
  [
    "the paper exhibits a reasonable amount of originality .",
    "NOVELTY"
  ],
  [
    "I agree that the idea of learning a universal image prior is appealing",
    "NOVELTY"
  ],
  [
    "-- Novelty is limited .",
    "NOVELTY"
  ],
  [
    "which is of limited contribution and novelty",
    "NOVELTY"
  ],
  [
    "This is a very nice , simple idea",
    "NOVELTY"
  ],
  [
    "The work does not seem particularly novel .",
    "NOVELTY"
  ],
  [
    "Perhaps the specific application of regularized autoencoders to the channel charting problem is novel .",
    "NOVELTY"
  ],
  [
    "The idea of imposing some structure on the latent space of an autoencoder is not particularly new either .",
    "NOVELTY"
  ],
  [
    "On the whole , I do n't think there is enough novel work for the venue .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel method for deep structured predictions . The MRF-style structured prediction problem is formulated as a deep recurrent neural network . The proposed method is very intersting and novel compared to current",
    "NOVELTY"
  ],
  [
    "It 's not extremely novel",
    "NOVELTY"
  ],
  [
    "The method is novel to my knowledge and makes some of the ideas leading to reduction more transparent .",
    "NOVELTY"
  ],
  [
    "My concern about the limited novelty is exacerbated by the fact that the generated images are still in low-resolution",
    "NOVELTY"
  ],
  [
    "The paper has some interesting contributions about nice connection between some existing models and different tensor decompositions",
    "NOVELTY"
  ],
  [
    "Overall , this architecture , while not groundbreaking , is novel in this context",
    "NOVELTY"
  ],
  [
    "The idea of modularization is not really new ( as other systems implement something similar )",
    "NOVELTY"
  ],
  [
    "the actual content of the paper describes an extension of an existing system .",
    "NOVELTY"
  ],
  [
    "the reviewer feels that , in the current form , the results in the paper are not novel enough to warrant an acceptance to ICLR . The connection of the $ \\ell^4 $ -norm maximization formulation with ICA have been previously noted in other paper , so this would hardly qualify as a novel contribution .",
    "NOVELTY"
  ],
  [
    "Originality The paper seems quite original , with new algorithms based on a novel principle of similarity between graphs .",
    "NOVELTY"
  ],
  [
    "issue ( graph compression ) in a novel way , with",
    "NOVELTY"
  ],
  [
    "The main contribution of the paper is the introduce such techniques to the ML community",
    "NOVELTY"
  ],
  [
    ", the paper lacks in novelty aspect , as it is uses mostly well-known techniques .",
    "NOVELTY"
  ],
  [
    "I can not accurately evaluate the originality of the paper .",
    "NOVELTY"
  ],
  [
    "and the experiments are insightful and relevant",
    "NOVELTY"
  ],
  [
    "The main contribution of the paper is incremental ( specially respect to Mithun et al. , 2019 ) , I do not see a ground-breaking contribution . One of the main novelties with respect to previous text-to-clip models is the use of co-attention schemes at the level of words and frames . However , the idea of co-attention at different grain-levels have been proposed before",
    "NOVELTY"
  ],
  [
    "originality The theoretical analyses on the scalability of GCN have great originality and important in practice .",
    "NOVELTY"
  ],
  [
    "The proposed architectures , namely , snowball GCN and truncated Krylov block network , have a certain novelty .",
    "NOVELTY"
  ],
  [
    "The thinning idea of learning point processes is interesting .",
    "NOVELTY"
  ],
  [
    "The idea seems interesting and has some novelty .",
    "NOVELTY"
  ],
  [
    "Perhaps the most important contribution of this submission is the architecture based on ConvLSTMs proposed by the authors , which apparently surpasses many alternatives",
    "NOVELTY"
  ],
  [
    "the proposed architecture does not seem sufficiently novel to warrant acceptance",
    "NOVELTY"
  ],
  [
    "and I am convinced that the authors \u2019 two-phase reinforcement learning solution to ( 2 ) is an interesting approach",
    "NOVELTY"
  ],
  [
    "the solution interesting",
    "NOVELTY"
  ],
  [
    "the novelties of this paper is very limited .",
    "NOVELTY"
  ],
  [
    "But this is also not a big contribution",
    "NOVELTY"
  ],
  [
    "I ve liked the idea of learning a speed-up operator to improve the performance of a standard solver and adapt it to new boundary conditions or problem geometries .",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper makes a nice conceptual contribution , by coming up with an apparently-new convex relaxation for a challenging signal recovery",
    "NOVELTY"
  ],
  [
    "which are not new",
    "NOVELTY"
  ],
  [
    "I agree with the authors ' assessment that this work is a theoretical advance",
    "NOVELTY"
  ],
  [
    "the results are original and of interest",
    "NOVELTY"
  ],
  [
    "the novelty of the work is relatively limited , while the validation is lacking a bit .",
    "NOVELTY"
  ],
  [
    "and novel findings to further state-of-the-art",
    "NOVELTY"
  ],
  [
    "the idea proposed by the paper which is to introduce a gating mechanism for recurrent output of the layer makes sense but is not sufficiently novel on its own . The combination of this and just decent improvement over previous SOTA makes it just a small positive contribution .",
    "NOVELTY"
  ],
  [
    "This approach seems like a promising direction",
    "NOVELTY"
  ],
  [
    "but are n't groundbreaking .",
    "NOVELTY"
  ],
  [
    "I liked the idea of the rhythm evaluation",
    "NOVELTY"
  ],
  [
    "the idea to measure IOI distributions is clever",
    "NOVELTY"
  ],
  [
    "The components of the model are not individually novel ,",
    "NOVELTY"
  ],
  [
    "The approaches to evaluation , while still somewhat unclear , are interesting and original to the best of my knowledge , and could be useful for other practitioners in need of ways to evaluate style transfer in music .",
    "NOVELTY"
  ],
  [
    "I really believe in the concept of learning",
    "NOVELTY"
  ],
  [
    "and I think the paper has some good ideas .",
    "NOVELTY"
  ],
  [
    "The idea of teaching a student model to imitate behavior of the teacher model on * new* data is interesting .",
    "NOVELTY"
  ],
  [
    "While the idea of",
    "NOVELTY"
  ],
  [
    "evaluation metric seems interesting",
    "NOVELTY"
  ],
  [
    "The work does not present a technical advance in itself",
    "NOVELTY"
  ],
  [
    "Using GANs to synthesize neural activity patterns is novel ( to my knowledge ) .",
    "NOVELTY"
  ],
  [
    "The novel idea of using the critic to learn something about the crucial population activity patterns is not fleshed out at all",
    "NOVELTY"
  ],
  [
    "but they do not necessarily offer much generally relevant scientific insight .",
    "NOVELTY"
  ],
  [
    "but they are quite minor and incremental , so it is unclear if they will be of interest to the NIPS audience .",
    "NOVELTY"
  ],
  [
    "The results presented in the paper are interesting and non trivial",
    "NOVELTY"
  ],
  [
    "I find this particularly interesting and surprising .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting and discusses the fact that expected risk does not necessarily improve with larger data sets .",
    "NOVELTY"
  ],
  [
    "but does not introduce original extensions to the model and does not explain any fundamental limitations",
    "NOVELTY"
  ],
  [
    "The idea of having a piecewise constant prior for latent variables is interesting",
    "NOVELTY"
  ],
  [
    "interesting algorithm for structured prediction ( base on reward",
    "NOVELTY"
  ],
  [
    "Using lower precision activations to save memory and compute seems new and widening the filter sizes seems to recover the accuracy lost due to the lower precision",
    "NOVELTY"
  ],
  [
    "the overall technical contribution of the paper that of widening the networks is fairly small .",
    "NOVELTY"
  ],
  [
    "The ideas presented in the paper are interesting",
    "NOVELTY"
  ],
  [
    "This paper has a number of original ideas .",
    "NOVELTY"
  ],
  [
    "The area needs its own original",
    "NOVELTY"
  ],
  [
    "contributions",
    "NOVELTY"
  ],
  [
    "I don\u00e2\u0080\u0099t find that there are original ideas in the paper",
    "NOVELTY"
  ],
  [
    "Combining it in VAE seems not novel .",
    "NOVELTY"
  ],
  [
    "the paper 's contributions and novelty compared with previous work seem limited ,",
    "NOVELTY"
  ],
  [
    "However , I have the impression that it 's largely an incremental improvement over recent work by McMahan et al . ( 2018 ) .",
    "NOVELTY"
  ],
  [
    "This approach seems hardly novel .",
    "NOVELTY"
  ],
  [
    "The iterative approach , with small networks doing the work , is a nice relief from the giant-network baselines",
    "NOVELTY"
  ],
  [
    "that take the entire pointcloud as input and produce all instance segmentations directly",
    "NOVELTY"
  ],
  [
    "Nevertheless , I find the approach interesting",
    "NOVELTY"
  ],
  [
    "Overall , I think the model and the algorithm are novel and",
    "NOVELTY"
  ],
  [
    "\u201d The propositions in this paper were , in my opinion , not particularly insightful .",
    "NOVELTY"
  ],
  [
    "Limited insight - Weak",
    "NOVELTY"
  ],
  [
    "Strengths Novel findings about the effect of network architecture , input representation and learning objective on cross lingual ability of M-BERT",
    "NOVELTY"
  ],
  [
    "The idea of introducing the notion of restricted approximability and discussing a sample complexity bound , polynomial in the dimension , for GANs are considered original .",
    "NOVELTY"
  ],
  [
    "But given that the theoretical contribution is a fairly straight-forward application of well-known ideas",
    "NOVELTY"
  ],
  [
    "the contribution and originality",
    "NOVELTY"
  ],
  [
    "The idea behind the paper is not novel .",
    "NOVELTY"
  ],
  [
    ", and the proposed idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "It is an interesting idea to be explored",
    "NOVELTY"
  ],
  [
    "This is in my opinion the weakest point of the paper . There is n't really much novelty in the work .",
    "NOVELTY"
  ],
  [
    "Overall I find this a very interesting approach .",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "With regards to the second part of the paper , using gradient methods to solve a minimax problem is not especially novel (",
    "NOVELTY"
  ],
  [
    "It seems the theoretical part has already been investigated in another paper",
    "NOVELTY"
  ],
  [
    "This is a very nice theory paper that introduces a general reduction scheme and then uses it to provide hardness results for several familiar problems .",
    "NOVELTY"
  ],
  [
    "While the result might be considered incremental , extending recent work by considering a more sophisticated class of algorithms",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the idea is new (",
    "NOVELTY"
  ],
  [
    "I believe this is a breakthrough result in the field of neural network theory .",
    "NOVELTY"
  ],
  [
    "This is a nice combination using the vMF model and Hungarian matching . I really like the ideas here and",
    "NOVELTY"
  ],
  [
    "The paper presents a novel kernel that derives from the assignment problem . The kernel is build on simpler kernels and it provides proof that is a symmetric and s.p.d . kernel .The simpler kernel fulfills a strong inequality constraint and can be induced by hierarchy over the set . Despite its generality , the kernel has been examined under the graph comparison problem using well known datasets and outperforms in 7 out of 9 datasets the state-of-art graph kernels . The paper presents a novel generalized kernel , which is build upon simpler kernels . Although the proposed method is interesting",
    "NOVELTY"
  ],
  [
    "This also makes me feel the contribution in terms of novelty is rather limited , since the tangent space regularization is not new [ 4 ] .",
    "NOVELTY"
  ],
  [
    "This paper is the first to suggest the tree-to-tree network and an interesting application of the network for the program translation problem",
    "NOVELTY"
  ],
  [
    "on relational learning with tensors",
    "NOVELTY"
  ],
  [
    "However , this framework seems hardly novel , relatively to the formalism introduced by LSTM or highway networks .",
    "NOVELTY"
  ],
  [
    "while the idea of replacing the softmax in the attention mechanism by a hierachical softmax is appealing",
    "NOVELTY"
  ],
  [
    "Overall I like the simplicity of the proposed idea .",
    "NOVELTY"
  ],
  [
    "Unclear novelty",
    "NOVELTY"
  ],
  [
    "The proposed approach looks unique and interesting .",
    "NOVELTY"
  ],
  [
    "This technical proposal looks novel and I believe highly contributing .",
    "NOVELTY"
  ],
  [
    "The paper is making a good contribution in proposing a novel clustering framework based on denoising formulation .",
    "NOVELTY"
  ],
  [
    "the proposed diverse loss is not a new approach .",
    "NOVELTY"
  ],
  [
    "But , its novelty is incremental and competitors are not actually the models capturing diversity .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is not clear .",
    "NOVELTY"
  ],
  [
    "Theorem 1 is quite interesting and provides a more tractable surrogate for the TT schatten norm . - The statistical results are a new contribution for tensor completion",
    "NOVELTY"
  ],
  [
    "paper presents many intriguing results under the setting of",
    "NOVELTY"
  ],
  [
    "The theoretical contribution of this paper is also weak",
    "NOVELTY"
  ],
  [
    "A novel approach",
    "NOVELTY"
  ],
  [
    "The setting introduced in this paper is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The idea of categorized bandits is not new as the authors note .",
    "NOVELTY"
  ],
  [
    "The technical novelty of the proposed approach is unclear .",
    "NOVELTY"
  ],
  [
    "Although optimization in semirings is not novel and the formulation provided by the authors is not very surprising",
    "NOVELTY"
  ],
  [
    "the methodology is interesting by itself",
    "NOVELTY"
  ],
  [
    "Employing inducing point training for task memorization is a novel and interesting idea",
    "NOVELTY"
  ],
  [
    "Overall , the presented ideas are fairly interesting",
    "NOVELTY"
  ],
  [
    "My major concern is that the proposed method is conceptually not novel enough compared to Nguyen et al. , 2017 .My",
    "NOVELTY"
  ],
  [
    "The fact is that the conceptual novelty of the paper is too slim compared to VCL .",
    "NOVELTY"
  ],
  [
    "There are no theorems here and no new deep network architectures",
    "NOVELTY"
  ],
  [
    "Those theoretical analysis is interesting although it is a bit incremental .",
    "NOVELTY"
  ],
  [
    "I feel that the contribution is rather incremental to the work [ 11 ] ( ICML2016 ) .",
    "NOVELTY"
  ],
  [
    "However , the contributions are more or less incremental and this work to me represents a technical report",
    "NOVELTY"
  ],
  [
    "It is incremental as it takes well-established ideas ( BiGAN + BigGAN ) and combines them in a straightforward way that would be only available to those with the most compute .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and simple",
    "NOVELTY"
  ],
  [
    "This is not a paper with grand new ideas",
    "NOVELTY"
  ],
  [
    "The paper presents a novel combination of biophysical modeling of ribbon synapse and a likelihood-free inference of the parameters . To my knowledge , the fully stochastic modeling of the vesicle-release dynamics is itself new .",
    "NOVELTY"
  ],
  [
    "this is certainly an encouraging first work",
    "NOVELTY"
  ],
  [
    "All in all , the paper is a solid contribution which deserves to be accepted .",
    "NOVELTY"
  ],
  [
    "I think the work done on analysis of the loss function is also new and interesting",
    "NOVELTY"
  ],
  [
    "Although this bound involves new insight , the novelty is limited if it is looser than existing upper bound .",
    "NOVELTY"
  ],
  [
    "Although the insight is interesting",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is not enough for being accepted by ICLR .",
    "NOVELTY"
  ],
  [
    "The approach taken here is quite similar to another ICLR submission this year , which basically does the same thing but applies these operations to GCNs instead of VAEs",
    "NOVELTY"
  ],
  [
    ".One novel aspect seems to be factorizing the choice out of N candidates by making it a binary selection .",
    "NOVELTY"
  ],
  [
    "Overall the method seems to be novel .",
    "NOVELTY"
  ],
  [
    "I think the idea in this paper is interesting .",
    "NOVELTY"
  ],
  [
    "Although the idea of this paper is",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "I think this paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "the method does not appear to be very novel",
    "NOVELTY"
  ],
  [
    "I think the theory is very interesting and a meaningful contribution in its own right .",
    "NOVELTY"
  ],
  [
    "the source of instability of adversarial images . To the best of my knowledge , the transferability of adaptive attacks against noisy channel defense methods has not been discussed in the literature .",
    "NOVELTY"
  ],
  [
    "While I appreciate that the work is incremental , and that it relies on a number of previously modules",
    "NOVELTY"
  ],
  [
    "Nevertheless , I believe the idea is interesting",
    "NOVELTY"
  ],
  [
    "With respect to novelty , some of the experiments are novel",
    "NOVELTY"
  ],
  [
    ", but others , including the improved training method , have been explored before",
    "NOVELTY"
  ],
  [
    "While to my knowledge the decision surface visualization is novel and might have important uses",
    "NOVELTY"
  ],
  [
    "It is therefore unclear what additional insight this analysis presents",
    "NOVELTY"
  ],
  [
    "The model described in the paper does not really introduce anything new",
    "NOVELTY"
  ],
  [
    "- might be a bit incremental - usefulness of sentence ordering",
    "NOVELTY"
  ],
  [
    "although the formulation of the proposed metric is new to my knowledge",
    "NOVELTY"
  ],
  [
    "As for introducing logic rules to guide event predication , this is not a new topic .",
    "NOVELTY"
  ],
  [
    "In the machine learning community , I think this work is somewhat original",
    "NOVELTY"
  ],
  [
    "The theoretical result are interesting and original .",
    "NOVELTY"
  ],
  [
    "I like the idea , and I think it is indeed a good idea for IoT and end devices .",
    "NOVELTY"
  ],
  [
    "I like this idea",
    "NOVELTY"
  ],
  [
    "Moderately novel ] Cross-lingual knowledge distillation approach that uses one and the same XLM model to serve both as teacher",
    "NOVELTY"
  ],
  [
    "Findings , methods and experiments are not strongly novel .",
    "NOVELTY"
  ],
  [
    "idea is interesting and the proposed solution seems interesting",
    "NOVELTY"
  ],
  [
    "The whole framework looks quite interesting and promising .",
    "NOVELTY"
  ],
  [
    "The surrogate loss to learn the features coupled with a linear policy evaluation algorithm appear to be novel",
    "NOVELTY"
  ],
  [
    "This therefore , does not appear to be a novel contribution .",
    "NOVELTY"
  ],
  [
    "The work done in the control setting appears to be very similar to the experiments performed in the paper : Shallow Updates for Deep Reinforcement Learning",
    "NOVELTY"
  ],
  [
    "However , the novelty is lacking as it appears to be training using a multi-headed approach ( which exists ) and the convergence results appear to be a straightforward application of Borkars two-timescale proof",
    "NOVELTY"
  ],
  [
    "The novelty therefore appears to be using a surrogate loss function for training the features which does not possess the sufficient novelty in my opinion for ICLR .",
    "NOVELTY"
  ],
  [
    "This is interesting ( and novel",
    "NOVELTY"
  ],
  [
    "compared to the `` Order Matters `` paper",
    "NOVELTY"
  ],
  [
    "paper proposes a novel solution to a *restricted* reinforcement learning problem",
    "NOVELTY"
  ],
  [
    "the analysis",
    "NOVELTY"
  ],
  [
    "The proposed approach is single and elegant .",
    "NOVELTY"
  ],
  [
    "The idea of using latent syntactic structure , and computing cross-sentence alignment over spans is very interesting .",
    "NOVELTY"
  ],
  [
    "This idea may not be too novel",
    "NOVELTY"
  ],
  [
    "the paper introduces an interesting idea to use a latent variable model to achieve several objectives",
    "NOVELTY"
  ],
  [
    "However , I think the overall research contribution is novel and maybe considered for acceptance .",
    "NOVELTY"
  ],
  [
    "and the proposed ideas are minor variations on well known concepts",
    "NOVELTY"
  ],
  [
    "the theoretical part of the paper is not really improved in my opinion",
    "NOVELTY"
  ],
  [
    "In terms of novelty , there seems to be sufficient novelty even though it is an extension of a",
    "NOVELTY"
  ],
  [
    "previous approach",
    "NOVELTY"
  ],
  [
    "proposes a new method that involves multi-scale inputs for each layer that could be used as network architecture search or data agumentation or Pros",
    "NOVELTY"
  ],
  [
    "The idea looks interesting",
    "NOVELTY"
  ],
  [
    "The authors provided a novel technique about the resizable approach and",
    "NOVELTY"
  ],
  [
    "A simple approach with limited novelty .",
    "NOVELTY"
  ],
  [
    "The idea of the described universality is very interesting .",
    "NOVELTY"
  ],
  [
    "so I think it can inspire other works on this topic",
    "NOVELTY"
  ],
  [
    "Matching density ratios is a novel and interesting idea .",
    "NOVELTY"
  ],
  [
    "group-sparse auto-encoder seems new to me .",
    "NOVELTY"
  ],
  [
    "The idea is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "and the authors offer extensive insight into their approach",
    "NOVELTY"
  ],
  [
    "which is not the novel contribution of the paper )",
    "NOVELTY"
  ],
  [
    "The paper a strong related work section and the methods described seem to be original .",
    "NOVELTY"
  ],
  [
    "I believe the main result Theorem 2.1 is novel .",
    "NOVELTY"
  ],
  [
    "The novelty of this work regarding learning representations seems limited to me , as opposed to the contribution on improving survival analysis & medical prediction .",
    "NOVELTY"
  ],
  [
    "but the novelty and strength of the contribution seems low for this conference .",
    "NOVELTY"
  ],
  [
    "This is a great idea and could be a strong paper",
    "NOVELTY"
  ],
  [
    "This concept is very similar to some previous works such as Inference Machine ( Langford et.al",
    "NOVELTY"
  ],
  [
    "I think the concept and the structure proposed in this paper is quite similar to Deep Tracking .",
    "NOVELTY"
  ],
  [
    "I think the contribution of the paper is only limited to learning state estimators for linear dynamical systems .",
    "NOVELTY"
  ],
  [
    "The main idea of using a binary predictors for predictions of permissible actions leading to desired states is interesting and novel .",
    "NOVELTY"
  ],
  [
    "and the approach is interesting",
    "NOVELTY"
  ],
  [
    "it lacks novelty and is limited to tabular data as presented",
    "NOVELTY"
  ],
  [
    "The novelty is limited .",
    "NOVELTY"
  ],
  [
    "The concept of student models approximating teacher models is not new either . The originality seems incremental in both directions .",
    "NOVELTY"
  ],
  [
    "Applying variance reduction in the non-convex is not novel .",
    "NOVELTY"
  ],
  [
    "This paper makes a nice contribution , tying together results sprinkled throughout the optimization literature , and also presents several new additions , putting them together in one cohesive piece of work .",
    "NOVELTY"
  ],
  [
    ", addresses a relevant problem ( classification of 3D point clouds with arbitrary , a priori unknown graph structure ) in an original way , and",
    "NOVELTY"
  ],
  [
    "My only serious concern is the degree of novelty with respect to ( Achlioptas et al. , 2017 )",
    "NOVELTY"
  ],
  [
    "The models are not particularly novel , employing conditional GANs but it is interesting how they work together as well as the introduction of the spatial transformer network",
    "NOVELTY"
  ],
  [
    "While the basic ingredients of the proposed method are not new",
    "NOVELTY"
  ],
  [
    ", their combination is certainly original",
    "NOVELTY"
  ],
  [
    "I think that the paper is rather incremental , but still has enough substance to make an interesting contribution .",
    "NOVELTY"
  ],
  [
    "the proposed",
    "NOVELTY"
  ],
  [
    "theorems are mostly mechanical applications of prior work to the current extended version",
    "NOVELTY"
  ],
  [
    "as there is n't that much novelty and the requirements are impractical",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "and propose a novel method .",
    "NOVELTY"
  ],
  [
    "The two regime claim of the paper is not really novel .",
    "NOVELTY"
  ],
  [
    "I believe these experiments are novel and the results are interesting .",
    "NOVELTY"
  ],
  [
    "On the other hand , contribution is somewhat incremental given observations made by related literature ( Keskar et al and others ) .",
    "NOVELTY"
  ],
  [
    "The theoretical contributions seem to be mature 2",
    "NOVELTY"
  ],
  [
    "I think the contributions are limited in terms of scientific contribution .",
    "NOVELTY"
  ],
  [
    "The scientific contributions are quite limited .",
    "NOVELTY"
  ],
  [
    "The connection to Good-Turing performance is especially striking",
    "NOVELTY"
  ],
  [
    "From a modeling standpoint , I generally like the ideas behind this paper .",
    "NOVELTY"
  ],
  [
    "The ideas are original within the field of systems neuroscience",
    "NOVELTY"
  ],
  [
    "The approach seems novel .",
    "NOVELTY"
  ],
  [
    ".Even though the idea they present is quite simple",
    "NOVELTY"
  ],
  [
    "I really like this paper",
    "NOVELTY"
  ],
  [
    "The main idea of the paper is not original .",
    "NOVELTY"
  ],
  [
    "This work lacks basic originality",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting improvement to the usual RL .",
    "NOVELTY"
  ],
  [
    "A novel approach for automatic design of neural network architectures .",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting and novel approach for neural network architecture design",
    "NOVELTY"
  ],
  [
    "The overall technique is intuitive and novel",
    "NOVELTY"
  ],
  [
    "the main result of the paper , in particular the generative process , is similar to existing literature",
    "NOVELTY"
  ],
  [
    "This paper provides a novel framework that utilizes importance weighting strategy to control the Jenson bound in KL-variational inference .",
    "NOVELTY"
  ],
  [
    "There is nothing new technically .",
    "NOVELTY"
  ],
  [
    "I propose a weak accept as I think the paper is interesting",
    "NOVELTY"
  ],
  [
    "The general idea of the paper is interesting .",
    "NOVELTY"
  ],
  [
    "I like the idea of this paper , which to me is novel .",
    "NOVELTY"
  ],
  [
    "The novelty of the work appears limited : the method is mostly based on a NIPS 2015 paper by the same authors",
    "NOVELTY"
  ],
  [
    "The experimental evaluation appears at least partially novel",
    "NOVELTY"
  ],
  [
    "but the theoritical contributions of the paper are incremental .",
    "NOVELTY"
  ],
  [
    "This paper is interesting",
    "NOVELTY"
  ],
  [
    "This paper proposes an interesting model and derives three main theorems",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "The model is interesting and has certain novelty .",
    "NOVELTY"
  ],
  [
    "Although the model is conceptually novel , the structure of cost function is similar to previous Bayesian decision models in 2AFC .",
    "NOVELTY"
  ],
  [
    "From computational point of view , the impact of this paper is limited .",
    "NOVELTY"
  ],
  [
    "Like I said in my previous review , I like the main idea of this paper",
    "NOVELTY"
  ],
  [
    "I definitely appreciate the theoretical contribution of this paper .",
    "NOVELTY"
  ],
  [
    "insightful",
    "NOVELTY"
  ],
  [
    "2 .My main concern of this paper is the novelty",
    "NOVELTY"
  ],
  [
    "The method itself has already been proposed many years ago as mentioned in the related work section in the paper",
    "NOVELTY"
  ],
  [
    "which makes me doubt the novelty of the paper",
    "NOVELTY"
  ],
  [
    "Many things mentioned in this paper have already been discovered at that time",
    "NOVELTY"
  ],
  [
    "and original . It is original because",
    "NOVELTY"
  ],
  [
    "there are only a few works which directly manipulate the latent space",
    "NOVELTY"
  ],
  [
    "The model seems quite novel",
    "NOVELTY"
  ],
  [
    "The paper is quite interesting",
    "NOVELTY"
  ],
  [
    "although not entirely novel or delivering impressive results .",
    "NOVELTY"
  ],
  [
    "As such it is not clear what is the novelty as compared to having a sparse encoding of the input space and the weight filters .",
    "NOVELTY"
  ],
  [
    ", and to my knowledge the approach is novel .",
    "NOVELTY"
  ],
  [
    "I 'm inclined to say that the introduction of the framework is a solid contribution , and the results presented are interesting .",
    "NOVELTY"
  ],
  [
    "The approach proposed in the paper looks interesting .",
    "NOVELTY"
  ],
  [
    "I found the proposed algorithm and the discussions in Section 2 and 3 interesting",
    "NOVELTY"
  ],
  [
    "Proposes a new normalisation statistics-based method for DA .",
    "NOVELTY"
  ],
  [
    "under-studied compared to other approaches .",
    "NOVELTY"
  ],
  [
    "Weak novelty . Addressing domain-shift via domain specific moments is not new .",
    "NOVELTY"
  ],
  [
    "The interest to the NIPS community is probably limited but I can not identify other significant drawbacks",
    "NOVELTY"
  ],
  [
    "I am not convinced about the novelty and contribution of the work .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the contribution to the state of the art is minimal , and editing highly lacking .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel perspective on GANs and an interesting conjecture regarding the failure of GANs to capture global consistency .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is mostly technical but is of interest .",
    "NOVELTY"
  ],
  [
    "the proposed stability metric seems not quite related with the above intuitions",
    "NOVELTY"
  ],
  [
    "It sounds like a good idea .",
    "NOVELTY"
  ],
  [
    "Nonetheless , I think this is an interesting idea",
    "NOVELTY"
  ],
  [
    "This is a significant and original contribution",
    "NOVELTY"
  ],
  [
    "but is entirely theoretical",
    "NOVELTY"
  ],
  [
    "The setting is new as far as my knowledge can tell",
    "NOVELTY"
  ],
  [
    "but modifying each training point by a small amount for an offline learner is new to me",
    "NOVELTY"
  ],
  [
    "The main limitation in my opinion is incremental contribution over the work of Honorio & Jaakkola [ 11 ]",
    "NOVELTY"
  ],
  [
    "novelty is limited and",
    "NOVELTY"
  ],
  [
    "Novelty of the work seems quite limited .",
    "NOVELTY"
  ],
  [
    "without much conceptual innovation",
    "NOVELTY"
  ],
  [
    "To the best of the reviewer 's knowledge , the term `` cursor `` is the authors ' original one .",
    "NOVELTY"
  ],
  [
    "Good originality .",
    "NOVELTY"
  ],
  [
    "That makes this paper novel .",
    "NOVELTY"
  ],
  [
    ", novel , and ideas are well motivated .",
    "NOVELTY"
  ],
  [
    "2 .Since mode collapse is a well-known phenomenon , the novelty of this paper is not sufficient .",
    "NOVELTY"
  ],
  [
    "Positives The idea of doing sequence classification , L2L , and meta-rl problems in spiking networks is very appealing , because of the applications in modeling of biological neural activity and neuromorphic computing .",
    "NOVELTY"
  ],
  [
    "able to solve these tasks with RSNNs at all appears to be a",
    "NOVELTY"
  ],
  [
    "Lack of novelty in the proposed method .",
    "NOVELTY"
  ],
  [
    "The algorithm pretty much is similar to the A2C algorithm ( very minor differences ) and overall , I do n't see the contribution of the paper to be significant enough .",
    "NOVELTY"
  ],
  [
    "the concept of constraint used in this work is totally different and it simply means copying the network weights .",
    "NOVELTY"
  ],
  [
    "The approach itself was already proposed in",
    "NOVELTY"
  ],
  [
    "Overall , the contribution seems rather marginal as the results are somehow expected",
    "NOVELTY"
  ],
  [
    "But from the point of view on Machine learning / deep learning , there is not much insight from it .",
    "NOVELTY"
  ],
  [
    "the contributions are original and provide new insights .",
    "NOVELTY"
  ],
  [
    "publication",
    "NOVELTY"
  ],
  [
    "The Prod version is a very nice idea . Great results . This looks original",
    "NOVELTY"
  ],
  [
    "but I 'm not expert enough in the huge masses of new deep neural network research popping up",
    "NOVELTY"
  ],
  [
    "The approach is novel and most relevant",
    "NOVELTY"
  ],
  [
    "The idea of separating policy and default policy seems similar to having high and low level controller ( HLC and LLC ) in hierarchical control -- where LLC takes proprioceptive observations as input , and HLC handles task specific goals",
    "NOVELTY"
  ],
  [
    "is a fascinating paper that applies sequential generative models to learn deep representations of 3D structures in an unsupervised manner .",
    "NOVELTY"
  ],
  [
    "The proposed learning framework that supports both 3D volumes and 2D images is also novel ,",
    "NOVELTY"
  ],
  [
    "it is derivative of previous research , and the results are not stronger",
    "NOVELTY"
  ],
  [
    "the proposed bilinear transformation is clearly different from existing works",
    "NOVELTY"
  ],
  [
    "The major contribution of this paper is three-fold .",
    "NOVELTY"
  ],
  [
    "However , I feel its novelty in methodologies does not meet the NIPS standard --",
    "NOVELTY"
  ],
  [
    "The model lacks enough technical novelty .",
    "NOVELTY"
  ],
  [
    "and presents a compelling innovation which complements GANs .",
    "NOVELTY"
  ],
  [
    "evaluation",
    "NOVELTY"
  ],
  [
    "The method is original and simple and yet powerful",
    "NOVELTY"
  ],
  [
    "Novel method that",
    "NOVELTY"
  ],
  [
    "The paper",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "The paper focuses on a novel constraining approach with seemingly superior scalability , and this is potentially a significant contribution .",
    "NOVELTY"
  ],
  [
    "The method is interesting , novel and seemingly efficient",
    "NOVELTY"
  ],
  [
    "Limited novelty : it is a fairly incremental variation compared to the Meta-Learner LSTM ( Ravi & Larochelle ) .",
    "NOVELTY"
  ],
  [
    "the presented method seems to be too incremental",
    "NOVELTY"
  ],
  [
    "While the idea presented in the paper is interesting",
    "NOVELTY"
  ],
  [
    "to me it seems fairly trivial from the technical perspective and insufficient to serve as the backbone of the entire paper .",
    "NOVELTY"
  ],
  [
    "while I like the general idea behind this paper",
    "NOVELTY"
  ],
  [
    "I still think the technical meat of the",
    "NOVELTY"
  ],
  [
    "weak",
    "NOVELTY"
  ],
  [
    "The monte carlo is new , the other methods not but the task of the equivalence is new .",
    "NOVELTY"
  ],
  [
    "It is kind of a combination",
    "NOVELTY"
  ],
  [
    "but the proposed ideas are new , it is very theoretical .",
    "NOVELTY"
  ],
  [
    "It is a new task .",
    "NOVELTY"
  ],
  [
    "An interesting idea of leveraging class dependency in meta-learning .",
    "NOVELTY"
  ],
  [
    "The ideas are pretty neat , and as far as i know , original .",
    "NOVELTY"
  ],
  [
    "the paper presents some compelling ideas",
    "NOVELTY"
  ],
  [
    "This is a good paper which provides a good contribution for the community .",
    "NOVELTY"
  ],
  [
    "Significance -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- The paper proposes a novel way to analyze dynamic functional connectivity , which is an active area of research in neuroscience",
    "NOVELTY"
  ],
  [
    "However , the idea of parametrizing covariance matrices using the matrix logarithm map in general is not new .",
    "NOVELTY"
  ],
  [
    "The proposed method improves upon the state of the art , while more strongly capturing multi-modality than previous methods . To the best of my knowledge , this is the first work w.r.t .future prediction with a principled treatment of uncertainty . I find the contributions significant",
    "NOVELTY"
  ],
  [
    "apply a novel approach",
    "NOVELTY"
  ],
  [
    "the proposed sampling strategy looks heuristic without any studies",
    "NOVELTY"
  ],
  [
    "I 'm not entirely sure about the fit to NIPS in terms of originality .",
    "NOVELTY"
  ],
  [
    "It does not propose entirely new concepts",
    "NOVELTY"
  ],
  [
    "put combines them in a new and non-trivial way",
    "NOVELTY"
  ],
  [
    "In terms of novelty , it feels like Zhang et al",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting application of LSTMs to biological data , and has some novel elements for model interpretation .",
    "NOVELTY"
  ],
  [
    "The adaptation of the class activation mapping method to the LSTM model is interesting",
    "NOVELTY"
  ],
  [
    "of the approach over existing approaches include",
    "NOVELTY"
  ],
  [
    "incremental",
    "NOVELTY"
  ],
  [
    "The idea of designing initialization heuristics to maintain the scale of outputs stable over different layers isn\u00e2\u0080\u0099t something very novel .",
    "NOVELTY"
  ],
  [
    "The idea was interesting",
    "NOVELTY"
  ],
  [
    "and is a somewhat novel contribution",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "Main paper Overall an interesting read but the novelty is not so clear to me .",
    "NOVELTY"
  ],
  [
    "extension",
    "NOVELTY"
  ],
  [
    "the paper proposes a mathematically interesting model for a context of a word ( i.e. , a Grassmanian manifold )",
    "NOVELTY"
  ],
  [
    "Originality The main originality is in the problem formulation .",
    "NOVELTY"
  ],
  [
    "Based on my knowledge , the idea is novel and the Inception",
    "NOVELTY"
  ],
  [
    "and is a good extension of the existing work on label ranking .",
    "NOVELTY"
  ],
  [
    "The surrogate least square approach used in this paper is , as far as I know , significantly different from the existing work ,",
    "NOVELTY"
  ],
  [
    "Overall , the paper takes an interesting , and new spectral perspective on robustness .",
    "NOVELTY"
  ],
  [
    "In other words , this paper lacks novelty , which seems incremental to the existing works .",
    "NOVELTY"
  ],
  [
    "A Novel Diffusion Convolutional Recurrent Neural Network framework for traffic forecasting \u2022 Apply bidirectional random walks with nice theoretical analysis to capture the spatial dependency \u2022 Novel applications of sequence to sequence architecture and the scheduled sampling technique into modeling the temporal dependency in the traffic domain",
    "NOVELTY"
  ],
  [
    "In terms of novelty , there are",
    "NOVELTY"
  ],
  [
    "some contributions in",
    "NOVELTY"
  ],
  [
    "terms of the insight that different coordinates converge at different rates and coordinate-descent methods should run faster",
    "NOVELTY"
  ],
  [
    "However , the novelty is limited in the sense it is application of coordinate descent on power iterations .",
    "NOVELTY"
  ],
  [
    "authors propose a new setting for structured prediction , and relates it well to the state of the art",
    "NOVELTY"
  ],
  [
    "and the connection with industrial recommendation systems where candidate nomination and ranker is being used is engaging",
    "NOVELTY"
  ],
  [
    "This is to my knowledge a novel approach in the neural theorem proving domain , and in my opinion one that offers a potentially significant advantage over the existing fixed-dataset appraoches .",
    "NOVELTY"
  ],
  [
    "I agree with the authors that this line of work , that is not very well known in the current machine learning community , includes a number of ideas that should be able to shed light on some of the currently open theoretical questions .",
    "NOVELTY"
  ],
  [
    "I really like this paper and it presents a nice vector space take on the text-network modeling idea .",
    "NOVELTY"
  ],
  [
    "the distributed Chebyshev Solver is non-trivial and it is an interesting idea to introduce such a technique into distributed Multitask Reinforcement Learning",
    "NOVELTY"
  ],
  [
    "which is very well described in the related work section , the paper presents novelty in the details of their approach and their goal to estimate full cause-specific and all-cause hazards .",
    "NOVELTY"
  ],
  [
    "The method is novel and tested on multiple audio classification datasets and results show a good compression ratio with a negligible accuracy drop",
    "NOVELTY"
  ],
  [
    "A relatively efficient way of exploiting second order dynamics in GAN training via latent space optimization .",
    "NOVELTY"
  ],
  [
    "All in all , this appears to be a solid contribution to the GAN literature , addressing some of the limitations of CS-GAN [ 1 ] .",
    "NOVELTY"
  ],
  [
    "there are some good technical contributions",
    "NOVELTY"
  ],
  [
    "this seems like a solid contribution on the technical side",
    "NOVELTY"
  ],
  [
    "Overall , I think the strongest part of this paper is in its conceptual contributions - I find the work thought-provoking and inspiring .",
    "NOVELTY"
  ],
  [
    "this approach is clearly interesting from a theoretical viewpoint .",
    "NOVELTY"
  ],
  [
    "the regret analysis derived for this class of problems is original",
    "NOVELTY"
  ],
  [
    "The paper presents an intriguing approach to outlier detection .",
    "NOVELTY"
  ],
  [
    "The work has limited novelty",
    "NOVELTY"
  ],
  [
    "However , I found the contribution of the actor-critic model is insufficient",
    "NOVELTY"
  ],
  [
    "I like the ideas and they have received enough scrutiny already .",
    "NOVELTY"
  ],
  [
    "The idea of using task decomposition to create intrinsic rewards seems really interesting",
    "NOVELTY"
  ],
  [
    "I also have a concern about the novelty of the approach",
    "NOVELTY"
  ],
  [
    "I think it is not novel enough for publication at ICLR",
    "NOVELTY"
  ],
  [
    "However , I do not see any novel findings in this study .",
    "NOVELTY"
  ],
  [
    "Overall , it is unclear what is the major novel contribution in this paper .",
    "NOVELTY"
  ],
  [
    "paper introduces a novel method for language modeling which is suitable for both modeling programming language as well as natural language .",
    "NOVELTY"
  ],
  [
    "Novel approach .",
    "NOVELTY"
  ],
  [
    "and the proposed solution novel",
    "NOVELTY"
  ],
  [
    "As far as I am aware this is a novel approach to estimating the value functions that has some potentially big advantages",
    "NOVELTY"
  ],
  [
    "The authors frame this as a novel idea/framework and do not make empirical claims",
    "NOVELTY"
  ],
  [
    "IMO this is an interesting , novel direction that is worth pursuing .",
    "NOVELTY"
  ],
  [
    "as it provides a new perspective/form for the value function and may inspire related ideas",
    "NOVELTY"
  ],
  [
    "Although the paper is incremental , it makes the following contributions",
    "NOVELTY"
  ],
  [
    "it has only a single hyper-parameter",
    "NOVELTY"
  ],
  [
    "The manuscript presents a novel approach to imitation learning .",
    "NOVELTY"
  ],
  [
    "Overall , there is some interesting innovation in the paper .",
    "NOVELTY"
  ],
  [
    "In terms of novelty",
    "NOVELTY"
  ],
  [
    "while the idea of making a conditional extension to the generative moment matching framework is quite natural",
    "NOVELTY"
  ],
  [
    "the mechanism and derivation of the empirical estimator was not obvious",
    "NOVELTY"
  ],
  [
    "I am not completely convinced by the",
    "NOVELTY"
  ],
  [
    "The conclusions of the paper",
    "NOVELTY"
  ],
  [
    "From methodological point of view , this idea is quite straightforward and not novel , since there are already several works that applied ensemble methods to improve the robustness of NNs",
    "NOVELTY"
  ],
  [
    "thus in some ways the paper is not very original",
    "NOVELTY"
  ],
  [
    "As for the contribution",
    "NOVELTY"
  ],
  [
    "piece with",
    "NOVELTY"
  ],
  [
    "but contribution of this work is limited",
    "NOVELTY"
  ],
  [
    "However , I am not sure if the paper presents a case of adequate novelty in terms of ideas as many of them are rather obvious and the current state-of-the-art models could also improve considerably using similar experimental setups",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is minor , since similar approaches have been done before .",
    "NOVELTY"
  ],
  [
    "performing dimensionality reduction to learn the low dimensional manifolds is popular in the research community , the extensions made and the approach authors have considered seems to be novel .",
    "NOVELTY"
  ],
  [
    "The idea is clear",
    "NOVELTY"
  ],
  [
    "which I did not find very insightful",
    "NOVELTY"
  ],
  [
    "To sump up , there are some interesting ideas in this paper .",
    "NOVELTY"
  ],
  [
    "paper proposes a novel architecture in the context of multitask learning and deep dependency structure",
    "NOVELTY"
  ],
  [
    "I feel this paper still presents",
    "NOVELTY"
  ],
  [
    "interesting contribution to the field",
    "NOVELTY"
  ],
  [
    "The resource constraint regularization is interesting .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel",
    "NOVELTY"
  ],
  [
    "but the main concern here",
    "NOVELTY"
  ],
  [
    "win over existing techniques in terms of performance",
    "NOVELTY"
  ],
  [
    "However , I overall liked the idea of using neural nets to design codes for some non-standard channels .",
    "NOVELTY"
  ],
  [
    "While at the decoding end it does not bring in anything new",
    "NOVELTY"
  ],
  [
    "Approximation for linear functions and polynomial have been studied in previous work",
    "NOVELTY"
  ],
  [
    "but I found the results interesting ,",
    "NOVELTY"
  ],
  [
    "The proposed ideas are quite interesting ,",
    "NOVELTY"
  ],
  [
    "Though there exist other works that weight samples from a replay buffer this paper presents a concrete alternative to one of off-policy learnings biggest woes : importance sampling . The paper provides extensive theoretical treatment and empirical validation that are original as far as i know .",
    "NOVELTY"
  ],
  [
    "While the ideas are so simple that they border on being trivial generalizations of previous work",
    "NOVELTY"
  ],
  [
    "The ideas underlying HSimplE and HypE are natural and clear",
    "NOVELTY"
  ],
  [
    "The ideas are obvious",
    "NOVELTY"
  ],
  [
    "the results are unsurprising ; the paper lacks `` deep insight `` .",
    "NOVELTY"
  ],
  [
    "I really like the idea of HypE ,",
    "NOVELTY"
  ],
  [
    "Overall , the model is a natural extension of both adversarial autoencoders and autoregressive models , and the paper presents a nice follow-up to VLAE and PixelVAE ( which study VAEs with autoregressive decoders ) .",
    "NOVELTY"
  ],
  [
    "The basic algorithm here is unsurprising",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is ok , but it \u2019 s partially based on Deep InfoMax",
    "NOVELTY"
  ],
  [
    "\u2013 Active perception , and more specifically recognition through saccades ( or viewpoint selection ) is an interesting biologically-inspired approach and seems like an intuitive and promising way to improve efficiency .",
    "NOVELTY"
  ],
  [
    "this paper provides many theoretical results concerning generative methods . Even though I am not very familiar with the theory of optimal transport , the proposed content seems novel",
    "NOVELTY"
  ],
  [
    "Compared to its predecessors , its contributions are three-fold",
    "NOVELTY"
  ],
  [
    "it introduces a new model for combinatorial tasks which delivers interesting results on several tasks which are varied though related",
    "NOVELTY"
  ],
  [
    "the contributions of this",
    "NOVELTY"
  ],
  [
    "paper are interesting but not ground-breaking . The REINFORCE tweak is close to other algorithms that have been tried in the last few years",
    "NOVELTY"
  ],
  [
    "The model architecture , while successful , is not a large departure from the Transformer presented in Vaswani et al , 2017 .",
    "NOVELTY"
  ],
  [
    "direction",
    "NOVELTY"
  ],
  [
    "the theoretical contributions are not ground-breaking",
    "NOVELTY"
  ],
  [
    "this could be a very good contribution to the field",
    "NOVELTY"
  ],
  [
    "it is clear that the novelty of the paper us much less than what I had initially thought",
    "NOVELTY"
  ],
  [
    "This idea is not novel but the authors report that there is no previous work that jointly trains sentiment aware embeddings with a sentiment classifier specifically",
    "NOVELTY"
  ],
  [
    "Analytical framework using state-space model proposed by authors is novel and very interesting .",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting that designing a two steps learning pipeline based on the shared latent space assumption which is implemented with the simple weight sharing technique",
    "NOVELTY"
  ],
  [
    "-- I did not find anything novel in this paper . The proposed incremental learning schedule is nothing new and is a natural thing to try when learning sequences . Similar idea have already been tried by a number of authors",
    "NOVELTY"
  ],
  [
    "The contributions of the work are very limited .",
    "NOVELTY"
  ],
  [
    "Method-wise , the encoder is not novel and decoder is rather straightforward . The contributions of the work are in general very limited .",
    "NOVELTY"
  ],
  [
    "The contributions of the work are very limited .",
    "NOVELTY"
  ],
  [
    "The paper seems original",
    "NOVELTY"
  ],
  [
    "but novel way of combining policies",
    "NOVELTY"
  ],
  [
    "While adding discrimative losses to intermediate layers of neural nets is not entirely new",
    "NOVELTY"
  ],
  [
    "the proposed method does demonstrate reasonable amount of novelty to obtain good empirical performance .",
    "NOVELTY"
  ],
  [
    "the approaches adopted in the paper and its focus significantly differs from some of the existing papers in this area .",
    "NOVELTY"
  ],
  [
    "While the first 3 auxiliary tasks are quite common , the 4th tasks called piecewise-linear autoencoding appears novel .",
    "NOVELTY"
  ],
  [
    "I think this is a nice paper with nice contributions",
    "NOVELTY"
  ],
  [
    "It is only an incremental but important step .",
    "NOVELTY"
  ],
  [
    "However , it turns out that this is not detrimental",
    "NOVELTY"
  ],
  [
    "This work seems to be original and significant",
    "NOVELTY"
  ],
  [
    "while the basic idea is nice",
    "NOVELTY"
  ],
  [
    "2 .The idea of sequential mini-batch translation connects nicely to the old school of making images by layering .",
    "NOVELTY"
  ],
  [
    "Quality The quality of the submission is extremely low",
    "NOVELTY"
  ],
  [
    "Originality The idea of visualizing states that reveal interesting insights about an agent 's behavior based on a user-defined target function sounds interesting .",
    "NOVELTY"
  ],
  [
    "While I do agree that the paper proposes an interesting idea",
    "NOVELTY"
  ],
  [
    "but the contribution seems marginal .",
    "NOVELTY"
  ],
  [
    "The novelty is incremental in most parts , but the overall",
    "NOVELTY"
  ],
  [
    "system can be seen as novel",
    "NOVELTY"
  ],
  [
    "I quite like the proposed model",
    "NOVELTY"
  ],
  [
    "the improvements appear relatively small ( especially for Neuron dataset ) given the enormous complexity of the model compared to baseline U-Net",
    "NOVELTY"
  ],
  [
    "But the analysis on the directional uniformity is interesting and original .",
    "NOVELTY"
  ],
  [
    "3 .This paper provides some",
    "NOVELTY"
  ],
  [
    "The results seem to be increment extension to previous work .",
    "NOVELTY"
  ],
  [
    "and somewhat incremental",
    "NOVELTY"
  ],
  [
    "My main concern is about the limited novelty of approach . The knowledge distillation method developed in the paper seems not particularly novel in principle .",
    "NOVELTY"
  ],
  [
    "Although interesting and showing some promise in",
    "NOVELTY"
  ],
  [
    "a bunch of",
    "NOVELTY"
  ],
  [
    "applications",
    "NOVELTY"
  ],
  [
    "I am still not convinced that the proposed approach is novel enough in principle .",
    "NOVELTY"
  ],
  [
    "I find the idea of fast/slow weights to be a refreshing and different approach compared to previous work on catastrophic forgetting .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is mostly experimental",
    "NOVELTY"
  ],
  [
    "While the idea of end-to-end training of musical synthesizers is interesting and timely",
    "NOVELTY"
  ],
  [
    "this is an interesting idea , and potentially an interesting system",
    "NOVELTY"
  ],
  [
    "This is a technically nontrivial paper about ordinal embedding with novel and interesting results and ideas .",
    "NOVELTY"
  ],
  [
    "One major weakness of this work is lack of technical novelty .",
    "NOVELTY"
  ],
  [
    "the method may be practically viable but bear little technical novelty .",
    "NOVELTY"
  ],
  [
    "I personally find the idea of incorporating the structural signature for input graphs into the GCN to modulate the parameters of the inference model very interesting .",
    "NOVELTY"
  ],
  [
    "I think this paper lacks technical novelty .",
    "NOVELTY"
  ],
  [
    "and I think the ideas presented in the paper are novel and interesting",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel and it replaces fully connected pattern of feature maps with 1-D convolutions .",
    "NOVELTY"
  ],
  [
    "The idea is novel , the paper",
    "NOVELTY"
  ],
  [
    "Overall , the technical contribution seems limited .",
    "NOVELTY"
  ],
  [
    "The second main contribution of the paper is",
    "NOVELTY"
  ],
  [
    "The modeling novelty is quite limited .",
    "NOVELTY"
  ],
  [
    "novelty is limited . Using per-image semantic information is not new in zero-shot learning at all .",
    "NOVELTY"
  ],
  [
    "' 16 .Metric scaling is not novel either .",
    "NOVELTY"
  ],
  [
    "Extending this idea to generalized zero-shot learning is not a sufficient contribution for ICLR .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the method presented in this paper is novel .",
    "NOVELTY"
  ],
  [
    "There is very little new theory in this paper",
    "NOVELTY"
  ],
  [
    "good",
    "NOVELTY"
  ],
  [
    "but provides many new insights about the problem or can be transferred to many different domains",
    "NOVELTY"
  ],
  [
    "The work seems to build upon a previous work , namely , tensor space language model ( TSLM ) .",
    "NOVELTY"
  ],
  [
    "To my knowledge , it is the first algorithm for learning a universal Lipschitz function under the architecture of neural network .",
    "NOVELTY"
  ],
  [
    "One-class extension of the prototypical network is a new idea , while prototypical networks are already popular for few-shot learning problems .",
    "NOVELTY"
  ],
  [
    "The contributions seem very incremental . Applying GANs for data augmentation is not new and regarding the policy search the authors strongly base their approach in Cubuk19",
    "NOVELTY"
  ],
  [
    "The paper is more technical than insightful",
    "NOVELTY"
  ],
  [
    "I find it hard to assess the novelty of this work because 1 ) the algorithm looks like a trivial application of continuous-time normalizing flow to graph data using message passing algorithm",
    "NOVELTY"
  ],
  [
    "I failed to find any algorithmic innovation more than a mere application of continuous-time flow to graph data .",
    "NOVELTY"
  ],
  [
    "the idea of using mixture of trees to do policy extraction is somewhat incremental",
    "NOVELTY"
  ],
  [
    "The novel aspect of the paper is employing a mixture of expert trees model instead of a single decision tree in Viper .",
    "NOVELTY"
  ],
  [
    "The proposed method is somewhat incremental in the sense that it is equivalent to replacing the first layer of the hard decision tree with a soft decision layer",
    "NOVELTY"
  ],
  [
    "Overall , the approach seems to be an incremental improvement over the previous work ResNeXt .",
    "NOVELTY"
  ],
  [
    "I feel the paper demonstrates neither enough novelty nor enough of a performance gain for me to advocate acceptance .",
    "NOVELTY"
  ],
  [
    "Originality and significance The unifying framework is interesting , and helps shed new light on some standard issues in sequence generation .",
    "NOVELTY"
  ],
  [
    "the new algorithm and its analysis seem like a slightly rushed attempt at leveraging the unifying framework",
    "NOVELTY"
  ],
  [
    "the first half of the paper is interesting and insightful",
    "NOVELTY"
  ],
  [
    "clarity of the ideas that are presented - interesting unifying perspective on sequence generation algorithms - insightful new interpretations of existing algorithms in terms of exploration Cons",
    "NOVELTY"
  ],
  [
    "the example new algorithm is not very original",
    "NOVELTY"
  ],
  [
    "The idea",
    "NOVELTY"
  ],
  [
    "I found the approach and content of the paper interesting and",
    "NOVELTY"
  ],
  [
    "I find the approach taken by the authors interesting and different from current MI estimation approaches .",
    "NOVELTY"
  ],
  [
    "The paper provides similar results to previous work , while removing some of the assumptions made in previous work . In that sense , the originality of the results is weak",
    "NOVELTY"
  ],
  [
    "I think the idea is original",
    "NOVELTY"
  ],
  [
    "-The formulation is interesting",
    "NOVELTY"
  ],
  [
    "To me the general idea is a straightforward application of GANs to the general inpainting/denoising problem",
    "NOVELTY"
  ],
  [
    "maybe not so novel since learning proposal distributions has been explored before",
    "NOVELTY"
  ],
  [
    "translation is not a new finding",
    "NOVELTY"
  ],
  [
    "I think the ideas presented in this paper are interesting",
    "NOVELTY"
  ],
  [
    "and on its own is somewhat incremental in nature",
    "NOVELTY"
  ],
  [
    "I like the new ideas in this paper",
    "NOVELTY"
  ],
  [
    "While the proposed approach is quite interesting",
    "NOVELTY"
  ],
  [
    "The approach is definitely interesting",
    "NOVELTY"
  ],
  [
    "The technical contribution -",
    "NOVELTY"
  ],
  [
    "detecting class skews , is marginal .",
    "NOVELTY"
  ],
  [
    "The general idea of suprising-driven feedback",
    "NOVELTY"
  ],
  [
    "Interesting idea - Seems to improve performances Cons",
    "NOVELTY"
  ],
  [
    "approach here is novel , technically deep and ( apparently ) sound , on a problem lots of smart people have thought about",
    "NOVELTY"
  ],
  [
    "but overall this is a novel approach to a hard problem and I can imagine this generating substantial follow-on work",
    "NOVELTY"
  ],
  [
    "this is the first work that demonstrates",
    "NOVELTY"
  ],
  [
    "A different view on IWAE-STL and IWAE-DREG is interesting and novel ( as mentioned above ) .",
    "NOVELTY"
  ],
  [
    "The recommendation of using RWS-style algorithms over IWAE as given in the abstract",
    "NOVELTY"
  ],
  [
    "is also not novel since this is also advocated by",
    "NOVELTY"
  ],
  [
    "My two main concerns are ( 1 ) lack of novelty and",
    "NOVELTY"
  ],
  [
    "the experimental evaluation",
    "NOVELTY"
  ],
  [
    "Overall , it is a decent contribution .",
    "NOVELTY"
  ],
  [
    "the main limitation of this paper is the lack of contribution . The proposed method can be seen as a relatively straightforward combination of existing works",
    "NOVELTY"
  ],
  [
    "which are missing in the related work section",
    "NOVELTY"
  ],
  [
    "The idea of building the high-level graph based on the sampled landmark states , and performing the planning (",
    "NOVELTY"
  ],
  [
    "in the graph to find the shortest path to the goal has been already proposed in [ 1",
    "NOVELTY"
  ],
  [
    "interesting , and novel - Use of feature-level set encoding is an interesting application of some recent work to this area",
    "NOVELTY"
  ],
  [
    "The CV proposed is clever",
    "NOVELTY"
  ],
  [
    "This is a contribution that can easily be incorporated when using the reparametrization trick",
    "NOVELTY"
  ],
  [
    "The methodology is novel and interesting",
    "NOVELTY"
  ],
  [
    "The idea is clean and inspiring .",
    "NOVELTY"
  ],
  [
    "While in terms of novelty , no new techniques/algorithms are proposed",
    "NOVELTY"
  ],
  [
    "My main concern for this paper is its novelty and whether it can be generalized to other models .",
    "NOVELTY"
  ],
  [
    "the object relation transformer model is a small variation of the standard transformer",
    "NOVELTY"
  ],
  [
    "the material presented here is original and has not appeared elsewhere Quality and significance",
    "NOVELTY"
  ],
  [
    "and I think it is a nice idea",
    "NOVELTY"
  ],
  [
    "The studied problem is original ,",
    "NOVELTY"
  ],
  [
    "I believe the paper arguably appears to be among very few works studying such a problem in TS",
    "NOVELTY"
  ],
  [
    "This paper is certainly very interesting , unlike other papers and makes some very solid contributions .",
    "NOVELTY"
  ],
  [
    "While the proposed approach is based on well-known models and techniques ( and thus is not new itself )",
    "NOVELTY"
  ],
  [
    ", to the best of my knowledge it has not been applied to the problem of estimating predictive uncertainty so far and could serve as a good benchmark in future",
    "NOVELTY"
  ],
  [
    "A drawback compared to the Bayesian models is that the approach comes without mathematical framework and guarantees .",
    "NOVELTY"
  ],
  [
    "the `` oracle with epiphany `` model is new to me , and I think it is interesting .",
    "NOVELTY"
  ],
  [
    "Novel formulation and approach that appears to be well-motivated from the literature on randomized gradient-free search methods .",
    "NOVELTY"
  ],
  [
    "approach with strong empirical results .",
    "NOVELTY"
  ],
  [
    "other works has more to offer but this is a promising technique for learning",
    "NOVELTY"
  ],
  [
    "The paper is incremental with limited novelty",
    "NOVELTY"
  ],
  [
    "While the approach is interesting and the",
    "NOVELTY"
  ],
  [
    "the approach is not fundamentally different from standard networks with cross-entropy training .",
    "NOVELTY"
  ],
  [
    "I find the proposed approach to watermark evasion interesting .",
    "NOVELTY"
  ],
  [
    "despite such attractive points , the novelty and strength of this study is not outstanding enough for publication in ICLR",
    "NOVELTY"
  ],
  [
    "which reduce the novelty of this study",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "However , it is kind of hard to claim this as novelty .",
    "NOVELTY"
  ],
  [
    "this paper seems like a preliminary work on framework/task definition",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this `` informationally asymmetric `` KL-regularization approach is novel .",
    "NOVELTY"
  ],
  [
    "-- Significance -- I think the idea of regularizing RL via an informationally asymmetric default policy is interesting .",
    "NOVELTY"
  ],
  [
    "The idea of regularizing RL via an informationally asymmetric default policy is interesting . To the best of my knowledge , this `` informationally asymmetric `` KL-regularization approach is novel .",
    "NOVELTY"
  ],
  [
    "The novelty of the ideas in the paper is perhaps limited (",
    "NOVELTY"
  ],
  [
    "but I liked the analysis and the resulting possibilities that the proposed method",
    "NOVELTY"
  ],
  [
    "and the technical contribution is quite vague",
    "NOVELTY"
  ],
  [
    "Although the idea of compressing the ( word ) embedding layer using low-rank structures is not new",
    "NOVELTY"
  ],
  [
    "At first glance , the idea presented in this paper seems not new",
    "NOVELTY"
  ],
  [
    "This paper proposes a brand new dataset that is unique in that it contains images paired with text with bias labels ( both noisy labels from source and also human labels ) .",
    "NOVELTY"
  ],
  [
    "I believe this is original",
    "NOVELTY"
  ],
  [
    ", but it 's a natural evolution of previous work on rerooting",
    "NOVELTY"
  ],
  [
    "The Edward library is clearly a unique collection of probabilistic inference methods .",
    "NOVELTY"
  ],
  [
    "In terms of the paper , the main threat to novelty comes from previous publications of the same group .",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel up to my knowledge . I find the idea of parameterizing the successor features in terms of the policy parameters very innovative .",
    "NOVELTY"
  ],
  [
    "There is nothing much new in the reader model ( quite standard approaches for MRC ) , so I am worried about the novelty of the paper . Overall",
    "NOVELTY"
  ],
  [
    "the contribution does not seem to be significant enough for ICLR .",
    "NOVELTY"
  ],
  [
    "It is a neat idea to introduce a different proximal term of the continuous variable w",
    "NOVELTY"
  ],
  [
    "The idea is",
    "NOVELTY"
  ],
  [
    "Although it is a small idea and kind of overlapping other ideas at a high level",
    "NOVELTY"
  ],
  [
    "I agree with other reviewers that the contribution of this work is solid although the change is slight",
    "NOVELTY"
  ],
  [
    "I am not aware of similar work and believe the idea is novel .",
    "NOVELTY"
  ],
  [
    "The idea of representing the architecture distribution using VAEs is very natural , which in principle could offer better coverage over interesting regions in the search space as compared to traditional factorized distribution representation ( which has a single mode only ) .",
    "NOVELTY"
  ],
  [
    "Such variational inference arguments for transfer learning in the context of MDPs are not new .",
    "NOVELTY"
  ],
  [
    "While the technique presented is not groundbreaking",
    "NOVELTY"
  ],
  [
    "The method seems new to me .",
    "NOVELTY"
  ],
  [
    "The connection to SMLC is interesting and it may contain lot of insights .",
    "NOVELTY"
  ],
  [
    "The concept of building continuous-time models ( or ODEs ) for stochastic optimization algorithms is not novel .",
    "NOVELTY"
  ],
  [
    "The approach is a novel twist on an existing method for learning from noisy data .",
    "NOVELTY"
  ],
  [
    "The idea of regularizing the logits is natural and precisely understanding its effect on the model is a valuable research direction . Overall I like the idea of the paper .",
    "NOVELTY"
  ],
  [
    "The proposed work is not the first to apply MPC to data center cooling .",
    "NOVELTY"
  ],
  [
    "I believe the idea is novel",
    "NOVELTY"
  ],
  [
    "Novelty : the proposed model is a small extension of a previous work ( Wang et al.",
    "NOVELTY"
  ],
  [
    "# 2 .",
    "NOVELTY"
  ],
  [
    "Although the introduced new concepts and ideas are interesting",
    "NOVELTY"
  ],
  [
    "The main issue of the paper is the novelty of the model and the inference . The model structure of using gamma parameters to incorporate meta information has been explored in several previous works and this paper did n't provide a structure with much differences to the previous ones .",
    "NOVELTY"
  ],
  [
    "to me , the proposed GDMF ( the one without meta info ) is similar to DCPF , in terms of model structure",
    "NOVELTY"
  ],
  [
    "The novelty of the model structure and the inference is limited .",
    "NOVELTY"
  ],
  [
    "There is no significant technical contribution",
    "NOVELTY"
  ],
  [
    "Even if no-one has had that idea before - it would be a minor contribution , but given that there is prior work on meta-learning in the context of model-based RL , this idea itself is not novel anymore",
    "NOVELTY"
  ],
  [
    "Quality This paper does not set out to produce a novel network architecture .",
    "NOVELTY"
  ],
  [
    "This is interesting and novel enough in my opinion to warrant publication at ICLR",
    "NOVELTY"
  ],
  [
    "The novelty in terms of techniques seems limited and the theory results not too surprising .",
    "NOVELTY"
  ],
  [
    "But , as the paper contains limited indications of its",
    "NOVELTY"
  ],
  [
    "I rate this contribution as insufficient for NIPS .",
    "NOVELTY"
  ],
  [
    "It seems to me that the methodological novelty is limited",
    "NOVELTY"
  ],
  [
    "the first claimed contribution of 5 times more concepts than previous work does not result in any significant difference from the previous approaches . 2 .The analysis presented in this work does not really give new insights .",
    "NOVELTY"
  ],
  [
    "Overall , this paper provides a nontrivial contribution for performing principal component analysis ( PCA ) using linear autoencoders ( LAEs ) , with this new novel loss function .",
    "NOVELTY"
  ],
  [
    "But I think the idea is both novel , general and the proposed data augmented Gibbs sampling algorithm make the paper an attractive contribution that could be studied and developed further in other model settings .",
    "NOVELTY"
  ],
  [
    "I am not sure if this work has been done before",
    "NOVELTY"
  ],
  [
    "Although the MFA is a known technique , employing it for FV coding is novel and effective .",
    "NOVELTY"
  ],
  [
    "I think this is a nice piece of work with simple but insightful ideas that will attract extensive attention",
    "NOVELTY"
  ],
  [
    "rather narrow",
    "NOVELTY"
  ],
  [
    "However , I do n't think the paper presents enough contribution and novelty .",
    "NOVELTY"
  ],
  [
    "The idea is novel and the experiment results suggest that the additional `` adversarial `` target helps",
    "NOVELTY"
  ],
  [
    "This work seems to be the first attempt to adopt the few-shot learning in graph classification tasks . The architecture is novel , and the classification of graph based on spectral embedding together with the Wasserstein metric is novel to me .",
    "NOVELTY"
  ],
  [
    "Overall , this paper could be a considerable theoretical contribution .",
    "NOVELTY"
  ],
  [
    "In terms of originality , the proposed margin based hinge loss is similar to the L1-regularized hinge loss in Rigaill et al",
    "NOVELTY"
  ],
  [
    "and the novelty of the work satisfies the NIPS standards .",
    "NOVELTY"
  ],
  [
    "the formulation of TVO is an interesting idea .",
    "NOVELTY"
  ],
  [
    "The connections to previous methods provides a new insights about unifying different learning methods .",
    "NOVELTY"
  ],
  [
    "The overall approach considered is interesting , and for the most",
    "NOVELTY"
  ],
  [
    "There is no new novel model or technique proposed in the paper .",
    "NOVELTY"
  ],
  [
    "Pros The proposed model provides a new view to generate training examples for random-walk-based embedding models .",
    "NOVELTY"
  ],
  [
    "The novelty is limited .",
    "NOVELTY"
  ],
  [
    "the paper lacks strong novelty",
    "NOVELTY"
  ],
  [
    "The idea is quite intriguing",
    "NOVELTY"
  ],
  [
    "Thus , the problem in this paper is new .",
    "NOVELTY"
  ],
  [
    "However , the proposed algorithm and the techniques to analyze its complexity is similar to those in [ RSW16 ] , which makes the contribution of this paper incremental .",
    "NOVELTY"
  ],
  [
    "Overall the presented result is timely and novel by providing a significant improvement over existing works .",
    "NOVELTY"
  ],
  [
    "This is an interesting approach",
    "NOVELTY"
  ],
  [
    "Although the technique in this paper is not that 'fancy",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is the first one with formal guarantees for the IRL problem",
    "NOVELTY"
  ],
  [
    "The final result for the CMAB problem is not trivial yet not very surprising",
    "NOVELTY"
  ],
  [
    "It introduces an elegant generalization of Amsgrad that",
    "NOVELTY"
  ],
  [
    "The whole relationship of SGD step size schedules to generalization",
    "NOVELTY"
  ],
  [
    "is certainly nontrivial",
    "NOVELTY"
  ],
  [
    "hierarchical levels of categories is novel",
    "NOVELTY"
  ],
  [
    "Given papers",
    "NOVELTY"
  ],
  [
    "I would say the current paper is not the first study of balancing g exposures in social networks .",
    "NOVELTY"
  ],
  [
    "I 'd like to emphasize that the creation of a large scale semantic parsing dataset is fantastic , and it is a much appreciated contribution",
    "NOVELTY"
  ],
  [
    "While the data contribution is great",
    "NOVELTY"
  ],
  [
    "Although it is an adaptation of an existing method",
    "NOVELTY"
  ],
  [
    "Although it is an adaptation",
    "NOVELTY"
  ],
  [
    "of an existing method ,",
    "NOVELTY"
  ],
  [
    "but the paper has issues with clarity and the rest of the framework is a bit limited in novelty (",
    "NOVELTY"
  ],
  [
    "GIN )",
    "NOVELTY"
  ],
  [
    "Review scores reflect this reviewers impression as `` an extremely well executed , albeit",
    "NOVELTY"
  ],
  [
    "incremental",
    "NOVELTY"
  ],
  [
    "the novelty of the main idea is marginal",
    "NOVELTY"
  ],
  [
    "The results presented by the authors are , to the best of my knowledge , novel and significant .",
    "NOVELTY"
  ],
  [
    "Overall , this is a good work with limited novelty but",
    "NOVELTY"
  ],
  [
    "the machine learning novelties and the contributions of this paper is ambiguous .",
    "NOVELTY"
  ],
  [
    "None of these ideas is fundamentally new",
    "NOVELTY"
  ],
  [
    ", but the descriptions and their combination is very nice .",
    "NOVELTY"
  ],
  [
    "Therefore , the contribution of the paper is limited since I can not judge whether the findings really tell me something about a unique relation between high-performing CNNs and the human visual system",
    "NOVELTY"
  ],
  [
    "All in all , I think that the paper now constitutes a decent contribution relating state-of-the art CNNs to human psychophysics and I would be happy for this work to be accepted",
    "NOVELTY"
  ],
  [
    "The paper lacks technical novelty .",
    "NOVELTY"
  ],
  [
    "While there has been long line of works in understanding Nystorm methods , the result obtained in this paper is new .",
    "NOVELTY"
  ],
  [
    "The idea of using a predefined basis to estimate filter weights in a neural network is novel and leads to significant reduction in memory usage .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel reinforcement adversarial learning approach for image enhancement",
    "NOVELTY"
  ],
  [
    "The overall strategy is very interesting",
    "NOVELTY"
  ],
  [
    "The proposed method is not very original since it is based on applying an existing technique ( normalizing flow networks",
    "NOVELTY"
  ],
  [
    "that of finding a maximum entropy distribution . The methodological contributions are almost non-existing .",
    "NOVELTY"
  ],
  [
    "The author do have some interesting derivations and results , and they do contribution with some novel insights .",
    "NOVELTY"
  ],
  [
    "Now the thing is that results concerning the behavior of maximum likelihood under misspecification are rather old",
    "NOVELTY"
  ],
  [
    "The differential geometry perspective is novel .",
    "NOVELTY"
  ],
  [
    "Overall , I think that this paper makes interesting and novel contributions .",
    "NOVELTY"
  ],
  [
    "The paper provides simple results and algorithms that , to the best of my knowledge , are quite clever and novel .",
    "NOVELTY"
  ],
  [
    "Overall conclusion : This paper is largely empirical and lacks technical depth .",
    "NOVELTY"
  ],
  [
    "This is a very interesting approach",
    "NOVELTY"
  ],
  [
    "So the idea itself is novel",
    "NOVELTY"
  ],
  [
    "while the idea is interesting",
    "NOVELTY"
  ],
  [
    "the paper does not offer significant technical contributions . Most of the techniques are not new",
    "NOVELTY"
  ],
  [
    "a bit too toy",
    "NOVELTY"
  ],
  [
    "Therefore I would say the proposed idea is new",
    "NOVELTY"
  ],
  [
    "The major drawback of the paper is a lack of novelty - the Go-Explore algorithm is already well known",
    "NOVELTY"
  ],
  [
    "the paper does not provide any insight beyond",
    "NOVELTY"
  ],
  [
    "and it successfully extends the existing work .",
    "NOVELTY"
  ],
  [
    "The extension to the model with bias seems a bit incremental .",
    "NOVELTY"
  ],
  [
    "The paper presents both a novel large dataset of sketches and a new rnn architecture to generate new sketches . + new and large dataset + novel algorithm +",
    "NOVELTY"
  ],
  [
    "The presented algorithm sketch-rnn seems novel and significantly different from prior work .",
    "NOVELTY"
  ],
  [
    "In my opinion , the ideas in the paper are exciting",
    "NOVELTY"
  ],
  [
    "According to my knowledge , this is the first paper to study the complete visual perception pipeline in autonomous driving .",
    "NOVELTY"
  ],
  [
    "I think this is a nice contribution",
    "NOVELTY"
  ],
  [
    "The method is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "Overall , I find the method interesting .",
    "NOVELTY"
  ],
  [
    "The proposed co-evolving latent feature process model is interesting",
    "NOVELTY"
  ],
  [
    "The notion of the polytope is interesting",
    "NOVELTY"
  ],
  [
    "This sentence",
    "NOVELTY"
  ],
  [
    "is not something that is novel to your paper",
    "NOVELTY"
  ],
  [
    "this contribution seems",
    "NOVELTY"
  ],
  [
    "No stunning new ideas but a very good combination of interesting approaches into one really combined one .",
    "NOVELTY"
  ],
  [
    "The use of a mixture of VAE is an incremental idea if novel .",
    "NOVELTY"
  ],
  [
    "Hyperbolic matching function is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and interesting",
    "NOVELTY"
  ],
  [
    "This method strictly improves over previous",
    "NOVELTY"
  ],
  [
    "the contribution of the paper is rather incremental .",
    "NOVELTY"
  ],
  [
    "the paper borrows the general idea of product keys from the database community",
    "NOVELTY"
  ],
  [
    "however the application to fast retrieval in neural memory systems seems quite novel to me",
    "NOVELTY"
  ],
  [
    "The first observation is interesting , is explained clearly and convincingly , and is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "it is not the first work that proposes to combine planning with representation learning ,",
    "NOVELTY"
  ],
  [
    "The method is a straight-forward combination of existing methods , so methodologically the novelty is kind of limited .",
    "NOVELTY"
  ],
  [
    "The new algorithm improves upon Analyze Gauss in only a relatively small set of parameter regimes",
    "NOVELTY"
  ],
  [
    "The ABM model itself is somewhat novel",
    "NOVELTY"
  ],
  [
    "Moreover , the path-following strategy used for convex-concave relaxations is also not new .",
    "NOVELTY"
  ],
  [
    ".I found the paper quite interesting and the analysis novel",
    "NOVELTY"
  ],
  [
    "It oversells the task/framework . The proposed task/framework is not different from what others have done .",
    "NOVELTY"
  ],
  [
    "There is not much novelty in the paper .",
    "NOVELTY"
  ],
  [
    "There is not much novelty in the method either . The paper proposes to use gated attention , which is not novel and it does not help much according to Figures 3b and 4b",
    "NOVELTY"
  ],
  [
    "the paper is mostly original in considering the problem of robustness to multiple perturbation types .",
    "NOVELTY"
  ],
  [
    "as space is quite limited and the contributions of this paper are somewhat heterogeneous in nature",
    "NOVELTY"
  ],
  [
    "The theoretical result ( Theorem 1 ) on the accuracy of NSUM is new and thus motivates to develop an unbiased and accurate estimator . + The problem addressed in the paper , which is concerned with the cluster size as well as the number of vertices , has a certain novelty .",
    "NOVELTY"
  ],
  [
    "I could not determine the novelty of the techniques used as there is no clear indication in the paper of what results are new or rather simple extensions of previous results",
    "NOVELTY"
  ],
  [
    "My main concern is about the novelty of technical contribution which is mainly composed by two",
    "NOVELTY"
  ],
  [
    "The overall contribution is incremental with limited novelty .",
    "NOVELTY"
  ],
  [
    "It is admirable that the authors use an interesting ( and to my knowledge novel ) data set .",
    "NOVELTY"
  ],
  [
    "i found the idea interesting though",
    "NOVELTY"
  ],
  [
    "That being said , the theoretical treatment does strike me as novel .",
    "NOVELTY"
  ],
  [
    "The idea is elegant and intuitive",
    "NOVELTY"
  ],
  [
    "I believe the work is original .",
    "NOVELTY"
  ],
  [
    "over prior neural link prediction methods",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is relatively novel and seems effective",
    "NOVELTY"
  ],
  [
    "The online algorithm and robustness is significantly interesting and novel on its own .",
    "NOVELTY"
  ],
  [
    "definitely novel",
    "NOVELTY"
  ],
  [
    "The multiscale Bernstein condition is novel and crucial",
    "NOVELTY"
  ],
  [
    "The concern is that the contribution is quite incremental from the theoretical side though it involves large amount of experimental efforts , which could be impactful .",
    "NOVELTY"
  ],
  [
    "The authors show a good awareness of the recent literature , and to the best of my knowledge , their empirical characterization of the number of latent parameters is original .",
    "NOVELTY"
  ],
  [
    "with many concepts applied in a novel way",
    "NOVELTY"
  ],
  [
    "but this is the first work that directly tackles this realistic problem",
    "NOVELTY"
  ],
  [
    "paper proposes a novel quantization algorithm for maximum inner product search",
    "NOVELTY"
  ],
  [
    "so it is hard for me to say whether this is truly novel",
    "NOVELTY"
  ],
  [
    "and as a neuroscientist I find the idea extremely appealing",
    "NOVELTY"
  ],
  [
    "I find that the paper has too few innovation in comparison with the approach introduced in Deshpande et al . ( 2019 ) (",
    "NOVELTY"
  ],
  [
    "the multi-answer pure exploration",
    "NOVELTY"
  ],
  [
    "the high-confidence regime , which remains open to the best of the reviewer 's knowledge",
    "NOVELTY"
  ],
  [
    "The authors ' approach is inspired by previous work on the single-answer setting , yet the work also contains sufficiently new techniques tailored to the challenges imposed by the multi-answer setting .",
    "NOVELTY"
  ],
  [
    "In this paper , the authors propose a novel point of view on a very well-known algorithm : UCB .",
    "NOVELTY"
  ],
  [
    "However I think that the approach is original and could open research avenue for bandit community .",
    "NOVELTY"
  ],
  [
    "The idea of calculating a score to indicate the usefulness of a sample for training deep networks by analyzing the neural activations in semi-supervised learning is interesting",
    "NOVELTY"
  ],
  [
    "I find the problem and perspective original",
    "NOVELTY"
  ],
  [
    "I feel that the topic and results of this paper looks quite similar to the previous COLT paper .",
    "NOVELTY"
  ],
  [
    "Overall , the theoretical results are beyond standard ones , but the similarity to Jun-Orabona-COLT19 makes me feel that the contribution is a bit incremental .",
    "NOVELTY"
  ],
  [
    "is a new model for domain adaptation",
    "NOVELTY"
  ],
  [
    "the priority queue training presented here for reinforcement learning with sparse rewards is interesting",
    "NOVELTY"
  ],
  [
    "In terms of algorithm , the contribution seems not strong .",
    "NOVELTY"
  ],
  [
    "It is hard to see any innovative aspect in terms of method .",
    "NOVELTY"
  ],
  [
    "The second part of the analysis is tailored to the small world kernel and seems novel .",
    "NOVELTY"
  ],
  [
    "5 .The experiments provides very interesting insight on this dataset .",
    "NOVELTY"
  ],
  [
    ": the idea of storing experiences in a graph and in using landmark similarity rather than metric embeddings is interesting .",
    "NOVELTY"
  ],
  [
    "A nice extension to the contextual bandit problem and relationship to KWIK",
    "NOVELTY"
  ],
  [
    "This paper is interesting and deals with new kind of results introducing computational aspects in standard minimax theory . The phenomenon illustrated is new to me , and present some limitation of the computationally tractable algorithm w.r.t",
    "NOVELTY"
  ],
  [
    "I generally liked the idea and recognized it as a good step towards constrained optimization .",
    "NOVELTY"
  ],
  [
    "This paper seems like a nice idea",
    "NOVELTY"
  ],
  [
    "I feel that the novelty of this paper is limited in a sense that the authors mainly adopt and combine two existing frameworks for their task .",
    "NOVELTY"
  ],
  [
    "I have some concerns about the novelty of this submission",
    "NOVELTY"
  ],
  [
    "While the algorithmic contribution is not that novel",
    "NOVELTY"
  ],
  [
    "The use of Scala is unique among deep learning frameworks , to my knowledge , making this framework interesting for Scala users .",
    "NOVELTY"
  ],
  [
    "DeepDSL is not especially novel when compared with existing frameworks , which is not a problem in and of itself",
    "NOVELTY"
  ],
  [
    "but the current version of the paper contains statements that overclaim novelty in ways that are misleading and unfair to existing frameworks",
    "NOVELTY"
  ],
  [
    "The ideas proposed ( i.e .GAN mechanism and adversarial mechanism ) are interesting additions to this literaature .",
    "NOVELTY"
  ],
  [
    "In terms of significance , I think this paper is slightly incremental .",
    "NOVELTY"
  ],
  [
    "results on both convergence and generalization have already been established in earlier works even for deep networks",
    "NOVELTY"
  ],
  [
    ", and the unbounded cache idea is intuitively appealing .",
    "NOVELTY"
  ],
  [
    "Cascading is not new",
    "NOVELTY"
  ],
  [
    "This idea is potentially very interesting",
    "NOVELTY"
  ],
  [
    "The paper seems quite similar in spirit to Bacon",
    "NOVELTY"
  ],
  [
    "while the proposed approach is quite interesting and definitely",
    "NOVELTY"
  ],
  [
    "The core contribution is a special case of previously published more general framework which is not cited in the paper .",
    "NOVELTY"
  ],
  [
    "are special cases of more general framework published in Jesus Cid-Sueiro et al .Consistency of Losses for Learning from Weak Labels",
    "NOVELTY"
  ],
  [
    "The novel part of the paper is the non-negative risk estimator proposed in sec 3.3 and the online optimization methods addressed in sec 3.4",
    "NOVELTY"
  ],
  [
    "This work is incremental to previous research .",
    "NOVELTY"
  ],
  [
    "The contribution seems incremental with respect to Eslami et al . ( 2018 ) .",
    "NOVELTY"
  ],
  [
    "This work provided a novel approach for designing convex loss surrogates for general discrete losses and analyzing their consistency .",
    "NOVELTY"
  ],
  [
    "This work highly contributes to give a novel and helpful insight into them and suggests that the compression of the information happens even in ReLU networks but it will be uncorrelated to generalization capacity .",
    "NOVELTY"
  ],
  [
    "Qualitative Assessment Their approach to calculate the leverage score and sampled index incrementally and use the calculated score for the approximate kernel ridge regression seems novel and rational .",
    "NOVELTY"
  ],
  [
    "It also makes the contribution seem fairly incremental , rather than providing a new insight .",
    "NOVELTY"
  ],
  [
    "The idea of training Q-network using the result of MCTS planning is not new",
    "NOVELTY"
  ],
  [
    "The idea of inferring the action space from unlabelled videos is very interesting and relevant .",
    "NOVELTY"
  ],
  [
    "While the idea is interesting and might be developped into a tool in the future",
    "NOVELTY"
  ],
  [
    "there is a risk that existing models already solve this problem very well , making the contribution unclear",
    "NOVELTY"
  ],
  [
    "the paper looks accurate , but lacks novelty .",
    "NOVELTY"
  ],
  [
    "and understood hence the contribution is rather incremental",
    "NOVELTY"
  ],
  [
    "The regret bounds seem to be novel .",
    "NOVELTY"
  ],
  [
    "Either proposal provides some useful but rather incremental contribution to the state of the art in dialog modeling",
    "NOVELTY"
  ],
  [
    "My main concern with the paper is the novelty of the contribution to the techniques .",
    "NOVELTY"
  ],
  [
    "and it 's difficult to see the contribution of this paper in terms of the contributing fundamentally new ideas",
    "NOVELTY"
  ],
  [
    "The authors ' approach to tackle the completion and clustering simultaneously seems very interesting and looks promising in numerical experiments",
    "NOVELTY"
  ],
  [
    "It seems novel in dealing with the trainability issue with recurrent networks .",
    "NOVELTY"
  ],
  [
    "Interesting and novel model combining RNNs and word-averaging - I find the multiview framework to be a nice contribution",
    "NOVELTY"
  ],
  [
    "and to the best of my knowledge , the main ideas of this paper ( Haar transformation and new gradient estimator using clustering ) are novel .",
    "NOVELTY"
  ],
  [
    "The approach does not seem very novel and it is hard to see what the representation learning",
    "NOVELTY"
  ],
  [
    "The regularization of the Q-values w.r.t .the policy of another agent is interesting Cons",
    "NOVELTY"
  ],
  [
    "paper has a very marginal novelty , basically combining two already known methods",
    "NOVELTY"
  ],
  [
    "I consider the theoretical guarantees associated with the proposed approach a welcome and valuable contribution to this field that has recently been relying primarily on limited empirical work to assess any method .",
    "NOVELTY"
  ],
  [
    "ideas",
    "NOVELTY"
  ],
  [
    "This work is similar to an existing line of work in terms of experiments and results , but extends it to the batch setting .",
    "NOVELTY"
  ],
  [
    "Overall , this is a very nice paper with some insightful results .",
    "NOVELTY"
  ],
  [
    "genuinely new",
    "NOVELTY"
  ],
  [
    "I believe the approach to be very similar to established models",
    "NOVELTY"
  ],
  [
    "the results on the mental rotation task are interesting and new",
    "NOVELTY"
  ],
  [
    "finding efficient way to relax locality constraint would be an interesting future work as suggested by the authors ) , the utility of the method is quite novel and and shed light on SGD training dynamics of different architectures",
    "NOVELTY"
  ],
  [
    "Proposed method is simple to understand but yet quite novel",
    "NOVELTY"
  ],
  [
    "The paper provides significant novel insights through their new proposed method .",
    "NOVELTY"
  ],
  [
    "This paper has several novelties",
    "NOVELTY"
  ],
  [
    "It is not easy to see what is the contribution of this work",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting .",
    "NOVELTY"
  ],
  [
    "However , the approach they take is not entirely novel compared to past work .",
    "NOVELTY"
  ],
  [
    "After reading the other reviews I would agree that this is somewhat incremental , with many of the core ideas coming from previous work",
    "NOVELTY"
  ],
  [
    "and believe that there are some nice algorithmic and modeling contributions .",
    "NOVELTY"
  ],
  [
    "problem / novel approach .",
    "NOVELTY"
  ],
  [
    "The idea of using advantage estimates to detect adversarial attacks is quite appealing , since by definition an adversarial attack should decrease the advantage of the policy regardless of the attack method used .",
    "NOVELTY"
  ],
  [
    "The main concern of this submission is the novelty . Proposed method to visualize the loss function sounds too incremental from existing works .",
    "NOVELTY"
  ],
  [
    "Basic idea of the paper seems promising",
    "NOVELTY"
  ],
  [
    "network architecture and encoding for point clouds",
    "NOVELTY"
  ],
  [
    "I do find the described idea moderately interesting",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is a new and interesting geometric fact about the problem .",
    "NOVELTY"
  ],
  [
    "An interesting idea to learn the hidden state evolution and the state-observation mapping jointly",
    "NOVELTY"
  ],
  [
    "The model is not new",
    "NOVELTY"
  ],
  [
    "While retriever-reader framework was often used for open-domain QA , this bi-directional interaction between the retriever and the reader is novel and effective because 1",
    "NOVELTY"
  ],
  [
    "The idea of",
    "NOVELTY"
  ],
  [
    "from the reader to the retriever is new 3",
    "NOVELTY"
  ],
  [
    "The idea of multi-step & bi-directional interaction between the retriever and the reader is novel enough (",
    "NOVELTY"
  ],
  [
    "Overall comment The idea in the paper is interesting",
    "NOVELTY"
  ],
  [
    "The idea in the paper is , to my knowledge , novel , and represents a good step toward the important task of generating interpretable visual rationales .",
    "NOVELTY"
  ],
  [
    "I would think that the reward function that induces this policy is not unique",
    "NOVELTY"
  ],
  [
    "on MTL",
    "NOVELTY"
  ],
  [
    "this paper contains an original contribution , which is tightly based on [",
    "NOVELTY"
  ],
  [
    "The originality lies in that the authors adapted batch normalization which is usually performed on real vectors to the SPD representations",
    "NOVELTY"
  ],
  [
    "From the mathematical standpoint the novelty is limited .",
    "NOVELTY"
  ],
  [
    "Although not very novel",
    "NOVELTY"
  ],
  [
    "The use of multi-agents cooperative game theory is interesting and well fit with the evolution of bodies .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is very limited . The idea of jointly optimizing bodies and controllers has been extensively explored in the existing literature . Compared to this literature , I do not see any significant novelty being introduced .",
    "NOVELTY"
  ],
  [
    "In its current form , the paper does not seem to be a significant contribution to the literature .",
    "NOVELTY"
  ],
  [
    "This is an interesting idea which",
    "NOVELTY"
  ],
  [
    "The paper feels almost more like a survey article than a NIPS paper -- -the framework presented is clearly incremental , straightforward",
    "NOVELTY"
  ],
  [
    "In particular , this proposes a novel combination of elements from few-shot learning , ( esp meta learning approaches like Matching Networks ) , imitation learning , transfer learning , and attention models .",
    "NOVELTY"
  ],
  [
    "To my knowledge this is among the first model that is able to perform coherent localization and incremental scene synthesis in an end-to-end fashion ,",
    "NOVELTY"
  ],
  [
    "it does provide a new concept of completeness , and I agree with R1 that it 's interesting and relevant .",
    "NOVELTY"
  ],
  [
    "interesting . The idea of learning to defer ( as proposed in the paper ) as a means to fairness is not only novel but also quite apt .",
    "NOVELTY"
  ],
  [
    "While this work is conceptually quite novel and interesting",
    "NOVELTY"
  ],
  [
    ", the technical novelty and contributions seem fairly minimal .",
    "NOVELTY"
  ],
  [
    "However , beyond this conceptual novelty , the work does not demonstrate a lot of technical novelty or depth .",
    "NOVELTY"
  ],
  [
    "I would say that the idea to combine MPP and GP is not new in the sense that there already exist some attempts to use similar models in practice",
    "NOVELTY"
  ],
  [
    "This paper is a nice contribution to nearest neighbor community in NeurIPS .",
    "NOVELTY"
  ],
  [
    "This is novel .",
    "NOVELTY"
  ],
  [
    "Theorem 1 , which combines the assumption on smoothness , the assumption that hat R can be achieved with error eta and the assumption on difference in errors between optimal and trained classifier , is novel , insightful and non-trivial",
    "NOVELTY"
  ],
  [
    "The proposed task construction in an unsupervised manner for the meta-learning framework is indeed simple and novel .",
    "NOVELTY"
  ],
  [
    "Originality The theoretical framework introduced in the paper is novel .",
    "NOVELTY"
  ],
  [
    "This idea is not new",
    "NOVELTY"
  ],
  [
    "This argument is not new",
    "NOVELTY"
  ],
  [
    "The proposed network is not much different from what several other SR methods used before",
    "NOVELTY"
  ],
  [
    "The paper provides an interesting",
    "NOVELTY"
  ],
  [
    "but from a research point view it 's a relatively minor contribution as it is a form of relatively straight forward architecture exploration .",
    "NOVELTY"
  ],
  [
    "The authors contribute a novel , large dataset of images and benchmark known methods for image classification",
    "NOVELTY"
  ],
  [
    "Overall I think this method is inventive and shows promise for probing",
    "NOVELTY"
  ],
  [
    "I 'm not convinced the current incarnation is showing anything insightful or useful .",
    "NOVELTY"
  ],
  [
    "The main contribution of this paper is the novel relation reasoning block .",
    "NOVELTY"
  ],
  [
    "This paper takes a very different , and non-restrictive approach to collaborative filtering and shows good results with it .",
    "NOVELTY"
  ],
  [
    "I do think that this idea of weighting based on variance is novel as are the extensions to tensor completion and I would like to see more discussion of the later",
    "NOVELTY"
  ],
  [
    "Thus the methodological contribution is incremental .",
    "NOVELTY"
  ],
  [
    "the main concern of the paper is that the methods adopted in the paper are too plain . The paper successfully integrated previous methods but did not propose new ideas that inspire future research .",
    "NOVELTY"
  ],
  [
    "This is a very interesting extension of the well-studied inverse reinforcement learning , which offers useful new",
    "NOVELTY"
  ],
  [
    "the paper is novel , thought-provoking ,",
    "NOVELTY"
  ],
  [
    "One major weakness of this paper is its lack of originality .",
    "NOVELTY"
  ],
  [
    "The presented method is at the same time very simple and clever",
    "NOVELTY"
  ],
  [
    "It is nice to see that kind",
    "NOVELTY"
  ],
  [
    "Nonetheless I believe this is a solid paper and a good NeuriPS contribution .",
    "NOVELTY"
  ],
  [
    "The originality of the work is low ,",
    "NOVELTY"
  ],
  [
    "Low originality and missing comparison to related work - Unconvincing",
    "NOVELTY"
  ],
  [
    "The ideas presented in this paper seem rudimentary and require further exploration before being publishable .",
    "NOVELTY"
  ],
  [
    "There is not a lot of novelty",
    "NOVELTY"
  ],
  [
    "Using a render engine to generate the initial sample appearance if of limited novelty",
    "NOVELTY"
  ],
  [
    "While there is an interesting idea of",
    "NOVELTY"
  ],
  [
    "limited )",
    "NOVELTY"
  ],
  [
    "the paper seems novel and results are promising - easy to implement cons",
    "NOVELTY"
  ],
  [
    "this is a very good paper with significant contributions to the filed .",
    "NOVELTY"
  ],
  [
    "This is a very exciting and novel paper",
    "NOVELTY"
  ],
  [
    "While the idea of doing the unpaired shape completion has",
    "NOVELTY"
  ],
  [
    "been known since the introduction unpaired image-based methods",
    "NOVELTY"
  ],
  [
    ", the application is novel and the methods are formulated using the language known in the point cloud learning literature",
    "NOVELTY"
  ],
  [
    "I believe that the paper does a good job of combining the established components into something new and useful",
    "NOVELTY"
  ],
  [
    "and compares to reasonable baselines representing the state of the art on dialog-based image retrieval The approach is new ,",
    "NOVELTY"
  ],
  [
    "The use of successor representation for transfer is not novel",
    "NOVELTY"
  ],
  [
    "Having said that the proposed method is novel and elegant",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the proposed representation of the function m ( x , r ) is new and I rather liked the motivation for it ( provided in the supplement ) .",
    "NOVELTY"
  ],
  [
    "the general phenomenon described and overall approach bears striking similarity to existing work",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge the proposed method is new and the paper",
    "NOVELTY"
  ],
  [
    "and the method is new",
    "NOVELTY"
  ],
  [
    "The idea of using GANs for outlier detection is interesting",
    "NOVELTY"
  ],
  [
    ", the originality is not high",
    "NOVELTY"
  ],
  [
    "The idea of the paper is not interesting and novel enough .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited .",
    "NOVELTY"
  ],
  [
    "There is nothing new technically in the paper",
    "NOVELTY"
  ],
  [
    "The fact that sigmoidal neural networks with bounded weights can be expressed as `` low `` degree polynomials is not new .",
    "NOVELTY"
  ],
  [
    "I think this paper has a collection of results that are well-known to experts in the field and add little novelty",
    "NOVELTY"
  ],
  [
    "To the best of the reviewer\u00e2\u0080\u0099s knowledge , this technique was first applied to the conditional gradient method and stochastic optimization in the following line of work Centralized setting",
    "NOVELTY"
  ],
  [
    "This paper presents a novel unsupervised domain adaptation framework for neural networks .",
    "NOVELTY"
  ],
  [
    "I like the simplicity of the idea and the fact that it",
    "NOVELTY"
  ],
  [
    "Overall , I think it \u2019 s a good paper presenting a thought-provoking idea .",
    "NOVELTY"
  ],
  [
    "there are certain contribution and orginality in the literature",
    "NOVELTY"
  ],
  [
    "I am not sure that the novelty is significant",
    "NOVELTY"
  ],
  [
    "and the idea is promising",
    "NOVELTY"
  ],
  [
    "From what I can see , the proposed method is very similar to the PlaNet algorithm with state reconstruction loss removed .",
    "NOVELTY"
  ],
  [
    "Although it seems novel combing CTTD with ConvLSTM , the idea of CTTD and the combination mainly comes from",
    "NOVELTY"
  ],
  [
    "I think the theoretical innovation is not enough for ICLR",
    "NOVELTY"
  ],
  [
    "This paper is in some way novel",
    "NOVELTY"
  ],
  [
    "but not enough for ICLR",
    "NOVELTY"
  ],
  [
    "The application of median of means appears to be novel to efficient exploration .",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper though is the novelty / proper connection to self-supervised learning",
    "NOVELTY"
  ],
  [
    "This is new material as far as I know that is sufficiently different from related work .",
    "NOVELTY"
  ],
  [
    "I am not sure how novel the convergence analysis for PowerSGD is",
    "NOVELTY"
  ],
  [
    "The idea of combining the strengths of both CNNs and CRF-based graphical models in a detection framework is interesting .",
    "NOVELTY"
  ],
  [
    "limiting novelty",
    "NOVELTY"
  ],
  [
    "I agree that the method of interpreting the black box has a lot of issues and the counterfactual approach/causal approach is probably the right way to go but this is hardly news to the community",
    "NOVELTY"
  ],
  [
    "and overall the work lacks novelty",
    "NOVELTY"
  ],
  [
    "Compared to other proposed model , this proposed model is the first to fulfil all these requirements , including differentiability and preserving natural symmetries .",
    "NOVELTY"
  ],
  [
    "which unfortunately also makes the work seems a little incremental . However",
    "NOVELTY"
  ],
  [
    ", the idea of the feature matrix D seems novel and could have potential applications outside the domain of PES modelling",
    "NOVELTY"
  ],
  [
    "The work has some both incremental aspects and some novel/original aspect",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first RL-based approach to handle the Rubik 's cube problem so well .",
    "NOVELTY"
  ],
  [
    "The idea is novel .",
    "NOVELTY"
  ],
  [
    "The idea inspired by the thalamus is novel .",
    "NOVELTY"
  ],
  [
    "the proposal is quite insightful .",
    "NOVELTY"
  ],
  [
    "but the results seem a bit incremental/incomplete ( for the prediction task ) and somewhat straightforward for the estimation task given the choice of the risk function ( bypasses having to deal with the Markovian nature of the data",
    "NOVELTY"
  ],
  [
    "3 .This paper is closely related to the POPQORN paper",
    "NOVELTY"
  ],
  [
    "The generalization brought by M-product seems to be general as it includes quite a few graph convolution elements for 3D tensors in a natural way",
    "NOVELTY"
  ],
  [
    "My first concern is that M-product formulation does not bring any new insights as people have already used some of the key elements in practice for a long time .",
    "NOVELTY"
  ],
  [
    "The proposed idea is not very different from other dynamic pruning methods .",
    "NOVELTY"
  ],
  [
    "proposed approach is one of the first to show that conditional computation can lead to real speed-ups by a very light control architecture and GPU friendly pruning",
    "NOVELTY"
  ],
  [
    "This is the most important contribution of this work .",
    "NOVELTY"
  ],
  [
    "The core concept of learned local planner providing additional cues for a global , memory-based planner is a clever idea",
    "NOVELTY"
  ],
  [
    "-W3 .The overall novelty of theory is limited .",
    "NOVELTY"
  ],
  [
    "the overall degree of novelty in theory is still relatively low",
    "NOVELTY"
  ],
  [
    "and the proposed gradient estimator seems to be a novel and more attractive alternative to the existing ones in a number of popular DL/RL applications",
    "NOVELTY"
  ],
  [
    "Since they are simply using previously proposed LSTM variants , I do not see much contribution here .",
    "NOVELTY"
  ],
  [
    "Overall , I 'd say that it 's not a huge/deep idea , but a very nice addition to the learning toolbox .",
    "NOVELTY"
  ],
  [
    "I like the idea and I can see some cases where it could be used",
    "NOVELTY"
  ],
  [
    "The weakness of the paper is perhaps the algorithm is the standard regularized follow-the-leader , and the techniques of updating by sub-derivative and matrix multiplicative weights are not new .",
    "NOVELTY"
  ],
  [
    "I very much like this approach .",
    "NOVELTY"
  ],
  [
    "Many of the existing approaches are overly complex cobblings of discrete-time and continuous-time ideas .",
    "NOVELTY"
  ],
  [
    "Having inspected it I consider it a positive and interesting contribution .",
    "NOVELTY"
  ],
  [
    "The actual contribution is quite technical in nature",
    "NOVELTY"
  ],
  [
    "Certainly the paper considers a very interesting , general , and seemingly novel form of matrix completion",
    "NOVELTY"
  ],
  [
    ", it 's novel enough",
    "NOVELTY"
  ],
  [
    "flow loss in CV to encourage exploration in an environment with sparse rewards",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this was the first paper proposed to use moving patterns in two consecutive observations to motivate agent exploration .",
    "NOVELTY"
  ],
  [
    "relatively weak",
    "NOVELTY"
  ],
  [
    "and the novelty was somewhat limited",
    "NOVELTY"
  ],
  [
    "The work is original ( as far as I know ) .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting ; the",
    "NOVELTY"
  ],
  [
    "While I am not experienced enough in the field to really comment on the originality , it does seem that the approach the authors have taken is original , and applies deep learning techniques to avoid having to custom-design a `` feature space `` for their particular family of problems .",
    "NOVELTY"
  ],
  [
    "it 's maybe not * super* novel .",
    "NOVELTY"
  ],
  [
    "I think the proposed model is very interesting",
    "NOVELTY"
  ],
  [
    "The way this is done in this paper is interesting",
    "NOVELTY"
  ],
  [
    "It presents some interesting novel ideas , leads to an efficient method",
    "NOVELTY"
  ],
  [
    "The setup of this paper reminds me of a similar synthesis of two methods : SVRG and randomized coordinate descent",
    "NOVELTY"
  ],
  [
    "This is probably the strongest contribution in this paper .",
    "NOVELTY"
  ],
  [
    "and sufficiently interesting",
    "NOVELTY"
  ],
  [
    "The paper makes some very interesting observations and uses those insights to improve the widely used SGD .",
    "NOVELTY"
  ],
  [
    "Learning through a different number of layers between different time steps is not a novel idea .",
    "NOVELTY"
  ],
  [
    "In general , I think the authors have provided an interesting idea",
    "NOVELTY"
  ],
  [
    "it seems to me this paper does not make enough contributions .",
    "NOVELTY"
  ],
  [
    "To me , this paper does not provide much additional theoretical insight on neuron splitting .",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is not clear .",
    "NOVELTY"
  ],
  [
    "All in all , there might be some interesting ideas in the paper",
    "NOVELTY"
  ],
  [
    "The main weakness of this paper is that the approach is mostly data-augmentation",
    "NOVELTY"
  ],
  [
    "I feel this contribution is not sufficient for ICLR .",
    "NOVELTY"
  ],
  [
    "Strengths of the paper",
    "NOVELTY"
  ],
  [
    "The ideas are interesting",
    "NOVELTY"
  ],
  [
    "algorithm is a cute extension of the classical DA",
    "NOVELTY"
  ],
  [
    "Overall , I think the contributions of this paper are too marginal for acceptance in a top tier conference .",
    "NOVELTY"
  ],
  [
    "using ensembling in deep networks is not a significant contribution .",
    "NOVELTY"
  ],
  [
    "Path-wise training is not original enough or indeed different enough from drop-path to count as a major contribution .",
    "NOVELTY"
  ],
  [
    "Both features are novel and are crucial for the efficiency and effectiveness of the model .",
    "NOVELTY"
  ],
  [
    "The optimization formulation seems to be novel .",
    "NOVELTY"
  ],
  [
    "While the components of this work are n't novel",
    "NOVELTY"
  ],
  [
    ", it combines them in an interesting , well-presented way that sheds new light .",
    "NOVELTY"
  ],
  [
    "if somewhat limited in novelty",
    "NOVELTY"
  ],
  [
    "Limited novelty of methods / theory Major Comments/Questions",
    "NOVELTY"
  ],
  [
    "so I would consider this an important contribution of this paper",
    "NOVELTY"
  ],
  [
    "It should be noted that most of the individual components used in this work are not novel",
    "NOVELTY"
  ],
  [
    "I see consider its main contribution combining those components in a coherent and practical way , and producing as a consequence a promising and well-founded approach to two important tasks",
    "NOVELTY"
  ],
  [
    "While the combination of methods is new I am not sure that this particular combination of methods to train an HRL policy is sufficiently novel .",
    "NOVELTY"
  ],
  [
    "The overall structure of the algorithm and the proof are similar to the previous work",
    "NOVELTY"
  ],
  [
    "The idea of using Moreau-Yoshida regularization is already present in some works of lower bounds",
    "NOVELTY"
  ],
  [
    "The innovation of in the scenario of optimization , is moderate .",
    "NOVELTY"
  ],
  [
    "My main concern regarding this paper is two-fold : limited novelty and insignificant performance gain .",
    "NOVELTY"
  ],
  [
    "This paper lacks any novelty/contribution as it",
    "NOVELTY"
  ],
  [
    "However , this paper does do a nice job of formalizing from the OO-MDP and Propositional MDP setting as opposed to the two papers I mentioned which do not",
    "NOVELTY"
  ],
  [
    "but still do not think it is novel enough to be accepted",
    "NOVELTY"
  ],
  [
    "not sure how this differs from relational MDPs .",
    "NOVELTY"
  ],
  [
    "but I 'm not sure it is novel",
    "NOVELTY"
  ],
  [
    "This problem formulation is quite novel compared to the standard imitation learning literature ( usually first-order perspective",
    "NOVELTY"
  ],
  [
    ", though has close links to the literature on transfer learning",
    "NOVELTY"
  ],
  [
    "The attribute ranking and selection method of informative attributes using combinations weighted TCAV and cosine similarity between the attribute activation map and the generated saliency map is novel .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution presented in 291\u00e2\u0080\u0094310 is a welcome insight on the computational power of ReLUs . The experimental results for rectified polynomial units reported in figures 2 and 3 are interesting and apparently novel , even in the context of standard feedforward multi-layer networks .",
    "NOVELTY"
  ],
  [
    "it should be noted that the reformulation of a classification problem as a partial input completion one is not novel .",
    "NOVELTY"
  ],
  [
    "The paper makes states that this is is a novel finding that contradicts the previous understanding of emergent communication in the literature",
    "NOVELTY"
  ],
  [
    "Not particularly novel , a modification of an existing idea",
    "NOVELTY"
  ],
  [
    "It is hard to find any technical novelty here .",
    "NOVELTY"
  ],
  [
    "Significant new results -- worthy of publication Originality",
    "NOVELTY"
  ],
  [
    "The paper presents a novel hierarchical clustering method over an embedding space",
    "NOVELTY"
  ],
  [
    "The only issue with this paper is its degree of novelty , which is narrow .",
    "NOVELTY"
  ],
  [
    "a quite refreshing approach to approximate inference and learning . The proposed approach combines several existing techniques in an intriguing way .",
    "NOVELTY"
  ],
  [
    "The approach presented is , to the best of my knowledge , novel , natural and elegant .",
    "NOVELTY"
  ],
  [
    "its originality and potential inspiration for further work in this direction are the main reasons why I recommend an accept",
    "NOVELTY"
  ],
  [
    "I feel this work \u2019 s contribution over prior work is not significant .",
    "NOVELTY"
  ],
  [
    "the primary issue is that the contribution regarding the additional term , while intuitive , is not a significant one in its own right .",
    "NOVELTY"
  ],
  [
    "It is also the first to study this problem under differential privacy",
    "NOVELTY"
  ],
  [
    "The results are new and non-trivial .",
    "NOVELTY"
  ],
  [
    "It also does not have much originality when compared to similar algorithms [ 1 , 2 ] .",
    "NOVELTY"
  ],
  [
    "The idea of using ensemble to detect out-of-distribution examples is not new .",
    "NOVELTY"
  ],
  [
    "the idea is nice",
    "NOVELTY"
  ],
  [
    "but based on the current state of the paper it seems incremental .",
    "NOVELTY"
  ],
  [
    "This is definitely a good contribution to the conference .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the concept of performing video frame prediction from a sparse keypoint representation is novel .",
    "NOVELTY"
  ],
  [
    "However , in my opinion , the technical novelty in the paper is somewhat thin .",
    "NOVELTY"
  ],
  [
    "The proposed FBI algorithms are novel and are suitable for streaming settings but don\u00e2\u0080\u0099t achieve the best performance on average when all labels have been collected",
    "NOVELTY"
  ],
  [
    "making this study novel and potentially impactful",
    "NOVELTY"
  ],
  [
    "so it is not a contribution of this submission",
    "NOVELTY"
  ],
  [
    "However , the novelty of their approach is very minor . The ideas of RL + GNN and RL for exploration arenot new , as stated in their related work . The idea of maintaining a graph-structured memory is not new",
    "NOVELTY"
  ],
  [
    "In particular , RL + GNN + exploration is not completely novel as well",
    "NOVELTY"
  ],
  [
    "To my best knowledge , the O ( 1/\\epsilon ) convergence rate of optimizing Eq ( 9 ) is new and is impressive .",
    "NOVELTY"
  ],
  [
    "with multiple significant",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting there are some encouraging results",
    "NOVELTY"
  ],
  [
    "All I can say is the approach is intuitively appealing",
    "NOVELTY"
  ],
  [
    "It 's a bit incremental in light of existing work , but does contribute to the important question of whether we can prove depth separations which are also robust",
    "NOVELTY"
  ],
  [
    "and original in the sense that it proposes to study EVGP but may be problematic",
    "NOVELTY"
  ],
  [
    "The architecture is novel and interesting .",
    "NOVELTY"
  ],
  [
    "in reviewer 's opinion , results looks quite incremental",
    "NOVELTY"
  ],
  [
    "The authors propose a novel method which successfully solves these problems . The effectiveness is validated with theoretical justifications and experimental results . In a nutshell , the authors provide an elegant solution for the problem considered , where previous methods",
    "NOVELTY"
  ],
  [
    "I feel that these are simple but novel additions to various existing approaches that typically use individual terms , and that the experiments justify the benefits of these additions .",
    "NOVELTY"
  ],
  [
    "I think the idea described in this submission is interesting .",
    "NOVELTY"
  ],
  [
    "the proposed method is a novel interesting solution to controlling soft bodies in simulation",
    "NOVELTY"
  ],
  [
    "the paper has some nice contributions",
    "NOVELTY"
  ],
  [
    "problem posed , and associated data sets and simulation code , if shared , could be an interesting and novel source of challenge to machine learning researchers .",
    "NOVELTY"
  ],
  [
    "the paper appears to be a fairly early work in progress",
    "NOVELTY"
  ],
  [
    "To best of my knowledge , this is the first paper that related RNNs with MASOs and provides insights on this re-formulation .",
    "NOVELTY"
  ],
  [
    "In general , I think this is an original work providing interesting viewing point",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "the work in this paper can be seen as adding the losses from GANs and VAEs together to help learn a better generative model , which is not very novel .",
    "NOVELTY"
  ],
  [
    "the proposed algorithm is novel , and the theoretical analysis also seem quite novel .",
    "NOVELTY"
  ],
  [
    "I really enjoyed the paper .",
    "NOVELTY"
  ],
  [
    "Cons .- in terms of the originality , the methodology of this method is rather incremental from the prior study ( Raffel et al ) , but it shows significant gains from it .",
    "NOVELTY"
  ],
  [
    "Novelty is a bit low",
    "NOVELTY"
  ],
  [
    "However , the novelty of the solution is a bit on the low side",
    "NOVELTY"
  ],
  [
    "multiple source domain adaptation is not a new problem",
    "NOVELTY"
  ],
  [
    "Technically , the paper does not introduce heavy machinery",
    "NOVELTY"
  ],
  [
    "but the obtained insights lead to new understanding of the problem which seems to be absent in the literature so far",
    "NOVELTY"
  ],
  [
    ", although",
    "NOVELTY"
  ],
  [
    "not extremely novel",
    "NOVELTY"
  ],
  [
    "it is able to provide insights that were not previously obtained in the literature .",
    "NOVELTY"
  ],
  [
    "as there is quite little innovation in modelling methodology",
    "NOVELTY"
  ],
  [
    "The presented method is a novel modification of continual resolving .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed method itself is not very high given that it just additionally predicts the variance of the output for aleatoric uncertainty while using Bayesian Deep Learning for epistemic uncertainty",
    "NOVELTY"
  ],
  [
    "This paper provides insight on that",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first bound on the generalization error custom tailored for accelerated gradient boosting approaches .",
    "NOVELTY"
  ],
  [
    "All in all , a very interesting contribution , proposing a theoretical view of accelerated ( regularized ) gradient boosting .",
    "NOVELTY"
  ],
  [
    "The idea to just use the return probabilities of random walks is new to my knowledge ,",
    "NOVELTY"
  ],
  [
    "although it can be considered a bit derivative .",
    "NOVELTY"
  ],
  [
    "Overall I see some original contribution here .",
    "NOVELTY"
  ],
  [
    "and to me come across as merely a motivation for their framework ( but no value added compared to existing literature",
    "NOVELTY"
  ],
  [
    "There is no new insight provided on the software engineering level either as far as I can see .",
    "NOVELTY"
  ],
  [
    "Interesting and novel connections are presented between steerable filters and so called \u201c steerable fibers \u201d .",
    "NOVELTY"
  ],
  [
    "most of the individual components have been proposed in previous work",
    "NOVELTY"
  ],
  [
    "However , to the best of my knowledge this work is indeed novel",
    "NOVELTY"
  ],
  [
    "It is a novel , sound and",
    "NOVELTY"
  ],
  [
    "The formulation in eq .1 appears new .",
    "NOVELTY"
  ],
  [
    "however it lacks technically novelty",
    "NOVELTY"
  ],
  [
    "Technical novelty is rather limited . Contribution is incremental with respect to previous works on CL , as they use the variational CL ( VCL ) framework of Nguyen at al , 2018 and the weight of evidence",
    "NOVELTY"
  ],
  [
    "These novel ideas together with impressive empirical results make this a",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting and",
    "NOVELTY"
  ],
  [
    "Although this is an incremental work",
    "NOVELTY"
  ],
  [
    ", this idea is relatively novel .",
    "NOVELTY"
  ],
  [
    "The technique is interesting and non-trivial .",
    "NOVELTY"
  ],
  [
    "I think the paper slightly overstates its contributions in terms of providing insight into the representations that are learned in generative convolutional models .",
    "NOVELTY"
  ],
  [
    "This is a creative piece of work , and",
    "NOVELTY"
  ],
  [
    "I think the paper is interesting and well written , and the algorithm is novel based on my knowledge .",
    "NOVELTY"
  ],
  [
    "While the fundamental technical contribution is interesting and should be published",
    "NOVELTY"
  ],
  [
    "This is what I find the most interesting contribution in this paper",
    "NOVELTY"
  ],
  [
    "relatively new application",
    "NOVELTY"
  ],
  [
    "The technical novelty is weak , and although the authors demonstrate that end-to-end holistic approaches outperform previous segmentation-and-feature-extraction approaches",
    "NOVELTY"
  ],
  [
    "Creation of a new dataset on a new and interesting problem",
    "NOVELTY"
  ],
  [
    "This paper is a nice attempt at doing that .",
    "NOVELTY"
  ],
  [
    "The framework about using primitive policy to solve a big task is novel and original .",
    "NOVELTY"
  ],
  [
    "I think the results presented in the paper seem interesting and novel",
    "NOVELTY"
  ],
  [
    "The work is original in its setup of preference order in multi-objective bayesian optimisation .",
    "NOVELTY"
  ],
  [
    "Strength The method is easy to implement and using the idea of interpretation for detecting adversarial examples seems interesting .",
    "NOVELTY"
  ],
  [
    "Weakness The idea of this paper is based on the interpretation method of DNN",
    "NOVELTY"
  ],
  [
    "I found the paper very interesting . I think it very nicely combines",
    "NOVELTY"
  ],
  [
    "regret bounds of online learning",
    "NOVELTY"
  ],
  [
    "terms , to give the best of both worlds .",
    "NOVELTY"
  ],
  [
    "The method appears novel and interesting to me",
    "NOVELTY"
  ],
  [
    "This paper has a moderate contribution because of the new algorithms and improved complexity results",
    "NOVELTY"
  ],
  [
    "However , the idea of variance reduction is not novel and the result is not surprising since the improvement comes purely from spider",
    "NOVELTY"
  ],
  [
    "and thus this work is somewhat incremental",
    "NOVELTY"
  ],
  [
    "and the core contribution of the paper seems incremental",
    "NOVELTY"
  ],
  [
    "ideas come across",
    "NOVELTY"
  ],
  [
    "This paper is one of the first papers , if not the very first , to introduce a coupled ODE framework that takes a principled approach on neural ODE to dynamically controlling the neural net parameters .",
    "NOVELTY"
  ],
  [
    "points are appealing about this approach",
    "NOVELTY"
  ],
  [
    "it is an interesting new contrasting approach to",
    "NOVELTY"
  ],
  [
    "new variant of AMSGrad called Optimistic-AMSGrad",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "in my opinion , the idea of using a trainable error feedback mechanism in synthesizing open-domain multi-line programs still has novelty , compared with using a deterministic executor to guide the generation of domain-specific logical forms",
    "NOVELTY"
  ],
  [
    "To summarize , I feel the technical contribution from ( 1 ) might be limited apart from introducing a new dataset , while",
    "NOVELTY"
  ],
  [
    "show that the performance of deep kernel models can match conventional deep neural",
    "NOVELTY"
  ],
  [
    "the idea of finite-dimensional subspace projection is inspiring",
    "NOVELTY"
  ],
  [
    "Originality The work is original in the sense that the evaluation of DTP variants on MNIST , CIFAR-10 and Imagenet was never published before .",
    "NOVELTY"
  ],
  [
    "The variants themselves are original as well , but minor and straightforward modifications of the original DTP .",
    "NOVELTY"
  ],
  [
    "The computation of the encoder and decoder is not novel .",
    "NOVELTY"
  ],
  [
    "The derived results are very interesting , closing a long-standing gap between upper and lower bounds .",
    "NOVELTY"
  ],
  [
    "The experimental results show the effectiveness of the proposed approach , which seems to bring an original contribution .",
    "NOVELTY"
  ],
  [
    "This idea is nice",
    "NOVELTY"
  ],
  [
    "which is not very novel",
    "NOVELTY"
  ],
  [
    "paper proposes a novel problem in the area of counterfactual learning",
    "NOVELTY"
  ],
  [
    "I really like the idea of certifying fairness through a held out safety dataset and suggesting that no solution exists and more data needs to be collected",
    "NOVELTY"
  ],
  [
    "the approach taken is fairly new to me",
    "NOVELTY"
  ],
  [
    "I find the problem investigated in this paper novel & interesting",
    "NOVELTY"
  ],
  [
    "Generally I found the idea interesting",
    "NOVELTY"
  ],
  [
    "However , this approach lacks novelty since similar techniques are widely used in the data mining community such as different forms of filter",
    "NOVELTY"
  ],
  [
    "Proposition 2.1 provides interesting insights into the invariance of the kernel space",
    "NOVELTY"
  ],
  [
    "although the paper introduces novel attempts and theoretically analyzing the CycleGAN",
    "NOVELTY"
  ],
  [
    "The key idea of the paper is intriguing ,",
    "NOVELTY"
  ],
  [
    "It is as such appropriately novel for a nips submission",
    "NOVELTY"
  ],
  [
    "The connection between elementary symmetric polynomials and its special cases was an interesting revelation .",
    "NOVELTY"
  ],
  [
    "The student-teacher framework by itself is n't novel .",
    "NOVELTY"
  ],
  [
    "The modifications to the objective function appears to be novel as far as I am aware",
    "NOVELTY"
  ],
  [
    "As far as I can tell , this work is original .",
    "NOVELTY"
  ],
  [
    "insightful",
    "NOVELTY"
  ],
  [
    "The major contribution lies in that it does not require aligned training pairs from two domains .",
    "NOVELTY"
  ],
  [
    "I 'm not sure I 'm convinced regarding the level of novelty of the arguments used",
    "NOVELTY"
  ],
  [
    "nevertheless I think this is a solid and nice contribution and I would like to keep my score",
    "NOVELTY"
  ],
  [
    "In this aspect , the work is somewhat incremental and I do not identify highly novel ingredients .",
    "NOVELTY"
  ],
  [
    "In my understanding , the main contribution of the paper is an elaboration on the existing graph filtering approaches and different filtering strategies in the problem of classification and studying their links to the recent graph CNNs , rather than the development of a novel and original methodology",
    "NOVELTY"
  ],
  [
    "I think this paper is a useful but minor contribution that shows that word alignment is a good way of getting short lists",
    "NOVELTY"
  ],
  [
    "The paper is relatively technical",
    "NOVELTY"
  ],
  [
    "but neither its originality and technical complexity",
    "NOVELTY"
  ],
  [
    "The proposed method of using adversarial and collaborative games is also quite unique .",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "The main advantage of STOC is its ability to handle novel content from open domains .",
    "NOVELTY"
  ],
  [
    "I did n't see any other contribution from this paper",
    "NOVELTY"
  ],
  [
    "However the level of novelty does not obviously meet the required criteria .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , NVA is the first one leveraging the regularity of value functions in RL to learn to leverage past estimates to improve value prediction automatically . The idea of NVA is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    "This is a novel formulation in graph theory and the paper provides near tight scaling laws for the problem .",
    "NOVELTY"
  ],
  [
    "2 .The mathematical model of inducable matchings is quite interesting , and shows why the multi-tasking parameter could be of",
    "NOVELTY"
  ],
  [
    "while the paper presents a fairly simplified model",
    "NOVELTY"
  ],
  [
    ", the mathematical modeling has novelty and the results are quite interesting .",
    "NOVELTY"
  ],
  [
    "These results are useful to have but I think that both technical and conceptual contributions are not quite significant enough for publication in NIPS .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is novel .",
    "NOVELTY"
  ],
  [
    "From my limited point of view , this seems like a sound , novel and potentially useful application of a interesting idea .",
    "NOVELTY"
  ],
  [
    "I really like the first contribution of the paper .",
    "NOVELTY"
  ],
  [
    "2 .The pseudo-PML is",
    "NOVELTY"
  ],
  [
    "novel as the previous PML method always utilizes the full profile",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "1- The novelty and contribution is not clear .",
    "NOVELTY"
  ],
  [
    "I didn\u00e2\u0080\u0099t think this section was particularly , insightful .",
    "NOVELTY"
  ],
  [
    "the actual novel research contribution of the paper is relatively small .",
    "NOVELTY"
  ],
  [
    "I think the paper constitutes a good contribution",
    "NOVELTY"
  ],
  [
    "Even though other optimization-based certification of Lipschitz constants have been proposed before , the theoretical result leading to the SDP formulation ( Theorem 1 ) is novel .",
    "NOVELTY"
  ],
  [
    "While a general solution is indeed a contribution to the literature",
    "NOVELTY"
  ],
  [
    "This paper indeed provides some new techniques and insights in this research direction",
    "NOVELTY"
  ],
  [
    "I found it to be very interesting",
    "NOVELTY"
  ],
  [
    "this is only one aspect of a broader set of ideas",
    "NOVELTY"
  ],
  [
    "Overall , the idea is interesting and the authors propose an extrinsic way to respect the underlying geometry by using tangent space projection .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel denoiser for long discrete sequences corrupted by iid noise . The denoiser is provides with a noise model ( symbol substitution probabilities ) and cost of symbols substitution , but is not provided with clean data . The denoiser is composed of an neural network that predicts `` pseudo-labels `` , which are in-fact a distribution over single-symbol denoisers ( conditioned on input context )",
    "NOVELTY"
  ],
  [
    "and presents an interesting and novel technique , supported by convincing experiments . I find the loss function used very interesting",
    "NOVELTY"
  ],
  [
    "Although the relationship between energy-based models and GANs is abundantly clear in the literature , the contributions of this paper seems to be a multimodal energy estimate , and training a transition operator instead of a sampler . The core technical contribution of the paper is not clear .",
    "NOVELTY"
  ],
  [
    "the authors need to make the core contribution of the paper much better",
    "NOVELTY"
  ],
  [
    "This paper is a new but rather obvious combination of previous work .",
    "NOVELTY"
  ],
  [
    "to the MPC cost function which makes the novelty in the paper very limited",
    "NOVELTY"
  ],
  [
    "as such , I believe the work is original",
    "NOVELTY"
  ],
  [
    "it also seems to be rather heuristic",
    "NOVELTY"
  ],
  [
    "original framework to the best of my knowledge Significance",
    "NOVELTY"
  ],
  [
    "Using GANs for this purpose is not new",
    "NOVELTY"
  ],
  [
    "So overall this is minor but importnat contribution .",
    "NOVELTY"
  ],
  [
    "and has a clear contribution",
    "NOVELTY"
  ],
  [
    "The theoretical results are a bit incremental",
    "NOVELTY"
  ],
  [
    "The practical usefulness of the method is not so clear",
    "NOVELTY"
  ],
  [
    "However I still think that the contribution is a bit incremental and I agree with Reviewer 1 that a more extensive empirical evaluation would have been beneficial",
    "NOVELTY"
  ],
  [
    "the ideas in this paper are very interesting",
    "NOVELTY"
  ],
  [
    "the contribution itself is fairly minimal",
    "NOVELTY"
  ],
  [
    "even if the contribution were more substantial",
    "NOVELTY"
  ],
  [
    "this paper is quite interesting",
    "NOVELTY"
  ],
  [
    "I believe the authors have introduced novel approaches for selecting a flat clustering from a hierarchical clustering . I believe that this work is interesting and novel .",
    "NOVELTY"
  ],
  [
    "The lack of novelty is quite problematic .",
    "NOVELTY"
  ],
  [
    "The remaining contributions look pretty weak without the main one .",
    "NOVELTY"
  ],
  [
    "But not novel , unfortunately .",
    "NOVELTY"
  ],
  [
    "which I do n't think",
    "NOVELTY"
  ],
  [
    "is very novel",
    "NOVELTY"
  ],
  [
    "The paper presents a novel combination of existing techniques with a good scope for applications",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , this is very different than any other previous PAC-Bayes theorems , and I think it can inspire others in the future .",
    "NOVELTY"
  ],
  [
    "My main issue with the paper is that while the SDP relaxation introduced may be novel , it is not clear that this will ever scale to anything beyond simple toy problems and toy architectures .",
    "NOVELTY"
  ],
  [
    "I think the model itself does not represent a major conceptual leap from prior work .",
    "NOVELTY"
  ],
  [
    ", and the approach of using an adversarial network for the task is very natural ( yet novel ) .",
    "NOVELTY"
  ],
  [
    "1 .The technical novelty of the paper is not that high .",
    "NOVELTY"
  ],
  [
    "4 .I am not sure about the novelty of Theorem 2 .",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed model is minor , relative to MGP-TCN , and",
    "NOVELTY"
  ],
  [
    "From a novelty standpoint though , the paper is not especially strong given that it represents a fairly straightforward application of ( Andrychowicz et al. , 2016 ) .",
    "NOVELTY"
  ],
  [
    "these are rather minor differentiating factors , since learning-to-learn is a quite general concept already , and the exact model structure is not the key novel ingredient .",
    "NOVELTY"
  ],
  [
    "CONCLUSION Overall , I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "and the solution seems elegant and novel to me .",
    "NOVELTY"
  ],
  [
    "-- The methodological contribution is too small , and fairly obvious .",
    "NOVELTY"
  ],
  [
    "The approach proposed by the authors is quite different from those proposed earlier in the literature .",
    "NOVELTY"
  ],
  [
    "and found it interesting and novel",
    "NOVELTY"
  ],
  [
    "making this more of a refinement paper than a groundbreaking one",
    "NOVELTY"
  ],
  [
    "the novelty is still sufficient for a decent conference submission",
    "NOVELTY"
  ],
  [
    "In terms of algorithmic development , the paper just applies known dual extrapolation to solve the modified problem and the rounding algorithm for the projection , so the novelty is limited",
    "NOVELTY"
  ],
  [
    "Although the idea of adapting prediction to each data point x by minimizing the MSE is not new",
    "NOVELTY"
  ],
  [
    "To my knowledge , I believe this paper contains sufficient originality .",
    "NOVELTY"
  ],
  [
    "Significance The significance of the paper is moderate given some similar previous works",
    "NOVELTY"
  ],
  [
    "the idea seems straightforward and has limited novelty .",
    "NOVELTY"
  ],
  [
    "And this idea has already used in existing papers",
    "NOVELTY"
  ],
  [
    "This paper describes a novel algorithm for safe model-based control of a unknown system .",
    "NOVELTY"
  ],
  [
    "I think the analysis and the algorithm are interesting",
    "NOVELTY"
  ],
  [
    "Its use of a reinforcement learning and attention model framework to learn the structure of the space in which combinatorial problems of variable size can be tackled appears novel .",
    "NOVELTY"
  ],
  [
    "If the proposed model is new given the reviewer 's knowledge , the contribution is small .",
    "NOVELTY"
  ],
  [
    "3 .The technique itself is a small change over real NVP and it 's not clear whether this change brings any improvements or provides any insights about generative modeling",
    "NOVELTY"
  ],
  [
    "The architecture of the proposed system is very similar to that in [ A ] , however",
    "NOVELTY"
  ],
  [
    "The ideas proposed are interesting",
    "NOVELTY"
  ],
  [
    "while I believe the ideas are intuitive and novel",
    "NOVELTY"
  ],
  [
    "The core model and it\u00e2\u0080\u0099s component are simple",
    "NOVELTY"
  ],
  [
    "but the way they have posed the problem and combined those components and the loss function combination is novel .",
    "NOVELTY"
  ],
  [
    "weakens the contribution of the",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "To my best knowledge , this is the first attempt to provide the general theorem on the support set recovery for the HTP-type algorithms .",
    "NOVELTY"
  ],
  [
    "are not novel .",
    "NOVELTY"
  ],
  [
    "the manuscript seems largely ignorant of advances in this direction",
    "NOVELTY"
  ],
  [
    "this manuscript is not up to the standards of NIPS",
    "NOVELTY"
  ],
  [
    "the novelty of the approach is limited .",
    "NOVELTY"
  ],
  [
    "Lack of novelty : The analytic KL term for spike and slab priors has been derived before in Discrete VAEs",
    "NOVELTY"
  ],
  [
    "The authors claim that the use of knowledge distillation is novel .",
    "NOVELTY"
  ],
  [
    "Proposing this , and especially making it work is in my understanding novel",
    "NOVELTY"
  ],
  [
    "The network architecture used for the experiments on CIFAR-10 is quite outdated and the",
    "NOVELTY"
  ],
  [
    "the general idea of having an actor-critic network as a meta-learner is an interesting idea .",
    "NOVELTY"
  ],
  [
    "The paper seems of fairly limited novelty .",
    "NOVELTY"
  ],
  [
    "The paper is a clear continuation of previous work on symmetric kernels",
    "NOVELTY"
  ],
  [
    "The idea of using a kernel to push apart the sampled points is interesting",
    "NOVELTY"
  ],
  [
    "their approach has a number of changes compared to DCGAN",
    "NOVELTY"
  ],
  [
    "While this has been done before , the solution here is new and very interesting .",
    "NOVELTY"
  ],
  [
    "While interesting and potentially very useful novelties are presented",
    "NOVELTY"
  ],
  [
    "And the major technical novelty , the expression for < h_j h_l > , is really interesting and useful .",
    "NOVELTY"
  ],
  [
    "Critically , the other paper does n't compare to applying group lasso by itself ( without tensor decomposition ) .",
    "NOVELTY"
  ],
  [
    "The idea sounds great",
    "NOVELTY"
  ],
  [
    "The originality and significance of the work reported in this paper are difficult to comprehend .",
    "NOVELTY"
  ],
  [
    "The contributions of the paper seem novel and significant in the field of convex optimization .",
    "NOVELTY"
  ],
  [
    "The task presented in the paper seems to not have been considered much in previous literature",
    "NOVELTY"
  ],
  [
    "This combination of methods is novel and figures illustrate the benefits that each component brings .",
    "NOVELTY"
  ],
  [
    "1- Investigating theoretically the shortcoming of the calibration metric for regression is interesting 2- Proposing the new metrics specifically designed for regression in novel ,",
    "NOVELTY"
  ],
  [
    "the novelty of proposed metrics are not enough .",
    "NOVELTY"
  ],
  [
    "The results shown are well placed in the current literature and form an important novelty that should have non-trivial impact in the sub-field .",
    "NOVELTY"
  ],
  [
    "I like the central idea of the",
    "NOVELTY"
  ],
  [
    "It seems to me the analysis here in Theorem 1 and Theorem 2 are new",
    "NOVELTY"
  ],
  [
    "The finding of connecting clustering with compression is novel and inspiring .",
    "NOVELTY"
  ],
  [
    "The idea is incremental and the novelty is limited .",
    "NOVELTY"
  ],
  [
    "A first attempt of dual learning and multiple languages",
    "NOVELTY"
  ],
  [
    "Limited novelty",
    "NOVELTY"
  ],
  [
    "The novelty therefore seems limited .",
    "NOVELTY"
  ],
  [
    "The paper is modestly original",
    "NOVELTY"
  ],
  [
    "The `` algorithmic `` novelty of the NC block feels modest",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "In terms of novelty , the paper is in many ways a straight forward extension of the GAN and DCGAN works to the 3D object generation task by replacing the 2D image generation and discrimination networks with 3D volumetric generation and discrimination networks",
    "NOVELTY"
  ],
  [
    "The notion of local elasticity is interesting and has the potential of opening up lots of further directions .",
    "NOVELTY"
  ],
  [
    "although not new",
    "NOVELTY"
  ],
  [
    "Overall , the approach is novel",
    "NOVELTY"
  ],
  [
    "The results seem to be novel and interesting .",
    "NOVELTY"
  ],
  [
    "The technique is not new ,",
    "NOVELTY"
  ],
  [
    "all the theoretical derivations by the authors are readily obtained from [ 1-3 ] and I fail to see any novelty here",
    "NOVELTY"
  ],
  [
    "For the proposed kernel , I also fail to see a significant difference compared to",
    "NOVELTY"
  ],
  [
    "Originality The main contribution ( i.e .the new sampling of the datapoints ) is a new twist on an existing algorithm . As such it 's not very original , though novel .",
    "NOVELTY"
  ],
  [
    "while the innovation is fairly minor",
    "NOVELTY"
  ],
  [
    "As a research contribution , this is in itself not very substantial .",
    "NOVELTY"
  ],
  [
    "This looks like a good set of theoretical contributions",
    "NOVELTY"
  ],
  [
    "the paper is built upon a synthesis of several known techniques Significance",
    "NOVELTY"
  ],
  [
    "The proposed new formulation of the problem is mainly incremental",
    "NOVELTY"
  ],
  [
    "but at limited level of novelty",
    "NOVELTY"
  ],
  [
    "I found this an innovative application of game-theoretic techniques .",
    "NOVELTY"
  ],
  [
    "the effort to predict links in dynamic graphs through a combination of variational autoencoder , graph neural network and recurrent neural network is the interesting contribution of the paper .",
    "NOVELTY"
  ],
  [
    "I have some doubts about the formulation that subtracts from my evaluation of originality",
    "NOVELTY"
  ],
  [
    "While most GAN papers today mainly focus on slight variations of the original net architecture or of the original GAN objective function , this paper really presents a new , original and very interesting algorithm that combines features of GANs with a strongly Bayesian viewpoint of Neural Nets",
    "NOVELTY"
  ],
  [
    "The concept underlying their innovative training methodology is not purely original because they are using the same foundation as in Patrini et al 2017",
    "NOVELTY"
  ],
  [
    "There are many interesting ideas in this paper",
    "NOVELTY"
  ],
  [
    "Medium/ High The proposed algorithm is considerably different than recently proposed methods for deep learning , which gravitate towards adaptive gradient methods",
    "NOVELTY"
  ],
  [
    "I consider it a significantly original work .",
    "NOVELTY"
  ],
  [
    "The idea is refreshing",
    "NOVELTY"
  ],
  [
    "I think the perspective is definitely new and probably quite relevant not only for practical approaches to escape saddles but also to understand learning in deep learning .",
    "NOVELTY"
  ],
  [
    "-- The idea is novel , and is relatively unexplored in the research community .",
    "NOVELTY"
  ],
  [
    "Originality The proposed ideas are novel in the context of calibrated multi-class classification .",
    "NOVELTY"
  ],
  [
    "The paper presents potentially high-impact novel contributions and provides a much-needed rigorous unifying view on the topic .",
    "NOVELTY"
  ],
  [
    "paper presents an interesting view on the batch normalization method .",
    "NOVELTY"
  ],
  [
    "this paper is original significance",
    "NOVELTY"
  ],
  [
    "Using ECC theory for reducing the memory footprint of a neural network seems both intuitive and innovative , while being grounded in well-understood theory .",
    "NOVELTY"
  ],
  [
    "The proposed scheme , which delays the application of regularization parameter , seems to be in contrast of the continuation approach used in sparse learning",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "Although the paper is partially an application of earlier theoretical",
    "NOVELTY"
  ],
  [
    "results , it is a novel way to apply the theory , and the resulting",
    "NOVELTY"
  ],
  [
    "While the manuscript is partially an application of earlier methodological contributions on equivariant networks",
    "NOVELTY"
  ],
  [
    "it is definitely an original contribution",
    "NOVELTY"
  ],
  [
    "The methodology described is a fundamentally new way of describing molecular interactions , and could have substantial impact within the molecular force",
    "NOVELTY"
  ],
  [
    "A novel perspective to understand the recent progress of neural network is proposed .",
    "NOVELTY"
  ],
  [
    "and an interesting alternative to the previously described models",
    "NOVELTY"
  ],
  [
    "In my opinion , this is a novel and creative work . The B-spline embedding trick is clever and efficient .",
    "NOVELTY"
  ],
  [
    "The novelty of this method is somewhat low and a",
    "NOVELTY"
  ],
  [
    "The newly derived adversarial imitation learning method , which draws on a connection to generative adversarial networks ( GANs ) ( formulating the problem of learning an occupancy measure as a classification problem ) , is interesting and seems less limited than the previously existing state of the art",
    "NOVELTY"
  ],
  [
    "The approach is novel",
    "NOVELTY"
  ],
  [
    ", however , similar ideas have been tried to solve problems unrelated to GANs .",
    "NOVELTY"
  ],
  [
    "and introduced a novel idea and",
    "NOVELTY"
  ],
  [
    "The idea of learning kernels in meta-learning is interesting .",
    "NOVELTY"
  ],
  [
    "it is not clear to me that the method is invulnerable to novel white-box attacks",
    "NOVELTY"
  ],
  [
    "It is novel and should generate further research with respect to understanding its vulnerabilities more completely",
    "NOVELTY"
  ],
  [
    "The proposed model ( Section 2 ) has also not been considered in prior work .",
    "NOVELTY"
  ],
  [
    "Nice suggestion of choosing",
    "NOVELTY"
  ],
  [
    "-- ELU/SELU/Softplus/Swish all satisfy this suggestion Cons",
    "NOVELTY"
  ],
  [
    "Novelty may be not strong enough as the standard analysis tool from",
    "NOVELTY"
  ],
  [
    "was mostly used",
    "NOVELTY"
  ],
  [
    "The model outperforms competitors in a range",
    "NOVELTY"
  ],
  [
    "The paper does not have a significant novel contribution ,",
    "NOVELTY"
  ],
  [
    "but rather composes and combines existing methods in a novel way for an interesting application .",
    "NOVELTY"
  ],
  [
    "and contributes a novel ( to the best of my knowledge )",
    "NOVELTY"
  ],
  [
    "However , the paper does not contribute novel modeling or inference tools , but rather",
    "NOVELTY"
  ],
  [
    "combines existing work in a novel way",
    "NOVELTY"
  ],
  [
    "a meaningful advance in federated learning",
    "NOVELTY"
  ],
  [
    "I would consider the work in this paper to be incremental overall .",
    "NOVELTY"
  ],
  [
    "adversarial objective",
    "NOVELTY"
  ],
  [
    "while the paper is",
    "NOVELTY"
  ],
  [
    "quite simple",
    "NOVELTY"
  ],
  [
    "The proposed trick to split the non-smooth regularization looks interesting to me .",
    "NOVELTY"
  ],
  [
    "Overall I like the work but find the novelty quite limited",
    "NOVELTY"
  ],
  [
    "The overall contribution on model quantization is based on existing methods , which makes the novelty of the paper suffer a bit .",
    "NOVELTY"
  ],
  [
    "This is a really wonderful paper",
    "NOVELTY"
  ],
  [
    "The analytical idea for constructing echo noise is also quite clever .",
    "NOVELTY"
  ],
  [
    "As far as I can tell , this work is quite novel .",
    "NOVELTY"
  ],
  [
    "However , the proposed method has only a very incremental novelty compared to SPORF and the previous approaches in computer vision (",
    "NOVELTY"
  ],
  [
    "But the authors failed to propose a novel method and",
    "NOVELTY"
  ],
  [
    "I find it hard to justify the novelty of the paper as the formulation is not too technical .",
    "NOVELTY"
  ],
  [
    "I still do not see enough new contribution from this paper",
    "NOVELTY"
  ],
  [
    "but as someone who is not an expert it was hard to understand the extent of the contribution compared to existing literature",
    "NOVELTY"
  ],
  [
    "Cons There is little novelty in the proposed method/models -- the paper is primarily focused on comparing existing models on a new task",
    "NOVELTY"
  ],
  [
    "in its current form the novelty and analysis are limited",
    "NOVELTY"
  ],
  [
    "The paper claims that the approach is novel in the context of policy gradient and Deep RL",
    "NOVELTY"
  ],
  [
    "Also since the main idea and the algorithms are quiet similar to the Brain paper I believe the novelty of this work is at best marginal .",
    "NOVELTY"
  ],
  [
    "of mixup",
    "NOVELTY"
  ],
  [
    "give new insights for understanding Neural ODEs",
    "NOVELTY"
  ],
  [
    "I think the contribution is limited from the viewpoint of the study of graph NNs .",
    "NOVELTY"
  ],
  [
    "This paper introduces I2A model which has both model-free and model-based components .",
    "NOVELTY"
  ],
  [
    "I like the idea of using policy distillation to simultaneously learn the rollout policy .",
    "NOVELTY"
  ],
  [
    "The proposed model is novel and has several potential applications .",
    "NOVELTY"
  ],
  [
    "The idea is original and will probably lead to new directions of research .",
    "NOVELTY"
  ],
  [
    "Thus my opinion is that this paper brings original and significant ideas in the field .",
    "NOVELTY"
  ],
  [
    "Novelty While recurrent neural networks have been quite thoroughly analysed in similar ways , this is to my knowledge the first work that does this for GRUs .",
    "NOVELTY"
  ],
  [
    "I do n't see why it could n't inspire similar analysis of other popular RNN architectures",
    "NOVELTY"
  ],
  [
    "Very insightful plot of the relation between the gradient norm and spectral radius .",
    "NOVELTY"
  ],
  [
    "I believe the idea is interesting but it needs a significant empirical work to be published",
    "NOVELTY"
  ],
  [
    "however , its novelty is not even clear since authors did not discuss majority of the existing related work",
    "NOVELTY"
  ],
  [
    "and also not really new",
    "NOVELTY"
  ],
  [
    "2 .Novelty .This paper proposed a novel approach to reformulate the meta-RL problem as model identification with a gradient descent based algorithm . To the best of my knowledge , this was the first paper broke the meta-RL problem into a simpler meta supervised learning problem and an off-policy RL learning problem .",
    "NOVELTY"
  ],
  [
    "Although each component of the proposed solution was not new",
    "NOVELTY"
  ],
  [
    "the combination of each component to address the meta-RL problem seemed to the novel to me . And I think the idea could be interesting to the ICLR community .",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting",
    "NOVELTY"
  ],
  [
    "insufficient experiments I like the idea of embedding all points in an image onto a sphere in order to do image alignment and keypoint tracking",
    "NOVELTY"
  ],
  [
    "The clarity of",
    "NOVELTY"
  ],
  [
    "This is",
    "NOVELTY"
  ],
  [
    "I liked the idea of using depth information to inform visual",
    "NOVELTY"
  ],
  [
    "3 .To use a siamese ( shared weights ) feature extractor between RGB and Depth images or not , is not a significant contribution by itself .",
    "NOVELTY"
  ],
  [
    "The technique used in this paper is not completely new",
    "NOVELTY"
  ],
  [
    ", but I think it makes some nice contribution to the theoretical understanding of the problem .",
    "NOVELTY"
  ],
  [
    "The improvements over basic ensembling are rather minimal",
    "NOVELTY"
  ],
  [
    "The novelty of this method is minimal .",
    "NOVELTY"
  ],
  [
    "this paper is good",
    "NOVELTY"
  ],
  [
    "but is not novel or important enough for acceptance .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and seems novel .",
    "NOVELTY"
  ],
  [
    "The approach is a refinement of previous methods ( iterative RPN , GA-RPN ) and thus incremental .",
    "NOVELTY"
  ],
  [
    "I enjoyed reading the paper and think it is novel enough to be accepted .",
    "NOVELTY"
  ],
  [
    "The novelty of the method is very limited .",
    "NOVELTY"
  ],
  [
    "the novelty of the work is not",
    "NOVELTY"
  ],
  [
    "The work does not propose any big new",
    "NOVELTY"
  ],
  [
    "ideas but it does propose a novel solution to a problem of growing importance in neuroscience .",
    "NOVELTY"
  ],
  [
    "I like the overall approach and the insight that when answering per-point queries , leveraging corresponding image-based features via reprojection should also help .",
    "NOVELTY"
  ],
  [
    "Similar insights have been exploited in learning-based multi-view reconstruction works",
    "NOVELTY"
  ],
  [
    ", but this approach is novel in context of single-view 3D reconstruction .",
    "NOVELTY"
  ],
  [
    "2017 .Novelty of the method over [ 44 ] is not major",
    "NOVELTY"
  ],
  [
    "It improves over the previous approaches that used simpler compositing operations",
    "NOVELTY"
  ],
  [
    ", and it presents several interesting ideas",
    "NOVELTY"
  ],
  [
    "Therefore , the paper can not be qualified for `` meta domain adaptation \u2019 \u2019 and has very limited novelty in terms of its contribution to meta-learning",
    "NOVELTY"
  ],
  [
    "the combination of domain adaptation and few-shot learning is fair",
    "NOVELTY"
  ],
  [
    "However , my criticisms remain that the paper is a simple combination of cycle GAN and prototypical networks , and lacks new insights/novelty .",
    "NOVELTY"
  ],
  [
    "the idea of proposal network break the traditional framework of sequence tagging formulation in NER task and thus can be effectively applied to detect overlapped named entities",
    "NOVELTY"
  ],
  [
    "The enumerating span ideas has been applied in many other tasks as well such as coreference resolution",
    "NOVELTY"
  ],
  [
    "none of which is mentioned in related work",
    "NOVELTY"
  ],
  [
    "I am afraid that the contributions of the paper are still not strong enough to reach the bar of acceptance because of the following reasons",
    "NOVELTY"
  ],
  [
    "The path encoding is an interesting approach and seems to improve upon just using the adjacency matrix directly",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "The work borders on incremental ( relative to their earlier work or that of Parikh et al . )",
    "NOVELTY"
  ],
  [
    "In summary -- the paper is self contained and makes a strong contribution",
    "NOVELTY"
  ],
  [
    "A new view of BN as a Kurtosis minimiser",
    "NOVELTY"
  ],
  [
    "Proposed method introduces interesting multi-modality effect to neuron activations Cons",
    "NOVELTY"
  ],
  [
    "The main contributions of the paper are the formalism for the novel multi-fidelity bandit optimization setting and the MF-GP-UCB algorithm for which a theoretical analysis of the regret upper bound is provided",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "This idea is original and quite nice .",
    "NOVELTY"
  ],
  [
    "-This paper has some interesting ideas ,",
    "NOVELTY"
  ],
  [
    "The overall novelty of the proposed method is not very significant",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first input sparsity time algorithm for this problem .",
    "NOVELTY"
  ],
  [
    "This is the first theoretical work",
    "NOVELTY"
  ],
  [
    "The task of the conditional generation of graphs is new , as well as the constraint of permutation invariance , and the flexibility in terms of the generated graph structures ( non-fixed set of nodes ) .",
    "NOVELTY"
  ],
  [
    "The second contribution of the paper , i.e. , the connection to epsilon norms and its impact on computation complexity of the sparse group lasso dual norm is the most exciting part of the work .",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "However , I do not find the M-step to be novel because the maximization of pseudolikelihood for MLNs is standard fare",
    "NOVELTY"
  ],
  [
    "I think it is a good paper and I like the contribution of the author .",
    "NOVELTY"
  ],
  [
    "This idea is not new",
    "NOVELTY"
  ],
  [
    "The idea of learning the models of environment ( or reward ) and simulating the model to train the policy is not novel",
    "NOVELTY"
  ],
  [
    "but the combination of these two is novel to my knowledge",
    "NOVELTY"
  ],
  [
    "I think that the paper in its present state have low novelty ,",
    "NOVELTY"
  ],
  [
    "2 .The exploration carried out in the paper is more on the system level and the novelty is not overwhelmingly significant",
    "NOVELTY"
  ],
  [
    "To my knowledge , the theoretical analysis carried out by the authors in the context of fully labeled data is novel .",
    "NOVELTY"
  ],
  [
    "I find the results interesting",
    "NOVELTY"
  ],
  [
    "as well as the resulting algorithm",
    "NOVELTY"
  ],
  [
    "however , it is hard to claim novelty in individual ideas in the paper .",
    "NOVELTY"
  ],
  [
    "Pros -The method outperforms the state-of-art regarding unsupervised methods for handwritten digits clustering on MNIST . -Use of ACOL and GAR is interesting",
    "NOVELTY"
  ],
  [
    "My main problem was about the lack of novelty .",
    "NOVELTY"
  ],
  [
    "I regard this paper as very interesting , as it has successfully married the capsules idea with conv nets , and makes use of the dynamic routing capabilities .",
    "NOVELTY"
  ],
  [
    "The idea of capsules is not new",
    "NOVELTY"
  ],
  [
    "Overall , I enjoyed the paper and the performance is interesting .",
    "NOVELTY"
  ],
  [
    "This paper should be rejected because it lacks originality",
    "NOVELTY"
  ],
  [
    "My main concern is about the novelty of the method",
    "NOVELTY"
  ],
  [
    "the unstructured grids",
    "NOVELTY"
  ],
  [
    "I think this paper has solid contributions",
    "NOVELTY"
  ],
  [
    "Its incorporation of key RL concepts ( like discounting and eligibility traces ) and the flexibility to learn these is very appealing .",
    "NOVELTY"
  ],
  [
    "significant contribution",
    "NOVELTY"
  ],
  [
    "The novel contributions are clearly marked as such",
    "NOVELTY"
  ],
  [
    "One could object that the originality with respect to the state-of-the-art approaches is limited since the difference with the Nie et al .approaches are that",
    "NOVELTY"
  ],
  [
    "my opinion is that the contribution is enough for the paper to be published",
    "NOVELTY"
  ],
  [
    "I think that the methodological contribution is incremental",
    "NOVELTY"
  ],
  [
    "I like the presentation and the thinking here",
    "NOVELTY"
  ],
  [
    "While the normative framework utilized in the work is not new",
    "NOVELTY"
  ],
  [
    ", the analysis that establishes the conditions under which hexagonal grid cells emerge is original and interesting and I believe relevant to NeurIPS .",
    "NOVELTY"
  ],
  [
    "Compared to prior work , the novelty is somewhat limited however",
    "NOVELTY"
  ],
  [
    "The method itself is incremental .",
    "NOVELTY"
  ],
  [
    "this work can be seen as complementary to many related works such as Igl 18 , but the novelty of the idea is rather limited .",
    "NOVELTY"
  ],
  [
    "I think the trick the paper uses is a practical one but not significantly novel enough for the ICLR community .",
    "NOVELTY"
  ],
  [
    "Clear , simple , and innovative idea",
    "NOVELTY"
  ],
  [
    "The proposed model is novel and seems to be suitable for the problem at hand .",
    "NOVELTY"
  ],
  [
    "I think there are some interesting ideas here",
    "NOVELTY"
  ],
  [
    "-- Summary -- The authors proposes a novel approach in learning a representation for HRL .",
    "NOVELTY"
  ],
  [
    "-- novelty -- To the best of my knowledge , this is the first paper that formalizes a framework for sub-optimality of goal-conditioned HRL and I think this is the main contribution of the paper , that might have lasting effect in the field .",
    "NOVELTY"
  ],
  [
    "There are multiple interesting contributions in this paper .",
    "NOVELTY"
  ],
  [
    "and it seems the authors advance the state-of-the-art with a solid and clear contribution",
    "NOVELTY"
  ],
  [
    "Even though the technology itself is not super exciting and completely new",
    "NOVELTY"
  ],
  [
    ", applying RL to tailor this specific problem is novel enough for a paper .",
    "NOVELTY"
  ],
  [
    "I like the idea and problem formulation ,",
    "NOVELTY"
  ],
  [
    "The reported speed-up of CA-imaging analysis by the proposed algorithm is extremely interesting",
    "NOVELTY"
  ],
  [
    "Tensorizing to a higher-order tensor with lower mode sizes and factorizing through tensor network approaches is not a new approach ,",
    "NOVELTY"
  ],
  [
    "it seems that this is the first effort of applying those ideas in the context of compressing neural network ( NN ) parameters , as well as deriving the update rules w.r.t .a NN",
    "NOVELTY"
  ],
  [
    "This idea is interesting to me .",
    "NOVELTY"
  ],
  [
    "I have some concerns about the contribution of the paper",
    "NOVELTY"
  ],
  [
    "The algorithm does not have any important contributions comparing to existing ones",
    "NOVELTY"
  ],
  [
    "The proposed method tends to be incremental .",
    "NOVELTY"
  ],
  [
    "Certainly a nice idea to explore within a NIPS community .",
    "NOVELTY"
  ],
  [
    "The contribution is incremental and the results are not significant .",
    "NOVELTY"
  ],
  [
    "novelty is low : the proposed algorithm is a heuristic similar to previously proposed algorithms in the transfer learning and auxiliary learning space",
    "NOVELTY"
  ],
  [
    "Unfortunately , the proposed method has limited novelty .",
    "NOVELTY"
  ],
  [
    "and the method here seems a bit ad-hoc and does n't compare to existing work",
    "NOVELTY"
  ],
  [
    "This is a nice piece of incremental work on top of previously published GAN imputation methods .",
    "NOVELTY"
  ],
  [
    "The proposed method is a minor extension of the existing method GraphSAGE",
    "NOVELTY"
  ],
  [
    "The scoring function that measure the number of points that must be changed to change a pairwise comparison of hypotheses appears to be a novel contribution , and its application into the exponential mechanism ( or GAP-MAX ) achieves novel utility bounds .",
    "NOVELTY"
  ],
  [
    "The paper proposed a simple but novel approach to make CNNs shift-invariant following the traditional signal processing principle .",
    "NOVELTY"
  ],
  [
    "The techniques are not fundamentally novel .",
    "NOVELTY"
  ],
  [
    "Novelty and significance -- -- -- -- -- -- -- -- -- -- -- -- While the proposed method draws inspiration from a variety of existing methods in transfer learning ( notably [ 20 ] ) , the particular formulation using deep residual networks as a meta-model , modeling the dynamics of adding progressively more training examples , and handling the case of different numbers of available training examples per category in a unified and automatic way are novel aspects of the paper to my knowledge .",
    "NOVELTY"
  ],
  [
    "I am a bit concerned with novelty as the `` reverse cross-entropy `` loss is not strictly new",
    "NOVELTY"
  ],
  [
    "However I do believe this paper is relatively weak in contribution",
    "NOVELTY"
  ],
  [
    "Overall , this paper proposed a novel optimistic non-parametric likelihood estimation .",
    "NOVELTY"
  ],
  [
    "The key novelties are the handling of a loss function over multiple decodings as well as the use of novel genetic algorithms to generate the adversari al examples .",
    "NOVELTY"
  ],
  [
    "what would happen if the Alzantot et al .method was applied to each While the idea is interesting but incremental , the evaluation of the approach is weak",
    "NOVELTY"
  ],
  [
    "This paper seems less novel .",
    "NOVELTY"
  ],
  [
    "I think the idea Combining ii-loss with Cross Entropy Loss proposed in this paper is quite similar to the Center Loss except that a",
    "NOVELTY"
  ],
  [
    "this paper seems not that novel",
    "NOVELTY"
  ],
  [
    "Both the the new minibatch estimator to train the objective based on the Total Correlation penalty , and the new disentanglement metric seem novel and significant advancements in the field . Besides explaining the way the beta-VAE works , the new",
    "NOVELTY"
  ],
  [
    "Pruning or regularization for compression is not new",
    "NOVELTY"
  ],
  [
    "The proof technique is not novel",
    "NOVELTY"
  ],
  [
    ", however the result is new to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The regret guarantees are fairly standard , but again novel .",
    "NOVELTY"
  ],
  [
    "and the novelty is limited",
    "NOVELTY"
  ],
  [
    "the paper presents an interesting idea and it is relatively easy to",
    "NOVELTY"
  ],
  [
    "The idea of using InfoMax with GCNs for unsupervised node learning is clever and timely",
    "NOVELTY"
  ],
  [
    "The methods proposed here are not all too original",
    "NOVELTY"
  ],
  [
    "`` It 's unclear if this observation is novel , but in any case the connection between these observations across NMT and summarization /captioning tasks is novel",
    "NOVELTY"
  ],
  [
    "The overall contribution is valid yet a bit incremental .",
    "NOVELTY"
  ],
  [
    "I would say the paper has made a valid yet quite limited improvement without",
    "NOVELTY"
  ],
  [
    "The tools and techniques used in the proofs are pretty standard , and do not contain novel ideas .",
    "NOVELTY"
  ],
  [
    "While none of the ideas , in isolation , are significantly new",
    "NOVELTY"
  ],
  [
    "The technical contributions of this paper are quite limited .",
    "NOVELTY"
  ],
  [
    "In doing so , it proposes a novel approach of explicit multilinear feature map to combine the feature representation as well as classifier output of a source/target sample before being fed to the domain-discriminator .",
    "NOVELTY"
  ],
  [
    "The approach is interesting",
    "NOVELTY"
  ],
  [
    "although this paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "if there 's any , it seems to be incremental .",
    "NOVELTY"
  ],
  [
    "the novelty of the methodology proposed by the authors might be limited",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "Overall , this is an impressive work with unique innovation .",
    "NOVELTY"
  ],
  [
    "unique",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "and perhaps the main innovation in this paper",
    "NOVELTY"
  ],
  [
    "contribution . It is also not clear if those theoretical results are novel .",
    "NOVELTY"
  ],
  [
    "Novelty The main contribution of this paper is basically a set of experiments looking into architectural choices",
    "NOVELTY"
  ],
  [
    "Thus , as such , the novelty or the contributions of this paper are minor .",
    "NOVELTY"
  ],
  [
    "the experiments do not offer any surprises",
    "NOVELTY"
  ],
  [
    "My biggest concern is the novelty of the model , since RTF is still a replay-based method that is very similar as DGR+distill",
    "NOVELTY"
  ],
  [
    "there seem to be no significant contribution of the proposed model . In my opinion , this paper look somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The combination of sampling in areas of 'greater interest ' while adjusting to the underlying distribution appears in many active learning works , but",
    "NOVELTY"
  ],
  [
    "the objective in ( 1 ) is novel and approaching both in a unified framework is challenging . The lower bounding of the optimization problem is also new Quality",
    "NOVELTY"
  ],
  [
    "However the theoretical contributions appear incomplete .",
    "NOVELTY"
  ],
  [
    "Overall , quite a neat idea",
    "NOVELTY"
  ],
  [
    "the application to low-rank matrix recovery appears to be novel here",
    "NOVELTY"
  ],
  [
    "My knowledge in this particular subfield is limit and I therefore can not assess the novelty of the approach",
    "NOVELTY"
  ],
  [
    "Trains a regression model that predicts improvement in generalisation error * To the best of my knowledge this is an original approach to this problem",
    "NOVELTY"
  ],
  [
    "The contribution is incremental .",
    "NOVELTY"
  ],
  [
    "the idea of learning uncertainty of BNN in the functional space appeared in Prof.",
    "NOVELTY"
  ],
  [
    "PQ is known to be successful for quantization in",
    "NOVELTY"
  ],
  [
    "The paper was very clear on its contribution . The variable-size input of this paper was novel as far as I know .",
    "NOVELTY"
  ],
  [
    "I think much of the ideas considered in this paper is already explored in previous work as it is acknowledged in the paper",
    "NOVELTY"
  ],
  [
    "However some of the techniques such as the way the policy is represented and the way the policy gradient formulation is approximated seems to be novel in the context of Deep RL though again these ideas have been explored in the literature of control and RL extensively",
    "NOVELTY"
  ],
  [
    "but it seems clear that there is no novelty nor sufficient rigor in it",
    "NOVELTY"
  ],
  [
    "Novelty-wise , there is very little as all modules have been commonly used for SR tasks .",
    "NOVELTY"
  ],
  [
    "To my understanding , the analysis of pPCA ( which probably has been observed before ) and Theorem 1 are rather interesting findings",
    "NOVELTY"
  ],
  [
    "I still believe there is a mismatch between experiments and theory but this is a good contribution",
    "NOVELTY"
  ],
  [
    "Derives a novel bound on accuracy and optimizes it , achieving state of the art results . The proof , bound , and algorithm are all novel and interesting . Although they build",
    "NOVELTY"
  ],
  [
    "However , it is a composition of ideas ( Hawkes processes , latent variable model ) that are not particularly novel . The problem itself is also not new .",
    "NOVELTY"
  ],
  [
    "I 'd rank the paper below average in terms of its novelty",
    "NOVELTY"
  ],
  [
    "The method is interesting",
    "NOVELTY"
  ],
  [
    "The final method is a mixup of many different techniques",
    "NOVELTY"
  ],
  [
    "not a strong contribution , but many smaller contributions",
    "NOVELTY"
  ],
  [
    "The connection to dropout , and the use of the Markov chain as away to get a robust model , is very interesting .",
    "NOVELTY"
  ],
  [
    "the neural networks used in the experiments are quite outdated .",
    "NOVELTY"
  ],
  [
    "Method is novel to me .",
    "NOVELTY"
  ],
  [
    "Its contribution is largely empirical \u00e2\u0080\u0093 the model is not new to the NIPS community and the general framework has been used several times in the past at NIPS",
    "NOVELTY"
  ],
  [
    "This paper is interesting",
    "NOVELTY"
  ],
  [
    "My major concern about this paper is its novelty .",
    "NOVELTY"
  ],
  [
    "My understanding is that NIPS papers should have notable novel contributions",
    "NOVELTY"
  ],
  [
    "The idea sounds interesting",
    "NOVELTY"
  ],
  [
    "while this seems like an interesting",
    "NOVELTY"
  ],
  [
    "I enjoyed the general theoretical framework provided , which is then specialized to the finite mixture model setting .",
    "NOVELTY"
  ],
  [
    "This paper is refreshing and elegant in its handling of ``",
    "NOVELTY"
  ],
  [
    "This is novel work and is something that expands the toolkit available to practitioners . I believe that this is a significant contribution as it provides a new an",
    "NOVELTY"
  ],
  [
    "and novel as far as the reviewer knows about",
    "NOVELTY"
  ],
  [
    "and thus the novelty of this contribution is also weak",
    "NOVELTY"
  ],
  [
    "The way of constructing deformation adversarial is interesting and novel",
    "NOVELTY"
  ],
  [
    "The paper can be a very interesting contribution to the conference and can be accepted as is",
    "NOVELTY"
  ],
  [
    "excellent",
    "NOVELTY"
  ],
  [
    "The main idea , to match up angles between points on the hypersphere and Hamming distance is pretty clever",
    "NOVELTY"
  ],
  [
    "I think this work contains a great main idea and could become quite a good paper in the future",
    "NOVELTY"
  ],
  [
    "2 .The originality of this paper lies in the usage of generative model to predict task id ( H-Net ) . To my knowledge has not been proposed before .",
    "NOVELTY"
  ],
  [
    "Expanding the network for new tasks is not a novel contribution of this paper , it has already been proposed in previous works on multi-task learning . Doing expansion on all of the layers does not qualify for a major",
    "NOVELTY"
  ],
  [
    "The weighted-online FDR control is a nice extension of online-FDR .",
    "NOVELTY"
  ],
  [
    "I think , two new ideas .",
    "NOVELTY"
  ],
  [
    "and to advance some interesting and important ideas for that literature .",
    "NOVELTY"
  ],
  [
    "both contributions are only loosely connected and b",
    "NOVELTY"
  ],
  [
    "The proposed method is a novel combination of the GRU-ODE and the GRU-Bayes .",
    "NOVELTY"
  ],
  [
    "The introduction of ArbNets does not bring much value or insight",
    "NOVELTY"
  ],
  [
    "interesting idea .",
    "NOVELTY"
  ],
  [
    "As far as I know , the core concept is original",
    "NOVELTY"
  ],
  [
    ", although indeed closely related to some previous work",
    "NOVELTY"
  ],
  [
    "This is a nice trick which is powerful enough to prove tight lower bounds , and extends generically to give lower bounds for ( eps , delta ) -DP . To summarize , the results are fairly interesting , deftly leverage recent advances in distribution testing , and introduce some nice new techniques .",
    "NOVELTY"
  ],
  [
    "The proposed idea is original and",
    "NOVELTY"
  ],
  [
    "A really novel methodology to learn search spaces in Bayesian Optimization that is able to build ellipsoidal search spaces that are sampled through rejection sampling .",
    "NOVELTY"
  ],
  [
    "I found this piece of work very interesting",
    "NOVELTY"
  ],
  [
    "The proposed architecture is novel",
    "NOVELTY"
  ],
  [
    "but limited to the benchmarks . The curriculum learning has been already explored .",
    "NOVELTY"
  ],
  [
    "Concerning the contributions of this paper , I find them novel and significant .",
    "NOVELTY"
  ],
  [
    "The manuscript at the current stage seems to be a preliminary work that is not well matured yet .",
    "NOVELTY"
  ],
  [
    "Using GAN to generate conditional independent sample is a new design and a new method to tackle the problem .",
    "NOVELTY"
  ],
  [
    "but the contribution so far is limited .",
    "NOVELTY"
  ],
  [
    "The main novelty of the paper seems to be the use of multiple GAN on different splits of the data , which seems a bit limited",
    "NOVELTY"
  ],
  [
    "The idea behind a Sparse Gated Mixture ( GM ) of Expert model has already been proposed in [ 1 ] .",
    "NOVELTY"
  ],
  [
    "The idea of using sparsely gated experts is very promising and finding new ways to apply it within model architectures",
    "NOVELTY"
  ],
  [
    "work",
    "NOVELTY"
  ],
  [
    "Some weaknesses are that the paper\u00e2\u0080\u0099s results are largely engineering-related , as the architecture itself does not contain many novel components but combines previous work",
    "NOVELTY"
  ],
  [
    "CAB ) into a higher performing model",
    "NOVELTY"
  ],
  [
    "this The improvement over DCGAN is quite limited given previous works such as WGAN-GP",
    "NOVELTY"
  ],
  [
    "This contributes to both originality and significance .",
    "NOVELTY"
  ],
  [
    "The proposed approach seems novel and contains lots of innovative design choices from experimental measurement setup to computational signal processing architecture .",
    "NOVELTY"
  ],
  [
    "The techniques in this work seem to be relatively principled and fit into the related work well .",
    "NOVELTY"
  ],
  [
    "This work seems like a",
    "NOVELTY"
  ],
  [
    "different take on a well-established problem",
    "NOVELTY"
  ],
  [
    "This is an interesting policy-as-inference approach",
    "NOVELTY"
  ],
  [
    "The novelty lies in not requiring normalization to account for gain variation , which is interesting .",
    "NOVELTY"
  ],
  [
    "The idea of structured matrices in this context is not new , but the diagonal block structure appears to be .",
    "NOVELTY"
  ],
  [
    "I think this work has theoretical novelty in understanding CASDF and has experimental support .",
    "NOVELTY"
  ],
  [
    "While the idea here is novel and impactful",
    "NOVELTY"
  ],
  [
    "but because this is novel and important work",
    "NOVELTY"
  ],
  [
    "The work is original and provides a new theoretical view on the robustness of word embeddings .",
    "NOVELTY"
  ],
  [
    "The idea of designing learnhull algorithm and its analysis is very interesting .",
    "NOVELTY"
  ],
  [
    "It is an interesting attempt to use the style-transferred images for generalization of RL agents .",
    "NOVELTY"
  ],
  [
    "It is a novel attempt to use GANs to generate pictures that help RL agents transfer the policies to other related environments .",
    "NOVELTY"
  ],
  [
    "While the paper does not propose a",
    "NOVELTY"
  ],
  [
    "novel algorithm",
    "NOVELTY"
  ],
  [
    "should be `` +W^-\u00e2\u0080\u009c The construction of the Laplacian is novel and interesting",
    "NOVELTY"
  ],
  [
    "The paper provides a novel extension of the Structured Procrastination ( SP ) algorithm together with a novel theoretical analysis .",
    "NOVELTY"
  ],
  [
    "The algorithm seems to be a clear improvement over previous work",
    "NOVELTY"
  ],
  [
    "The proposed algorithm improves over existing work in that it is both anytime and adaptive .",
    "NOVELTY"
  ],
  [
    "However the novelty is limited and not well explained .",
    "NOVELTY"
  ],
  [
    "approach is interesting and promising",
    "NOVELTY"
  ],
  [
    "I like the general premise of the paper .",
    "NOVELTY"
  ],
  [
    "This is not a new direction , however",
    "NOVELTY"
  ],
  [
    "There are also novel directions in this work that haven\u00e2\u0080\u0099t been explored in previous works .",
    "NOVELTY"
  ],
  [
    "I like the paper and the direction it\u00e2\u0080\u0099s taking .",
    "NOVELTY"
  ],
  [
    "this significantly reduces the novelty of the analysis",
    "NOVELTY"
  ],
  [
    "The paper seems to be the first to combine reward maximization and 1-step empowerment inside a single objective function .",
    "NOVELTY"
  ],
  [
    "Significance -- -- -- -- -- -- -- The main contribution of the paper is on the theoretical side",
    "NOVELTY"
  ],
  [
    "The idea of dividing the latent representation in different subsets and using a proxy task involving triplets of images has been already explored in",
    "NOVELTY"
  ],
  [
    "However , the use of Siamese networks in this context is novel and sound .",
    "NOVELTY"
  ],
  [
    "+The idea of using a proxy task ( contrastive loss with triplets of generated images ) is somewhat novel and promising .",
    "NOVELTY"
  ],
  [
    "1 .This is an interesting paper - introduces useful concepts such as the formulation of the utility and privacy loss functions with respect to the learning paradigm 2",
    "NOVELTY"
  ],
  [
    "The idea proposed is fairly straight-forward .",
    "NOVELTY"
  ],
  [
    "The contribution is interesting and the idea to replace the restrictive rank one",
    "NOVELTY"
  ],
  [
    "Moderate to high The idea of using better , more human-aligned risks is a nice idea that extends recent interest in having more risk-averse losses and training procedures .",
    "NOVELTY"
  ],
  [
    "I think the ideas and approach are new ,",
    "NOVELTY"
  ],
  [
    "The idea of training the physics part of the network with synthetic data and later fine-tuning it with real images is interesting .",
    "NOVELTY"
  ],
  [
    "Overall the method looks very interesting .",
    "NOVELTY"
  ],
  [
    "paper proposes a novel intrinsic reward/curiosity metric that combines both episodic and \u201c life-long \u201d novelty",
    "NOVELTY"
  ],
  [
    "the analysis is nontrivial",
    "NOVELTY"
  ],
  [
    "The idea of storing a small subset of a original dataset for each task has been already explored in [ Nguyen et al .18 ] , and thus is not novel .",
    "NOVELTY"
  ],
  [
    "The technological contribution is rather limited .",
    "NOVELTY"
  ],
  [
    "The idea is novel and worth exploring",
    "NOVELTY"
  ],
  [
    "it is not a breakthrough in the sense that a domain-specific representation is expected to be better behaved than the features of the inception classifier and using a Gaussian mixture would be an obvious step after FID",
    "NOVELTY"
  ],
  [
    "Combination of two idea seems novel . I like the idea of considering the weight parameter as the `` global `` random variables and the mask parameters as the task-specific random variables .",
    "NOVELTY"
  ],
  [
    "In general , I think it is a nice idea to combine two existing approaches .",
    "NOVELTY"
  ],
  [
    "I think the claim that the proposed definition of qW is new is not true",
    "NOVELTY"
  ],
  [
    "and introduces an interesting approach that combines SeqGANs with MIXER training and a self critical baseline .",
    "NOVELTY"
  ],
  [
    "I find the proposed technique interesting",
    "NOVELTY"
  ],
  [
    "Improvements over previous techniques seem somewhat incremental",
    "NOVELTY"
  ],
  [
    "Theoretical contributions : None .",
    "NOVELTY"
  ],
  [
    "as far as I know , the MCTS approach for the NAS problem is not a standard solution for NAS ( which is not proved to be practically useful in other people",
    "NOVELTY"
  ],
  [
    "which diminishes the contribution of the improvements of MCTS in NAS",
    "NOVELTY"
  ],
  [
    "These ideas are novel and shown to provide better superior performance",
    "NOVELTY"
  ],
  [
    "and with new contributions",
    "NOVELTY"
  ],
  [
    "The improvement of convergence speed by increasing the step-size due to the observation that not all atoms are used is natural",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel method of variable selection for functional classification .",
    "NOVELTY"
  ],
  [
    "Novelty/originality To the best of my knowledge , no one has previously suggested using MH in this way . The method is new .",
    "NOVELTY"
  ],
  [
    "I am not convinced that the level of novelty is very high",
    "NOVELTY"
  ],
  [
    "the introduced way of fine-tuning is interesting alternative to the typical last layer re-training .",
    "NOVELTY"
  ],
  [
    "the contributions are novel to my best knowledge .",
    "NOVELTY"
  ],
  [
    "I believe that this paper is not the first one to study question generation from logical form",
    "NOVELTY"
  ],
  [
    "The use of a weighted sum of the forward & KL divergences to train a generative model is hardly new ,",
    "NOVELTY"
  ],
  [
    "and this submission does not contribute much",
    "NOVELTY"
  ],
  [
    "Overall originality is minor ; projected significance is minor to medium .",
    "NOVELTY"
  ],
  [
    "2 .Learning to output the k class membership probability and the loss in eqn 5 seems novel .",
    "NOVELTY"
  ],
  [
    "I think this is a very interesting and novel approach to regression .",
    "NOVELTY"
  ],
  [
    "It 's a novel and promising approach to an interesting problem in regression .",
    "NOVELTY"
  ],
  [
    "This is a valuable advance , though somewhat incremental .",
    "NOVELTY"
  ],
  [
    "and the hierarchical normal prior formulation with conditionally conjugate updates is very clever . Overall , I like the proposed ideas .",
    "NOVELTY"
  ],
  [
    "it is not exactly modern",
    "NOVELTY"
  ],
  [
    "Novel high-level controller that takes in front-view visual information + Novel multi-policy low level controller",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this paper proposes a novel interesting method for modeling humanoid motor skills with front-view visual input .",
    "NOVELTY"
  ],
  [
    "I find this to be a good paper presenting an interesting method",
    "NOVELTY"
  ],
  [
    "I do find interesting the formulation of population risk in terms of tensor decomposition , this is insightful My issues with the paper are as follows",
    "NOVELTY"
  ],
  [
    "the technical analysis does not seem to be very different that what existed in the literature .",
    "NOVELTY"
  ],
  [
    "the derivation of lower bounds seem to be pretty novel .",
    "NOVELTY"
  ],
  [
    "This kind of relational modeling has been seen in many other domains .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "The idea themselves are possibly not too surprising , but their combination is novel and",
    "NOVELTY"
  ],
  [
    "The idea of using rewiring to make graph attack is interesting and sensible .",
    "NOVELTY"
  ],
  [
    "The suggested surrogate task that learns view-invariant representation is interesting",
    "NOVELTY"
  ],
  [
    "While the approach is novel and well-motivated",
    "NOVELTY"
  ],
  [
    "As far as I know , this work is among the earliest works to think about GNN pre-training .",
    "NOVELTY"
  ],
  [
    "These strategies are not surprising for me and the novelty is incremental .",
    "NOVELTY"
  ],
  [
    "and has a good contribution",
    "NOVELTY"
  ],
  [
    "This is an important and novel contribution where the authors propose an approach for OPE that comes down to solving a fixed point operator .",
    "NOVELTY"
  ],
  [
    "their main contribution is in terms of using such operators for the OPE problem , which seems novel to me and is an interesting approach",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper has useful contributions .",
    "NOVELTY"
  ],
  [
    ", reformulate neural architecture search for video representation is novel .",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "3 .I do like the proposed method .",
    "NOVELTY"
  ],
  [
    "It is hard to observe anything new",
    "NOVELTY"
  ],
  [
    "To my knowledge , the idea of considering latent variables that might be or might not be shared across different environments and the idea of considering latent environments are new and original .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this has not been done before and opens interesting research diretions .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm with an innovative IRN architecture was intriguing .",
    "NOVELTY"
  ],
  [
    "The authors propose a novel relaxation ( to the best of my knowledge ) for networks with ReLU activations that tighten previously proposed relaxations that ignore the correlations between neurons in the network . The theoretical results are also novel (",
    "NOVELTY"
  ],
  [
    "although unsurprising )",
    "NOVELTY"
  ],
  [
    "Another concern is that the paper seems to borrow quite a lot of ideas from the paper `` Global Guarantees for Enforcing Deep Generative Priors by Empirical Risk `` by Hand and Voroninski",
    "NOVELTY"
  ],
  [
    "The core idea of the proposed paper is very interesting .",
    "NOVELTY"
  ],
  [
    "This idea has been explored previously in other multi-modal works on the literature",
    "NOVELTY"
  ],
  [
    "so the technical novelty is limited",
    "NOVELTY"
  ],
  [
    "The proposed approach is definitely interesting and novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The novelty is marginal .",
    "NOVELTY"
  ],
  [
    "this paper sounds like a direct application of the method of Arora et al.",
    "NOVELTY"
  ],
  [
    "Overall , I have to say that I am very disappointed with this paper , because there are no new theoretical tools being introduced , and the authors seem to be applying Arora et al.",
    "NOVELTY"
  ],
  [
    "The approach of the paper to the problem is",
    "NOVELTY"
  ],
  [
    "The paper appears to be the first to give fast learning rates for learning in unbounded domains with heavy tailed loss functions , under conditions introduced",
    "NOVELTY"
  ],
  [
    "Originality It seems that the proposed extension was not proposed before but it seems like a straight forward extension",
    "NOVELTY"
  ],
  [
    "this paper is interesting",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting",
    "NOVELTY"
  ],
  [
    "the technical contribution seems very limited .",
    "NOVELTY"
  ],
  [
    "-- This paper presents an interesting empirical analysis relating fairness to disentanglement of learned representations",
    "NOVELTY"
  ],
  [
    "Therefore I think the paper makes a good contribution despite a number of smaller issues",
    "NOVELTY"
  ],
  [
    "I think the paper makes a good contribution as it stands and may inspire a lot of interesting",
    "NOVELTY"
  ],
  [
    "and the contribution is relevant to ICLR . NTP systems by combining the advantages of neural models and symbolic reasoning are a promising research direction .",
    "NOVELTY"
  ],
  [
    "I found the paper relatively creative and",
    "NOVELTY"
  ],
  [
    "Performing discrete , stochastic memory addressing for memory-augmented generative model is a novel idea which makes sense .",
    "NOVELTY"
  ],
  [
    "this is a good paper that presents a novel , working idea",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "some interesting ideas for",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed model is limited since it is essentially adding an existing GGNN layer",
    "NOVELTY"
  ],
  [
    "on top of an existing LSTM encoder",
    "NOVELTY"
  ],
  [
    "Overall the paper brings an incremental but valuable contribution , and is very competent in its presentation .",
    "NOVELTY"
  ],
  [
    "The idea of using the prototype and the polar system is interesting ,",
    "NOVELTY"
  ],
  [
    "I am a bit concerned about the novelty of the approach .",
    "NOVELTY"
  ],
  [
    "Currently the paper does not show very-well the contributions",
    "NOVELTY"
  ],
  [
    "and the proposed technique is novel .",
    "NOVELTY"
  ],
  [
    "I think that having a Minimum Mean Squared Error ( MMSE ) estimator is , by itself , very interesting and a good contribution .",
    "NOVELTY"
  ],
  [
    "While the proposed",
    "NOVELTY"
  ],
  [
    "approach seems novel",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "The approach seems really interesting and I think combining demonstrations with reinforcement learning for meta learning is a very promising approach .",
    "NOVELTY"
  ],
  [
    "While the novelty of this paper is low",
    "NOVELTY"
  ],
  [
    "I think it is a great contribution .",
    "NOVELTY"
  ],
  [
    "however , the idea of using an extra label for OODs is not new and was previously explored in different domains .",
    "NOVELTY"
  ],
  [
    "I found that this submission contains several interesting ideas . The theoretical proposal about the function of gain modulation seems to be novelty",
    "NOVELTY"
  ],
  [
    "While the problem statement is novel",
    "NOVELTY"
  ],
  [
    "the methodological novelty smaller than the bulk of ICLR works , and",
    "NOVELTY"
  ],
  [
    "I am concerned by the lack of methodological advance .",
    "NOVELTY"
  ],
  [
    "which of itself is not a bad idea",
    "NOVELTY"
  ],
  [
    "The general idea is not unique",
    "NOVELTY"
  ],
  [
    ", but it is an interesting one",
    "NOVELTY"
  ],
  [
    "the idea is interesting and seems to be quite efficient from experiments on USPS data",
    "NOVELTY"
  ],
  [
    "It is not extremely original in its main ideas though",
    "NOVELTY"
  ],
  [
    "but the actual algorithm and implementation seem new and effective .",
    "NOVELTY"
  ],
  [
    "Novelty is somewhat limited : the method is conceptually similar to VIN .",
    "NOVELTY"
  ],
  [
    "I think the paper is interesting",
    "NOVELTY"
  ],
  [
    "the paper assembles other state of the art techniques",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the notion of `` pseudo count `` , how to use this notion for exploration , and its connection to information gain , are novel .",
    "NOVELTY"
  ],
  [
    "The technique is not very original , as it 's a logical combination of pre-existing ideas",
    "NOVELTY"
  ],
  [
    "The paper presents a solid contribution into the statistical literature related to the stochastic block model .",
    "NOVELTY"
  ],
  [
    "In my opinion the paper remains of borderline originality .",
    "NOVELTY"
  ],
  [
    "novel idea , promising results ,",
    "NOVELTY"
  ],
  [
    "I believe that this is an interesting , novel paper , which could be of high interest in the ICLR community",
    "NOVELTY"
  ],
  [
    "Although the idea of reranking is not new in the semantic parsing community",
    "NOVELTY"
  ],
  [
    "The streaming algorithm is novel and",
    "NOVELTY"
  ],
  [
    "weakly supervised instance segmentation is an original and novel contribution",
    "NOVELTY"
  ],
  [
    "The theory developed ( and other connections , e.g .variational objective ) is interesting . The approach seems to be novel",
    "NOVELTY"
  ],
  [
    "The methods mentioned in the paper are a novel combination of well-known prior techniques .",
    "NOVELTY"
  ],
  [
    "The idea of Lipchitz-like condition is proposed by other works .",
    "NOVELTY"
  ],
  [
    "the Bregman parts are not novel .",
    "NOVELTY"
  ],
  [
    "The total idea is good",
    "NOVELTY"
  ],
  [
    "but the novelty is not much .",
    "NOVELTY"
  ],
  [
    "Overall the paper is interesting and provides a nice way of generalizing Hedge algorithms to combinatorial problems whose offline version can be solved using DP .",
    "NOVELTY"
  ],
  [
    "The idea is quite interesting , and is novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "I really like the key idea of the paper . It is very convincing and clean . To exploit the clustering idea in the dual space via Haar-transform is a highly original and effective insight .",
    "NOVELTY"
  ],
  [
    "4 .There is no theoretical novelty and the empirical one seems to be very limited , with less",
    "NOVELTY"
  ],
  [
    "and is in this sense somewhat incremental",
    "NOVELTY"
  ],
  [
    "but its novelty and intuition are unclear .",
    "NOVELTY"
  ],
  [
    "and provides a novel solution",
    "NOVELTY"
  ],
  [
    "and presents a novel approach that",
    "NOVELTY"
  ],
  [
    "For one , removing the fully connected classification layer is not a novel idea ; All Convolutional Networks",
    "NOVELTY"
  ],
  [
    "Including a fixed Hadamard matrix for the classification layer is I believe new",
    "NOVELTY"
  ],
  [
    "But the notion of fixing or removing the classification layer is n't particularly novel",
    "NOVELTY"
  ],
  [
    "The idea of formulating link prediction as a few-shot learning problem and solving it via multi-graph meta-learning is novel .",
    "NOVELTY"
  ],
  [
    "the technical contribution does not seem significant to me",
    "NOVELTY"
  ],
  [
    "but it has little novelty and a similar idea is there in VQA",
    "NOVELTY"
  ],
  [
    "MLM and MRM are not new training procedure either",
    "NOVELTY"
  ],
  [
    "The algorithm to generate the adversarial examples is a bit different from previous works as it adds some additional constraints into to the optimization",
    "NOVELTY"
  ],
  [
    "built on an interesting idea of using an attention mechanism to specify sub-goals",
    "NOVELTY"
  ],
  [
    "The idea of analyzing the gap to variational posterior lower bound for different dropout inference model is interesting .",
    "NOVELTY"
  ],
  [
    "be a convincing novel contribution",
    "NOVELTY"
  ],
  [
    "while I really like that the method presented in this paper is very different than existing PAC methods , I am not convinced that the algorithm presented offers any advantage compared to existing algorithms",
    "NOVELTY"
  ],
  [
    "Originality The combination of MCTS with learned policy and value priors has been explored in a number of domains , but this application to KBC appears novel and includes a",
    "NOVELTY"
  ],
  [
    "number of algorithmic and architectural innovations .",
    "NOVELTY"
  ],
  [
    "Though the proposed framework is novel and general",
    "NOVELTY"
  ],
  [
    "The authors ' perspective is quite fresh and inspiring",
    "NOVELTY"
  ],
  [
    "The contribution in posing the objective as a DC function looks limited as it is very straightforward .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , it includes pointers to relevant prior work both on shallow and deep learning algorithms . For these reasons , I think the manuscript is original and should contribute to increased visibility of poisoning in the adversarial ML community .",
    "NOVELTY"
  ],
  [
    "I do n't see much novelty .",
    "NOVELTY"
  ],
  [
    "it is quite similar to approaches that learn optical flow in unsupervised manner , with image reconstruction loss and local smoothness loss",
    "NOVELTY"
  ],
  [
    "The main direction of incorporating human feedback in the loop is original .",
    "NOVELTY"
  ],
  [
    "Weak technical contribution to the problem",
    "NOVELTY"
  ],
  [
    "I am not sure how novel the techniques are compared",
    "NOVELTY"
  ],
  [
    "paper studies a non-local form of adversarial perturbation , which , to my limited knowledge is new",
    "NOVELTY"
  ],
  [
    "and does not offer a machine learning contribution",
    "NOVELTY"
  ],
  [
    "The novelty and innovation of the paper are low .",
    "NOVELTY"
  ],
  [
    "the approach of the paper which is considering a lower bound to estimate the mutual information is quite",
    "NOVELTY"
  ],
  [
    "It is still unclear about the contributions of the paper .",
    "NOVELTY"
  ],
  [
    "The results are quite incremental from the existing ones .",
    "NOVELTY"
  ],
  [
    "While the fairness definitions have some flaws , the proposed methods are very interesting .",
    "NOVELTY"
  ],
  [
    "which is novel and interesting",
    "NOVELTY"
  ],
  [
    "The idea of studying GANs from the game theory perspective is not new ;",
    "NOVELTY"
  ],
  [
    "however , using the duality gap as a performance metric ( some sort of divergence between the generated data distribution and the real data distribution ) is original to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Novelty is limited : SALSA is an aggregation of already proposed methodologies .",
    "NOVELTY"
  ],
  [
    "This paper has limited model novelty and doesn \u2019 t overcome this by having great experiments or analysis",
    "NOVELTY"
  ],
  [
    "The contribution appears novel and references relevant related work .",
    "NOVELTY"
  ],
  [
    "Section 3 ( Theorem 2 ) is not original work ,",
    "NOVELTY"
  ],
  [
    "are not original work either",
    "NOVELTY"
  ],
  [
    "The proposed algorithms seems new",
    "NOVELTY"
  ],
  [
    "The theoretical results are new and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm",
    "NOVELTY"
  ],
  [
    "The idea itself is novel and interesting , and could have major impact in learning structured manifolds .",
    "NOVELTY"
  ],
  [
    "The authors claim in the introduction that they provide a novel Bayesian formulation of DA .",
    "NOVELTY"
  ],
  [
    "The graph representation of the problem is novel , and draws both on core ideas from Hindley-Milner typing ( in the subtyping/assignment graph bits ) as well as neural ideas",
    "NOVELTY"
  ],
  [
    "The neural message passing architecture is adapted to the problem ,",
    "NOVELTY"
  ],
  [
    "with a novel approach",
    "NOVELTY"
  ],
  [
    "as a whole , I think this is a strong contribution and a nicely put together piece of work .",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting",
    "NOVELTY"
  ],
  [
    "I would like to emphasize that even though the proposed approach may not work in all tasks it provides a novel approach to POMDP solving and could be beneficial in many practical problems .",
    "NOVELTY"
  ],
  [
    "Using factored beliefs in POMDP planning is not new .",
    "NOVELTY"
  ],
  [
    "This is the first paper , to the best of my knowledge , showing the efficacy of model extraction of large pretrained language models using rubbish/nonsensical inputs .",
    "NOVELTY"
  ],
  [
    "2.The novelty of the model : GAN models with multiple G-Ds or local/global discriminators is not novel ( see the references",
    "NOVELTY"
  ],
  [
    "This is work is original to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The idea of the second algorithm is not very trivial .",
    "NOVELTY"
  ],
  [
    "I have settled on a weak reject because in my view , the novelty and results are minor .",
    "NOVELTY"
  ],
  [
    "So I view the novelty of the approach to be fairly low .",
    "NOVELTY"
  ],
  [
    "but I find the specific contributions to be lacking in novelty and impressiveness of results .",
    "NOVELTY"
  ],
  [
    "then the contribution of this work is incremental at most",
    "NOVELTY"
  ],
  [
    "The idea seems to be simple and does not have significant originality .",
    "NOVELTY"
  ],
  [
    "I like the derivation of the method and the ideas behind it .",
    "NOVELTY"
  ],
  [
    "as I think it is incremental",
    "NOVELTY"
  ],
  [
    "and the fact that the method is rather incremental",
    "NOVELTY"
  ],
  [
    "Overall this is a nice contribution to the options literature .",
    "NOVELTY"
  ],
  [
    "Limited novelty .",
    "NOVELTY"
  ],
  [
    "To me , at least from the algorithmic point of view , the approach is too incremental .",
    "NOVELTY"
  ],
  [
    "both interesting and novel",
    "NOVELTY"
  ],
  [
    "These corruptions are not terribly novel with respect to previous work ,",
    "NOVELTY"
  ],
  [
    "There is not significant methodological novelty , as the authors are essentially combining standard components in a straightforward way .",
    "NOVELTY"
  ],
  [
    "Although sharing some similarities , the extension of using implicit decoder is interesting , and leading to some interesting results",
    "NOVELTY"
  ],
  [
    "Originality The extension over Zhang et al. , 2016 is relatively small in terms of the technical contribution , but I do think that the generative formulation has clear advantages over previous work .",
    "NOVELTY"
  ],
  [
    "To me the approach is novel and proposes a very interesting alternative to unsupervised learning that takes advantage of the `` possibility `` of control that an agent has over the environment .",
    "NOVELTY"
  ],
  [
    "Looking at RNN from an iterative refinement point of view seems novel .",
    "NOVELTY"
  ],
  [
    "Quality of technique While the temporal masks are novel and qualitatively `` make sense ``",
    "NOVELTY"
  ],
  [
    "the generation of the spatial masks is not novel",
    "NOVELTY"
  ],
  [
    "It would be great to see more innovation on the temporal mask generation to address some of these issues",
    "NOVELTY"
  ],
  [
    "factor in the bound may be an interesting development but the novelty does appear to be limited .",
    "NOVELTY"
  ],
  [
    "This is an interesting",
    "NOVELTY"
  ],
  [
    "Interesting insight into defensive distillation and the effects of uncertainty in neural networks .",
    "NOVELTY"
  ],
  [
    "Brings both new ideas and unexpected experimental results",
    "NOVELTY"
  ],
  [
    "This tool is new and seems promising .",
    "NOVELTY"
  ],
  [
    "I found the use of parallel transport to define biases in hyperbolic networks , particularly nice and clever",
    "NOVELTY"
  ],
  [
    "the methods they use are quite similar to prior work",
    "NOVELTY"
  ],
  [
    "the approach is not very novel",
    "NOVELTY"
  ],
  [
    "One weakness of the paper is that the relative incremental nature of the study ,",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "with an interesting design of the variational distribution to approximate the true autoregressive distribution .",
    "NOVELTY"
  ],
  [
    "The design of the confidence model looks a bit heuristic",
    "NOVELTY"
  ],
  [
    "but the trade-off ability between efficiency and quality it brings is also quite interesting",
    "NOVELTY"
  ],
  [
    "while the claims of the paper are interesting and relevant for the representation learning community",
    "NOVELTY"
  ],
  [
    ", similar work has already been done , at much larger scale , from visual observations , using RL and self-supervised learning",
    "NOVELTY"
  ],
  [
    "It is a novel idea to project feature vector into orthogonal subspace .",
    "NOVELTY"
  ],
  [
    "This is an interesting idea with",
    "NOVELTY"
  ],
  [
    "3 .The way the authors handle inverse matrix gradient propagation is interesting .",
    "NOVELTY"
  ],
  [
    "its improvements over the existing literature are not dramatic .",
    "NOVELTY"
  ],
  [
    "the proposed method is simple and intuitive",
    "NOVELTY"
  ],
  [
    "the proposed Nucleus Sampling seems to be a trivial variant of Top-k sampling",
    "NOVELTY"
  ],
  [
    "When the method seems intuitive , it shows a novel way to combine transfer-based and score-based attack methods .",
    "NOVELTY"
  ],
  [
    "Given these previous works , the contribution and novelty of the paper is limited .",
    "NOVELTY"
  ],
  [
    "In terms of originality , it is different from warping training example for the same task and it is a good extension of previously suggested example mixing procedures with a targeted benefit for improved discriminative power .",
    "NOVELTY"
  ],
  [
    "Derivation of a novel method for constructing attribution maps .",
    "NOVELTY"
  ],
  [
    "Proposal of a novel quantitative measure to compare quality of pixel-level attribution maps in image classification , and extension of a previously reported method .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the proposed method is sufficiently novel and the application of the information bottleneck framework to pixel-level attribution has not been reported before .",
    "NOVELTY"
  ],
  [
    "But with fairly little novelty",
    "NOVELTY"
  ],
  [
    "very little insights of why this should work at all",
    "NOVELTY"
  ],
  [
    "paper improves the correlation alignment approach to domain adaptation from two aspects",
    "NOVELTY"
  ],
  [
    "I like the idea of automatically choosing free parameters using the entropy over the target domain .",
    "NOVELTY"
  ],
  [
    "is a significant contribution to the literature on NMF",
    "NOVELTY"
  ],
  [
    "-- it provides many insights",
    "NOVELTY"
  ],
  [
    "The formulation of the minimax",
    "NOVELTY"
  ],
  [
    "Original idea for modelling distribution of sequence data - Theoretical convergence in the Jensen Shanon divergence sense",
    "NOVELTY"
  ],
  [
    "It is an incremental work to SENet .",
    "NOVELTY"
  ],
  [
    "Overall , I like the paper and the introduced environment .",
    "NOVELTY"
  ],
  [
    "The paper is interesting however the benefit over the traditional maximum likelihood estimator is small and the writing needs a",
    "NOVELTY"
  ],
  [
    "The specific algorithm and ergodicity results are novel",
    "NOVELTY"
  ],
  [
    "The paper is too much incremental from the papers of Belkin et al . ( 2018 ) and Xing et al . ( 2018 ) and the bene ts of the proposed interpolation are limited",
    "NOVELTY"
  ],
  [
    "However , the paper contains only little novelty and proposes a fairly straight-forward way to parallelize successive halving .",
    "NOVELTY"
  ],
  [
    "The proposed approach , NoisyNet , seems very simple and",
    "NOVELTY"
  ],
  [
    "Overall the proposed approach is interesting and has strengths",
    "NOVELTY"
  ],
  [
    "More generally , this paper seems to be only a marginal advance over other methods .",
    "NOVELTY"
  ],
  [
    "I like the idea in this paper",
    "NOVELTY"
  ],
  [
    "The paper seems to be the first attempt to extending stochastically controlled functions to the compositional problems .",
    "NOVELTY"
  ],
  [
    "it is unclear how much this work differs from other papers .",
    "NOVELTY"
  ],
  [
    "novelty The differentiable NPE is a novel concept .",
    "NOVELTY"
  ],
  [
    "based on euclideian distance are novel to this work .",
    "NOVELTY"
  ],
  [
    "recommendation The main issue with this work is the unclear novelty with respect to work of Battaglia et al .at NIPS'16 .",
    "NOVELTY"
  ],
  [
    "The main contributions in section 4 look nice",
    "NOVELTY"
  ],
  [
    "The idea is novel , the",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is new work and nice attempt to link cut measures of graph to regularization and try to find significance of regularization by analyzing the Core-cut measure .",
    "NOVELTY"
  ],
  [
    "The idea of utilizing supervised or unsupervised dependency tree as constraints to control which relations influence the representation seems novel and interesting .",
    "NOVELTY"
  ],
  [
    "Therefore , the proposed method is incremental rather than innovative .",
    "NOVELTY"
  ],
  [
    "My major concern with this paper is with marketing the dynamic filter network as something entirely new .",
    "NOVELTY"
  ],
  [
    "The main insight ( compositional languages are easier to teach ) is interesting",
    "NOVELTY"
  ],
  [
    "I think the contribution of the current paper is quite incremental over [ 2,20 ] and other works on similar topic , some of which the authors have not cited",
    "NOVELTY"
  ],
  [
    "3 .There is not much innovation in the scheme or the lower bound .",
    "NOVELTY"
  ],
  [
    "But the technical contribution beyond prior work is minimal and does n't suffice for publication at NeurIPS .",
    "NOVELTY"
  ],
  [
    "the ideas of this paper are interesting",
    "NOVELTY"
  ],
  [
    "learning the truncation points is a novel",
    "NOVELTY"
  ],
  [
    "but obvious and incremental next step",
    "NOVELTY"
  ],
  [
    "Overall rating While the technique introduced in this paper is interesting",
    "NOVELTY"
  ],
  [
    "the evaluation seems to be flawed .",
    "NOVELTY"
  ],
  [
    "The model seems interesting",
    "NOVELTY"
  ],
  [
    "I am worried about the novelty of the proposed approach .",
    "NOVELTY"
  ],
  [
    "Both these ideas seem relatively incremental .",
    "NOVELTY"
  ],
  [
    "The main innovation seems to be 1",
    "NOVELTY"
  ],
  [
    "I like the discussion in the model formulation part and I like the idea of doing private SVD .",
    "NOVELTY"
  ],
  [
    "The idea",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "To strengthen the contribution , it would be required to propose a novel approach based on the bounds derived in the paper .",
    "NOVELTY"
  ],
  [
    "However it is one of the first papers",
    "NOVELTY"
  ],
  [
    "novelty-pursuit for exploration in large state space",
    "NOVELTY"
  ],
  [
    "I found this paper",
    "NOVELTY"
  ],
  [
    "the theoretical contribution is weak",
    "NOVELTY"
  ],
  [
    "This in itself is an interesting idea",
    "NOVELTY"
  ],
  [
    "The actual contribution from prior work is not large",
    "NOVELTY"
  ],
  [
    "The results are for sure",
    "NOVELTY"
  ],
  [
    "The results are not particularly surprising",
    "NOVELTY"
  ],
  [
    "This seems new to me and is rather effectice .",
    "NOVELTY"
  ],
  [
    "The paper is a novel combination of two known techniques - AlphaRank and UCB .",
    "NOVELTY"
  ],
  [
    "The work is novel and it comes with the theoretical derivation of a variational lower bound for POMDPs in general .",
    "NOVELTY"
  ],
  [
    "The paper introduces the novel idea of first order motion and occlusion modeling to unsupervised image animation .",
    "NOVELTY"
  ],
  [
    "contributions and the algorithm only pipelines known algorithms in a problem-specific way .",
    "NOVELTY"
  ],
  [
    "the paper contains no theoretic contributions to the field of anomaly detection .",
    "NOVELTY"
  ],
  [
    "brings . Although this reviewer is not an expert in this literature , the proposed approach appears novel .",
    "NOVELTY"
  ],
  [
    "The authors used novel proof techniques .",
    "NOVELTY"
  ],
  [
    "interesting idea",
    "NOVELTY"
  ],
  [
    "But my impression is that achieving speed up using existing MLIR framework has no surprising novelty .",
    "NOVELTY"
  ],
  [
    "However the novelty factor of this paper is fairly low \u2014 recursive neural nets have been applied to code/equations before in similar models .",
    "NOVELTY"
  ],
  [
    "While the techniques",
    "NOVELTY"
  ],
  [
    "in this paper is similar to some",
    "NOVELTY"
  ],
  [
    "existing results in the literature",
    "NOVELTY"
  ],
  [
    "it is applied to a new problem setting .",
    "NOVELTY"
  ],
  [
    "The idea of combining this approach with a LTSM is a novel and interesting specification which allows complex dynamics in the conditional distribution of returns .",
    "NOVELTY"
  ],
  [
    "This paper is one of the first works aiming at Bert model compression .",
    "NOVELTY"
  ],
  [
    "I found the connection to MAB with switching costs to be surprising and interesting .",
    "NOVELTY"
  ],
  [
    "3 .Novelty and Motivation The novelty of the paper is quite limited .",
    "NOVELTY"
  ],
  [
    "and the central idea is intuitive and appealing",
    "NOVELTY"
  ],
  [
    "However , I am uncertain about the novelty of this contribution .",
    "NOVELTY"
  ],
  [
    "but the novelty is not apparent",
    "NOVELTY"
  ],
  [
    "1 .To my knowledge , using the logged",
    "NOVELTY"
  ],
  [
    "4 .The ensemble based DQNs proposed in Section 4 are very interesting",
    "NOVELTY"
  ],
  [
    "and I liked the idea of using renyi correlation which also has a nice theoretical formulation allowing to be optimized more efficiently",
    "NOVELTY"
  ],
  [
    "The paper contains some potentially interesting ideas",
    "NOVELTY"
  ],
  [
    "but it is artificial",
    "NOVELTY"
  ],
  [
    "and , as far as I",
    "NOVELTY"
  ],
  [
    "topic has not been studied in such detail previously",
    "NOVELTY"
  ],
  [
    "Strengths -The formulation of the problem is novel and general .",
    "NOVELTY"
  ],
  [
    "-Modeling 3D scene by a generative query network is novel .",
    "NOVELTY"
  ],
  [
    "I first thought modeling a 3D scene by a generative query network is pretty novel",
    "NOVELTY"
  ],
  [
    "While the idea of pivot based common representation learning for language pairs with no parallel data is not new",
    "NOVELTY"
  ],
  [
    ", adding the communication aspect as an additional supervision is novel",
    "NOVELTY"
  ],
  [
    "the method they propose offers very little that is new when compared to e.g .Vaswani",
    "NOVELTY"
  ],
  [
    "This paper presents an interesting reduction from multi-class classification with many classes to binary classification and corresponding generalization bounds for dealing with the fact that the reduced dataset contains correlated data .",
    "NOVELTY"
  ],
  [
    "On the other hand however , there is limited novelty in the setup .",
    "NOVELTY"
  ],
  [
    "Although the method is interesting",
    "NOVELTY"
  ],
  [
    "The paper provides an interesting result that guarantees l_p robustness for a piecewise affine classifier based on only l_1 and l_\\infty robustness .",
    "NOVELTY"
  ],
  [
    "This work builds on the prior work Padam",
    "NOVELTY"
  ],
  [
    "The introduction of the offset is not novel .",
    "NOVELTY"
  ],
  [
    "The proof is not new .",
    "NOVELTY"
  ],
  [
    "The idea proposed in this paper seems to have broad applications in some other EM algorithms , which have high dependency on the data size at each step",
    "NOVELTY"
  ],
  [
    "This is a novel idea and can be used for other clustering algorithms .",
    "NOVELTY"
  ],
  [
    "Notably the idea of inter-layer correlations is not new",
    "NOVELTY"
  ],
  [
    "All in all I think the submission proposes an interesting combination of existing methods leading to reasonable extension of the body of work in fast style transfer .",
    "NOVELTY"
  ],
  [
    "I am not convinced that the proposed method substantially advances the field of fast style transfer to warrant publication at ICLR .",
    "NOVELTY"
  ],
  [
    "Overall the contribution does seem a bit incremental based on prior work and",
    "NOVELTY"
  ],
  [
    "although somewhat incremental",
    "NOVELTY"
  ],
  [
    "The work seems novel in proposing the specific activation function but in general there are many other works that propose learnable or more elaborate activation functions",
    "NOVELTY"
  ],
  [
    "The idea of applying optimism to Adam was already presented in Daskalakis et al , 2018",
    "NOVELTY"
  ],
  [
    "I do not find this extensions to be sufficiently novel or significant to merit publication .",
    "NOVELTY"
  ],
  [
    "I think from a theoretical perspective , the paper has sufficient novelty and depth",
    "NOVELTY"
  ],
  [
    "This is an interesting paper with solid and novel work .",
    "NOVELTY"
  ],
  [
    "The class-distribution-aware margin trade-off theory is profound and novel .",
    "NOVELTY"
  ],
  [
    "The idea of studying embedding of a hypergraph is interesting and novel",
    "NOVELTY"
  ],
  [
    "Despite",
    "NOVELTY"
  ],
  [
    "the novel idea about hyperedge embedding generation",
    "NOVELTY"
  ],
  [
    "At this point , the novelty is weaken .",
    "NOVELTY"
  ],
  [
    "Overall , I do like the idea behind this paper ...",
    "NOVELTY"
  ],
  [
    "Technically , the approach also seems very similar to N3NN by Parisotto et al , ICLR 2017 .",
    "NOVELTY"
  ],
  [
    "2 .A new model combining prototypical network with GAN and cycle-consistency loss for addressing meta-learning domain shift scenario .",
    "NOVELTY"
  ],
  [
    "4 .The novelty of the model is relatively limited as it is a combination of previous techniques on a new problem .",
    "NOVELTY"
  ],
  [
    "the problem of considering test distributions different from the input distributions one is not new ,",
    "NOVELTY"
  ],
  [
    "The strengths of the paper are its originality and significance . The ideas in the paper are original",
    "NOVELTY"
  ],
  [
    "still find the method proposed in this paper appealing",
    "NOVELTY"
  ],
  [
    "I do think that the approach is interesting",
    "NOVELTY"
  ],
  [
    "Interesting idea , impressive results for a first paper",
    "NOVELTY"
  ],
  [
    "since the problem appears novel and the experimental results seem very promising for a first paper on a new problem",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the problem domain ( machine learning for satisfiability problems that are so large that they are difficult to solve using conventional methods ) is both novel and well-motivated .",
    "NOVELTY"
  ],
  [
    "I find the proposed idea to be promising and quite intriguing",
    "NOVELTY"
  ],
  [
    "The approach comprises a novel regularization technique that gradually lowers the absolute values of weights with low sensitivities , while weights with high sensitivities are not modified",
    "NOVELTY"
  ],
  [
    "The paper presents a new stochastic regularize-and-prune technique that is an interesting extension and a concurrent of weight decay .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is incremental .",
    "NOVELTY"
  ],
  [
    "The paper 's method of creating high precision labels using their multi-step clustering algorithm with information measures is quite interesting .",
    "NOVELTY"
  ],
  [
    "Overall the paper has significant contributions in the following aspects",
    "NOVELTY"
  ],
  [
    "I think this paper can be an interesting addition",
    "NOVELTY"
  ],
  [
    "The results show that meta-learning by gradient descent to modulate the plasticity learning rate is a promising direction -- a significant contribution in my view",
    "NOVELTY"
  ],
  [
    "As implied in my summary above , the unexplored corner of imitation learning that they\u00e2\u0080\u0099ve uncovered with this formalism ( that is , beam + continue with oracle costs ) , is novel and interesting .",
    "NOVELTY"
  ],
  [
    "I am afraid that such work do not have sufficient theoretical or algorithmic contributions .",
    "NOVELTY"
  ],
  [
    "In this regard , it does not show much novelty .",
    "NOVELTY"
  ],
  [
    "Method is relatively simple extension from existing work in maximum entropy reinforcement learning .",
    "NOVELTY"
  ],
  [
    "However , some of the authors ' contributions are not new ( see below ) , so the overall novelty is limited .",
    "NOVELTY"
  ],
  [
    "The idea is simple and motivated by the Fisher vector work ( Jaakkola &",
    "NOVELTY"
  ],
  [
    "The approach is original in terms of the three points stated in Q1 above",
    "NOVELTY"
  ],
  [
    "look quite promising",
    "NOVELTY"
  ],
  [
    "This paper",
    "NOVELTY"
  ],
  [
    ", and presents a nice combination of several interesting ideas presented in related works ( switching variables",
    "NOVELTY"
  ],
  [
    "networks",
    "NOVELTY"
  ],
  [
    "filter",
    "NOVELTY"
  ],
  [
    "The novelty of this paper in terms of original ideas is limited",
    "NOVELTY"
  ],
  [
    "the novel part lies in the clever combination of known approaches",
    "NOVELTY"
  ],
  [
    "The paper is a somewhat incremental extension of previous work laying out the theory of EGT and the specific distance functions needed .",
    "NOVELTY"
  ],
  [
    "the contribution and the importance of this paper still seems incremental to me .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "and seems to be promising",
    "NOVELTY"
  ],
  [
    "however originality seems incremental .",
    "NOVELTY"
  ],
  [
    "A novel algorithm that promotes the interpolation ability of AE 2",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "that has been explored in a different context before",
    "NOVELTY"
  ],
  [
    "Therefore",
    "NOVELTY"
  ],
  [
    "it lacks of proper formalism",
    "NOVELTY"
  ],
  [
    "Overall , I agree that the idea is interesting and novel",
    "NOVELTY"
  ],
  [
    "The proposed strategy contains several novelties related to the model and the application domain .",
    "NOVELTY"
  ],
  [
    "the idea of using AL and RL to control the labeling process in a semantic segmentation application is interesting and particularly relevant for this application . While the proposed method has some weaknesses , it is novel and it will be of interest to people interested in semantic segmentation .",
    "NOVELTY"
  ],
  [
    "This is an important theoretical advance",
    "NOVELTY"
  ],
  [
    "The strength of this paper is that it both gives a more systematic framework for and builds on existing ideas ( character-based models , using dictionary definitions ) to implement them as part of a model trained on the end task .",
    "NOVELTY"
  ],
  [
    "The contribution is clear but not huge .",
    "NOVELTY"
  ],
  [
    "The approach is appealing in its simplicity and generality .",
    "NOVELTY"
  ],
  [
    "However , conceptually there is little that is new .",
    "NOVELTY"
  ],
  [
    "The idea of reimplementing an iterative algorithm in a deep architecture is not new",
    "NOVELTY"
  ],
  [
    "but solving a CS problem for MRI recovery with a Deep-ADMM architecture is novel as far as I can say .",
    "NOVELTY"
  ],
  [
    "while this paper might lack in originality",
    "NOVELTY"
  ],
  [
    "it",
    "NOVELTY"
  ],
  [
    "I still like the idea of the paper",
    "NOVELTY"
  ],
  [
    "The originality of the paper is basically beyond doubt",
    "NOVELTY"
  ],
  [
    "the work appears original to me Significance",
    "NOVELTY"
  ],
  [
    "but the present formulation seems novel",
    "NOVELTY"
  ],
  [
    "this paper has severe flaws in terms",
    "NOVELTY"
  ],
  [
    "and limited contributions .",
    "NOVELTY"
  ],
  [
    "Therefore , the contribution of this work is quite limited .",
    "NOVELTY"
  ],
  [
    "based on my understanding a lot of the technical contributions of the paper are well known",
    "NOVELTY"
  ],
  [
    "Overall , reviewer is very positive about the technical novelty of the paper .",
    "NOVELTY"
  ],
  [
    "the performance delta seems very incremental .",
    "NOVELTY"
  ],
  [
    "While not overly ambitious in terms of technical novelty",
    "NOVELTY"
  ],
  [
    "I think this",
    "NOVELTY"
  ],
  [
    "the theoretical contributions seem weak .",
    "NOVELTY"
  ],
  [
    "While the combination of submodular minimization and isotonic constraints seems novel",
    "NOVELTY"
  ],
  [
    ", this paper builds heavily on the results of [ 1 ] .",
    "NOVELTY"
  ],
  [
    "I am familiar with the few-shot learning literature and this particular approach is novel as far as I know",
    "NOVELTY"
  ],
  [
    "The method presented here is novel ,",
    "NOVELTY"
  ],
  [
    "This method is creative , could be applied to other tasks with constraints , and",
    "NOVELTY"
  ],
  [
    "the wider deep learning community .",
    "NOVELTY"
  ],
  [
    "immediately interesting",
    "NOVELTY"
  ],
  [
    "and a novel approach",
    "NOVELTY"
  ],
  [
    "and the approach is interesting",
    "NOVELTY"
  ],
  [
    "the paper has some really nice ideas",
    "NOVELTY"
  ],
  [
    "My main concern is the novelty of the paper .",
    "NOVELTY"
  ],
  [
    "the machine learning novelties are rather small",
    "NOVELTY"
  ],
  [
    "I believe the paper to be a substantial contribution in vision",
    "NOVELTY"
  ],
  [
    "This is a nice use of Google 's resources to help the community .",
    "NOVELTY"
  ],
  [
    "The idea of quantifying the fraction of infeasible parameters ( e.g .those that diverge ) is nice , because it 's",
    "NOVELTY"
  ],
  [
    "I guess the point of this paper is not really to be novel in the first place -- which is totally fine with me",
    "NOVELTY"
  ],
  [
    "Releases a new synthetic dataset and benchmark for visual explanation methods",
    "NOVELTY"
  ],
  [
    "However , the proposed method seems to be somewhat incremental",
    "NOVELTY"
  ],
  [
    "it is not clear to me how the method that the authors use in practice differs significantly from regular Path-SGD introduced in previous work",
    "NOVELTY"
  ],
  [
    "In a nutshell , this is an excellent piece of work .",
    "NOVELTY"
  ],
  [
    "Finally , the conclusion that larger capacity can improve both model accuracy and robustness has already been made in prior work",
    "NOVELTY"
  ],
  [
    ".The intuition that added capacity helps by allowing the model to leverage higher order terms of the loss is interesting but a rather incremental contribution",
    "NOVELTY"
  ],
  [
    "while the ideas presented in the paper could be of interest",
    "NOVELTY"
  ],
  [
    "The progressive bound tightening is a novel idea as far as I can see",
    "NOVELTY"
  ],
  [
    "-- Method -- Methodologically , the contribution is somewhat weak .",
    "NOVELTY"
  ],
  [
    "The idea of using tensor networks for machine learning problems is interesting .",
    "NOVELTY"
  ],
  [
    "The work builds on ( Williamson , 2016 ) and seems solid",
    "NOVELTY"
  ],
  [
    "though the work follows on some of the existing literature , I believe that it is substantially original and novel to score highly on this metric .",
    "NOVELTY"
  ],
  [
    "which is substantially novel",
    "NOVELTY"
  ],
  [
    "area are greatly appreciated",
    "NOVELTY"
  ],
  [
    "but not the architecture of choice .",
    "NOVELTY"
  ],
  [
    "I could not find the technical contributions of the proposed method in it .",
    "NOVELTY"
  ],
  [
    "Thus , the novelty of this paper is somewhat weak .",
    "NOVELTY"
  ],
  [
    "6 .The contribution of the current paper is very incremental .",
    "NOVELTY"
  ],
  [
    "While entropy based RL has been explored extensively , the insight in this paper is , to my knowledge , novel , and leads to a very elegant algorithmic idea .",
    "NOVELTY"
  ],
  [
    "The off-policy actor critic proposed here is only slightly different from previous work such as A2C",
    "NOVELTY"
  ],
  [
    ", but makes much more sense theoretically",
    "NOVELTY"
  ],
  [
    ", the idea is clever and appealing",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed model is somewhat incremental , which combines some existing methods",
    "NOVELTY"
  ],
  [
    "The idea of this paper is simple but non-trivial .",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is still significant",
    "NOVELTY"
  ],
  [
    "The approach is novel and more general than previous approaches",
    "NOVELTY"
  ],
  [
    "To conclude , the presented method is clearly novel and provides an interesting solution to a challenging problem .",
    "NOVELTY"
  ],
  [
    "I think the work is quite novel ,",
    "NOVELTY"
  ],
  [
    "Intuitively I like the idea of denoising .",
    "NOVELTY"
  ],
  [
    "for BO seems like a very natural idea",
    "NOVELTY"
  ],
  [
    "However the general contribution of the paper is not enough",
    "NOVELTY"
  ],
  [
    "The idea of formulating the cycle constraint in the minimum cost multi-cut problem as a high order energy function is inspiring .",
    "NOVELTY"
  ],
  [
    "Although being an interesting research idea",
    "NOVELTY"
  ],
  [
    "Whilst the proposed method is interesting and relevant",
    "NOVELTY"
  ],
  [
    "The method is somewhat of a simple extension of the idea presented in previous work but",
    "NOVELTY"
  ],
  [
    "It is an interesting idea",
    "NOVELTY"
  ],
  [
    "Even though the proposed minCUT pool is interesting",
    "NOVELTY"
  ],
  [
    "I still believe the contribution/novelty is limited .",
    "NOVELTY"
  ],
  [
    "The idea is incremental :",
    "NOVELTY"
  ],
  [
    "the contribution and novelty of this paper are very limited .",
    "NOVELTY"
  ],
  [
    "Conceptually",
    "NOVELTY"
  ],
  [
    "The key idea in this paper (",
    "NOVELTY"
  ],
  [
    "computed on a small subset of data points ) has unfortunately already been proposed and tested in classical",
    "NOVELTY"
  ],
  [
    "it is the manipulation of infinity and imaginary numbers that could be considered to be one of the greatest achievements of symbolic mathematics over the last couple of hundred years",
    "NOVELTY"
  ],
  [
    "my main concern is with its novelty",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the broad idea of applying information theory to multi-agent exploration , in addition to the specific instantiation described in the paper , is novel .",
    "NOVELTY"
  ],
  [
    "I think this observation , although intuitive , is very original .",
    "NOVELTY"
  ],
  [
    "the separation between interactive and sequentially interactive is novel , and uses a new technique for lower bounds that relies on margin complexity .",
    "NOVELTY"
  ],
  [
    "Whereas simply joining 2 existing techniques may not seem pretty original",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "This is a straightforward idea and is not novel",
    "NOVELTY"
  ],
  [
    "The theory part of this paper is a bit incremental .",
    "NOVELTY"
  ],
  [
    "I found the ideas in this paper quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "Originality As far as I can tell , the proposed use of influence functions is new . The experimental design , theoretical analysis , and case studies also appear to be novel .",
    "NOVELTY"
  ],
  [
    "The proposed architecture is novel and interesting .",
    "NOVELTY"
  ],
  [
    "making",
    "NOVELTY"
  ],
  [
    "The application to the CNF pictorial puzzle data set seems original",
    "NOVELTY"
  ],
  [
    "The method itself is not novel and it basically down weights the bootstrap estimate",
    "NOVELTY"
  ],
  [
    "A lot of the techniques described for building the traditional CBMT system are obsolete these days and people prefer neural methods",
    "NOVELTY"
  ],
  [
    "I find the discussions in page 15 very enlightening",
    "NOVELTY"
  ],
  [
    "the method proposed in this paper does not provide a new perspective for these domains .",
    "NOVELTY"
  ],
  [
    "The idea for rewinding is not novel ,",
    "NOVELTY"
  ],
  [
    "and to my knowledge it is a novel approach",
    "NOVELTY"
  ],
  [
    "The idea of the paper is novel and elegant",
    "NOVELTY"
  ],
  [
    "The idea of identifying noisy examples through ensemble consensus is novel and plausible .",
    "NOVELTY"
  ],
  [
    "each of the two distinct contributions are good starts on interesting",
    "NOVELTY"
  ],
  [
    "and the two contributions are quite distinct , so that the paper lacks a consistent thread",
    "NOVELTY"
  ],
  [
    "The biggest weakness of the paper is wrt novelty . Masking out entities and training to context is not a new idea .",
    "NOVELTY"
  ],
  [
    "this paper needs to make its own contribution clear compared to Yamada et al. , 2017",
    "NOVELTY"
  ],
  [
    "Even in the coNLL benchmark , the initial results of the paper is significantly behind .",
    "NOVELTY"
  ],
  [
    "I think the idea presented is interesting",
    "NOVELTY"
  ],
  [
    "and was efficient . The combination of those properties is novel",
    "NOVELTY"
  ],
  [
    "however each of the other approaches had two of these properties , and so the combination did not seem too groundbreaking or significant .",
    "NOVELTY"
  ],
  [
    "Application of this technique for continuous multimodal time series data modeling and prediction for high accuracy requirement applications is very promising .",
    "NOVELTY"
  ],
  [
    "The idea of using compression in decentralized learning seems natural but interesting",
    "NOVELTY"
  ],
  [
    "Both decentralized learning by model averaging and communication compression have been studied before",
    "NOVELTY"
  ],
  [
    "but their combination is relatively new",
    "NOVELTY"
  ],
  [
    "Moreover , they are to the best of my knowledge the first to theoretically analyse this approach . Thus , the main contribution of the paper are two novel and theoretically sound algorithms for decentralized learning with compression .",
    "NOVELTY"
  ],
  [
    "I really liked the paper",
    "NOVELTY"
  ],
  [
    "I think this work is innovative and good enough to be considered publication in NIPS .",
    "NOVELTY"
  ],
  [
    "The novelty of the work is limited though .",
    "NOVELTY"
  ],
  [
    "Overall , this idea is interesting and",
    "NOVELTY"
  ],
  [
    "The application is new to most people in the machine learning community .",
    "NOVELTY"
  ],
  [
    "However , the main contributions of this paper are empirical",
    "NOVELTY"
  ],
  [
    "The theoretical contributions are completely novel .",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel to my knowledge",
    "NOVELTY"
  ],
  [
    "because it presents a simple and intuitive idea",
    "NOVELTY"
  ],
  [
    "The main idea of the paper - avoiding the long horizon problem by computing IS over state distributions rather than trajectories - was already introduced in",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", the approach the authors take to leveraging this idea is original .",
    "NOVELTY"
  ],
  [
    "I found the idea proposed in the paper very interesting .",
    "NOVELTY"
  ],
  [
    "I dont get what is the novelty in this paper .",
    "NOVELTY"
  ],
  [
    "But as mentioned by the authors , this is not new either .",
    "NOVELTY"
  ],
  [
    "but this paper makes a significant theoretical contribution",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the convergence analysis of the Adam-type methods ( including established methods AdaGrad , RMSprop , Adam , AMSGrad ) in the _non-convex _ setting is a novel , original contribution .",
    "NOVELTY"
  ],
  [
    "This is an original paper making a significant theoretical contribution .",
    "NOVELTY"
  ],
  [
    "To mend those shortcomings their proposed algorithm takes the novel approach of combining mathematical category theory and continental philosophy .",
    "NOVELTY"
  ],
  [
    "Novel approach towards more explainable and shorter training times/ less data",
    "NOVELTY"
  ],
  [
    "Even though the idea presented is a novel contribution and has potential",
    "NOVELTY"
  ],
  [
    "One central problem of the paper is missing novelty .",
    "NOVELTY"
  ],
  [
    "Despite its limited novelty",
    "NOVELTY"
  ],
  [
    "the present result is trivial and",
    "NOVELTY"
  ],
  [
    "The parer is interesting",
    "NOVELTY"
  ],
  [
    "Therefore , I think this work does n't make enough contribution and the novelty is not enough for ICLR standard .",
    "NOVELTY"
  ],
  [
    "The flexibility of the method in considering test-time cost maps and user-defined goals (",
    "NOVELTY"
  ],
  [
    "is appealing",
    "NOVELTY"
  ],
  [
    "the theoretical contribution is actually marginal",
    "NOVELTY"
  ],
  [
    "The idea is novel ( to the best of my knowledge ) , interesting and the experiments seem",
    "NOVELTY"
  ],
  [
    "While the idea seems very interesting",
    "NOVELTY"
  ],
  [
    "I really enjoyed this paper .",
    "NOVELTY"
  ],
  [
    "i.e .non-monotonic behavior of simple learners , originality and quality of the paper is quite high ,",
    "NOVELTY"
  ],
  [
    "Overall , the paper does not seem to present novel ideas",
    "NOVELTY"
  ],
  [
    "in a novel way",
    "NOVELTY"
  ],
  [
    "The distillation framework the authors use in their methods is not new .",
    "NOVELTY"
  ],
  [
    "It 's main weakness is that the method does n't seem to be particularly new .",
    "NOVELTY"
  ],
  [
    "The main concern is the novelty , since the proposed method is pretty close to the graph attention network",
    "NOVELTY"
  ],
  [
    "Overall , this is a well-developed paper that presents an elegant new framework for directional EEG analysis , informed by an auxiliary data modality .",
    "NOVELTY"
  ],
  [
    ", using the fMRI as a precomputed spatial prior is not particularly innovative as far as multimodal approaches go .",
    "NOVELTY"
  ],
  [
    "This paper presents novel investigation of the regularization effects of the method , i.e. , the resilience to noisy labels and the analysis of learned weight matrices .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel text embedding approach in the spherical space and develops an optimization algorithm to train the model .",
    "NOVELTY"
  ],
  [
    "the approach proposed seems very similar to MIXER , which also learns a regressor to predict the reward for each action .",
    "NOVELTY"
  ],
  [
    "I think that this paper makes a solid contribution over the existing literature .",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "Although I thought the contribution is incremental to the other normalization works",
    "NOVELTY"
  ],
  [
    "I think that PONO itself is an incremental work compared to the other normalization techniques such as BN , GN and IN because recently many normalizations works combine multiple normalizations into a single normalization to achieve a better estimation of statistics",
    "NOVELTY"
  ],
  [
    "I conclude that the contribution of PONO is rather weak .",
    "NOVELTY"
  ],
  [
    "-- Earlier review follows below -- The paper was clear to follow and introduces a novel model in multi-armed bandit problems with well-analyzed algorithms .",
    "NOVELTY"
  ],
  [
    "these extensions are relatively straightforward and thus the technical contribution is lean .",
    "NOVELTY"
  ],
  [
    "Summary Interesting though relatively incremental adaptation",
    "NOVELTY"
  ],
  [
    "Relatively incremental",
    "NOVELTY"
  ],
  [
    "The idea of proof is simple but very interesting",
    "NOVELTY"
  ],
  [
    "Such type of extension is nontrivial and can potentially bring about better understanding of data-dependent generalization bounds",
    "NOVELTY"
  ],
  [
    "Overall , I 'm uncomfortable accepting this paper in its current form because I 'm not sure it constitutes a large enough unit of novel work .",
    "NOVELTY"
  ],
  [
    "With simulated fMRI data and through analysis of real fMRI recordings , they presented the following novel insights",
    "NOVELTY"
  ],
  [
    "To sum up , the novel insights derived from analysis of simulated and real fMRI data with GC measures are interesting and could have potential to advance the research field .",
    "NOVELTY"
  ],
  [
    "may be limited in originality",
    "NOVELTY"
  ],
  [
    "The insight on the connection between the spectral properties of the Gram matrix and convergence of gradient descent is nice and seems to be a very promising technique for future work .",
    "NOVELTY"
  ],
  [
    "I believe the paper is an important contribution",
    "NOVELTY"
  ],
  [
    "Combining meta-gradients and GVFs for auxiliary task discovery is fairly novel .",
    "NOVELTY"
  ],
  [
    "The approach is novel ,",
    "NOVELTY"
  ],
  [
    "it does seems like a fairly creative combination of existing approaches",
    "NOVELTY"
  ],
  [
    ".The novelty of the paper is limited . While the authors claim that it is the first time to approach it in the proposed manner , the problem of both p ( y ) and p ( x|y ) change is not new .",
    "NOVELTY"
  ],
  [
    "The technical novelty of this paper is marginal and",
    "NOVELTY"
  ],
  [
    "Marginal novelty compared to related work There have been several masking-based black-box methods",
    "NOVELTY"
  ],
  [
    "in particular , the novelty of the proposed method is marginal",
    "NOVELTY"
  ],
  [
    "This paper has some interesting ideas in it .",
    "NOVELTY"
  ],
  [
    "The ideas in this paper are interesting and novel .",
    "NOVELTY"
  ],
  [
    "The paper has very interesting contributions .",
    "NOVELTY"
  ],
  [
    "the best performing method is not novel",
    "NOVELTY"
  ],
  [
    "I think this is a nice applied piece",
    "NOVELTY"
  ],
  [
    "With respect to novelty the Convolution-VAE model is in it self not a novel contribution since this have been used in several other papers previously",
    "NOVELTY"
  ],
  [
    "al .2016 .On the other hand stochastic pooling is a new and possibly interesting idea and probabilistic language models have to the best of my knowledge not been applied to captioning before .",
    "NOVELTY"
  ],
  [
    ", modest originality and significance",
    "NOVELTY"
  ],
  [
    "The analysis of the results is quite insightful .",
    "NOVELTY"
  ],
  [
    "There is no novelty about this .",
    "NOVELTY"
  ],
  [
    "my current decision is reject mainly because of its weakness in technical novelty and contribution",
    "NOVELTY"
  ],
  [
    "In my opinion , the authors proposed some very interesting and novel definitions",
    "NOVELTY"
  ],
  [
    "The analysis is novel .",
    "NOVELTY"
  ],
  [
    "While the idea of using GMMs in GANs is not novel",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is quite limited .",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "While the idea of extending variance reduction and incremental algorithms to saddle point problem might sound straightforward , the results established here is notably novel and the technicality is surely non-trivial .",
    "NOVELTY"
  ],
  [
    "Overall : I think the idea of approximating posterior distributions via fixed point iterations as presented here is interesting since it presents a reasonable way to trade off between expressivity and computational complexity .",
    "NOVELTY"
  ],
  [
    "about an interesting integrative approach to dynamic connectivity analysis in MEG/EEG .",
    "NOVELTY"
  ],
  [
    "In my view , the paper definitely has a contribution",
    "NOVELTY"
  ],
  [
    "but the contribution is limited .",
    "NOVELTY"
  ],
  [
    "demonstrating that a simple GA can successfully be applied to larger networks than was previously thought to be possible and b ) introducing a novel software implementation that allows GAs to be efficiently scaled/distributed ( similar in nature to the work of Salimans et al . )",
    "NOVELTY"
  ],
  [
    "The idea of combining softmax functions in the hidden layers is not novel neither ,",
    "NOVELTY"
  ],
  [
    ". As a result , I find the contribution of the paper very limited , which could be summarized as applying an existing technique on a specific problem .",
    "NOVELTY"
  ],
  [
    "The task is new and the methods",
    "NOVELTY"
  ],
  [
    "This work is a novel combination of the techniques in stochastic differential equations , and the deep learning methodologies .",
    "NOVELTY"
  ],
  [
    "To the best of",
    "NOVELTY"
  ],
  [
    "This submission addresses a difficult task in a better way than previous work , and advances the state-of-the-art results in a demonstratable way . The work provides unique theoretical analysis .",
    "NOVELTY"
  ],
  [
    "It 's novel to introduce GAN to solve the PML problem .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited to some extent . It seems that the model just combines ideas of GAN and PML",
    "NOVELTY"
  ],
  [
    "the two steps are totally separated , thus the contribution of this paper is incremental .",
    "NOVELTY"
  ],
  [
    "and the proposed method provides a novel and interesting way to approach this problem",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are mainly experimental and show different `` surprising `` aspects about GNNs",
    "NOVELTY"
  ],
  [
    "as this is a very good stress test for current algorithms and can potentially help identifying novel challenges",
    "NOVELTY"
  ],
  [
    "The proposed method is an interesting way of combining an unsupervised learning objective and a supervised one . While the idea is interesting",
    "NOVELTY"
  ],
  [
    "3 .The novelty is limited by the prior work .",
    "NOVELTY"
  ],
  [
    "1 .The idea for this",
    "NOVELTY"
  ],
  [
    "Overall I think the idea is novel and the contribution is significant .",
    "NOVELTY"
  ],
  [
    "The theoretical and practical contributions of this paper are minor .",
    "NOVELTY"
  ],
  [
    "3 .The overall technical contribution is somewhat incremental based on previous work on GNN and manifold mixup based regularizations .",
    "NOVELTY"
  ],
  [
    "as the formulation looks very similar to Syed",
    "NOVELTY"
  ],
  [
    "The quality of the submission is fairly high",
    "NOVELTY"
  ],
  [
    "The originality of the work is just OK",
    "NOVELTY"
  ],
  [
    "The ultimate algorithm *seems* like it is really quite similar to other policy gradient methods such as A3C",
    "NOVELTY"
  ],
  [
    "Most of the machine learning techniques used in the paper are quite dated .",
    "NOVELTY"
  ],
  [
    "while having run real experiments , the paper does not make a concrete conceptual contribution , and most of the practical elements are fairly basic",
    "NOVELTY"
  ],
  [
    "instead , I think it is pretty novel to explain the design of neural nets , by way of quantum physics .",
    "NOVELTY"
  ],
  [
    "I think the use of this decontextualized variant as is done here is nice because it avoids issues with feature interactions in the hidden space that might result in misleading 'attribution ' w.r.t .the original inputs .",
    "NOVELTY"
  ],
  [
    "Overall , this is a nice contribution that offers a new mechanism for exploiting human provided annotations .",
    "NOVELTY"
  ],
  [
    "I think the originality of the query model is decreased and the significance of the results as well .",
    "NOVELTY"
  ],
  [
    "I find the results of the paper quite novel and I recommend acceptance",
    "NOVELTY"
  ],
  [
    "it is unclear to me what the originality is of the proposed algorithm",
    "NOVELTY"
  ],
  [
    "This paper provides an interesting theoretical contribution .",
    "NOVELTY"
  ],
  [
    "I am not convinced about novelty and originality of this paper , especially on the model side",
    "NOVELTY"
  ],
  [
    "the idea of the paper is very interesting to learn data-augmentation but yet I am not convinced the current paper has enough novelty and contribution and see the contribution of paper as on more the application side rather than on model and problem side",
    "NOVELTY"
  ],
  [
    "the improvement over related methods such as ridge regression is minuscule",
    "NOVELTY"
  ],
  [
    "Limited novelty",
    "NOVELTY"
  ],
  [
    "3 .Novelty The novelty of the paper is quite limited since it is an extension of BERT to the visual domain .",
    "NOVELTY"
  ],
  [
    "however this might not be a substantial extension of previous work",
    "NOVELTY"
  ],
  [
    "The novelty is limited .",
    "NOVELTY"
  ],
  [
    "which is of limited novelty",
    "NOVELTY"
  ],
  [
    "present a very interesting new extension to random partition type priors with an appealing inference scheme .",
    "NOVELTY"
  ],
  [
    "I think the idea is quite novel and well written .",
    "NOVELTY"
  ],
  [
    "Apparently , this is the first work that studies this problem for general loss functions .",
    "NOVELTY"
  ],
  [
    "Again , as far as I can see , this approach is original to this work .",
    "NOVELTY"
  ],
  [
    "The mathematical techniques are based on standard approaches and are not very novel in my opinion .",
    "NOVELTY"
  ],
  [
    "The concept is very interesting and promising .",
    "NOVELTY"
  ],
  [
    "While the idea of using the successor representation in exploration is interesting and has been considered recently",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel direction for curriculum learning .",
    "NOVELTY"
  ],
  [
    "Weak Reject -- The class-wise idea for curriculum learning is interesting",
    "NOVELTY"
  ],
  [
    "The class-wise idea used in this paper seems to add a new direction to the area of curriculum learning .",
    "NOVELTY"
  ],
  [
    "This reviewer does not believe that modifying the loss function of a well established previous method that is over 10 years old ( DrLIM ) constitutes a significant enough contribution .",
    "NOVELTY"
  ],
  [
    "the method is not terribly original -- this is a simple hybrid SVGD",
    "NOVELTY"
  ],
  [
    "While the idea",
    "NOVELTY"
  ],
  [
    "I would overall consider the paper as based on a novel idea .",
    "NOVELTY"
  ],
  [
    "The proposed technique ( dubbed R2D2 ) is not particularly original",
    "NOVELTY"
  ],
  [
    "Compared to other structured classification approaches whose scope is limited by the complexity of the inference process , this approaches is very attractive",
    "NOVELTY"
  ],
  [
    "they seem new in the context of hierarchical/multi-label/structured classification",
    "NOVELTY"
  ],
  [
    "Whereas all of the parts employed in the proposed `` pipeline `` are based on previous works , their arrangement into this contiguous framework is new ,",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is fairly novel in the context of VQA .",
    "NOVELTY"
  ],
  [
    "As far as I know , this is the first work that provides theoretical guarantees for rank-one matrix sensing with symmetric sensing matrix using alternating minimization approach .",
    "NOVELTY"
  ],
  [
    "The idea of the proposed method is natural , which is incorporating the functionality of SVGD to reduce the auto-correlation of Langevin dynamics .",
    "NOVELTY"
  ],
  [
    "This is",
    "NOVELTY"
  ],
  [
    "an interesting work which is deviates from EMCapsules in several ways",
    "NOVELTY"
  ],
  [
    "itself is a great achievement",
    "NOVELTY"
  ],
  [
    "and serves as a refreshing take on the matter",
    "NOVELTY"
  ],
  [
    "Introducing multi-step discretization is novel .",
    "NOVELTY"
  ],
  [
    "Overall , this idea is a promising approach to obtain networks that are provably under-confident far from training examples .",
    "NOVELTY"
  ],
  [
    "Worst-case evaluation of OOD ( out of domain ) performance seems novel and the gains not this objective using the proposed approach of this paper are interesting and promising .",
    "NOVELTY"
  ],
  [
    "From my perspective , the paper is interesting because it introduces new methods into GANs from another community .",
    "NOVELTY"
  ],
  [
    "The QDSFM is a novel contribution to literature , in my view .",
    "NOVELTY"
  ],
  [
    "The algorithms , however are similar to the ones used to solve DSFM problems .",
    "NOVELTY"
  ],
  [
    "My main concern with the paper is that it seems too incremental to stand on its own",
    "NOVELTY"
  ],
  [
    "The idea of tying weights in the neural network in order to compress the model is not entirely new .",
    "NOVELTY"
  ],
  [
    "I think the paper was very insightful and represents a significant advance .",
    "NOVELTY"
  ],
  [
    "The proposed architecture with memory database is interesting and appears to be novel .",
    "NOVELTY"
  ],
  [
    "The particular form of network architecture with the memory-based fully convolutional adversarial loss appears to be novel and potentially interesting .",
    "NOVELTY"
  ],
  [
    "The paper describes potentially interesting",
    "NOVELTY"
  ],
  [
    "The proposed architecture seems novel and potentially interesting",
    "NOVELTY"
  ],
  [
    "I don \u2019 t think this paper adds much on top of the previous work",
    "NOVELTY"
  ],
  [
    "I think this an interesting and possibly novel use of a kNN layer",
    "NOVELTY"
  ],
  [
    "At the same time it 's not presenting a ground breaking new algorithm or anything like that .",
    "NOVELTY"
  ],
  [
    "I am not sure the idea of applying conCNN to 6 categories of COCO is a great idea to begin with",
    "NOVELTY"
  ],
  [
    "The paper 's ideas are novel and good in general , and would make a good contribution to ICLR 2019 .",
    "NOVELTY"
  ],
  [
    "and the paper 's contribution on using Gumbel-softmax relaxation and the relational memory is novel",
    "NOVELTY"
  ],
  [
    "The research contribution is relatively low .",
    "NOVELTY"
  ],
  [
    "this is an article with a rather simple",
    "NOVELTY"
  ],
  [
    "but elegant idea",
    "NOVELTY"
  ],
  [
    "While the paper seems interesting",
    "NOVELTY"
  ],
  [
    "I am not sure what its novel contribution is and how broad the claims made actually are in their applicability",
    "NOVELTY"
  ],
  [
    "The idea however is not quite novel .",
    "NOVELTY"
  ],
  [
    "Though the ideas are interesting",
    "NOVELTY"
  ],
  [
    "The Finance model was new to me",
    "NOVELTY"
  ],
  [
    "and it 's",
    "NOVELTY"
  ],
  [
    "the contributions are clear",
    "NOVELTY"
  ],
  [
    "and makes novel contributions to both stochastic opt and bandit literature .",
    "NOVELTY"
  ],
  [
    "the analysis does not seem to reveal some novel insights either",
    "NOVELTY"
  ],
  [
    "This paper manages to unify different perturbation based algorithms to one template and as a byproduct it gives a randomized version of UCB .",
    "NOVELTY"
  ],
  [
    "The general analysis on perturbed algorithms for stochastic multi-armed bandit problem is inspiring .",
    "NOVELTY"
  ],
  [
    "as far as I know the proposed technique is original and of great significance .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm differs very little from previous approaches based on primal-dual algorithms",
    "NOVELTY"
  ],
  [
    "The presented algorithm doesn\u00e2\u0080\u0099t seem to differ much from prior work and without empirical results",
    "NOVELTY"
  ],
  [
    "It has to the best of my knowledge not been studied using graphical models , exploiting the compositional structure of these rules , which is a significant step forward",
    "NOVELTY"
  ],
  [
    "One is related to the novelty as the existing work of Xie et al .ECCV'16 also proposed similar technique with very similar aim",
    "NOVELTY"
  ],
  [
    "Negligible improvements with respect to CRF techniques on modern deep architectures",
    "NOVELTY"
  ],
  [
    "The use of denoising auto encoders ( DAEs ) for capturing pixel label relations and then using them to iteratively refine the segmentation predictions is interesting .",
    "NOVELTY"
  ],
  [
    "-The use of attribute and object recognition as an auxiliary task for zero-shot transfer has been previously explored in",
    "NOVELTY"
  ],
  [
    "Overall ,",
    "NOVELTY"
  ],
  [
    "I did not find the ideas presented in this work to be sufficiently novel or new .",
    "NOVELTY"
  ],
  [
    "A new problem domain is introduced , which I think will be interesting to",
    "NOVELTY"
  ],
  [
    "The approach is , despite simple , quite novel and reasonable .",
    "NOVELTY"
  ],
  [
    "I think this paper makes a good contribution to NeurIPS",
    "NOVELTY"
  ],
  [
    "Fairly original",
    "NOVELTY"
  ],
  [
    "but it still needs some work to justify it better",
    "NOVELTY"
  ],
  [
    "while I found the architecture interesting",
    "NOVELTY"
  ],
  [
    "I am not convinced that the model 's main innovation -- the 2d structure of the embedding matrix -- is actually doing anything important or meaningful beyond what is being accomplished by similar attentive embedding models already present in the literature .",
    "NOVELTY"
  ],
  [
    "The mathematical ideas used in the proofs are quite challenging",
    "NOVELTY"
  ],
  [
    "The proposed model is novel and practical ,",
    "NOVELTY"
  ],
  [
    "b .The idea of critical periods during training with reference to regularization is interesting .",
    "NOVELTY"
  ],
  [
    "The decision of Weak as opposed to a Strong accept is because the submission does not introduce anything truly novel",
    "NOVELTY"
  ],
  [
    "The proposed method extending hindsight experience replay with k-step inverse dynamics learning is original and significant .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is limited .",
    "NOVELTY"
  ],
  [
    "The theoretical analysis about existing adaptive methods provides nothing new .",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "Weaknesses The field of meta-learning variants is crowded , and this paper struggles to carve out its novelty .",
    "NOVELTY"
  ],
  [
    "while the technical contribution is limited",
    "NOVELTY"
  ],
  [
    "I have to say the innovation of this paper is limited .",
    "NOVELTY"
  ],
  [
    "s cube problem has been solved with other optimal approaches in the past",
    "NOVELTY"
  ],
  [
    "The approach is novel as far as I know of .",
    "NOVELTY"
  ],
  [
    "to my knowledge this is the first time this approach has been used for learning disentangled representations",
    "NOVELTY"
  ],
  [
    "The technical contributions of the paper are significant",
    "NOVELTY"
  ],
  [
    "In general , I believe that the paper constitutes one of the first attempts to deal with algorithmic fairness in the context of unsupervised learning ,",
    "NOVELTY"
  ],
  [
    "The presented slight algorithm modification and used proof techniques are interesting and novel",
    "NOVELTY"
  ],
  [
    "which has not",
    "NOVELTY"
  ],
  [
    "been done before",
    "NOVELTY"
  ],
  [
    ".The extension of the Caron -- Fox and Todeschini et al .models to a temporal setting is novel , and very few models have approached this .",
    "NOVELTY"
  ],
  [
    "The modelling work is interesting and to a high standard , and I believe provides novel insight ( both analytic and geometric ) into the conditions under which integration vs segregation is favoured .",
    "NOVELTY"
  ],
  [
    "This work is sufficiently original",
    "NOVELTY"
  ],
  [
    "beyond that paper .",
    "NOVELTY"
  ],
  [
    "The error-specific and performance-control characteristics of pGAN seem to be interesting",
    "NOVELTY"
  ],
  [
    "The techniques used to implement the method are not novel",
    "NOVELTY"
  ],
  [
    "but they were combined in a novel and relevant way .",
    "NOVELTY"
  ],
  [
    "The two algorithms presented in the paper are basically applications of the existing algorithms",
    "NOVELTY"
  ],
  [
    "My main concern is novelty . It feels like this work is a rather trivial follow-up on an existing model",
    "NOVELTY"
  ],
  [
    "I am afraid , however , that the model is not novel enough , nor the questions deep enough , to make this paper better than borderline for ICLR .",
    "NOVELTY"
  ],
  [
    "I think the paper is borderline leaning towards accept -- there is a novel idea here for framing slate recommendation problems in an auto-encoder framework that can spur some follow-up works",
    "NOVELTY"
  ],
  [
    "The idea is nice",
    "NOVELTY"
  ],
  [
    "the binary representation outperforms the Semantic hashing method from Salakhutdinov",
    "NOVELTY"
  ],
  [
    "the insertion of the sigmoid to produce binary codes ( from Lin & al",
    "NOVELTY"
  ],
  [
    "'15 ) in the training process is incremental",
    "NOVELTY"
  ],
  [
    "The main idea is combining two known properties of NN for detection so this work has slightly limited novelty .",
    "NOVELTY"
  ],
  [
    "However , there is n't enough novel contribution in this paper to warrant a publication .",
    "NOVELTY"
  ],
  [
    "The model is incrementally different than the baseline .",
    "NOVELTY"
  ],
  [
    "As it stands , the paper is a bit thin on new contributions .",
    "NOVELTY"
  ],
  [
    "the novelty is limited and not well explained .",
    "NOVELTY"
  ],
  [
    "The authors introduce an interesting new direction for applying generative networks .",
    "NOVELTY"
  ],
  [
    "I had trouble identifying the novel contributions of this work",
    "NOVELTY"
  ],
  [
    "and the methods , although simple modifications of existing algorithms , are intuitive .",
    "NOVELTY"
  ],
  [
    "My main concern with the paper is regarding its novelty",
    "NOVELTY"
  ],
  [
    "The motion model is too simplistic .",
    "NOVELTY"
  ],
  [
    "then the novelty of their framework is not clear -- as then the proposed model would just be a couple of neural networks to learn the motion and observation models",
    "NOVELTY"
  ],
  [
    "Here again , the technical novelty is not clear .",
    "NOVELTY"
  ],
  [
    "and it seems like a nice idea",
    "NOVELTY"
  ],
  [
    "The combination of VAEs and GANs , while new for videos , had already been proposed for image generation as indicated in the Related Work section and its formulation for video prediction is relatively straightforward given existing VAE",
    "NOVELTY"
  ],
  [
    "the framework and proofs are novel and mathematically elegant .",
    "NOVELTY"
  ],
  [
    "The authors approach in this vein seem to be only empirical .",
    "NOVELTY"
  ],
  [
    "As far as I know the algorithmic development , the interpretations and the experimental results are original .",
    "NOVELTY"
  ],
  [
    "the proposed task is novel + novel two stage coarse-to-fine architecture + well written + while the results contain discernible artifacts",
    "NOVELTY"
  ],
  [
    "Most of the theoretical work presented here are built upon prior work",
    "NOVELTY"
  ],
  [
    "the paper .",
    "NOVELTY"
  ],
  [
    "The proposed approach of making the discriminator 's task progressively harder to regularize GAN training appears novel , and makes sense .",
    "NOVELTY"
  ],
  [
    "contribution , but one that does not appear to bring dramatic new capability or understanding .",
    "NOVELTY"
  ],
  [
    "I am not sure that the results of this paper are real advances for this field .",
    "NOVELTY"
  ],
  [
    "It 's a promising idea .",
    "NOVELTY"
  ],
  [
    "Originality While the general idea of fitting models and adapting proposals has appeared periodically in the MCMC literature , this work is novel .",
    "NOVELTY"
  ],
  [
    "Overall the approaches in this work are reasonable but not new .",
    "NOVELTY"
  ],
  [
    "A new manually annotated corpus in Amharic is a good contribution .",
    "NOVELTY"
  ],
  [
    "The contributions are incrementally building upon previous work , but",
    "NOVELTY"
  ],
  [
    "the novelty of the chosen approach",
    "NOVELTY"
  ],
  [
    "this",
    "NOVELTY"
  ],
  [
    "The primary contribution of the paper is novel and",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper provides a novel contribution for modeling event data specifically for medical data .",
    "NOVELTY"
  ],
  [
    "This is a reasonable contribution",
    "NOVELTY"
  ],
  [
    "although it does not add significantly to the current state of the art .",
    "NOVELTY"
  ],
  [
    "Summary of review I find the contribution to be incremental , and the validation weak .",
    "NOVELTY"
  ],
  [
    "Incremental contributions and limited novelty .",
    "NOVELTY"
  ],
  [
    "The technical contribution of this work is limited .",
    "NOVELTY"
  ],
  [
    "The novelty is trivial .",
    "NOVELTY"
  ],
  [
    "The analysis of vanishing gradients and of cell change is insightful .",
    "NOVELTY"
  ],
  [
    "As far as I know , the model is novel .",
    "NOVELTY"
  ],
  [
    "I liked the idea of comparing different training optimization schemes (",
    "NOVELTY"
  ],
  [
    "applied to continual learning through visualization",
    "NOVELTY"
  ],
  [
    "This is very insightful considering recently a lot of language models are focusing on increasing the size of model and training data",
    "NOVELTY"
  ],
  [
    "These results are also insightful and meaningful for the readers to understand the method .",
    "NOVELTY"
  ],
  [
    "Though this is not absolutely new and relatively simple",
    "NOVELTY"
  ],
  [
    "I think this paper overall is insightful and thoughtful .",
    "NOVELTY"
  ],
  [
    "They provide analytical insight as well as a few experiments",
    "NOVELTY"
  ],
  [
    "I like the idea of preserving neighborhood relationships across views for retrieval tasks .",
    "NOVELTY"
  ],
  [
    "it is very hard to see this as a contribution",
    "NOVELTY"
  ],
  [
    "This work is related to ( though clearly different",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is the first work exploring reversible architecture for recurrent neural networks .",
    "NOVELTY"
  ],
  [
    "=================================== This work is original , as I do n't believe these mask criteria have been analyzed before",
    "NOVELTY"
  ],
  [
    "The idea of training discriminators to determine coherence and cohesion , and training those discriminators as part of an NLG system using policy gradients , is an interesting one .",
    "NOVELTY"
  ],
  [
    "2 .The authors propose a novel SACN architecture to capture the relevance of OD flows by modeling each OD flow map as an adjacency matrix .",
    "NOVELTY"
  ],
  [
    "the proof is correct to the best of my knowledge and the technique is the major contribution of the paper .",
    "NOVELTY"
  ],
  [
    "The idea is novel and the method is interesting enough .",
    "NOVELTY"
  ],
  [
    "Novel approach",
    "NOVELTY"
  ],
  [
    "However , the idea of using geometric features has been investigated in quite a few previous literature and",
    "NOVELTY"
  ],
  [
    "The importance of geometry in geolocation has been studied in many previous works",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting idea .",
    "NOVELTY"
  ],
  [
    "From the contribution point of view the paper looks like to be a combination of several existing and well developed approach : Neural Hawkes Process + particle smoothing + minimum bayes risk + alignment .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is natural",
    "NOVELTY"
  ],
  [
    "I appreciate the elegant idea",
    "NOVELTY"
  ],
  [
    "1 .The concept of using simpler models to approximate other complex models ( model distillation ) is not new and has been explored quite a bit already in ML literature .",
    "NOVELTY"
  ],
  [
    "This seems rather incremental .",
    "NOVELTY"
  ],
  [
    "The proposed approach lacks novelty 2",
    "NOVELTY"
  ],
  [
    "the components of their method are not novel",
    "NOVELTY"
  ],
  [
    "The components of this setup are n't particularly novel",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are n't fundamental",
    "NOVELTY"
  ],
  [
    "2 is a highly relevant and novel result that should be the focus .",
    "NOVELTY"
  ],
  [
    "I believe the paper does contain interesting results that are novel and useful to the community",
    "NOVELTY"
  ],
  [
    "However , the generative process is not new",
    "NOVELTY"
  ],
  [
    "I like the idea of making recurrent cells operate with nearly independent transition dynamics and interact only sparingly through the attention bottleneck",
    "NOVELTY"
  ],
  [
    "Some novel contributions",
    "NOVELTY"
  ],
  [
    "The assumption that a low-rank parameter space exists among tasks rather than original feature spaces is not new and widely used in literature .",
    "NOVELTY"
  ],
  [
    "Though with a quite novel idea on solving multi-task censored regression problem",
    "NOVELTY"
  ],
  [
    "The novelty looks a bit low .",
    "NOVELTY"
  ],
  [
    "this paper utilizes several novel ideas such as the multiplied version \\sigma^t of the influence function",
    "NOVELTY"
  ],
  [
    "and idea is quite novel to me .",
    "NOVELTY"
  ],
  [
    "This paper does not propose a new domain adaptation algorithm .",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting transfer learning schema where the data between the source and target domain can not be shared with each other to protect the data-privacy",
    "NOVELTY"
  ],
  [
    "seems to be an interesting idea",
    "NOVELTY"
  ],
  [
    "This paper has solid contribution and worth publishing in NIPS",
    "NOVELTY"
  ],
  [
    "The idea of combining these two perspectives is interesting",
    "NOVELTY"
  ],
  [
    "And this stacking seems to be simple combination of existing approaches , without fully integrating them",
    "NOVELTY"
  ],
  [
    "Due to the above issues , I feel the novelty of the approach is limited and incremental .",
    "NOVELTY"
  ],
  [
    "I think the proposed algorithm is novel enough and the jointly training mechanism is also beneficial for the state-of-the-arts results reported in the experiments",
    "NOVELTY"
  ],
  [
    "The paper kind of lacks of novelty .",
    "NOVELTY"
  ],
  [
    "and the developed solution is interesting",
    "NOVELTY"
  ],
  [
    "This is certainly original work ,",
    "NOVELTY"
  ],
  [
    "and the authors have provided a promising first step",
    "NOVELTY"
  ],
  [
    "PROS -Idea is very interesting and novel , with a nice connection to normalizing flows -Underexplored area of research",
    "NOVELTY"
  ],
  [
    "The technical development isn \u2019 t surprising and doesn \u2019 t have much to teach researchers working in the area . Given that the technical novelty is rather light and the experimental benefits are not quite there",
    "NOVELTY"
  ],
  [
    "While the paper is interesting with regards to the ranking perspective",
    "NOVELTY"
  ],
  [
    "I am not fully convinced about the novelty of the reduction of off-policy learning to supervised learning .",
    "NOVELTY"
  ],
  [
    "The idea of leveraging predictions to train feature representations for discrimination is not new . However , the paper presents a couple of interesting ideas , partially inspired from other work in other areas",
    "NOVELTY"
  ],
  [
    "The proof seems non-trivial and the use of stopping times according to when each arm has been pulled for the first time to my knowledge is novel .",
    "NOVELTY"
  ],
  [
    "While the discussion about the Phase transitions and Cyclic Phenomena is insightful",
    "NOVELTY"
  ],
  [
    "Overall the contributions of the paper seem significant and especially the proof of the lower bounds seem novel .",
    "NOVELTY"
  ],
  [
    "The proposed method is a simple combination of existing works without any creative improvement .",
    "NOVELTY"
  ],
  [
    "is novel as to what the reviewer knows",
    "NOVELTY"
  ],
  [
    "In general , the idea of the paper is natural and",
    "NOVELTY"
  ],
  [
    "The problem the paper study is innovative and interesting .",
    "NOVELTY"
  ],
  [
    "However , the techniques the paper relies are variation and combination of existing methods .",
    "NOVELTY"
  ],
  [
    "the proposed approach is intuitive",
    "NOVELTY"
  ],
  [
    "However , these are not novel insights to my knowledge but have been exploited before .",
    "NOVELTY"
  ],
  [
    "This manuscript definitely introduces some new ideas",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "makes a good contribution to the literature on adversarial machine learning",
    "NOVELTY"
  ],
  [
    "The presentation would be too plain to find what parts are novel contributions .",
    "NOVELTY"
  ],
  [
    "and the proposed approach is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The main idea of this paper is very interesting and the empirical results look encouraging .",
    "NOVELTY"
  ],
  [
    "Generally I like the idea of extending Information Bottleneck to dynamic systems and I think the experiment is interesting .",
    "NOVELTY"
  ],
  [
    "But overall I think the idea in this paper is interesting , if well illustrated",
    "NOVELTY"
  ],
  [
    "the paper fails to demonstrate the novelties and their importance of some conclusions",
    "NOVELTY"
  ],
  [
    "Remarking the existence of the trade-off will not be a strong contribution .",
    "NOVELTY"
  ],
  [
    "To my best knowledge , experimentally showing that adversarial inputs have larger gradient norms ( Section 4 ) is novel , and it is potentially interesting .",
    "NOVELTY"
  ],
  [
    "The paper presents original work .",
    "NOVELTY"
  ],
  [
    ", presents very interesting ideas and seems to be state of the art for compression .",
    "NOVELTY"
  ],
  [
    "A clear disadvantage of the approach to prior algorithmic work is that",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel framework for robust estimation .",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    ", this is not the most innovative work",
    "NOVELTY"
  ],
  [
    "but definitely",
    "NOVELTY"
  ],
  [
    "The paper presents a novel architecture by proposing a generator that outputs a graphic layout consisting of class probabilities and polygon keypoints .",
    "NOVELTY"
  ],
  [
    "The paper contains interesting new ideas",
    "NOVELTY"
  ],
  [
    "Summary An interesting paper with novel theoretical ideas",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel architecture which jointly attends over the context and the query .",
    "NOVELTY"
  ],
  [
    "2 .The architecture is new and incorporates novel and interesting aspects",
    "NOVELTY"
  ],
  [
    "The model itself is clever , and introduces non-linearity through an intuitively appealing collection of latent sub-events .",
    "NOVELTY"
  ],
  [
    "I think that the paper is interesting and of high quality",
    "NOVELTY"
  ],
  [
    "The paper has novel components",
    "NOVELTY"
  ],
  [
    "Prior work is not demonstrated in their experiments so it is impossible to assess their work in context though this work may be completely novel and I would like to see a statement along these lines",
    "NOVELTY"
  ],
  [
    "To my best knowledge , the work is novel and provide an extension to the successor representation .",
    "NOVELTY"
  ],
  [
    "Overall the contribution of this paper is incremental over Wang et al and is mainly in the introduction of their new loss terms to regularize the hallucination process .",
    "NOVELTY"
  ],
  [
    "I believe this paper to be a useful contribution to the literature . It both solidifies understanding of existing methods and provides new insight into quantitate ways of analysing",
    "NOVELTY"
  ],
  [
    "However , this work seems to be rather incremental compared to a previous method adopting another variance reduction method ( SVRG ) [",
    "NOVELTY"
  ],
  [
    "makes an interesting contribution",
    "NOVELTY"
  ],
  [
    "the authors consider interesting approach to life-long learning and I really liked the idea of a surprise-based signal to choose the data to store .",
    "NOVELTY"
  ],
  [
    "the paper builds on the prior work of Kaiser et al. , 2017 and Santoro et al. , 2016 ,",
    "NOVELTY"
  ],
  [
    "but the proposed modifications are novel to my best knowledge",
    "NOVELTY"
  ],
  [
    "I think the problem formulation is very realistic and interesting and I am not aware of it being explored previously - The newly proposed architecture STAM is also interesting .",
    "NOVELTY"
  ],
  [
    "While it remains unclear if STAM can generalize to realistic images , the idea of UPL is very interesting and speaks for accepting the paper , although there are several weaknesses the authors should address",
    "NOVELTY"
  ],
  [
    "The paper has contributions in multiple directions both algorithmic and theoretical .",
    "NOVELTY"
  ],
  [
    "I am not sure how novel they are .",
    "NOVELTY"
  ],
  [
    "2 .The idea is interesting",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this is the first time a convolutional neural network is applied to this fairly well studied modeling problem .",
    "NOVELTY"
  ],
  [
    "Thus I find these results novel and exciting .",
    "NOVELTY"
  ],
  [
    "To the best of my understanding , this study mostly focuses on the latter",
    "NOVELTY"
  ],
  [
    "The proposed idea of generating text using summary sentences is new .",
    "NOVELTY"
  ],
  [
    "although the idea presented in this paper is interesting",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting .",
    "NOVELTY"
  ],
  [
    "Although , the analysis is very similar to the recent analysis for PU learning published by Du Plessis et al .recently at NIPS",
    "NOVELTY"
  ],
  [
    "but the problem setting is novel and interesting",
    "NOVELTY"
  ],
  [
    "paper that develops a neat novel idea for regularization of deep networks",
    "NOVELTY"
  ],
  [
    "The idea is , however , not tremendously novel in light of recent work ( res-nets and stochastic depth networks",
    "NOVELTY"
  ],
  [
    "The paper considers a very novel ( but important ) RL context where the agent has a constrained amount of information for representing a policy .",
    "NOVELTY"
  ],
  [
    "1- The application of the difference of Gaussians kernel in the computer vision domain is not new .",
    "NOVELTY"
  ],
  [
    "While the model on its own is not very novel",
    "NOVELTY"
  ],
  [
    "the work seems fairly incomplete",
    "NOVELTY"
  ],
  [
    "Although the paper is purely experimental without any particular theoretical considerations",
    "NOVELTY"
  ],
  [
    "it presents a few surprising observations defying conventional wisdom",
    "NOVELTY"
  ],
  [
    "and presents interesting insights for the design of convolutional network architectures and challenges mainstream views",
    "NOVELTY"
  ],
  [
    "-- The novelty of the proposed approach is very marginal",
    "NOVELTY"
  ],
  [
    "However , the novelty of the proposed method is very marginal .",
    "NOVELTY"
  ],
  [
    "but what 's novel here is the particular combination of parts and choice of techniques",
    "NOVELTY"
  ],
  [
    "Text makes a small but significant contribution",
    "NOVELTY"
  ],
  [
    "While the authors state the application L0 to a novel context to select features is different from prior work , the novelty is rather incremental",
    "NOVELTY"
  ],
  [
    "from both novelty , performance , and self-explaining perspectives , this work does not introduce much to the field .",
    "NOVELTY"
  ],
  [
    "The novelty is not sufficient considering the prior works on sparse neural network training .",
    "NOVELTY"
  ],
  [
    "the work is rich , complex , original , and uses leading methods from multiple areas of ML .",
    "NOVELTY"
  ],
  [
    "The idea of using MDP techniques to solve resource-constrained classification is not new .",
    "NOVELTY"
  ],
  [
    "overall : the paper is well developed and novel in its application area .",
    "NOVELTY"
  ],
  [
    "There is a novel",
    "NOVELTY"
  ],
  [
    "As far as I can tell the approach is novel , makes sense , and requires a lot of technical innovations .",
    "NOVELTY"
  ],
  [
    "In my opinion , combining VAE with GLOW is not sufficiently novel idea .",
    "NOVELTY"
  ],
  [
    "and the techniques used in this paper are interesting .",
    "NOVELTY"
  ],
  [
    "-The overall novelty is limited considering the major technical components like LSTM RNN and ensemble method are already established .",
    "NOVELTY"
  ],
  [
    "interpretation of the BN re-parametrisation",
    "NOVELTY"
  ],
  [
    "The originality of this study lies in the use of Riemannian geometry .",
    "NOVELTY"
  ],
  [
    "This paper extended this algorithm for inferring granger causality through applying group sparse regularization , which is a pretty smart design to me .",
    "NOVELTY"
  ],
  [
    "these show only incremental improvements over recent baselines",
    "NOVELTY"
  ],
  [
    "The idea of using shared and private encoders in the multitask setup is interesting",
    "NOVELTY"
  ],
  [
    "So overall I believe that the incremental contributions in this paper as well as the lack of favorable results that would support the additions made over Conneau et al .make this paper rather an interesting workshop addition than a conference full-paper",
    "NOVELTY"
  ],
  [
    "The paper suggests an interesting approach",
    "NOVELTY"
  ],
  [
    "but to my knowledge this is the first theoretically complete demonstration of such links",
    "NOVELTY"
  ],
  [
    "I do not understand the theoretical contribution of the paper .",
    "NOVELTY"
  ],
  [
    "synthesizing realistic images with text , but modifying specific attributes of an image while maintaining the image content is fairly a novel approach",
    "NOVELTY"
  ],
  [
    "This is a nice idea .",
    "NOVELTY"
  ],
  [
    "this design is just a simple variant of original GNN and I did not see any novel thing here .",
    "NOVELTY"
  ],
  [
    "However , the combination of these two into one framework is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new ,",
    "NOVELTY"
  ],
  [
    "The originality and the technical quality of the proposed method is not high as it is a straightforward combination of two existing method .",
    "NOVELTY"
  ],
  [
    "I find the interface design really interesting as I have not seen many active work in this direction .",
    "NOVELTY"
  ],
  [
    "I believe that the new technical insights of the paper alone is not significant enough",
    "NOVELTY"
  ],
  [
    "So I think the novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "The theoretical analysis sounds interesting",
    "NOVELTY"
  ],
  [
    "Although the modifications to CPC are n't particularly original",
    "NOVELTY"
  ],
  [
    "CPC is already a promising unsupervised representation learning technique",
    "NOVELTY"
  ],
  [
    "but the authors currently",
    "NOVELTY"
  ],
  [
    "incremental novelty",
    "NOVELTY"
  ],
  [
    "the general pruning strategy used here is very similar to that introduced by Narang et al.",
    "NOVELTY"
  ],
  [
    "the originality of the different pruning strategies used here for convolutional and fully-connected layers is very limited .",
    "NOVELTY"
  ],
  [
    "these strategies directly follow those studied by Mao et al. , 2017 .- The study of robustness to adversarial attacks , while interesting , is also not novel per se ,",
    "NOVELTY"
  ],
  [
    "My main concern about this paper is its novelty , as the method essentially uses the method of Narang et al.",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed algorithm might not enough .",
    "NOVELTY"
  ],
  [
    "was original and experiment results show the proposed CapsGNN is effective in large graph data analysis",
    "NOVELTY"
  ],
  [
    "Use of capsules nets and routing in CapsGNN are close to that in the original CapsNet",
    "NOVELTY"
  ],
  [
    "I generally like this idea .",
    "NOVELTY"
  ],
  [
    "Overall , This is an original work with clear presentation .",
    "NOVELTY"
  ],
  [
    "making it learnable inside the deep network is a clear contribution",
    "NOVELTY"
  ],
  [
    "the idea is nice",
    "NOVELTY"
  ],
  [
    "which is an interesting and novel contribution",
    "NOVELTY"
  ],
  [
    "Originality/Significance While the architecture is new , it is based on a combination of previous ideas about fast weights , hypernetworks and activation gating and I \u2019 d say that the novelty of the approach is average",
    "NOVELTY"
  ],
  [
    "the impact of this paper seems somewhat limited to me",
    "NOVELTY"
  ],
  [
    "While the authors propose a novel extension to an existing algorithm",
    "NOVELTY"
  ],
  [
    "Novel CPC|Action algorithm",
    "NOVELTY"
  ],
  [
    "This work can be a significant contribution as it is a simple linear model but practically performs better than other deep nonlinear networks",
    "NOVELTY"
  ],
  [
    "the proposed loss functions utilize only the spectral information of graph structure with novel approaches .",
    "NOVELTY"
  ],
  [
    "Overall , this paper presents a novel approach utilizing graph spectral information with empirical improvements .",
    "NOVELTY"
  ],
  [
    "No significant theoretical contribution .",
    "NOVELTY"
  ],
  [
    "but the contribution is unclear",
    "NOVELTY"
  ],
  [
    "-This is an incremental step in covering missing data scenarious",
    "NOVELTY"
  ],
  [
    "paper proposes solutions that weaken the requirements of previous works",
    "NOVELTY"
  ],
  [
    "The proposed solutions offer some nice novel insights to the problem , and the proposed methods improve seriously on existing methods , most notably in applicability . The most valuable contribution might be , however , is the generalization of the problem itself , which potentially opens up some novel topic for the future research - both for theory and application .",
    "NOVELTY"
  ],
  [
    "Therefore , its technical contribution is limited .",
    "NOVELTY"
  ],
  [
    "Despite the limited originality",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "Actually , the motivation is not new as some recent work also investigated a similar objective",
    "NOVELTY"
  ],
  [
    "So the methodology itself is still incremental .",
    "NOVELTY"
  ],
  [
    "While the idea may be novel and interesting",
    "NOVELTY"
  ],
  [
    "Learning good similarity functions is also not novel [ 3",
    "NOVELTY"
  ],
  [
    "while the",
    "NOVELTY"
  ],
  [
    "This work propose a novel explicit 3D structural understanding for deformable face through 2D image matching ( with or without keypoints representation ) by inducing affine transformation with a direct closed-formed solution .",
    "NOVELTY"
  ],
  [
    "The NP-hardness result is interesting extension to existing similar results .",
    "NOVELTY"
  ],
  [
    "The idea seems novel , at least for FGMs .",
    "NOVELTY"
  ],
  [
    "the techniques employed to prove theorems look similar to those in Qiao et al .I do not have a specific comment about the theoretical results",
    "NOVELTY"
  ],
  [
    "While the D-Conv idea seems fairly simple and natural , it is novel AFAIK and fairly appropriate to model point-cloud data streams .",
    "NOVELTY"
  ],
  [
    "optional losses is",
    "NOVELTY"
  ],
  [
    "but I appreciate the novelty in this paper on bridging the two subfields",
    "NOVELTY"
  ],
  [
    "Overall I liked the submission",
    "NOVELTY"
  ],
  [
    "and so forth ; I found this idea clever and elegant",
    "NOVELTY"
  ],
  [
    "I think this paper proposes a clever and elegant",
    "NOVELTY"
  ],
  [
    "The analysis of the phases in the hyperparameter space is interesting and insightful .",
    "NOVELTY"
  ],
  [
    "All of these are novel",
    "NOVELTY"
  ],
  [
    "The Graph neural network architecture proposed in Section 4 to compute literals of the formula is an original idea .",
    "NOVELTY"
  ],
  [
    "My main concern is that the novelty from a machine learning and reinforcement learning point of view remains limited while the application seems original and promising .",
    "NOVELTY"
  ],
  [
    "The idea of using signSGD for distributed optimization make it attractive as it is naturally communication efficient .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper proposes a novel distributed optimization algorithm that has both theoretical and experimental contribution .",
    "NOVELTY"
  ],
  [
    "While this is an interesting idea",
    "NOVELTY"
  ],
  [
    "The work is original",
    "NOVELTY"
  ],
  [
    "The models introduced in this paper are not novel",
    "NOVELTY"
  ],
  [
    "by the information bottleneck literature and the although the mutual information derivations present in this work are not novel (",
    "NOVELTY"
  ],
  [
    "The infinite support hyper-plane machine ( iSHM ) , which is used as layer here , is an interesting and novel application of non-parametric Bayesian inference , which enables learning of the network structure directly without cross-validation .",
    "NOVELTY"
  ],
  [
    "and presents a novel approach",
    "NOVELTY"
  ],
  [
    "The novelty of integrating knowledge is not new .",
    "NOVELTY"
  ],
  [
    "-- but it is not new and has been studied in a few papers before .",
    "NOVELTY"
  ],
  [
    "While this is an interesting idea",
    "NOVELTY"
  ],
  [
    "I think overall the idea maybe nice",
    "NOVELTY"
  ],
  [
    "Overall , I like the approach",
    "NOVELTY"
  ],
  [
    "I like the ideas of the paper and the exposition in this paper .",
    "NOVELTY"
  ],
  [
    "an incredible achievement since PossibleWorldNet effectively beat out other methods on a dataset that they created expressly for it",
    "NOVELTY"
  ],
  [
    "This has limited academic novelty .",
    "NOVELTY"
  ],
  [
    "so not really an academic contribution",
    "NOVELTY"
  ],
  [
    "though not groundbreaking",
    "NOVELTY"
  ],
  [
    "Originality The main novelty seems to be coming from the idea of parameter sharing between pairwise payoffs , but the overall architecture seems to be the same as",
    "NOVELTY"
  ],
  [
    "Although the paper presents a new idea very well",
    "NOVELTY"
  ],
  [
    ", the overall idea seems a bit incremental .",
    "NOVELTY"
  ],
  [
    "While the theory is interesting",
    "NOVELTY"
  ],
  [
    "The technical contribution is significant and original and brings great insight about an important class of",
    "NOVELTY"
  ],
  [
    "Overall , this paper seems like a solid contribution to the literature .",
    "NOVELTY"
  ],
  [
    "but given it \u2019 s true , this is an interesting application of these ideas . I also like the application to dialog because pre-trained language models have been shown to offer very good priors for high-quality natural language generation",
    "NOVELTY"
  ],
  [
    "but the contribution seems marginal .",
    "NOVELTY"
  ],
  [
    "the claim of novelty is n't defined well enough to be useful",
    "NOVELTY"
  ],
  [
    "the minimal revisions in the paper do not make the contributions clear yet",
    "NOVELTY"
  ],
  [
    "demonstrations is a cool idea but effectively is a very straightforward application based on the insight that the approach can handle truly off-policy samples",
    "NOVELTY"
  ],
  [
    "The application seems original .",
    "NOVELTY"
  ],
  [
    "interesting idea of using the algorithm for",
    "NOVELTY"
  ],
  [
    "The paper appears to be original",
    "NOVELTY"
  ],
  [
    "The approach is novel and has well-developed theory supporting it .",
    "NOVELTY"
  ],
  [
    "However I found the high level motivations given in Introduction/Sec 3 are similar ( at times even the wording ) to those of Belilovsky et al 2017 which introduced/ motivate the data driven approach to this problem",
    "NOVELTY"
  ],
  [
    "but limited novelty",
    "NOVELTY"
  ],
  [
    "intuitive method Draws from existing literature relating to dropout-like methods Little computational overhead Solid experimental justification Some theoretical support for the method Cons",
    "NOVELTY"
  ],
  [
    "The idea of evaluating the network capability of memorization for estimating the quantization of the parameters make sense to me and is novel in my knowledge .",
    "NOVELTY"
  ],
  [
    "evaluation : The proposed idea and experiments seem interesting",
    "NOVELTY"
  ],
  [
    "The denoising autoencoder regularized trajectory optimization is a novel method to deal with the adversarial effect with the learned dynamic model in the model-based RL framework .",
    "NOVELTY"
  ],
  [
    "This paper has no machine learning algorithmic contribution",
    "NOVELTY"
  ],
  [
    "The paper presents a novel approach to alter the artistic style of images .",
    "NOVELTY"
  ],
  [
    "The presented paper combines familiar techniques ( i.e . [ 11 ] and [ 3 ] ) in a novel way and presents adequate advances over existing methods .",
    "NOVELTY"
  ],
  [
    "While the individual parts are not novel",
    "NOVELTY"
  ],
  [
    "I feel like there might be some interesting ideas in this work",
    "NOVELTY"
  ],
  [
    "this is not the first attempt to use 3D structure to create molecular representations .",
    "NOVELTY"
  ],
  [
    "The novelty of the work lies in that unlike most recent approaches , it presents a deterministic , rather than randomized , approach to selecting these explicit features .",
    "NOVELTY"
  ],
  [
    "The framing of the problem as an OMP-like problem is new as far as I am aware",
    "NOVELTY"
  ],
  [
    "Though the paper proposes an interesting concept",
    "NOVELTY"
  ],
  [
    "That being said , I like the idea of incorporating a discriminator , which is something not explored in the previous work .",
    "NOVELTY"
  ],
  [
    "This theoretical contribution is novel and provides a new tool to understand why word embeddings can capture various semantics of words . The originality and quality of this paper would be above the threshold",
    "NOVELTY"
  ],
  [
    "the novelty is significant",
    "NOVELTY"
  ],
  [
    "The idea is novel , well motivated and explained .",
    "NOVELTY"
  ],
  [
    "It presents a novel , straightforward and practical solution to efficiently computing Wasserstein distances and performing related image manipulations .",
    "NOVELTY"
  ],
  [
    "I 'm willing to be convinced that this is an interesting and scientifically novel result",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- The paper",
    "NOVELTY"
  ],
  [
    "The receiving agent 's direct control over dialog length is also novel and allows for the interesting analysis presented in later sections .",
    "NOVELTY"
  ],
  [
    "The proposed reference game provides a number of novel contributions -- giving the agents control over dialog length , providing both agents with the same vocabulary without constraints on how each uses it ( implicit through pretraining or explicit in the structure/loss ) , and introducing an asymmetric multi-modal context for the dialog .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is novel and the derived lower bound is tied nicely to the problem , bringing a rare balance of theory and application .",
    "NOVELTY"
  ],
  [
    "I liked the ideas present in the paper .",
    "NOVELTY"
  ],
  [
    "Proposals are a fast moving subfield of computer vision and this paper",
    "NOVELTY"
  ],
  [
    "and the proposed algorithm is also interesting",
    "NOVELTY"
  ],
  [
    "However the idea is an interesting follow up to the previous works [ 1,2 ] ,",
    "NOVELTY"
  ],
  [
    "This is the first contribution of the paper which breaks the glass ceiling of embedding based methods .",
    "NOVELTY"
  ],
  [
    "As far as I know , it seems original that the work focuses on leveraging a flexible metric ( e.g .information geometry ) into probability discrepancies .",
    "NOVELTY"
  ],
  [
    "I have found this work to be quite original and interesting .",
    "NOVELTY"
  ],
  [
    "They use both synthetic and real data for the experiments and compare to state-of-the-art image-based rendering methods of Hedman et al .I think the method discussed in the paper is a nice contribution to the neural rendering area",
    "NOVELTY"
  ],
  [
    "the paper presents , to best of my knowledge , the most universal framework for the acceleration .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel algorithm for black-box optimization .",
    "NOVELTY"
  ],
  [
    "NeuroSAT \u2019 s approach is novel .",
    "NOVELTY"
  ],
  [
    "Overall , the idea is interesting",
    "NOVELTY"
  ],
  [
    "I think the paper presents an interesting idea but I have questions regarding its practical significance as highlighted in my specific comments above",
    "NOVELTY"
  ],
  [
    "Using random nets in texture synthesis and style transfer is novel/original , afaik .",
    "NOVELTY"
  ],
  [
    "Using deep networks in POMDP is not new",
    "NOVELTY"
  ],
  [
    "Thus I believe the originality of the paper lies in the type of loss used and the evaluation of the learned representation trough the construction of a belief over current and previous states",
    "NOVELTY"
  ],
  [
    "So in that context , I am not sure the contributions of this paper are highly significant as they are presented .",
    "NOVELTY"
  ],
  [
    "which is a good contribution",
    "NOVELTY"
  ],
  [
    "novel interpretation of deep residual networks",
    "NOVELTY"
  ],
  [
    "with a novel methodology",
    "NOVELTY"
  ],
  [
    "limited novelty",
    "NOVELTY"
  ],
  [
    "In my opinion , 1. is not much of a contribution since a number of works have already made use of different types of model uncertainty in the context of model-based RL .",
    "NOVELTY"
  ],
  [
    "the formulation of the proposed method is interesting",
    "NOVELTY"
  ],
  [
    "The algorithm is original and",
    "NOVELTY"
  ],
  [
    "sufficient .",
    "NOVELTY"
  ],
  [
    "However , given Cogswell et al . ( 2015 ) or Xiong et al . ( 2016 ) , it seems novelty is somehow incremental",
    "NOVELTY"
  ],
  [
    "The use of a GAN to constrain the possible inputs via a learned measure p ( x|y ) is a nice idea",
    "NOVELTY"
  ],
  [
    "and represents a concrete utility for GANs beyond generating images .",
    "NOVELTY"
  ],
  [
    "The explanation about how the residual block is added to the CNN architecture and used to estimate the perturbation function to the target classifier is very clear and constitutes an interesting novel contribution .",
    "NOVELTY"
  ],
  [
    "This is definitely useful but the novelty does n't open up entirely novel models or algorithms and it is not clear that this can be generalized to other related situations",
    "NOVELTY"
  ],
  [
    "The main novelties are two folds .",
    "NOVELTY"
  ],
  [
    "The method proposed , to the best of my knowledge , is new for the task of GP regression .",
    "NOVELTY"
  ],
  [
    "The submission introduces a training method for GP regres- sion which , to the best of my knowledge , is a new technique .",
    "NOVELTY"
  ],
  [
    "Albeit the paper presents an original and significant theoretical progress and",
    "NOVELTY"
  ],
  [
    "I really like the idea of applying Transfer Learning to AutoML .",
    "NOVELTY"
  ],
  [
    "I 'll start off the review by stating that I find the idea and theoretical justification of separating the non-linear and linear parts of value function estimation to be quite interesting , potentially impacting RL",
    "NOVELTY"
  ],
  [
    "and if it is indeed novel then it can have a lot of impact",
    "NOVELTY"
  ],
  [
    "my feeling it that the proposed neural network has some",
    "NOVELTY"
  ],
  [
    "novelty",
    "NOVELTY"
  ],
  [
    "The proposed architecture includes many components",
    "NOVELTY"
  ],
  [
    "and it\u00e2\u0080\u0099s not clear if they are original or not",
    "NOVELTY"
  ],
  [
    "as indicated by the human evaluation scores ) and the overall novelty of the approach seems to be somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The COMPAS dataset has been studied for fairness-accuracy trade-offs in many other previous works with different learning methods",
    "NOVELTY"
  ],
  [
    "I like this paper as it explores novel and natural ideas .",
    "NOVELTY"
  ],
  [
    "however , the novelty of this work does not seem to be significant as I will elaborate more .",
    "NOVELTY"
  ],
  [
    "So the novelty is limited .",
    "NOVELTY"
  ],
  [
    "and given the limited novelty of the paper",
    "NOVELTY"
  ],
  [
    "interesting discriminative variant of LDA",
    "NOVELTY"
  ],
  [
    "While the proposed ideas are interesting",
    "NOVELTY"
  ],
  [
    "Overall I enjoyed reading this paper , and it is of pretty high quality , and moderately original .",
    "NOVELTY"
  ],
  [
    "This is not too much `` incremental ``",
    "NOVELTY"
  ],
  [
    "Using spectral regularization to improve robustness is not new",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well communicated and a novel idea .",
    "NOVELTY"
  ],
  [
    "I found the task is new and interesting .",
    "NOVELTY"
  ],
  [
    "have been explored in individual methods , but this seems a compelling and novel combination of these methods .",
    "NOVELTY"
  ],
  [
    "The current proposal of using region based loss is both novel and intuitive to me .",
    "NOVELTY"
  ],
  [
    "Unfortunately , the results are rather incremental for the level of NIPS , as the result only holds for random design matrices",
    "NOVELTY"
  ],
  [
    "Unfortunately , the results are rather incremental for the level of NIPS , as the result only holds for random design matrices",
    "NOVELTY"
  ],
  [
    "Although the method is not very novel",
    "NOVELTY"
  ],
  [
    ", there are some interesting architecture innovations",
    "NOVELTY"
  ],
  [
    "which does appear to be a novel combination",
    "NOVELTY"
  ],
  [
    "The use of graphical models combined with RNN inference networks to enable parsing scenes with multiple objects is a nice idea and is likely to be adopted by others if the speed claims are suitably substantiated",
    "NOVELTY"
  ],
  [
    "Therefore , the proposed method is basically a modification or extension of D-Learner , which seems not to be totally novel . In this perspective , this paper is rather incremental than innovative .",
    "NOVELTY"
  ],
  [
    "I am still not totally convinced the novelty of the proposed method .",
    "NOVELTY"
  ],
  [
    "The proposed approach is to my knowledge novel and highly interesting .",
    "NOVELTY"
  ],
  [
    "Overall , this is a highly interesting theoretical paper that proposes a novel ( supervised ) learning approach for graphical models .",
    "NOVELTY"
  ],
  [
    "the contribution of the paper is still not clear to me .",
    "NOVELTY"
  ],
  [
    "I thought that the paper has interesting ideas but seems to be premature to publish at NIPS",
    "NOVELTY"
  ],
  [
    "novelty &",
    "NOVELTY"
  ],
  [
    "The theoretical innovation of this paper is trivial .",
    "NOVELTY"
  ],
  [
    "the same approach to interpreting interactions can provide new insights into domains even beyond recommendation",
    "NOVELTY"
  ],
  [
    "although there is no significant theoretical innovation",
    "NOVELTY"
  ],
  [
    "This is a great idea !",
    "NOVELTY"
  ],
  [
    "This proposed approach of using neural techniques to build partitions of space for fast nearest neighbors is novel .",
    "NOVELTY"
  ],
  [
    "this is the first application of neural techniques as far as I can tell",
    "NOVELTY"
  ],
  [
    "This is not new -- e.g .the benchmarks provided by Andoni and co-authors are evaluated on a QPS basis",
    "NOVELTY"
  ],
  [
    "The approach ,",
    "NOVELTY"
  ],
  [
    "does not seem different from",
    "NOVELTY"
  ],
  [
    "where hyperparameter optimization was considered for",
    "NOVELTY"
  ],
  [
    "for me there does not seem to be any novelty in this approach and the paper itself . The experiments involve synthetic regression and classification datasets but there are no novel insights that advance what is already known about the hyperparameter optimization",
    "NOVELTY"
  ],
  [
    "5 .The model seems to be related to Adaptive Computation Time",
    "NOVELTY"
  ],
  [
    "The idea to apply tensor factorization approaches to the multi-label learning is novel up to my knowledge and is a pro of the paper .",
    "NOVELTY"
  ],
  [
    "and in the present form there is no novelty in the proposed procedure",
    "NOVELTY"
  ],
  [
    "The study of the learned representations in the context of hide and seek is new .",
    "NOVELTY"
  ],
  [
    "both the heuristics used in practice and the adaptive counterparts that the paper uses to replace those heuristics are all available in existing approaches and there is no novel contribution in that direction too .",
    "NOVELTY"
  ],
  [
    "Overall , the paper does not have any novel technical contributions or theoretical analysis on the effect of such inductive biases which makes it very weak .",
    "NOVELTY"
  ],
  [
    "This seems like a major weakening of the paper 's contributions",
    "NOVELTY"
  ],
  [
    "The transfer to novel domain combinations , novel domains , and novel values of dimensions is impressive and surprising .",
    "NOVELTY"
  ],
  [
    "8 .In general , the connection to the cognitive literature is creative and tantalizing",
    "NOVELTY"
  ],
  [
    "Thus the conceptual innovation is rather marginal .",
    "NOVELTY"
  ],
  [
    "The realization seems very similar to a group or block sparse coding implementation",
    "NOVELTY"
  ],
  [
    "this method , this is hardly surprising or novel .",
    "NOVELTY"
  ],
  [
    "Considering the recent advances in the hashing area , the paper has low novelty and",
    "NOVELTY"
  ],
  [
    "I would quite concern about the technical novelty of this proposed work since there have been recently published works that use similar alternating optimization",
    "NOVELTY"
  ],
  [
    "From the model , I could not observe the technical novelty , although the authors focus on the `` Aligner ``",
    "NOVELTY"
  ],
  [
    "It is an interesting idea and an intuitive improvement over ( Gu et al .2017 )",
    "NOVELTY"
  ],
  [
    "This paper does not propose any new attack algorithms .",
    "NOVELTY"
  ],
  [
    "The technical contribute is minimal , the author combine two already existent techniques .",
    "NOVELTY"
  ],
  [
    "As far as I know , the paper presents a novel method for group sparse nonlinear classification with additive models .",
    "NOVELTY"
  ],
  [
    "Truly novel is the update for Keras which allows Riemannian gradient descent on parameters living on manifolds .",
    "NOVELTY"
  ],
  [
    "the software package seems to provide nice functionality with integration into a currently popular machine learning framework",
    "NOVELTY"
  ],
  [
    "but it \u2019 s novelty compared to existing software packages is limited . The novel parts ( performance improvements , integration with keras ) are not sufficiently",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "This work seems rather preliminary in terms of experimentation and using forward modeling as pretraining has already been proposed and applied to video and text classification tasks",
    "NOVELTY"
  ],
  [
    "The proposed change is a small extension to the Neural Transformer model .",
    "NOVELTY"
  ],
  [
    "Rather small , the proposed addition adds little modeling power to the network and its advantage may vanish with more data/different learning rate schedule",
    "NOVELTY"
  ],
  [
    "The ideas of layer-wise sampling and variance reduction are not new ,",
    "NOVELTY"
  ],
  [
    "acceptable",
    "NOVELTY"
  ],
  [
    "Overall the paper has several interesting ideas .",
    "NOVELTY"
  ],
  [
    "I like the idea of defining more plausible solutions to the puzzle of volatililty",
    "NOVELTY"
  ],
  [
    "1 .Lack of novelty .",
    "NOVELTY"
  ],
  [
    "The dense output re-feeding is not something particularly novel",
    "NOVELTY"
  ],
  [
    "The main contributions of this paper are not clear to me , compared with other SOTAs .",
    "NOVELTY"
  ],
  [
    "which to the best of my knowledge is the main published work in the space other than Curve-GCN",
    "NOVELTY"
  ],
  [
    "I find the method interesting .",
    "NOVELTY"
  ],
  [
    "There is no great novelty",
    "NOVELTY"
  ],
  [
    "These results are new as far as I know .",
    "NOVELTY"
  ],
  [
    "Although proof techniques are not so novel from the optimization literature , this type of the convergence result of stochastic EM-algorithm is first in this context except for a few studies",
    "NOVELTY"
  ],
  [
    "I think this paper makes a certain technical contribution to the machine learning community .",
    "NOVELTY"
  ],
  [
    "novel formulation for transductive zero-shot learning",
    "NOVELTY"
  ],
  [
    "Pros -The proposed approach is novel and interesting",
    "NOVELTY"
  ],
  [
    "This is a neat idea and certainly a novel one .",
    "NOVELTY"
  ],
  [
    "I genuinely liked this paper , and I think it presents a very interesting idea that I am sure",
    "NOVELTY"
  ],
  [
    "While this paper certainly presents a \u00e2\u0080\u009ccool\u00e2\u0080\u009d idea",
    "NOVELTY"
  ],
  [
    "1 .Summary This paper presents a novel spatio-temporal attention mechanism .",
    "NOVELTY"
  ],
  [
    "The paper do not present substantial novelty compared to previous work ( see",
    "NOVELTY"
  ],
  [
    "# 2",
    "NOVELTY"
  ],
  [
    "3 .Novelty The main concern of the proposal in this paper is its novelty .",
    "NOVELTY"
  ],
  [
    "I think the technical contribution of the paper is marginal because of the lack of reliable mathematical discussion or",
    "NOVELTY"
  ],
  [
    "I am not sure whether the authors are adding new ingredients to existing algorithms that are already nontrivial on their own",
    "NOVELTY"
  ],
  [
    "Originality This paper has an originality . The invertible recurrent inference machine ( i-RIM ) is a new structure",
    "NOVELTY"
  ],
  [
    "Quality The proposed method i-RIM outperforms all conventional",
    "NOVELTY"
  ],
  [
    "the authors proposed several concepts : a global pooling method using dynamic routing , an attention mechanism , a novel reconstruction loss , interpreting deep node embeddings as spatial positions",
    "NOVELTY"
  ],
  [
    "The qualitative capsule embedding analysis is interesting",
    "NOVELTY"
  ],
  [
    "Small amount of novelty ; primarily an application of established techniques",
    "NOVELTY"
  ],
  [
    "The error bounds proved in the paper are novel .",
    "NOVELTY"
  ],
  [
    "The paper makes a number of contributions .",
    "NOVELTY"
  ],
  [
    "The bits-Back interpretation of VAE is a nice contribution to the community .",
    "NOVELTY"
  ],
  [
    "the formulation of pseudo-count seems novel",
    "NOVELTY"
  ],
  [
    "The stated relationship , though technically sound , does n't seem to relate to existing intrinsic motivation literature .",
    "NOVELTY"
  ],
  [
    "-- The proposed model adopted the idea from predictive coding and came up with a relatively novel idea for HSC problems .",
    "NOVELTY"
  ],
  [
    "it seems that their method doesn \u2019 t really learn anything new in most of the tasks",
    "NOVELTY"
  ],
  [
    "The paper 's adaptive convex combination using learned transformation and mixing networks is interesting and relatively novel .",
    "NOVELTY"
  ],
  [
    "The idea to prune nodes on basis of attention scores they get is novel compared to previous work",
    "NOVELTY"
  ],
  [
    "in my opinion , HMC is a nice idea",
    "NOVELTY"
  ],
  [
    "but I do not understand the huge amount of extensions that can be found in literature",
    "NOVELTY"
  ],
  [
    "I am not sure that the novel proposed technique is really a relevant improvement",
    "NOVELTY"
  ],
  [
    "However , in my opinion , this manuscript lacks any novelty unless ( a few of ) the optimizations to the clarans presented in the manuscript are new . That does not mean that I think this manuscript does not make a significant contribution .",
    "NOVELTY"
  ],
  [
    "As far as I can tell the approach presented in this paper is original .",
    "NOVELTY"
  ],
  [
    "But it is considerably novel in incorporating this idea in an end-to-end deep network .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "I think this paper introduces a novel and interesting idea that is likely to spark future experimentation towards multi-modal early-fusion methods .",
    "NOVELTY"
  ],
  [
    "The paper presents only a new \u201c interpretation \u201d of the Hadamard product which has previously been widely used for pooling , including for VQA .",
    "NOVELTY"
  ],
  [
    "the theoretical construction given is interesting and hence I believe this paper should be accepted",
    "NOVELTY"
  ],
  [
    "CONS Quite unpolished / not enough contributions for a finished paper .",
    "NOVELTY"
  ],
  [
    "The paper contains nice ideas",
    "NOVELTY"
  ],
  [
    "but in my opinion it does not contribute sufficiently many results for a Conference paper .",
    "NOVELTY"
  ],
  [
    "and the proof technique seems to be novel",
    "NOVELTY"
  ],
  [
    "but it 's novelty and scope too small",
    "NOVELTY"
  ],
  [
    "However , this paper lacks academic novelty and originality in that the proposed method solely combined existing works .",
    "NOVELTY"
  ],
  [
    "I feel that this work is largely incremental",
    "NOVELTY"
  ],
  [
    "the idea of smoothing gradients is not new Evaluation",
    "NOVELTY"
  ],
  [
    "as a non expert in the field , I am not completely convinced by the novelty of the",
    "NOVELTY"
  ],
  [
    "The novelty might be limited , as it does not propose a brand new architecture or method .",
    "NOVELTY"
  ],
  [
    "the base of the formulation is not particularly novel",
    "NOVELTY"
  ],
  [
    "the use of a custom objective for screening orientations for each voxel by greedy selection is an original contribution that seems crucial for achieving plausible",
    "NOVELTY"
  ],
  [
    "paper proposes a new model for opinion-dynamics in social networks",
    "NOVELTY"
  ],
  [
    "the proposed model has some unique properties that makes it interesting compared to classical models for opinion-dynamics . While I really enjoyed the technical contributions of the paper",
    "NOVELTY"
  ],
  [
    "I feel the experiments do n't do justice to the paper .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper is well-written with significant technical contributions .",
    "NOVELTY"
  ],
  [
    "and the contribution is relevant to ICLR",
    "NOVELTY"
  ],
  [
    "Using attention mechanisms to improve the model robustness in an adversarial training setting is a strong and novel contribution - Both quantitative and qualitative results are interesting .",
    "NOVELTY"
  ],
  [
    "Otherwise , the contribution seems rather limited",
    "NOVELTY"
  ],
  [
    "I think overall the contribution of the paper is rather limited .",
    "NOVELTY"
  ],
  [
    "and it appears that overall there are bold claims made in the paper but it lacks significant scientific contribution",
    "NOVELTY"
  ],
  [
    "that makes the overall contribution and novelty of the paper rather limited",
    "NOVELTY"
  ],
  [
    "While it does not achieve state-of-the-art performance , it advances an interesting class of models",
    "NOVELTY"
  ],
  [
    "The proposed model outperforms the previous models .",
    "NOVELTY"
  ],
  [
    "The overall idea of the algorithm is sufficiently novel .",
    "NOVELTY"
  ],
  [
    "Each piece of the algorithm seems to draw heavily on previous work ; bi-clustering , diffusion maps , but overall",
    "NOVELTY"
  ],
  [
    "the idea is novel enough",
    "NOVELTY"
  ],
  [
    "The energy formulations for U\u03b8 , namely an autoencoder and Gibbs model , are not to my knowledge new in this context .",
    "NOVELTY"
  ],
  [
    "The manuscript presents an original and important extension of Noise2Noise .",
    "NOVELTY"
  ],
  [
    "Considering that the paper introduces an original , highly significant extension to Noise2Noise and validates the approach via sufficient experiments",
    "NOVELTY"
  ],
  [
    "Originality The unified interpretation of the different optimization algorithms in one ODE formulation is nice to see .",
    "NOVELTY"
  ],
  [
    "The idea of post-processing word embeddings to improve their performance is not new",
    "NOVELTY"
  ],
  [
    "but I believe the specific procedure and its connection to the concept of isotropy has not been investigated previously",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "with nothing new in the methodology",
    "NOVELTY"
  ],
  [
    "importance sampling over a novel simulation and model",
    "NOVELTY"
  ],
  [
    "I believe the convergence results could be a significant contribution",
    "NOVELTY"
  ],
  [
    "This is a promising idea .",
    "NOVELTY"
  ],
  [
    "The problem of multimodal learning is an interesting and challenging problem - The paper is novel",
    "NOVELTY"
  ],
  [
    "while the idea of a joint shared embedding space is not new this paper adds new losses as summarized above and shows reasonably convincing empirical results",
    "NOVELTY"
  ],
  [
    "Overall the paper is well written and had novel aspects which are convincingly evaluated on challenging and diverse tasks .",
    "NOVELTY"
  ],
  [
    "But otherwise the novelty is limited as the same meta-learning pipeline proposed for few-shot in MAML",
    "NOVELTY"
  ],
  [
    "I find the technical novelty of this work very limited .",
    "NOVELTY"
  ],
  [
    "but using GAN to sequential model itself is not a novel techniques [ 2 ] .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the improvements in terms of BLEU are relatively small , and the technical contributions seem quite thin to me for a ML conference .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is a novel contribution and raises a few interesting questions and ideas about future work in this area .",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge , the two surrogate functions are original .",
    "NOVELTY"
  ],
  [
    "Novel , intuitive , and simple method building on",
    "NOVELTY"
  ],
  [
    "This seems like a relatively straight-forward combination of ideas , reducing the novelty of contribution .",
    "NOVELTY"
  ],
  [
    "but without a substantial amount of novelty due to the combination of existing methods or theoretical guarantees",
    "NOVELTY"
  ],
  [
    "The computation of the upper confidence part is interesting and deviates from the standard proofs for Multi-arm bandit cases because the samples in case of LSTD are not independent of each other",
    "NOVELTY"
  ],
  [
    "The derivation is novel through relatively straight forward ,",
    "NOVELTY"
  ],
  [
    "Overall , I believe that the paper makes an interesting contribution and should be accepted for publication",
    "NOVELTY"
  ],
  [
    "I really like the basic premise of the paper .",
    "NOVELTY"
  ],
  [
    "But overall , I think this is sufficiently novel that I am supportive .",
    "NOVELTY"
  ],
  [
    "I found the descriptions of the issues on page 1 and 2",
    "NOVELTY"
  ],
  [
    "The algorithms proposed in the paper are very interesting and innovative , and the ideas are original .",
    "NOVELTY"
  ],
  [
    "This is the most important and novel contribution of the paper .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "and makes strong contributions to the fairness in ranking field .",
    "NOVELTY"
  ],
  [
    "and while it 's been used in the context of reinforcement learning , it has n't been popularized as a regularizer for improving generalization in supervised learning",
    "NOVELTY"
  ],
  [
    "the idea of representing clusters by prototypes and subspace feature indicators is not new and must have been explored by works on K-means .",
    "NOVELTY"
  ],
  [
    "The improvement of the proposed method seems to be very marginal compared to ALI",
    "NOVELTY"
  ],
  [
    "Overall , the paper provides novel bounds on the step length necessary to converge to a certain subset of stationary points .",
    "NOVELTY"
  ],
  [
    "This is the part of the paper that I would consider most novel and interesting",
    "NOVELTY"
  ],
  [
    "The presented ideas are interesting and could potentially inspire other works in this field .",
    "NOVELTY"
  ],
  [
    "Overall there is not a great deal of novelty other than",
    "NOVELTY"
  ],
  [
    "time .",
    "NOVELTY"
  ],
  [
    "I 'm not convinced that the usage of Sequitur to build the macro-actions is sufficient to declare this work novel wrt .",
    "NOVELTY"
  ],
  [
    "The proposed normalization method is new",
    "NOVELTY"
  ],
  [
    ", although it mimic the process of Kalman filter and has similar idea as ResNet",
    "NOVELTY"
  ],
  [
    "But overall , the contributions in this paper are significant .",
    "NOVELTY"
  ],
  [
    "Thus the contributions of the paper are not substantial .",
    "NOVELTY"
  ],
  [
    "If so , the novelty of the proposed method is limited .",
    "NOVELTY"
  ],
  [
    "this kind of character level modelling has been used in many previous works",
    "NOVELTY"
  ],
  [
    "and the proposed idea is interesting .",
    "NOVELTY"
  ],
  [
    "The contribution of the proposed method is not clear to me .",
    "NOVELTY"
  ],
  [
    "The idea of using a binary classifier for a two-sample testing is not new ,",
    "NOVELTY"
  ],
  [
    ", principled and very performant solution",
    "NOVELTY"
  ],
  [
    "While the proposed technique consists of previously known building blocks ( spectral Stein gradient estimator and random projections ) , it is cleverly applied in a novel context of estimating MI gradients .",
    "NOVELTY"
  ],
  [
    "a .About the algorithm The idea of incorporating a GAN based model to regularize the representation learning is not completely novel .",
    "NOVELTY"
  ],
  [
    "Causal misidentification is a very relevant and novel problem as current learning methods often fail due to distributional shift .",
    "NOVELTY"
  ],
  [
    "The problem of causal misidentification is novel and interesting .",
    "NOVELTY"
  ],
  [
    "This weakens a possible theoretical contribution of the paper . *Originality* The proposed modification appears to amount to a regularizer for bi-LSTMs which bears close similarity to Z-Forcing",
    "NOVELTY"
  ],
  [
    "and the originality of this paper is hard to evaluate",
    "NOVELTY"
  ],
  [
    "ORIGINALITY To my knowledge , the methods presented in the paper have not been considered before .",
    "NOVELTY"
  ],
  [
    "combining SPG and RAML by introducing their respective regularization terms is a rather straightforward exercise , and so seems quite incremental .",
    "NOVELTY"
  ],
  [
    "the contribution over RAML and SPG in combining them is quite incremental",
    "NOVELTY"
  ],
  [
    "generalization of RAML and SPG is straightforward , incremental .",
    "NOVELTY"
  ],
  [
    "and the reductions to RAML and SPG are straightforward by design , and so do not really provide much new insight .",
    "NOVELTY"
  ],
  [
    "Overall , the trojan horse attacking scenario considered in this paper is novel and provides new insights to the research in adversarial machine learning .",
    "NOVELTY"
  ],
  [
    "I actually quite like the idea and believe the threat model is valid if addressed fin a clearer manner",
    "NOVELTY"
  ],
  [
    "I like the idea of learning basis vectors from the representations and constraining to follow the primitive semantics .",
    "NOVELTY"
  ],
  [
    "The idea seems original and well executed",
    "NOVELTY"
  ],
  [
    "I found this paper very interesting .",
    "NOVELTY"
  ],
  [
    "but to my knowledge this is the first package that I 've seen which put more focus on compositional inference",
    "NOVELTY"
  ],
  [
    "But , to the best of my judgement , this paper has an interesting idea but is not yet ready to be published in ICLR",
    "NOVELTY"
  ],
  [
    "The paper is a first attempt to solve a very challenging problem , where a robot is taught real-world tasks with very few visual demonstrations and without further retraining",
    "NOVELTY"
  ],
  [
    "In terms of `` core CS , `` the contribution here is not huge .",
    "NOVELTY"
  ],
  [
    "The proposed method is very similar to the APN method and so its novelty is limited .",
    "NOVELTY"
  ],
  [
    "They are derived in an ad-hoc way based on less theoretical background and thus lack novelty .",
    "NOVELTY"
  ],
  [
    "The regularization by Gini impurity is a well-known technique to induce sparsity , lacking novelty",
    "NOVELTY"
  ],
  [
    "sets Weakness -- the novelty of the proposed method is marginal -- Some real-case study on why the model works are not presented",
    "NOVELTY"
  ],
  [
    "I feel the novelty of the proposed method is marginal .",
    "NOVELTY"
  ],
  [
    "The proposed method for unsupervised domain adaptation is very similar to the prototypical networks approach in [ 3 ] , with the primary difference being a loss term incentivizing a Gaussian mixture distribution over features",
    "NOVELTY"
  ],
  [
    "Overall , the idea is good",
    "NOVELTY"
  ],
  [
    "Originality To my knowledge the method proposed in this work is novel .",
    "NOVELTY"
  ],
  [
    "This approach appears interesting .",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are moderately novel proposing mainly the attention mechanism and the convolutional re-encoding",
    "NOVELTY"
  ],
  [
    "and the approach proposed is original and supported by theoretical results",
    "NOVELTY"
  ],
  [
    "The contribution of algorithm 1 is not significant .",
    "NOVELTY"
  ],
  [
    "This is an important advance in the generative memory models",
    "NOVELTY"
  ],
  [
    "some of the ideas are interesting and seem creative",
    "NOVELTY"
  ],
  [
    "not insightful",
    "NOVELTY"
  ],
  [
    "in some parts the authors exaggerate the contribution and do not well connect with prior art",
    "NOVELTY"
  ],
  [
    "While parts of the paper in isolation",
    "NOVELTY"
  ],
  [
    "would be incremental",
    "NOVELTY"
  ],
  [
    ", in total the paper is original and provides several new insights .",
    "NOVELTY"
  ],
  [
    "but overall the novelty is fairly limited",
    "NOVELTY"
  ],
  [
    "This work extends the recent word-movers distance , which is an interesting",
    "NOVELTY"
  ],
  [
    "In other words , the main technical contributions of this paper do not seem to contribute very much over this initialisation method based on existing techniques .",
    "NOVELTY"
  ],
  [
    "o The originality is mostly related to the way to optimise the metric",
    "NOVELTY"
  ],
  [
    "the idea of a linear metric learning within the earth-movers distance is very interesting but a limited contribution in itself .",
    "NOVELTY"
  ],
  [
    "Originality The model proposed here is , to the best of my knowledge , novel in this context .",
    "NOVELTY"
  ],
  [
    "The idea of using IRL to learn generalizable reward functions to learn policies so as to aid transfer between environments in such vision-language navigation tasks is interesting and clearly shows benefits to behavior cloning .",
    "NOVELTY"
  ],
  [
    "Using multiple generators for GAN training has been proposed in many previous work that are cited in the paper",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "that presents several potential applications of a simple , good idea .",
    "NOVELTY"
  ],
  [
    "Theorem1 and its proof are not very new .",
    "NOVELTY"
  ],
  [
    "The paper combines variational auto-encoder training with adversarial training in a novel way .",
    "NOVELTY"
  ],
  [
    "I consider the proposed method as novel",
    "NOVELTY"
  ],
  [
    "I am not convinced that the proposed method is one of the best methods among all these existing methods .",
    "NOVELTY"
  ],
  [
    "which I found quite insightful",
    "NOVELTY"
  ],
  [
    "but I think its contribution is on the small side for a conference paper .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "combine prolog with neural models , and the weak unification notion . The approach seems sufficiently novel ,",
    "NOVELTY"
  ],
  [
    "I am not sure if the novelty of this paper is suitable for NeurIPS . It is an incremental improvement to an existing model ( TDM ) by doing an additional optimization step .",
    "NOVELTY"
  ],
  [
    "The task is novel and methodology uses existing work on computing attribution maps using Taylor series approximation to compute ambiguity maps . The use and analysis of the effects of hardness scores are interesting",
    "NOVELTY"
  ],
  [
    "I like the idea of using a visual illusion because it explains the task",
    "NOVELTY"
  ],
  [
    "As such , it may seem only incremental",
    "NOVELTY"
  ],
  [
    "I found the notion of similarity preserving transformations interesting , as well the posited learning rules .",
    "NOVELTY"
  ],
  [
    "I would classify this work as original , and possibly significant .",
    "NOVELTY"
  ],
  [
    "The idea is really interesting .",
    "NOVELTY"
  ],
  [
    "The extension to other types of label noise is also very intuitive",
    "NOVELTY"
  ],
  [
    "As such , I found the contributions of this paper to be novel and believe the results will be of interest to practitioners and theorists alike .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the algorithm presented is original",
    "NOVELTY"
  ],
  [
    "and a natural idea",
    "NOVELTY"
  ],
  [
    "The formulation of the P-BN seems to be closely related to ResNet",
    "NOVELTY"
  ],
  [
    "While the specifics are somewhat incremental , I think this is a great idea ,",
    "NOVELTY"
  ],
  [
    "Augmenting agent state with state of DFA tracking action sequence constraints is novel and useful for this problem Cons",
    "NOVELTY"
  ],
  [
    "I think the method has its fundamental flew and the paper offers very limited novelty .",
    "NOVELTY"
  ],
  [
    "drawbacks of the",
    "NOVELTY"
  ],
  [
    "There is not much technical contribution .",
    "NOVELTY"
  ],
  [
    "and the paper makes a clear contribution",
    "NOVELTY"
  ],
  [
    "This paper is n't especially novel .",
    "NOVELTY"
  ],
  [
    "very elegant",
    "NOVELTY"
  ],
  [
    "Overall , I really like the idea of this paper and believe that this paper should be accepted .",
    "NOVELTY"
  ],
  [
    "there are dozens of literature on meta-learning learning rate and the proposed approach does not seem to be novel",
    "NOVELTY"
  ],
  [
    "My only concern is that the contribution seems a bit incremental .",
    "NOVELTY"
  ],
  [
    "The introduction of spatial basis is interesting",
    "NOVELTY"
  ],
  [
    "but is not completely new either .",
    "NOVELTY"
  ],
  [
    "I still think the idea and experiments are quite interesting and there are enough new thoughts to benefit future research",
    "NOVELTY"
  ],
  [
    "even though the speed-up of training is the most important and unique contribution of SNIPER",
    "NOVELTY"
  ],
  [
    "Its originality is quite limited .",
    "NOVELTY"
  ],
  [
    "3 .Originality The originality of SNIPER seems quite limited since it is an extension of SNIP [ 24 ] .",
    "NOVELTY"
  ],
  [
    ", but is implemented by a set of simple practical techniques",
    "NOVELTY"
  ],
  [
    "This is an extension of SNIP [ 24 ] , and focuses mostly on speed-up . Thus its novelty is significantly limited .",
    "NOVELTY"
  ],
  [
    "On the whole , I think the idea presented is clever and novel .",
    "NOVELTY"
  ],
  [
    "The idea of using likelihood ratio ( LLR ) with respect to a background distribution to detect OOD is novel",
    "NOVELTY"
  ],
  [
    "The weakness of this paper is that there is no technical innovation",
    "NOVELTY"
  ],
  [
    "However , the empirical contributions are quite limited , since the authors only use one very",
    "NOVELTY"
  ],
  [
    "The techniques seem to be build upon polynomial-approximation based techniques provided in [ 25 ]",
    "NOVELTY"
  ],
  [
    "The idea is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "the only question is whether or not it contains enough novelty ,",
    "NOVELTY"
  ],
  [
    "Significance I think this paper constitutes a nice addition to the literature on graph Gaussian processes",
    "NOVELTY"
  ],
  [
    "While not groundbreaking novel",
    "NOVELTY"
  ],
  [
    "The idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "the problem is a little far from real world cases , which limits the contribution of the paper",
    "NOVELTY"
  ],
  [
    "attractive",
    "NOVELTY"
  ],
  [
    "Technically the contribution is not significant .",
    "NOVELTY"
  ],
  [
    "I think the contribution of the paper is a bit limited .",
    "NOVELTY"
  ],
  [
    "Novelty over [ 8,10 ] is limited .",
    "NOVELTY"
  ],
  [
    "those are sufficient advances for the paper to add to our knowledge of keypoint detection and description",
    "NOVELTY"
  ],
  [
    "NOVELTY The novelty is limited on both the methodological and theoretical contributions .",
    "NOVELTY"
  ],
  [
    "I think the improvement is not incremental",
    "NOVELTY"
  ],
  [
    "The main weakness is that none of the proposed methods are entirely original ,",
    "NOVELTY"
  ],
  [
    "The authors admit that gradual quantization has been proposed before , and clamping a ReLU is also not new",
    "NOVELTY"
  ],
  [
    "C1 .The novelty of the paper is rather limited , both in terms of the convergence analysis and exploiting the low-rank structure in tensor trains .",
    "NOVELTY"
  ],
  [
    "Section 3 is also not novel to the paper .",
    "NOVELTY"
  ],
  [
    "The proposed model is not exceptionally novel from a technical perspective .",
    "NOVELTY"
  ],
  [
    "the paper has somewhat weak technical contribution",
    "NOVELTY"
  ],
  [
    "the contribution of this paper is limited",
    "NOVELTY"
  ],
  [
    "The empirical study has moderate originality since the techniques have been used elsewhere in the literature . The finite sample bounds are interesting and look original to me .",
    "NOVELTY"
  ],
  [
    "The problem formulation is not new and can be found in [ 7 ] .",
    "NOVELTY"
  ],
  [
    "this submission provides the first ( as far as I know ) generalization error guarantee",
    "NOVELTY"
  ],
  [
    "The derivation of the second generalization error bound in Section 4 is sufficiently novel and interesting to me .",
    "NOVELTY"
  ],
  [
    "My main concern is about the novelty of the approach which looks mostly incremental as a rather direct extension of the robust model ( Wong & Kolter 2018 ) to cost-sensitive setting .",
    "NOVELTY"
  ],
  [
    "The novelty of method is mostly incremental given the prior work of ( Wong & Kolter 2018 ) .",
    "NOVELTY"
  ],
  [
    "The problem is new ( to Deep RL ) and interesting .",
    "NOVELTY"
  ],
  [
    "existing approaches",
    "NOVELTY"
  ],
  [
    "The idea of bounding multilinear extension by a concave function for coverage functions is already introduced in [ 1",
    "NOVELTY"
  ],
  [
    "Considering these points and the fact that the result is only for a subclass of submodular functions with a matroid constraint , I find the contribution of this paper somewhat marginal",
    "NOVELTY"
  ],
  [
    "the paper contribution and the novelty are limited giving the fact that there is another related paper published",
    "NOVELTY"
  ],
  [
    "New formulation of SPNs + New inference algorithm Cons",
    "NOVELTY"
  ],
  [
    "The idea is great",
    "NOVELTY"
  ],
  [
    "as far as I am concerned this work makes a contribution but is insufficient .",
    "NOVELTY"
  ],
  [
    "and proposes an insightful metric",
    "NOVELTY"
  ],
  [
    "However , the submission seems to have limited novelty , based on which I am leaning towards rejecting the paper .",
    "NOVELTY"
  ],
  [
    "The novelty of the `` Coherent Gradients hypothesis `` is not clear to me .",
    "NOVELTY"
  ],
  [
    "I enjoyed reading the paper because the idea",
    "NOVELTY"
  ],
  [
    "-- The use of randomly sampled learning rate for deep learning models is novel and easy to implement .",
    "NOVELTY"
  ],
  [
    "The contributions are incrementally building upon previous work , but",
    "NOVELTY"
  ],
  [
    "the novelty of the chosen approach ( encoder-decoder network plus spatial transformer network , in combination with the projection loss function ) is conveyed",
    "NOVELTY"
  ],
  [
    "Novelty is not really the aim of this paper since it mostly investigates existing architectures .",
    "NOVELTY"
  ],
  [
    "To use the mutual information to obtain bits per parameter scores in highly non-linear parameterized functions is new to me .",
    "NOVELTY"
  ],
  [
    "I \u2019 d argue that the paper is original enough for that reason alone .",
    "NOVELTY"
  ],
  [
    "The paper provides some interesting new insights into the properties of RNNs .",
    "NOVELTY"
  ],
  [
    "The way of quantifying capacity in neural networks adds to the novelty of the paper .",
    "NOVELTY"
  ],
  [
    "The overall idea is similar to the semi-supervised learning method co-training",
    "NOVELTY"
  ],
  [
    ", as it has no real technical content or contribution .",
    "NOVELTY"
  ],
  [
    "This is a really clever idea .",
    "NOVELTY"
  ],
  [
    "There are many contributions to this work .",
    "NOVELTY"
  ],
  [
    "I lean to vote for accepting this paper since the idea is simple but novel",
    "NOVELTY"
  ],
  [
    "The idea itself is simple and novel .",
    "NOVELTY"
  ],
  [
    "and it is also very novel",
    "NOVELTY"
  ],
  [
    "The proposed framework for unsupervised object segmentation is novel and its the first work using generative models to demonstrate unsupervised segmentation on real world datasets .",
    "NOVELTY"
  ],
  [
    "it is not entirely clear what theoretical results are novel",
    "NOVELTY"
  ],
  [
    "Compared with them , the theoretical contribution of this work seems less significant .",
    "NOVELTY"
  ],
  [
    "Technical novelty is limited .",
    "NOVELTY"
  ],
  [
    "The contributions are to my knowledge both novel and significant .",
    "NOVELTY"
  ],
  [
    "Overall , it is a strong paper with novel theoretical contributions and",
    "NOVELTY"
  ],
  [
    "they theoretical analysis is still valid and novel enough",
    "NOVELTY"
  ],
  [
    "The ideas look interesting , even though they are mostly small modification of the previous",
    "NOVELTY"
  ],
  [
    "works",
    "NOVELTY"
  ],
  [
    "and it is a very insightful sketch",
    "NOVELTY"
  ],
  [
    "This paper is extremely interesting and quite surprising .",
    "NOVELTY"
  ],
  [
    "I like the main idea and then everything leading to the algorithm .",
    "NOVELTY"
  ],
  [
    "Although the application is different , the key insight of using weights that are directly optimized is similar to Zubizarreta 's work .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "A nice interpretation of CycleGAN with OT",
    "NOVELTY"
  ],
  [
    "Overall the quantity of novelties is , in the eyes of the reviewer , somehow limited .",
    "NOVELTY"
  ],
  [
    "The work is original and is references the relevant literature .",
    "NOVELTY"
  ],
  [
    "While the paper does a good combination of existing techniques",
    "NOVELTY"
  ],
  [
    "it is difficult for me to assess the level of novelty of the ideas proposed in the work proposed in this paper .",
    "NOVELTY"
  ],
  [
    "Overall , I think it is a very nice contribution ,",
    "NOVELTY"
  ],
  [
    "I think this is a nice and solid work but just not has much novelty",
    "NOVELTY"
  ],
  [
    "is incremental",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is not enough to justify its acceptance at the conference .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "The originality of the concatenation of several frames is somewhat limited",
    "NOVELTY"
  ],
  [
    "Making features invariant to attributes to improve generalization is not a new idea",
    "NOVELTY"
  ],
  [
    "The novelty of the approach is a bit limited since",
    "NOVELTY"
  ],
  [
    "but the core of the paper is a bit incremental .",
    "NOVELTY"
  ],
  [
    "Deriving DINGO from he optimization of the gradient norm is interesting",
    "NOVELTY"
  ],
  [
    "The theoretical study of instance shrinkage in pegasos is as far as I know novel and interesting .",
    "NOVELTY"
  ],
  [
    "Originality The work seems original .",
    "NOVELTY"
  ],
  [
    "The idea of incorporating passing gradients among tasks seems very interesting , which is new as far as I am aware of .",
    "NOVELTY"
  ],
  [
    "The system framework for MTL introduced by the authors seem to be kind of isolated to the method proposed .",
    "NOVELTY"
  ],
  [
    "The proposed is overall novel , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "While the proposed method does not appear groundbreakingly novel",
    "NOVELTY"
  ],
  [
    "The ideas of grouped graphical model estimation and using Bayesian methods in this area are not new .",
    "NOVELTY"
  ],
  [
    "The specific estimator the authors propose and their analysis of it seem to be new .",
    "NOVELTY"
  ],
  [
    "but the authors seem to have provided a good theoretical contribution over other work in the area .",
    "NOVELTY"
  ],
  [
    "the current work outperforms related prior work through the use of the new regularization technique",
    "NOVELTY"
  ],
  [
    "Although this research is not a large departure from prior work",
    "NOVELTY"
  ],
  [
    "This is a paper presenting a significantly useful and novel technique , and",
    "NOVELTY"
  ],
  [
    "Major comments To the best of my knowledge , this is the first paper to apply attention to the learning to rank problem .",
    "NOVELTY"
  ],
  [
    "I believe the proposed idea of reweighing is interesting",
    "NOVELTY"
  ],
  [
    "As for the technical content , I find the contribution in terms of new proof techniques quite marginal .",
    "NOVELTY"
  ],
  [
    "The connection between these two separate auxiliary variable Monte Carlo methods is interesting",
    "NOVELTY"
  ],
  [
    "This is a simple idea and has been considered before in literature",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed approach is new Cons",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the distributional optimistic approach to approximating the likelihood function , based on constructing an uncertainly set and picking the most likely distribution in this set , is a novel and interesting idea . The idea borrows from the robust optimization community as well as the principle of optimism under uncertainty and is intuitively appealing",
    "NOVELTY"
  ],
  [
    "paper proposes a novel and well performing method to boost the performance of ME and SCF tests",
    "NOVELTY"
  ],
  [
    "I 'm pleased to see the authors not only proposing a new instance of a solution",
    "NOVELTY"
  ],
  [
    "The novelty in this paper comes from the problem setup which I have not seen treated before",
    "NOVELTY"
  ],
  [
    "The loss function they propose also appears original .",
    "NOVELTY"
  ],
  [
    "Strength The authors provided a relatively new perspective on how the model should be robust to the minor changes of the input variable values .",
    "NOVELTY"
  ],
  [
    "I am not convinced that this work contains some original idea and has any kind of significance to the supervise learning community .",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea of being able to take advantage of non-linear relationships between tasks .",
    "NOVELTY"
  ],
  [
    "have given a novel and expressive manner to learn covariance functions for Gaussian processes",
    "NOVELTY"
  ],
  [
    "In a sense , supervising attention in such way was already suggested in [ Bordes and Weston 2015 ] , the novelty seems very limited to me while the analysis provided by this work might be useful as an interesting starting point for further analysis and propositions in this domain",
    "NOVELTY"
  ],
  [
    "The proposed approach seems novel and relevant .",
    "NOVELTY"
  ],
  [
    "and the idea is original .",
    "NOVELTY"
  ],
  [
    "Perhaps more importantly , the paper has no novelty .",
    "NOVELTY"
  ],
  [
    "The implementation is not state-of-the-art , and there is no novelty in this work .",
    "NOVELTY"
  ],
  [
    "The authors also propose that using batch norm inside of Fast RCNN is an innovation .",
    "NOVELTY"
  ],
  [
    "The paper makes a solid theoretical contribution .",
    "NOVELTY"
  ],
  [
    "There is no particular theoretical or algorithmic novelty in the paper",
    "NOVELTY"
  ],
  [
    "It seems to me that the submitted paper is very similar to ref [ a ] ( see questions below ) that already proposed to tackle similar types of problems in the context of multi-modal data",
    "NOVELTY"
  ],
  [
    "If this the case , then the contribution of the paper seems limited to me .",
    "NOVELTY"
  ],
  [
    "The model described in Section 2 is very similar to the approach described in ref",
    "NOVELTY"
  ],
  [
    "The idea of randomly combining Q networks is interesting and paper is well written to demonstrate their key ideas .",
    "NOVELTY"
  ],
  [
    "My biggest concern is that this paper seems to be very similar to Du & Hu ( 2019 ) in many places .",
    "NOVELTY"
  ],
  [
    "The contribution in this paper is too incremental given previous work .",
    "NOVELTY"
  ],
  [
    "2 .A general way to transform any pixel-attack algorithm to its \u201c semantic version \u201d is novel .",
    "NOVELTY"
  ],
  [
    "I really like the idea of studying the impact of the depth in the training dynamics .",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "I think this paper should be accepted because it makes several interesting contributions",
    "NOVELTY"
  ],
  [
    "It appears to me that the contribution of the work is pretty solid",
    "NOVELTY"
  ],
  [
    "Originality As far as I am aware , this work is the first to combine work from the disentangling literature with the SHAP method for interpretability .",
    "NOVELTY"
  ],
  [
    "One could contend that disentangling is essentially clustering and that feature selection ( which is what SHAP does ) on top of clustering is not novel",
    "NOVELTY"
  ],
  [
    "but not novel as such",
    "NOVELTY"
  ],
  [
    "I would tend to reject the paper because I do not fully understand where is where is the main novelty",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "The main flaw would be the lack of originality of the proposed goal-driven web navigation task , since it is almost indistinguishable from the task proposed by West et al and referenced in the present paper .",
    "NOVELTY"
  ],
  [
    "since the architectures are not novel nor sophisticated",
    "NOVELTY"
  ],
  [
    "I like the main ideas in this paper although some more empirical elbow grease is in order",
    "NOVELTY"
  ],
  [
    "The idea of estimating wind speed from imagery ( video ) is novel to my knowledge , and in my opinion is the main contribution of the paper .",
    "NOVELTY"
  ],
  [
    "There is nothing novel about the model",
    "NOVELTY"
  ],
  [
    "This work is a novel combination of two well-known models , namely BiGAN and BigGAN .",
    "NOVELTY"
  ],
  [
    "There are no theoretical contributions .",
    "NOVELTY"
  ],
  [
    "the work remains a significant contribution as the investigation is exemplary",
    "NOVELTY"
  ],
  [
    "I can not see any significant contribution of the proposed methods compared with existing approaches .",
    "NOVELTY"
  ],
  [
    "The proposed idea",
    "NOVELTY"
  ],
  [
    "I think this contribution is not very significant .",
    "NOVELTY"
  ],
  [
    "The interplay between batch normalization and the behavior of Fisher information is interesting .",
    "NOVELTY"
  ],
  [
    "The implementation of the architecture is similar to R2P2",
    "NOVELTY"
  ],
  [
    "proposed metrics",
    "NOVELTY"
  ],
  [
    "intuitive",
    "NOVELTY"
  ],
  [
    "Nevertheless , the idea and introduction of particle gradient decent and optimization on measure is quite interesting , and innovative .",
    "NOVELTY"
  ],
  [
    "I believe it would make a nice contribution to NeurIPS .",
    "NOVELTY"
  ],
  [
    "Surprisingly , and to the extend of my knowledge , this distribution has not been previously proposed in the literature .",
    "NOVELTY"
  ],
  [
    "they propose a simple approach to a prevalent problem in the previous literature and has a significant novelty by introducing a distribution that despite its simplicity , and to the extend of my knowledge , has not been proposed before .",
    "NOVELTY"
  ],
  [
    "While this idea has been explored in prior work ( as noted in the related work section ) , the proposed idea seems like a useful contribution to the literature .",
    "NOVELTY"
  ],
  [
    "This is a very interesting and thought provoking body of work and I am in complete accord with the observations and conclusions of the paper",
    "NOVELTY"
  ],
  [
    "It 's a very nuanced and not insightful construction",
    "NOVELTY"
  ],
  [
    "I find the contribution of this work to be a bit limited .",
    "NOVELTY"
  ],
  [
    "In general , the paper contains interesting ideas and results .",
    "NOVELTY"
  ],
  [
    "The idea of using the \\xi transformation for the lower bound of the sigmoid was interesting to me -- since I have not seen it before",
    "NOVELTY"
  ],
  [
    "albeit I would say its a bit weak on novelty",
    "NOVELTY"
  ],
  [
    "it is hard to measure the novelty of the paper ( originality )",
    "NOVELTY"
  ],
  [
    "and as a result I do not consider it to make a scientific contribution",
    "NOVELTY"
  ],
  [
    "The contribution is incremental , but important .",
    "NOVELTY"
  ],
  [
    "The methodological contribution is strong",
    "NOVELTY"
  ],
  [
    "the approach is novel and interesting",
    "NOVELTY"
  ],
  [
    "Interesting work , unusual approach to recommendation systems .",
    "NOVELTY"
  ],
  [
    "-- the novelty of the proposed is marginal",
    "NOVELTY"
  ],
  [
    "However , the novelty of the proposed technique seems to be marginal to me .",
    "NOVELTY"
  ],
  [
    "and the",
    "NOVELTY"
  ],
  [
    "I did not fully understand the paper",
    "NOVELTY"
  ],
  [
    "but thought that the insights and model itself were a very interesting , and potentially useful , take on the design of crowdsourcing aggregation techniques .",
    "NOVELTY"
  ],
  [
    "the proposed method lacks novelty and has not been well evaluated comparing with other representation",
    "NOVELTY"
  ],
  [
    "I admit the proposed \\log p ( y|z ) is novel",
    "NOVELTY"
  ],
  [
    "there\u00e2\u0080\u0099s no novel mathematical proved in this paper .",
    "NOVELTY"
  ],
  [
    "Thus , the analysis is incremental .",
    "NOVELTY"
  ],
  [
    "But the technical novelty is somewhat limited .",
    "NOVELTY"
  ],
  [
    "Incorporating DCRF into depth and normal estimation is also not new .",
    "NOVELTY"
  ],
  [
    "But I do not think the technical novelty is significant enough for a NIPS paper .",
    "NOVELTY"
  ],
  [
    "and the results are novel and interesting",
    "NOVELTY"
  ],
  [
    "The paper presents a new methodological idea , which allows for nice practical contribution .",
    "NOVELTY"
  ],
  [
    "There is no theoretical contribution or any deep",
    "NOVELTY"
  ],
  [
    "Despite the the idea of exploiting generative models to perform data augmentation is interesting",
    "NOVELTY"
  ],
  [
    ", using it as an evaluation metric does not constitute an innovative enough contribution .",
    "NOVELTY"
  ],
  [
    "The idea is interesting .",
    "NOVELTY"
  ],
  [
    "3 .Overall I think the theoretical contribution of this paper is limited .",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea and the task is also interesting .",
    "NOVELTY"
  ],
  [
    "this paper is the first to analyze it in such generality",
    "NOVELTY"
  ],
  [
    "the gains obtained using the proposed method appear to be similar to other works that do allow for improvements in terms of both memory and computation",
    "NOVELTY"
  ],
  [
    "2 .The SDSS technique in the paper appears to be very similar to the \u201c Perforated CNN \u201d technique proposed by Figurnov et al . ( 2015 ) .",
    "NOVELTY"
  ],
  [
    "This is very novel to me .",
    "NOVELTY"
  ],
  [
    "Addressing the regression task using aggregate observations instead of individual observations using GP with Poisson likelihood is interesting & fairly new to me",
    "NOVELTY"
  ],
  [
    "This is an interesting paper with novel contributions . The proposed theoretical framework is new to me ( to the best of my knowledge ) &",
    "NOVELTY"
  ],
  [
    "However , the paper itself is light on novelty , as the core ideas were already established by [ Frankle et al ] , and the application of them here is relatively straightforward .",
    "NOVELTY"
  ],
  [
    "The authors propose an interesting approach for learning long-range dependencies and mixing over canonical orderings .",
    "NOVELTY"
  ],
  [
    "The characterization of the memorization problem and the proposed regularizer are novel contributions .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and new .",
    "NOVELTY"
  ],
  [
    "The algorithm seems novel ,",
    "NOVELTY"
  ],
  [
    "but is clearly very closely related to other things in the literature .",
    "NOVELTY"
  ],
  [
    "Although the theoretical analysis of the paper is interesting",
    "NOVELTY"
  ],
  [
    "The proposed method is certainly novel and the contribution is original enough .",
    "NOVELTY"
  ],
  [
    "The idea of SEFT is novel and the results are also showing its promise",
    "NOVELTY"
  ],
  [
    "there are several issues that limit the contribution and maturity of this paper",
    "NOVELTY"
  ],
  [
    "While these techniques are not novel",
    "NOVELTY"
  ],
  [
    "the technical contribution is lean . Neither the multi-agent learning or the hierarchical learning of the algorithm is novel .",
    "NOVELTY"
  ],
  [
    "I also do not agree with another claim that `` We consider the simulation and training environment to be another novel contribution ...",
    "NOVELTY"
  ],
  [
    "This is a very interesting paper that applies the pixelCNN ( Oord et al .2016 ) framework to 3D point cloud generation .",
    "NOVELTY"
  ],
  [
    "Despite the high-quality generation results shown in the paper , reviewer feels the novelty of this paper is quite limited",
    "NOVELTY"
  ],
  [
    "Overall the paper is original and clearly",
    "NOVELTY"
  ],
  [
    "which I believe is a good amount of contribution",
    "NOVELTY"
  ],
  [
    "I have n't encountered this before and it could make an interesting proposal",
    "NOVELTY"
  ],
  [
    "While this paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "but I think it contains an interesting idea . Compared to the previous work on similarity matching , this is the first one that extends similarity matching cost function to networks with several layers and structured connectivity",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge these results are new .",
    "NOVELTY"
  ],
  [
    "so in that sense it is novel",
    "NOVELTY"
  ],
  [
    "stride in presenting for the first time a theoretical consolidation and treatment of the mode collapse problem",
    "NOVELTY"
  ],
  [
    "perhaps this is the first time a framework of mode collapse is constructed and its theoretical underpinnings are discussed",
    "NOVELTY"
  ],
  [
    "I think this is a strong contribution to NIPS this year .",
    "NOVELTY"
  ],
  [
    "Also , mask-based image generation is not entirely new",
    "NOVELTY"
  ],
  [
    "the proposed approach is a combination of well-known techniques for a novel scenario . The technical novelty seems somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The first work that trains GAN for spectrogram-to-waveform conversion without distillation .",
    "NOVELTY"
  ],
  [
    "but the approach outlined is interesting",
    "NOVELTY"
  ],
  [
    "Overall , the paper is very well written and provides interesting insights into the multi-modal structure of deep neural network loss landscapes .",
    "NOVELTY"
  ],
  [
    "Even though the hypothesis of the paper is not entirely new and has been touched upon in Fort",
    "NOVELTY"
  ],
  [
    "and the approach is appealing .",
    "NOVELTY"
  ],
  [
    "However , it seems to me that there does n't seem to be that much new over the 2011 method of Shelton et al [ 13 ] , which was also applied to the Sparse Coding problem .",
    "NOVELTY"
  ],
  [
    "While I would not say the",
    "NOVELTY"
  ],
  [
    "are necessarily big steps away",
    "NOVELTY"
  ],
  [
    "from existing methods",
    "NOVELTY"
  ],
  [
    "While the idea of boosting generative models and the proposed methods are interesting",
    "NOVELTY"
  ],
  [
    "and ( as far as the reviewer knows ) original",
    "NOVELTY"
  ],
  [
    "and the proposed integrated recurrent architecture seems very appealing . The considered set up with three computer vision tasks is very interesting and natural , and , to my knowledge , it was not explored before .",
    "NOVELTY"
  ],
  [
    "In general , I like the idea of this paper and I wish the text was more clear",
    "NOVELTY"
  ],
  [
    "Other than this particular setup of geo-localizing based on lean images only , the novelty of the paper and the approach seem limited and does not offer new insights in geo-interpolation methods , geometry-aware neural networks , or memorization .",
    "NOVELTY"
  ],
  [
    "A new variant of the invertible-flow based graph generation model .",
    "NOVELTY"
  ],
  [
    "Quality This is",
    "NOVELTY"
  ],
  [
    "Originality This is one of the first uses of GANs in the context of neuroimaging .",
    "NOVELTY"
  ],
  [
    "and original contribution demonstrating the use of GANs in the context of neuroimaging .",
    "NOVELTY"
  ],
  [
    "There is novelty in the particular combination of techniques that the authors have employed and some of the empirical results show the strength of the technique",
    "NOVELTY"
  ],
  [
    "the main contribution of the paper is a careful combination of existing techniques and the associated",
    "NOVELTY"
  ],
  [
    "Overall the experimental results in the paper are weak and the novelty of the proposed methods is low .",
    "NOVELTY"
  ],
  [
    "While the theory is interesting",
    "NOVELTY"
  ],
  [
    "While I like the paper as an interesting idea and proof of concept",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting mix of neural networks and traditional PDE solvers for system control",
    "NOVELTY"
  ],
  [
    "There is not a single concrete contribution .",
    "NOVELTY"
  ],
  [
    "Their algorithmic contributions are both ( i ) clearly novel and ( ii ) significant improvements over na\u00c3\u00afve baselines .",
    "NOVELTY"
  ],
  [
    "However , I think that the work is interesting and sufficiently novel and could be accepted if the mentioned issues were adequately addressed",
    "NOVELTY"
  ],
  [
    "and a promising approach for training robots by non-experts .",
    "NOVELTY"
  ],
  [
    "This paper proposes an original idea and theoretically appealing solutions to solve it .",
    "NOVELTY"
  ],
  [
    "The purpose of this paper is appealing and its solutions are novel .",
    "NOVELTY"
  ],
  [
    "there seems to be a lack of technical contributions in the paper .",
    "NOVELTY"
  ],
  [
    "I am still unconvinced in the contributions of the paper outside of what I previously listed .",
    "NOVELTY"
  ],
  [
    "This is a very interesting piece of",
    "NOVELTY"
  ],
  [
    "The idea of a multi-view generation model based on restricted kernel machines is interesting .",
    "NOVELTY"
  ],
  [
    "I vote for accept as this paper proposes a novel technique to combine mutual information based intrinsic control objectives with successor features , which allow for combining the benefits of both in a complementary way",
    "NOVELTY"
  ],
  [
    "The technique for enforcing the restriction in Eq .10 , as well as being able to use it with generalized policy improvement is a good novel contribution in the paper .",
    "NOVELTY"
  ],
  [
    "Weak Reject considering that the novelty is limited",
    "NOVELTY"
  ],
  [
    "The idea of utilizing deep learning models to learn encoded representations for clustering is interesting and could be a promising solution .",
    "NOVELTY"
  ],
  [
    "the proposed KNG and its theoretical properties are novel .",
    "NOVELTY"
  ],
  [
    "In general , the proposed attacking scenarios is novel and missing from the current adversarial attack",
    "NOVELTY"
  ],
  [
    "research , which",
    "NOVELTY"
  ],
  [
    "mostly attack by adding constraint noise in the image space , instead of directly train a new adversarial controlling policy",
    "NOVELTY"
  ],
  [
    "In terms of the techniques for reducing the communication burden , the authors seem to just put all the other approaches together with minimal novelty .",
    "NOVELTY"
  ],
  [
    ".Overall I think the paper adds an interesting contribution",
    "NOVELTY"
  ],
  [
    "with the datasets themselves which can be used for image similarity tasks for example Although the contribution of the paper is important , it seems limited for the conference with no novel method proposed .",
    "NOVELTY"
  ],
  [
    "it is difficult to decide whether this method represents an advance in area of graph generation",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "method is similar to the approach of Li et al . [ 1",
    "NOVELTY"
  ],
  [
    "and contains a few novel parts",
    "NOVELTY"
  ],
  [
    "C 1- This is an incremental contribution over the original Accelerated Sketch-and-Project and its application over matrix inversion problem .",
    "NOVELTY"
  ],
  [
    "Novelty This is the first approach for an end-to-end learning method for irregularly sampled time series .",
    "NOVELTY"
  ],
  [
    "However , the core ideas of this paper are not very innovative to me .",
    "NOVELTY"
  ],
  [
    "but I think that alone does not have enough originality to carry the paper",
    "NOVELTY"
  ],
  [
    "Pros .1 .This paper presents a nice overview of three popular semi-supervised learning methods in Section 3.1 , and presents insights regarding these models .",
    "NOVELTY"
  ],
  [
    "the development looks quite heuristic and not completely intuitive .",
    "NOVELTY"
  ],
  [
    ", I am not sure what the contributions of the paper are .",
    "NOVELTY"
  ],
  [
    "general , this is an interesting idea to me .",
    "NOVELTY"
  ],
  [
    "This makes the novelty of the paper quite thin , as the main underlying idea of the paper was previously introduced .",
    "NOVELTY"
  ],
  [
    "these results and the novelty of the paper are not entirely clear .",
    "NOVELTY"
  ],
  [
    "I voted for Weak Reject because this paper presents a fairly incremental advance over what has been done ( e.g .HoloGAN",
    "NOVELTY"
  ],
  [
    "The proposed approach seems interesting and relatively novel ,",
    "NOVELTY"
  ],
  [
    "I think the idea presented is certainly promising",
    "NOVELTY"
  ],
  [
    "The idea of mixing the sigmoid function and a tanh function in order to capture negative , zero and positive correlations in attention mechanisms is quite novel .",
    "NOVELTY"
  ],
  [
    "with intriguing ideas that challenge the \u2018 dense",
    "NOVELTY"
  ],
  [
    "In this respect , the algorithms proposed in this paper represent an excellent extension of existing sparse algorithms that go against the current trend of focusing on compact dense representations because this is what GPUs handle best .",
    "NOVELTY"
  ],
  [
    "working on sparse representations is quite \u2018 original \u2019",
    "NOVELTY"
  ],
  [
    "now",
    "NOVELTY"
  ],
  [
    "such as paper would have been less original",
    "NOVELTY"
  ],
  [
    "I really enjoyed reading this paper and was really intrigued by the author 's solution .",
    "NOVELTY"
  ],
  [
    "This does n't produce anything new .",
    "NOVELTY"
  ],
  [
    "I like the idea of learning a consistent embedding space for prediction and label propagation seems interesting and novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The major concern is the novelty .",
    "NOVELTY"
  ],
  [
    "This seems like a nice piece of work , an original approach that solves a problem that was never really fully resolved in previous work ,",
    "NOVELTY"
  ],
  [
    "The method seems to be new , even if it is",
    "NOVELTY"
  ],
  [
    "not a major breakthrough",
    "NOVELTY"
  ],
  [
    "Novel and interesting formulation of meta-learning by learning an unsupervised update rule for representation learning .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel estimator , analyzes",
    "NOVELTY"
  ],
  [
    "I would consider the contributions of this paper as very significant .",
    "NOVELTY"
  ],
  [
    "Thus I think the novelty is fairly weak and fails to cohere with the NIPS standard .",
    "NOVELTY"
  ],
  [
    "but even in the current state I believe both the technique and the results are interesting",
    "NOVELTY"
  ],
  [
    "The novelty of this paper mainly seems to be with respect to video classification and captioning",
    "NOVELTY"
  ],
  [
    "Considering that multi-view and multi-modal RL papers tend to offer ad-hoc solutions to the problem , this paper 's formalization is a nice contribution",
    "NOVELTY"
  ],
  [
    "I think this paper shows interesting findings on the training dynamics of GANs .",
    "NOVELTY"
  ],
  [
    "In my opinion , this paper is rather incremental .",
    "NOVELTY"
  ],
  [
    "Limited convincing the advantage of GCN itself Detailed comments The paper incorporates the graph structures in sentences and KB to make richer representations of conversation and achieves a state-of-the-art performance on the DSTC2 dataset",
    "NOVELTY"
  ],
  [
    "However , as the paper combines existing mechanisms to design a model for dialog , the novelty seems to be relatively weak .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , most theoretical results on explorations are built on the state-action visit count , not state visit count",
    "NOVELTY"
  ],
  [
    "The idea of trading off linear approximation and extrapolation in linear-combination-of-features function approximation is interesting . The theoretical intuition about error scaling and control of the error amplification due to Bellman iterates is a good and novel contribution .",
    "NOVELTY"
  ],
  [
    "The greedy approach to adding anchor points to meet a specified amplification target is a nice contribution .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "it presents an interesting idea and analysis , and has novel and technically",
    "NOVELTY"
  ],
  [
    "is well formulated and the presented solution is novel .",
    "NOVELTY"
  ],
  [
    "I agree that the idea of the paper is interesting , and deserves explorations .",
    "NOVELTY"
  ],
  [
    "Originality The work is in some ways similar to Yang and Wang but takes different approaches and derives different insights",
    "NOVELTY"
  ],
  [
    "Originality is good .",
    "NOVELTY"
  ],
  [
    "Methodology and Significance The idea to use image quality metrics as regularizers is simple , yet seems intuitive",
    "NOVELTY"
  ],
  [
    "while the method is simple and intuitive",
    "NOVELTY"
  ],
  [
    ", its contribution is somewhat limited .",
    "NOVELTY"
  ],
  [
    "The most important and novel result is the concavity of the value function with respect to the policy .",
    "NOVELTY"
  ],
  [
    "Technical contribution looks non-trivial , based on the permutation technique .",
    "NOVELTY"
  ],
  [
    "I think this paper presents a solid contribution and recommend acceptance",
    "NOVELTY"
  ],
  [
    "-In terms of novelty , the proposed approach is a combination of several past works so the technical novelty is limited .",
    "NOVELTY"
  ],
  [
    "I find it difficult to believe that experts in the field are not aware of this potential behavior but the paper develops the idea considerably and seems interesting",
    "NOVELTY"
  ],
  [
    "Introduced , studied , and supported the novel idea that BNNs are robust to adversarial attacks .",
    "NOVELTY"
  ],
  [
    "This paper states an interesting and novel idea- that learned shape bases could outperform hand-crafted heuristic functions",
    "NOVELTY"
  ],
  [
    "-As stated above , the paper has an interesting and novel high-level key idea .",
    "NOVELTY"
  ],
  [
    "There is very little actually new here , of course",
    "NOVELTY"
  ],
  [
    "While the general theme of model-based RL outperforming model-free RL is not new",
    "NOVELTY"
  ],
  [
    "there is some question as to whether the work here is novel enough to warrant publication",
    "NOVELTY"
  ],
  [
    "overcome",
    "NOVELTY"
  ],
  [
    "fairly minimal contribution from an algorithmic perspective",
    "NOVELTY"
  ],
  [
    "The primary weakness of this work its lack of novelty and lack of evidence of generalization of the approach , which limits its significance .",
    "NOVELTY"
  ],
  [
    "Even though I am not an expert in the field , to the best of my knowledge this is a new line of work .",
    "NOVELTY"
  ],
  [
    "The idea of learning a residual difference to produce a target classifier is novel , simple , and interesting .",
    "NOVELTY"
  ],
  [
    "The MMD loss is not novel and",
    "NOVELTY"
  ],
  [
    "it 's simply unclear if the novel portions of the approach are actually contributing much to the overall system .",
    "NOVELTY"
  ],
  [
    "Operator learning has been already studied in FDA",
    "NOVELTY"
  ],
  [
    "the theoretical results seem a bit incremental compared with ( Xu et al .2018 ) .2. it would be nice to comment on how this will affect cases with nontrivial node features and general node classification tasks",
    "NOVELTY"
  ],
  [
    "I like the ideas and they are explained well",
    "NOVELTY"
  ],
  [
    "but the novel idea itself is worth publishing even if it is just as good as the state of the art",
    "NOVELTY"
  ],
  [
    "I liked the paper very much because it provides quite an innovative new approach to look at active learning , which resembles GANs and Core set ideas in some ways , yet differs in significant ways that are critical for active learning . I 've been working and publishing in related areas for a long time so I genuinely found your central idea refreshing and new .",
    "NOVELTY"
  ],
  [
    "The idea of",
    "NOVELTY"
  ],
  [
    "However , the originality of the approach is undercut by the recent work of Wang et al",
    "NOVELTY"
  ],
  [
    "2 .The work is in the middle ground of two previous works",
    "NOVELTY"
  ],
  [
    "although the practical contribution is mild",
    "NOVELTY"
  ],
  [
    "I like this idea , it intuitively seems like a promising method for obtaining semantically meaningful adversarial examples .",
    "NOVELTY"
  ],
  [
    "-Originality Few other works have explored the use of warping for video model",
    "NOVELTY"
  ],
  [
    "This paper propose a novel model that propose to learn the filter support in addition to filter weight which is an interesting step toward better video model .",
    "NOVELTY"
  ],
  [
    "I think this paper 's contribution is rather theoretical than",
    "NOVELTY"
  ],
  [
    "although the concept of ` deficiency ` in a bottleneck setting is novel",
    "NOVELTY"
  ],
  [
    "The idea proposed in the paper is very interesting .",
    "NOVELTY"
  ],
  [
    "The idea of using t-consistency for computing variations between probability vectors is quite elegant , and the idea of using clustering techniques to overcome non-transitivity of t-equality is also quite interesting .",
    "NOVELTY"
  ],
  [
    ", and the approaches proposed here do not seem to be very novel in terms of machine learning",
    "NOVELTY"
  ],
  [
    "the novelty seems a bit limited and",
    "NOVELTY"
  ],
  [
    "It is both novel and technically strong .",
    "NOVELTY"
  ],
  [
    "Overall , the paper was extremely insightful and a pleasure to read .",
    "NOVELTY"
  ],
  [
    "The criterion to stop the exploration of the image",
    "NOVELTY"
  ],
  [
    ") seems to be novel .",
    "NOVELTY"
  ],
  [
    "I do not feel that the technical contributions are substantial enough to warrant acceptance at ICLR .",
    "NOVELTY"
  ],
  [
    "the methodological novelty is limited",
    "NOVELTY"
  ],
  [
    "I see the contributions of this paper is incremental and limited as the goal is not that significant and the approaches are mostly based on existing strategies such as [ 12 , 24 , 30 ] .",
    "NOVELTY"
  ],
  [
    "this paper is just an incremental paper with even less insights than the seminal paper",
    "NOVELTY"
  ],
  [
    "It seems to be an ensemble of several existing works and definitely not innovative .",
    "NOVELTY"
  ],
  [
    "Overall , I like this paper and the approach of extending TS-style algorithms to Deep RL by just taking the final layer of the neural network .",
    "NOVELTY"
  ],
  [
    "This paper presents an interesting ideas which is also based on an exhaustive theoretical derivation .",
    "NOVELTY"
  ],
  [
    "I think the method is interesting and novel",
    "NOVELTY"
  ],
  [
    "The idea is novel and well motivated .",
    "NOVELTY"
  ],
  [
    "The improvement over the previous work",
    "NOVELTY"
  ],
  [
    "this paper actually does make a very nice contribution",
    "NOVELTY"
  ],
  [
    "Architecture is simpler than that of previous related work ( hGRU",
    "NOVELTY"
  ],
  [
    "Not clear what the objectives/contributions are - No advancement of state of the art in computer vision - No novel insights about brain function - Motivation of the `` texturized challenge `` is unclear",
    "NOVELTY"
  ],
  [
    "It neither presents an advance of the state of the art in any computer vision problem nor does it lead to any novel insights about the brain .",
    "NOVELTY"
  ],
  [
    "Therefore , the technical contribution of the paper is largely incremental .",
    "NOVELTY"
  ],
  [
    "Overall , the paper presents a novel approach for evaluating transferability , that I think would be interesting to many researchers in this field .",
    "NOVELTY"
  ],
  [
    "*Originality* The way authors take advantage of depth information extracted from a simulator as privileged information is novel in the sense that , with respect to the original student-teacher paradigm of the paper by Vapnik & Vashist , here the idea of privileged information is interpreted as a regularizer to boost the training stage .",
    "NOVELTY"
  ],
  [
    "2 .Using privileged information from simulators seems novel and well presented in this paper .",
    "NOVELTY"
  ],
  [
    "with an interesting usage of z-buffer from a simulator as privileged information",
    "NOVELTY"
  ],
  [
    "and provides many highly non-trival results , and insightful conceptual messages",
    "NOVELTY"
  ],
  [
    "However , the machine learning contributions of the paper are marginal to me .",
    "NOVELTY"
  ],
  [
    "The use of ( optimized ) product quantization for approximating inner product is not particularly novel .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- I 'm not an expert in this area but I do find this paper interesting",
    "NOVELTY"
  ],
  [
    "In terms of novelty the new term , the paper does not make a breakthrough contribution ,",
    "NOVELTY"
  ],
  [
    "but I",
    "NOVELTY"
  ],
  [
    "And I don \u2019 t see significant contribution to empirical algorithm .",
    "NOVELTY"
  ],
  [
    "It is an interesting paper with a novel approach to multi-task learning .",
    "NOVELTY"
  ],
  [
    "The paper shows some interesting results contrary to the common curriculum learning ideas of using easy training samples first",
    "NOVELTY"
  ],
  [
    "Overall , the proposed method on estimating the sign of the gradient for black-box attacks is novel .",
    "NOVELTY"
  ],
  [
    "While",
    "NOVELTY"
  ],
  [
    "the paper is structured as a",
    "NOVELTY"
  ],
  [
    "grab bag of improvements to the i-ResNet model , the methods are original and well explained via text",
    "NOVELTY"
  ],
  [
    "The paper produces a generalization of SVGD that captures many other already known variants",
    "NOVELTY"
  ],
  [
    "The paper is a nice contribution to the topic of SVGD and provides some ideas for incorporating more information about the score function .",
    "NOVELTY"
  ],
  [
    "Although the idea of using motion to bridge the gap between synthetic and real data is not new",
    "NOVELTY"
  ],
  [
    "and achieving results that are pretty comparable with state of the art from outdoor images is new as well",
    "NOVELTY"
  ],
  [
    "As previously mentioned , the idea is not extremely novel .",
    "NOVELTY"
  ],
  [
    "The whole study is novel , and beneficial for the community of graph neural network study .",
    "NOVELTY"
  ],
  [
    "The architecture is novel to combine static and dynamic objects .",
    "NOVELTY"
  ],
  [
    "Novelty I 'm not sure about the novelty of the paper , but I suspect it to be rather incremental .",
    "NOVELTY"
  ],
  [
    "The paper says `` To the best of our knowledge , this is the first time to consider residual non-local attention for image restoration problems",
    "NOVELTY"
  ],
  [
    "that would not constitute much novelty",
    "NOVELTY"
  ],
  [
    "Originality To my knowledge , the introduction of spatial aggregation of the input space is indeed novel , though",
    "NOVELTY"
  ],
  [
    "perhaps not overly so",
    "NOVELTY"
  ],
  [
    "writing is insightful",
    "NOVELTY"
  ],
  [
    "However , to the best of my knowledge , it is original and poses the basis of interesting future works .",
    "NOVELTY"
  ],
  [
    "While the theory seems a bit incremental",
    "NOVELTY"
  ],
  [
    "it \u2019 s the first paper that theoretically validates the benefits of sharing knowledge , which is a contribution to the MTRL field .",
    "NOVELTY"
  ],
  [
    "The idea of the Jacobian as a natural replacement for embeddings is interesting",
    "NOVELTY"
  ],
  [
    "The direction of the paper is definitely interesting",
    "NOVELTY"
  ],
  [
    "This is",
    "NOVELTY"
  ],
  [
    "The paper offers novel regret bounds for Thompson sampling and UCB algorithms",
    "NOVELTY"
  ],
  [
    "but the key idea is mostly a straightforward extension of Russo and Van Roy",
    "NOVELTY"
  ],
  [
    "The proofs are not trivial but , as I explain below , the contribution appears to me insufficient for NIPS .",
    "NOVELTY"
  ],
  [
    "The main architectural pieces ( VAE , message passing ) have been proposed previously , but",
    "NOVELTY"
  ],
  [
    "the specific focus on directed graphs using these components is new to my knowledge .",
    "NOVELTY"
  ],
  [
    ".It is a straightforward and effecient idea , although a bit incremental .",
    "NOVELTY"
  ],
  [
    "The proposed model and method are reasonably original and novel .",
    "NOVELTY"
  ],
  [
    "this presented idea is interesting and well-suited for NIPS",
    "NOVELTY"
  ],
  [
    "From an originality standpoint , the model builds on a variety of object-centric forward models",
    "NOVELTY"
  ],
  [
    "I should emphasize that I consider this train-test split design to be quite novel as well -- some recent works have moved towards a more dev psych= inspired train/test split",
    "NOVELTY"
  ],
  [
    "The paper is an incremental work to the existing one by Paun et al . ( 2018b ) .",
    "NOVELTY"
  ],
  [
    "But this is not the case for the considered paper - the idea to embed to a latent space and then perform prediction in the latent space is not new .",
    "NOVELTY"
  ],
  [
    "I think that the approach is intriguing",
    "NOVELTY"
  ],
  [
    "Maybe they are novel for this problem , though .",
    "NOVELTY"
  ],
  [
    "Additionally the use of multi-source word embeddings is novel too",
    "NOVELTY"
  ],
  [
    "Still , the overall contribution is mostly in combining existing methods and can be judged as rather incremental .",
    "NOVELTY"
  ],
  [
    "This is the first inconsistency analysis for random forests",
    "NOVELTY"
  ],
  [
    "Novel/interesting way of defending against adversarial attacks by taking advantage of the manifold assumption .",
    "NOVELTY"
  ],
  [
    "The idea of using shared memory for knowledge base completion is new and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed idea is novel and intriguing , utilizing tools from combinatorial optimization to select an appropriate subset for approximating the training loss .",
    "NOVELTY"
  ],
  [
    "1 .This paper seems to integrate multiple ideas studied before into a single attack method",
    "NOVELTY"
  ],
  [
    "Interesting direction of extending supervised VQA to a novel answer space .",
    "NOVELTY"
  ],
  [
    "3 .Overall novel model which aims to decouple task prediction from answer prediction .",
    "NOVELTY"
  ],
  [
    "Although the methods are not original",
    "NOVELTY"
  ],
  [
    "The empirical evaluation is insightful",
    "NOVELTY"
  ],
  [
    "the empirical evaluation presented in the paper",
    "NOVELTY"
  ],
  [
    "is limited but , within its scope , thorough and insightful , and I believe it is borderline sufficient",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , all lower bounds (",
    "NOVELTY"
  ],
  [
    "which is somewhat simpler ) are new",
    "NOVELTY"
  ],
  [
    "Although this idea is not entirely new",
    "NOVELTY"
  ],
  [
    "the analysis itself seems to be original ,",
    "NOVELTY"
  ],
  [
    "which is certainly new",
    "NOVELTY"
  ],
  [
    "from the literature",
    "NOVELTY"
  ],
  [
    "This is a novel result on the MAB problem with limited switch cost problem .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "and I personally quite like its idea .",
    "NOVELTY"
  ],
  [
    "The proposed search space is new and the model transformation method for practical NAS for object detection task is interesting .",
    "NOVELTY"
  ],
  [
    "However , the search pipeline is largely based on previous works on gradient-based NAS , which makes the novelty of the proposed method limited .",
    "NOVELTY"
  ],
  [
    "Although I still think the technical contribution of this paper is limited",
    "NOVELTY"
  ],
  [
    "I agree with the other reviewers that the proposed practical NAS method for objection detection can be a new and promising direction in future research .",
    "NOVELTY"
  ],
  [
    "and the contribution of this paper ( generalization of these two methods ) is a somewhat natural extension without significant novelty .",
    "NOVELTY"
  ],
  [
    "I like the idea of using two VAEs to model dance at different levels .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work to build a simulator that can generate data with causal relations . This paper is novel",
    "NOVELTY"
  ],
  [
    "The paper contains a solid novel contributions .",
    "NOVELTY"
  ],
  [
    "In that sense , the novelties of this paper rather limited and seems to be a direct application of classical conformal prediction with a quantile regression algorithm .",
    "NOVELTY"
  ],
  [
    "The work seems to be an extension of Schiratti et al . ( 2015 ) , which first introduced this modeling framework",
    "NOVELTY"
  ],
  [
    "I don \u2019 t see the novelty in the authors \u2019 contribution in defining the clinical risk .",
    "NOVELTY"
  ],
  [
    "The proposed methods appear novel and worth pursuing .",
    "NOVELTY"
  ],
  [
    "All I can say is the approach is intuitively appealing",
    "NOVELTY"
  ],
  [
    "The methodological novelty is limited as the model is a straightforward extension of [ 1 ] .",
    "NOVELTY"
  ],
  [
    "My biggest concern is novelty , as the modifications are minor .",
    "NOVELTY"
  ],
  [
    "This paper is not novel .",
    "NOVELTY"
  ],
  [
    "The model side has very limited novelty .",
    "NOVELTY"
  ],
  [
    "The paper is really interesting .",
    "NOVELTY"
  ],
  [
    "The idea looks original .",
    "NOVELTY"
  ],
  [
    "interesting idea",
    "NOVELTY"
  ],
  [
    "the Rainbow-IQN improvement is too incremental to be considered a significant contribution",
    "NOVELTY"
  ],
  [
    "but I do n't think it provides enough new knowledge to be a conference paper",
    "NOVELTY"
  ],
  [
    "Novel idea",
    "NOVELTY"
  ],
  [
    "This is an interesting paper with novel idea and efficient implementation .",
    "NOVELTY"
  ],
  [
    "which is novel the interesting",
    "NOVELTY"
  ],
  [
    "Although the novelty of this work is somehow limited",
    "NOVELTY"
  ],
  [
    "However , my main concern about this work is its novelty ,",
    "NOVELTY"
  ],
  [
    "In this sense , there is not too much contribution for the current paper given the previous work Du & Hu ( 2019 ) .",
    "NOVELTY"
  ],
  [
    "This is certainly a very creative work with a non-obvious idea",
    "NOVELTY"
  ],
  [
    "but more developments are needed from these initial experimental results",
    "NOVELTY"
  ],
  [
    "While the Lagrangian relaxation idea is interesting and could yield interesting follow-up work",
    "NOVELTY"
  ],
  [
    "I do n't think there is enough interesting novelty in this paper .",
    "NOVELTY"
  ],
  [
    "The resulting algorithm appears to be novel and technically sound .",
    "NOVELTY"
  ],
  [
    "I like the idea of binarizing deep neural networks",
    "NOVELTY"
  ],
  [
    "The main drawback of the paper is its novelty .",
    "NOVELTY"
  ],
  [
    "I am not sure what insight to take away from the paper",
    "NOVELTY"
  ],
  [
    "Strengths The approach is novel and very interesting The paper",
    "NOVELTY"
  ],
  [
    "I think this is a strong paper both theoretically and practically which makes a worthy contribution to NIPS",
    "NOVELTY"
  ],
  [
    "The article is quite novel in my opinion . To the best of my knowledge , it is the first article that implements a generic method for learning arbitrary PDE models from data .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , they are the first to show the connection between res-net type architecture and numerical solutions of PDEs .",
    "NOVELTY"
  ],
  [
    "As I mentioned , up to my knowledge , the idea of using Hamiltonian equations as loss functions of NNs is new , interesting and easy to",
    "NOVELTY"
  ],
  [
    "The paper makes an interesting contribution",
    "NOVELTY"
  ],
  [
    "the contributions of the work heavily depends on the WikiSQL dataset",
    "NOVELTY"
  ],
  [
    "I find the submission contains certain interesting ideas",
    "NOVELTY"
  ],
  [
    "The approach is novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "although the problem as stated is not new",
    "NOVELTY"
  ],
  [
    "Overall I like the contributions .",
    "NOVELTY"
  ],
  [
    "it should not come as a big surprise in terms of novelty",
    "NOVELTY"
  ],
  [
    "this work which builds upon a number of",
    "NOVELTY"
  ],
  [
    "The paper presents a novel approach for machine comprehension .",
    "NOVELTY"
  ],
  [
    "which is a novel combination for machine comprehension task",
    "NOVELTY"
  ],
  [
    "-- Relation of their model to Visual Question Answering approaches , and computing features from context and query",
    "NOVELTY"
  ],
  [
    "Convolutional Neural Networks , are interesting",
    "NOVELTY"
  ],
  [
    "Novel , state-of-the-art , and well-studied machine comprehension approach .",
    "NOVELTY"
  ],
  [
    "this paper makes a potentially interesting contribution",
    "NOVELTY"
  ],
  [
    "The idea that overfitting is mitigated thourh similarity between models is not novel as such but compared to earlier related approaches that are being cited",
    "NOVELTY"
  ],
  [
    "this work provides new empirical evidence and theoretical understanding of this phenomenon",
    "NOVELTY"
  ],
  [
    "and I do n't see it as having originality",
    "NOVELTY"
  ],
  [
    "the results are unsurprising , and I am not clear what is novel or significant about them .",
    "NOVELTY"
  ],
  [
    "The emphasis on `` deep `` therefore seems to detract from the core ideas of the paper",
    "NOVELTY"
  ],
  [
    "Generally speaking , I like the overall idea , which , as far as I know , is a novel approach for dealing with discrete inputs .",
    "NOVELTY"
  ],
  [
    "While such a pipeline for scaling using a graph coarsening and refinement based approach is not new",
    "NOVELTY"
  ],
  [
    "and the only argument might be that the advance here is perhaps overly incremental .",
    "NOVELTY"
  ],
  [
    "I like the idea of using the important variables to train another model for testing how accurately the models can choose important variables Issues",
    "NOVELTY"
  ],
  [
    "The methodological novelty of IMV-LSTM is limited .",
    "NOVELTY"
  ],
  [
    "This paper is not so different from other works",
    "NOVELTY"
  ],
  [
    "and presents an interesting approach and insights",
    "NOVELTY"
  ],
  [
    "I feel the whole paper lacks novelty , and have",
    "NOVELTY"
  ],
  [
    "I think the technique used in this paper is not novel as well .",
    "NOVELTY"
  ],
  [
    "Originality The application to financial time series is straight forward but I have not seen it before .",
    "NOVELTY"
  ],
  [
    "Though the contribution looks incremental",
    "NOVELTY"
  ],
  [
    ", the experimental performance is promising",
    "NOVELTY"
  ],
  [
    "and also added an interesting example application of color transfer",
    "NOVELTY"
  ],
  [
    "esoteric",
    "NOVELTY"
  ],
  [
    "+This paper presents a novel approach for transfer reinforcement learning .",
    "NOVELTY"
  ],
  [
    "the proposed network can be considered as ensemble reinforcement learning that take advantages of learned agents with different expertise to solve the novel task",
    "NOVELTY"
  ],
  [
    "The approach does seem somewhat incremental",
    "NOVELTY"
  ],
  [
    "All told this is a good contribution .",
    "NOVELTY"
  ],
  [
    "Overall , there seem to be three novel things presented in the paper",
    "NOVELTY"
  ],
  [
    "Their formulation of the problem as a GNN pruning is brilliant and widens the path for future research in the feature matching",
    "NOVELTY"
  ],
  [
    "valuable and novel method for pruning the sift feature matches .",
    "NOVELTY"
  ],
  [
    "Considered paper is one of the first approaches to learn GAN-type generative models .",
    "NOVELTY"
  ],
  [
    "While on the AE model / architecture side I feel the contribution is very marginal",
    "NOVELTY"
  ],
  [
    "This result might be interesting but not really surprising and the paper does not put any new theoretical ideas or proof techniques .",
    "NOVELTY"
  ],
  [
    "All in all , the contributions is interesting",
    "NOVELTY"
  ],
  [
    "but really incremental",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the method proposed by the authors is novel , and differs from traditional sentence generation ( as an example ) models because it is intended to produce continuous domain outputs .",
    "NOVELTY"
  ],
  [
    "Even though the contributions are mostly empirical",
    "NOVELTY"
  ],
  [
    "Overall this is well-written and makes interest theoretical and conceptual contributions .",
    "NOVELTY"
  ],
  [
    "-The idea of",
    "NOVELTY"
  ],
  [
    "The AdaGain algorithm is , to the best of my knowledge , novel , and the focus on `` stability , not convergence `` seems like an interesting idea",
    "NOVELTY"
  ],
  [
    "I felt that the central ideas were only thinly vetted",
    "NOVELTY"
  ],
  [
    "2 .I am a little bit concerned that the theoretical contribution seems weak .",
    "NOVELTY"
  ],
  [
    "Though Eq . ( 4 ) and ( 5 ) seem to be novel",
    "NOVELTY"
  ],
  [
    "and the idea seems nice",
    "NOVELTY"
  ],
  [
    "At the conceptual level , the idea of jointly modeling local video events is not novel",
    "NOVELTY"
  ],
  [
    "The weaknesses of the paper are novelty , clarity , and evaluation .",
    "NOVELTY"
  ],
  [
    "Novelty of the proposed idea .",
    "NOVELTY"
  ],
  [
    "The major issue of the paper is the lack of novelty .",
    "NOVELTY"
  ],
  [
    "The techniques are novel as far as I know .",
    "NOVELTY"
  ],
  [
    "The paper falls a bit short both empirically and technically .",
    "NOVELTY"
  ],
  [
    "While their technique is interesting",
    "NOVELTY"
  ],
  [
    "The idea is pretty simple , and it is a natural extension of FiLM to the graph setting .",
    "NOVELTY"
  ],
  [
    "The paper provides a new perspective in the workings of word embeddings that I find interesting",
    "NOVELTY"
  ],
  [
    "My major concern is the limited contribution .",
    "NOVELTY"
  ],
  [
    "The analysis seem to be quite similar to the previous analysis of the SMB algorithm .",
    "NOVELTY"
  ],
  [
    "Though , I think it is a nice contribution .",
    "NOVELTY"
  ],
  [
    "and introduces an interesting extension to RBMs allowing for infinite hidden units",
    "NOVELTY"
  ],
  [
    "There are a lot of extremely interesting ideas in this paper",
    "NOVELTY"
  ],
  [
    "my limited knowledge could not help me to fully understand the theoretical novelty .",
    "NOVELTY"
  ],
  [
    "The suggested algorithm ( SA ) is also new to field with various strengths against other baseline methods .",
    "NOVELTY"
  ],
  [
    "as a new pioneer of ERM under EBC",
    "NOVELTY"
  ],
  [
    "While none of the pieces of this model are particularly novel",
    "NOVELTY"
  ],
  [
    "Joint training of word and document embeddings is not a new idea",
    "NOVELTY"
  ],
  [
    "Coupled with the word2vec-style loss and training methods , this paper offers little on the novelty front .",
    "NOVELTY"
  ],
  [
    "despite the lack of novelty",
    "NOVELTY"
  ],
  [
    "The idea of using user studies to elicit the relevant notion of \u00e2\u0080\u009cinterpretability\u00e2\u0080\u009d is an interesting one .",
    "NOVELTY"
  ],
  [
    "which is quite novel and interesting",
    "NOVELTY"
  ],
  [
    "I like the novel idea of channel-wise search space , which provides great flexibility for NAS .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and the result looks promising",
    "NOVELTY"
  ],
  [
    "The originality of the work is not clearly defined .",
    "NOVELTY"
  ],
  [
    "it is not easy to assess the novelty of the paper .",
    "NOVELTY"
  ],
  [
    "The paper overall looks interesting with some nice ideas .",
    "NOVELTY"
  ],
  [
    "The main idea of this work is interesting .",
    "NOVELTY"
  ],
  [
    "and",
    "NOVELTY"
  ],
  [
    "The sensitivity analysis , with upper and lower bounds , is insightful as well as leading to a practical algorithm .",
    "NOVELTY"
  ],
  [
    "The proposed compression scheme involves significant novelty .",
    "NOVELTY"
  ],
  [
    "This paper",
    "NOVELTY"
  ],
  [
    "Therefore , the setup of this problem seems novel",
    "NOVELTY"
  ],
  [
    "this feels a bit too simplistic .",
    "NOVELTY"
  ],
  [
    "This reviewer feels that augmenting a 2-hidden-layer VAE with a softmax classification layer does not seem to be a very significant new contribution by itself .",
    "NOVELTY"
  ],
  [
    "but the relative amount of novelty might to be somewhat limited when viewed from this perspective",
    "NOVELTY"
  ],
  [
    "but not ground breaking",
    "NOVELTY"
  ],
  [
    "and the idea is fairly straight forward",
    "NOVELTY"
  ],
  [
    "As such , the originality is limited .",
    "NOVELTY"
  ],
  [
    "I like the idea of connecting signal processing with recurrent network and then using tools from one setting in the other .",
    "NOVELTY"
  ],
  [
    "1 .The novelty of the proposed algorithm did not come out properly- the concept of keeping upper/lower confidence bounds for arms reward distribution are already prevalent in MAB literature",
    "NOVELTY"
  ],
  [
    "The idea behind the algorithm is not particularly novel .",
    "NOVELTY"
  ],
  [
    "There is no new novel contribution on the methods side .",
    "NOVELTY"
  ],
  [
    "Technical novelty : while they address a problem that has not yet seen much attention , their solution is combination existing solutions .",
    "NOVELTY"
  ],
  [
    "auxiliary loss has not been experimentally shown to be crucial and therefore the technical novelty may be relatively limited",
    "NOVELTY"
  ],
  [
    "The idea is simple and novel .",
    "NOVELTY"
  ],
  [
    "The theoretical results are new and important . The experiments ( on a large taxi domain ) are convincing . Overall , the paper advances the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "and the method is interesting",
    "NOVELTY"
  ],
  [
    "I found this paper generally insightful and well thought .",
    "NOVELTY"
  ],
  [
    "these are nice efforts",
    "NOVELTY"
  ],
  [
    ", and single-source robustness is novel .",
    "NOVELTY"
  ],
  [
    "-The proposed latent ensemble layer is not a very novel way to fuse features .",
    "NOVELTY"
  ],
  [
    "which is a reasonable way of fusion but without much novelty",
    "NOVELTY"
  ],
  [
    "It goes pretty much against the current trend of unified the deep learning black box and therefore is sufficiently original on its own .",
    "NOVELTY"
  ],
  [
    ", showing significant improvement over the state of the art",
    "NOVELTY"
  ],
  [
    "The paper provides an interesting take on the old idea of layer models and the performance evaluation on the two datasets",
    "NOVELTY"
  ],
  [
    "The individual parts of this work",
    "NOVELTY"
  ],
  [
    "so nothing stands out as original",
    "NOVELTY"
  ],
  [
    "however the combination of existing ideas",
    "NOVELTY"
  ],
  [
    "The proposed framework is novel and the idea",
    "NOVELTY"
  ],
  [
    "The idea of using dynamic programming to integrate the effect of the new evaluations in future decisions is a natural one",
    "NOVELTY"
  ],
  [
    "I think that this work is an incremental contribution to the Bayesian optimization literature .",
    "NOVELTY"
  ],
  [
    "Limited technical contribution",
    "NOVELTY"
  ],
  [
    "and simply applying this idea to learning-to-rank application does not seem to be a big contribution .",
    "NOVELTY"
  ],
  [
    "I think the idea is interesting and novel .",
    "NOVELTY"
  ],
  [
    "Overall assessment : I find the analytical results of the paper very original and interesting .",
    "NOVELTY"
  ],
  [
    "I think this is all very nice and original .",
    "NOVELTY"
  ],
  [
    "4 .No major novelty is introduced .",
    "NOVELTY"
  ],
  [
    "The high level idea of this paper is very interesting and attractive , and in particular , the introduction of continuous-time reinforcement learning is novel .",
    "NOVELTY"
  ],
  [
    "although I think the paper is interesting and novel on the high level",
    "NOVELTY"
  ],
  [
    "but in my understanding very incremental .",
    "NOVELTY"
  ],
  [
    "The idea of applying transformations to minimize MMD between two sources seems new and interesting ,",
    "NOVELTY"
  ],
  [
    "but rather straight forward given previous work on MMD hypothesis testing",
    "NOVELTY"
  ],
  [
    "My main issue with the paper is that its conceptual contribution seems limited and unclear .",
    "NOVELTY"
  ],
  [
    "overall topic of",
    "NOVELTY"
  ],
  [
    "I currently find the conceptual contribution to be too thin , raising doubts on novelty and significance .",
    "NOVELTY"
  ],
  [
    "The problem formulation , algorithm , and analysis of the algorithm appear to be novel and original .",
    "NOVELTY"
  ],
  [
    "The proposed UPM approach is novel and significant",
    "NOVELTY"
  ],
  [
    "The approach of using robust features is interesting and promising , as well as the idea of training on multiple languages .",
    "NOVELTY"
  ],
  [
    "I found the idea of the paper interesting",
    "NOVELTY"
  ],
  [
    "While I find the idea of incorporating information geometry into embeddings very promising",
    "NOVELTY"
  ],
  [
    "the experiments are not particularly insightful .",
    "NOVELTY"
  ],
  [
    "it does n't seem very novel ,",
    "NOVELTY"
  ],
  [
    "My main concerns are over the originality ( it seems very similar to [ 34 ] ) , and the weakness of the experiments .",
    "NOVELTY"
  ],
  [
    "The experimental data is simple , but the model is very interesting and relatively novel .",
    "NOVELTY"
  ],
  [
    "I like the idea of using hypersphere as the output space despite the possible technical difficulties .",
    "NOVELTY"
  ],
  [
    "This approach to density matching is new to me .",
    "NOVELTY"
  ],
  [
    "Overall , I think the technical contribution is strong .",
    "NOVELTY"
  ],
  [
    "In light of this prior work , I do not believe the idea or current results alone are sufficiently novel or impressive to carry the paper .",
    "NOVELTY"
  ],
  [
    "The first is that the method is rather incremental and I am uncertain how it will stand the test of time and will be adopted .",
    "NOVELTY"
  ],
  [
    "While the idea of using random weights in neural representations is very common , the way it is done here , and , in particular , the quality of the results attained seems like a nice contribution .",
    "NOVELTY"
  ],
  [
    "This is a nice paper that takes",
    "NOVELTY"
  ],
  [
    "a unitary matrix even though this specific subject matter was rather new to me",
    "NOVELTY"
  ],
  [
    "I consider the technical contribution both solid and interesting , as it connects iterative methods and numerical analysis in a novel way .",
    "NOVELTY"
  ],
  [
    "I find the connection between the numerical techniques to extrapolate limits of sequences in this paper and the study of accelerated methods very interesting ,",
    "NOVELTY"
  ],
  [
    "-- Originality -- I believe the work is original . The paper explores a natural idea and the claims/results are not surprising",
    "NOVELTY"
  ],
  [
    "Therefore I believe the impact of the paper to be limited .",
    "NOVELTY"
  ],
  [
    "I , therefore , assume that this work is novel .",
    "NOVELTY"
  ],
  [
    "Detailed comments I enjoyed the concept and",
    "NOVELTY"
  ],
  [
    "albeit incremental paper",
    "NOVELTY"
  ],
  [
    "The proposed idea is not very original .",
    "NOVELTY"
  ],
  [
    "Despite the lack of novelty of the method",
    "NOVELTY"
  ],
  [
    "The idea is not very original .",
    "NOVELTY"
  ],
  [
    "I believe this a relatively incremental approach .",
    "NOVELTY"
  ],
  [
    "The idea on how to utilise the unlabeled test data to realise tranductive learning is novel",
    "NOVELTY"
  ],
  [
    "The authors make clear that the particular algorithms used in this approach are not novel , but that does not detract from the importance of the submission",
    "NOVELTY"
  ],
  [
    "seems to me to slightly diminish the novelty of the work",
    "NOVELTY"
  ],
  [
    "In this sense , the paper is not novel although I agree this paper has added an additional insight that",
    "NOVELTY"
  ],
  [
    ", and the novelty appears fairly low",
    "NOVELTY"
  ],
  [
    "it is unclear if Theorem 2 and Theorem 3 are both being stated as novel results",
    "NOVELTY"
  ],
  [
    "One of my main concerns is the novelty of this paper . Many of the solutions in the paper have already been discovered in literature .",
    "NOVELTY"
  ],
  [
    "Combining neuron alignment with mode connectivity seems to be a good idea",
    "NOVELTY"
  ],
  [
    "the idea seems to be interesting",
    "NOVELTY"
  ],
  [
    "I like the high-level idea of this work and agree that there is not much work on using prediction explanations to help improve model performance",
    "NOVELTY"
  ],
  [
    "I like the idea of using explanations to help build a better classifier",
    "NOVELTY"
  ],
  [
    "The intuition of the model is similar to existing curriculum base model ( e.g .MentorNet",
    "NOVELTY"
  ],
  [
    "but the approach to estimate the weight of each example",
    "NOVELTY"
  ],
  [
    "is new",
    "NOVELTY"
  ],
  [
    "the proposed curriculum based approach outperforms existing curriculum based approaches like MentorNet",
    "NOVELTY"
  ],
  [
    "but based on simple ideas",
    "NOVELTY"
  ],
  [
    "The idea of putting a mixture model on the global parameters is not surprising",
    "NOVELTY"
  ],
  [
    "This paper",
    "NOVELTY"
  ],
  [
    "vs. 1 feedback caption is insightful and interesting",
    "NOVELTY"
  ],
  [
    "The paper is overall a good contribution .",
    "NOVELTY"
  ],
  [
    "The idea of how to formulate the classifier set and how to sample from the set is interesting .",
    "NOVELTY"
  ],
  [
    "As far as I know , the proposed method is a novel and clever ( though not ground-breaking ) contribution to the field of performing global structure inference over TGKs .",
    "NOVELTY"
  ],
  [
    "it looks like this is the first paper that extends existing literature into the stochastic parametric bandit setting .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the present work provides first theoretical insights into mode connectivity for general deep neural networks .",
    "NOVELTY"
  ],
  [
    "The constructions in the proofs are interesting and fairly intuitive .",
    "NOVELTY"
  ],
  [
    "While the proposed idea is interesting",
    "NOVELTY"
  ],
  [
    ", many of the core ideas seem to have been proposed in earlier work (",
    "NOVELTY"
  ],
  [
    "and the novel contributions of this work are not clearly explained .",
    "NOVELTY"
  ],
  [
    "Though the proposed model is very simple --",
    "NOVELTY"
  ],
  [
    "the inference is nontrival and the work combines a few interesting tricks",
    "NOVELTY"
  ],
  [
    "The contribution , a scheme for hierarchical RL ( HRL ) in the online , on-policy setting , where the low-level policies are adapted , using the advantage function of the high level policy , seams to be novel , is elegant and might be a real improvement for HRL .",
    "NOVELTY"
  ],
  [
    "The pairing of simulation with trail navigation is an interesting idea",
    "NOVELTY"
  ],
  [
    ", and is not much of a contribution to the research problem",
    "NOVELTY"
  ],
  [
    "Leveraging a triplet loss for this problem may have some novelty",
    "NOVELTY"
  ],
  [
    "although it may be somewhat limited given some concurrent work",
    "NOVELTY"
  ],
  [
    "Given the similarity of the developed approach , it somewhat limits the novelty of the proposed approach in my view",
    "NOVELTY"
  ],
  [
    "The core idea is quite elegant",
    "NOVELTY"
  ],
  [
    "I think",
    "NOVELTY"
  ],
  [
    "and includes many insightful experimental findings Con",
    "NOVELTY"
  ],
  [
    "Although C is practical and novel contribution",
    "NOVELTY"
  ],
  [
    "The main idea is sensible",
    "NOVELTY"
  ],
  [
    "though distilling into the same architecture ( sFEED ) is not that novel .",
    "NOVELTY"
  ],
  [
    "The latter result is the most interesting contribution of the paper .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , their model is novel .",
    "NOVELTY"
  ],
  [
    "Technical novelty over LARS seems to be incremental , where a large portion of the work is essentially applying LARS to Adam and demonstrate its effectiveness on BERT and ResNet",
    "NOVELTY"
  ],
  [
    "find this a nice piece of",
    "NOVELTY"
  ],
  [
    "This is potentially a very significant contribution which could become the next state-of-the-art optimization method for deep learning .",
    "NOVELTY"
  ],
  [
    "However I still feel like the novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "-- A major drawback is that the novelty and contribution is rather limited .",
    "NOVELTY"
  ],
  [
    "The kernelized version is very similar to the Kernel-based tensor PLS regression which can be found in the paper",
    "NOVELTY"
  ],
  [
    "Doing curriculum training when there is a measure of difficulty , is not new .",
    "NOVELTY"
  ],
  [
    "Interesting work and good contribution",
    "NOVELTY"
  ],
  [
    "The proposed interpretability discrepancy measure is novel and has been proven effective to defend interpretability sneaking attacks that aiming to fool both classifiers and detectors and against interpretability-only attacks .",
    "NOVELTY"
  ],
  [
    "and makes new and non-trivial contributions to model inference and the application .",
    "NOVELTY"
  ],
  [
    "Fairly incremental extension of the PG ( and TRPO ) with the conditioning on the potentially ( unobserved ) input variables .",
    "NOVELTY"
  ],
  [
    "and hence is of less novelty",
    "NOVELTY"
  ],
  [
    "+The information theory based derivation of learning disentangled codes is somewhat novel , although it bears similar theoretical background with wake-sleep algorithm and variational auto-encoders",
    "NOVELTY"
  ],
  [
    "To my knowledge , the approach presented in the paper is novel",
    "NOVELTY"
  ],
  [
    "Constructing individualized feature space tailored to each query is a novel idea .",
    "NOVELTY"
  ],
  [
    "so the contribution of this paper is very limited .",
    "NOVELTY"
  ],
  [
    "I am not sure that video-to-video translation is new",
    "NOVELTY"
  ],
  [
    "I am not sure how the metrics are new .",
    "NOVELTY"
  ],
  [
    ", and the approach is novel and interesting .",
    "NOVELTY"
  ],
  [
    ", and to my knowledge the contribution is novel .",
    "NOVELTY"
  ],
  [
    "The use of encoder-decoder for fMRI decoding is not new .",
    "NOVELTY"
  ],
  [
    "This is clever and inspiring .",
    "NOVELTY"
  ],
  [
    "Although the method is interesting and has novelty",
    "NOVELTY"
  ],
  [
    "the neuroscientific insight is limited .",
    "NOVELTY"
  ],
  [
    "The authors can argue that the introduction of dynamically adjustable momentum and noise can make the paper novel and unique .",
    "NOVELTY"
  ],
  [
    "3 .For the experiments , the authors introduced ResNet++ architecture which is based on ResNet architecture but is novel in its design with the use of SELU and removal of BatchNorm and with different initialization schemes .",
    "NOVELTY"
  ],
  [
    "The proposed method as well is novel and outperforms similar algorithms in the experimental evaluation",
    "NOVELTY"
  ],
  [
    ", proposes a novel Neuro-Symbolic approach to the classical SAT problem , and",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed approach is novel .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is novel and",
    "NOVELTY"
  ],
  [
    "In terms of methodology , using gumbel trick for learning routing matrix seems new to my knowledge .",
    "NOVELTY"
  ],
  [
    "I like the idea of using this trick to make the learning of routing network unified under optimization compared to the learning in the original routing network .",
    "NOVELTY"
  ],
  [
    "Overall , I find the idea of using gumbel trick for learning routing networks interesting .",
    "NOVELTY"
  ],
  [
    "The idea is original and",
    "NOVELTY"
  ],
  [
    "I still think this is a very interesting , novel and relevant idea that desires attention",
    "NOVELTY"
  ],
  [
    "2 .It is the first theoretical analysis that provides the errors of the neural FQI algorithm with a ReLU network",
    "NOVELTY"
  ],
  [
    "I do not consider the contribution of this paper substantial given the fact the a more involved framework",
    "NOVELTY"
  ],
  [
    "I am not very much convinced that the proposed approach is brand-new .",
    "NOVELTY"
  ],
  [
    "However the addition of Hawkes process while maintaining advantages of GP appear novel to me and more elegant than previous discrete time approaches .",
    "NOVELTY"
  ],
  [
    "and some interesting inference",
    "NOVELTY"
  ],
  [
    "Combination of Hawkes process and GP was new to me and interesting to see .",
    "NOVELTY"
  ],
  [
    "While I find the idea to be potentially interesting",
    "NOVELTY"
  ],
  [
    "but I \u2019 m not sure that this approach is different enough from CycleGAN",
    "NOVELTY"
  ],
  [
    "While the idea of scoring evaluation expansions is not novel , applying it to the EVAL function is Cons",
    "NOVELTY"
  ],
  [
    "Novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "This is less novel than the authors seem to claim",
    "NOVELTY"
  ],
  [
    "the proposed system is not related to the focus of ICLR and it lacks the novelty .",
    "NOVELTY"
  ],
  [
    "The ideas it develops are very interesting and promising , and I am sure they will lead to many new insights in two-sample tests and relative issues",
    "NOVELTY"
  ],
  [
    "in the process of doing so the authors appear to have developed a good amount of new theory .",
    "NOVELTY"
  ],
  [
    "The work presented in the paper is original and aims to answer some open questions arising from famous findings in research on attractiveness .",
    "NOVELTY"
  ],
  [
    "highly interesting paper that proposes a set of methods that combine ideas from imitation learning , evolutionary computation and reinforcement learning in a novel way",
    "NOVELTY"
  ],
  [
    "I think the proposed method is genuinely novel",
    "NOVELTY"
  ],
  [
    "novelty of idea - crossover visualization , analysis - scalability Cons",
    "NOVELTY"
  ],
  [
    "I think this is a good paper presenting a sensible idea",
    "NOVELTY"
  ],
  [
    "The extent of technical novelty is somewhat limited .",
    "NOVELTY"
  ],
  [
    "The proposed method is simple and maybe novel .",
    "NOVELTY"
  ],
  [
    "The authors propose a nice framework for interpreting differentiable",
    "NOVELTY"
  ],
  [
    "LEG is a nice generalization of multiple existing approaches .",
    "NOVELTY"
  ],
  [
    "the authors do this with simple and naive tools which will not scale to complex tasks , offering no new insights or advances to the field .",
    "NOVELTY"
  ],
  [
    "The contribution of this work is not on par with ICLR standard for conference papers .",
    "NOVELTY"
  ],
  [
    "This paper provides us with a novel insight that searching neural architecture on the channel level instead of operation and connection level .",
    "NOVELTY"
  ],
  [
    "it just combines NAS and pruning parts together , which lacks of novelty in the algorithm level .",
    "NOVELTY"
  ],
  [
    "it lacks of novelty",
    "NOVELTY"
  ],
  [
    "Both parts are the same as previous works almost and there is no innovation and improvements .",
    "NOVELTY"
  ],
  [
    "The paper describes a novel model for image compression that uses neural networks",
    "NOVELTY"
  ],
  [
    "I found the authors ' perspective on variational inference as a form of importance sampling to be illuminating",
    "NOVELTY"
  ],
  [
    "as far as I can tell the proposed bound is new",
    "NOVELTY"
  ],
  [
    "The permutation objective seems very similar to the XLNet objective .",
    "NOVELTY"
  ],
  [
    "My major concerns for this submission are its clarity",
    "NOVELTY"
  ],
  [
    "and theoretical depth .",
    "NOVELTY"
  ],
  [
    "There is no novelty here",
    "NOVELTY"
  ],
  [
    "The idea and the proposed model are not novel .",
    "NOVELTY"
  ],
  [
    "Novel idea",
    "NOVELTY"
  ],
  [
    "I liked the idea and motivation of the paper",
    "NOVELTY"
  ],
  [
    "I think that originality is somewhat limited in this paper",
    "NOVELTY"
  ],
  [
    "this paper",
    "NOVELTY"
  ],
  [
    "proposes an interesting trick that seems to work in practice but the novelty remains limited",
    "NOVELTY"
  ],
  [
    "ve found the paper very interesting and promising but",
    "NOVELTY"
  ],
  [
    "The idea of using integral image for convolutions and learn the filter size and position is new in my knowledge and seems to",
    "NOVELTY"
  ],
  [
    "without relying on several convutional layers",
    "NOVELTY"
  ],
  [
    "Novelty is quite limited .",
    "NOVELTY"
  ],
  [
    "as the main contribution of this work , GLCM is proposed from Haralick et al . ( 1973 ) , which is not novel .",
    "NOVELTY"
  ],
  [
    "the network structure used in this work is also based on SRGAN/EDSRGAN , which is also not novel .",
    "NOVELTY"
  ],
  [
    "but the paper is not mature enough .",
    "NOVELTY"
  ],
  [
    "the contributions are significant .",
    "NOVELTY"
  ],
  [
    "The work is novel and the derivation appears",
    "NOVELTY"
  ],
  [
    "This is very original work .",
    "NOVELTY"
  ],
  [
    "The idea of formulating the L_MIM objective appears interesting , which uses the mixture of P_\\theta and Q_\\theta and minimizes an upper bound to H ( x ) + H",
    "NOVELTY"
  ],
  [
    "- I ( x , z ) , so it is effectively minimizing a lower bound to I ( x , z ) , under the proposed symmetric distribution .",
    "NOVELTY"
  ],
  [
    "One big concern that I have about this paper is technical depth and novelty",
    "NOVELTY"
  ],
  [
    "It appears that using anomaly detection to fund performance problems is not new or novel",
    "NOVELTY"
  ],
  [
    "So what we are left with is a solidly-written paper that applies a standard anomaly detection methodology to a problem that has been studied previously .",
    "NOVELTY"
  ],
  [
    "I believe this is a strong paper and it represents an interesting contribution for the community .",
    "NOVELTY"
  ],
  [
    "It is an interesting and reasonable idea for defence against adversarial attacks to combine adversarial training and randomness in a NN ( bringing randomness into a new level in the form of a BNN ) ,",
    "NOVELTY"
  ],
  [
    "random NN alone .",
    "NOVELTY"
  ],
  [
    "the main idea appears to be novel",
    "NOVELTY"
  ],
  [
    "the quality of the paper is poor and the originality of the work is low .",
    "NOVELTY"
  ],
  [
    "This work lacks novelty as the only contribution is quite simply a Monte Carlo average of a fixed number of ALDs",
    "NOVELTY"
  ],
  [
    "As far as I \u2019 m aware , this is a novel and noteworthy contribution .",
    "NOVELTY"
  ],
  [
    "Limited novelty .",
    "NOVELTY"
  ],
  [
    "In terms of impact , its novelty is limited",
    "NOVELTY"
  ],
  [
    "The idea of modeling deep learning computation is not in itself particularly novel .",
    "NOVELTY"
  ],
  [
    "proposes algorithm for self-supervised learning",
    "NOVELTY"
  ],
  [
    "JVI seems to be an interesting extension of , and perspective on , the IWAE bound ( and other Monte Carlo",
    "NOVELTY"
  ],
  [
    "Overall the paper is gives new and original ideas about using hashing for making deterministic classifiers from stochastic classifiers",
    "NOVELTY"
  ],
  [
    "the results do not offer a lot of new insights .",
    "NOVELTY"
  ],
  [
    "The method is novel and simple while strongly reducing variance in Monte Carlo policy gradient estimates without inducing bias .",
    "NOVELTY"
  ],
  [
    "the paper appears correct and novel .",
    "NOVELTY"
  ],
  [
    ", the auction approach is a nice idea/novel .",
    "NOVELTY"
  ],
  [
    "The notion of using 'scarce ' training domains to cover possible choices for the target domain is interesting and novel .",
    "NOVELTY"
  ],
  [
    "I still think the contribution of this paper is not enough as",
    "NOVELTY"
  ],
  [
    "the only novelty of this work is the proposed factorization and not the encoding scheme .",
    "NOVELTY"
  ],
  [
    "Though the method isn\u00e2\u0080\u0099t necessarily novel",
    "NOVELTY"
  ],
  [
    "and unfortunately it is hard to capture the contribution of this paper though with some interesting properties",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "I think that the novelty in the current submission is limited",
    "NOVELTY"
  ],
  [
    "The proposed method is intuitive and natural .",
    "NOVELTY"
  ],
  [
    "The definition of this covariance function constitutes one of the major contributions of this work .",
    "NOVELTY"
  ],
  [
    "and there are at least two novel contributions",
    "NOVELTY"
  ],
  [
    "This is a unique contribution to this field .",
    "NOVELTY"
  ],
  [
    "Despite the focus of the paper on empirical evaluation , the paper contributes new insights that relate kernel approximation methods to neural networks .",
    "NOVELTY"
  ],
  [
    "I think that the contribution of the paper is still short of what is expected for the conference .",
    "NOVELTY"
  ],
  [
    "the only real innovation here is to use the LSTM to learn a search heuristic .",
    "NOVELTY"
  ],
  [
    "Many of the ideas here are reminiscent of methods existing in those communities",
    "NOVELTY"
  ],
  [
    "The formulation of the method seems interesting",
    "NOVELTY"
  ],
  [
    "and thus the contribution to machine learning appears limited",
    "NOVELTY"
  ],
  [
    "I like the approach .",
    "NOVELTY"
  ],
  [
    "The variational method used seems very similar to that of [ 4",
    "NOVELTY"
  ],
  [
    "The basic idea of repurposing locally-learned representations for large-scale attention where backprop would normally be prohibitively expensive is an interesting one , and could probably be used to improve other types of memory networks .",
    "NOVELTY"
  ],
  [
    "My main criticism of this work is its simplicity and incrementality when compared to previously existing literature .",
    "NOVELTY"
  ],
  [
    "and the paper \u2019 s novel approach is noteworthy in itself .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper may be limited , as it needs a specific setting , as shown in Figure 1",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is somewhat limited , as it requires a specific setting and has been applied in only one domain .",
    "NOVELTY"
  ],
  [
    "It is an incremental modification of prior work ( ResNeXt ) that performs better on several experiments selected by the author",
    "NOVELTY"
  ],
  [
    "I think this paper contains some novelty inside",
    "NOVELTY"
  ],
  [
    "Using a coarse-to-fine generator is an interesting idea .",
    "NOVELTY"
  ],
  [
    "I think this is a decent contribution",
    "NOVELTY"
  ],
  [
    "it seems to be the only contribution of this paper .",
    "NOVELTY"
  ],
  [
    "Basically , I like this paper and I think it makes a certain contribution to this line of researches .",
    "NOVELTY"
  ],
  [
    "The notion of attaching the weights that represent the training set to the activations that accord with the test set in a theoretical framework is interesting .",
    "NOVELTY"
  ],
  [
    "Even though the paper addresses the interesting and challenging problem of slow adaption when distribution shifts",
    "NOVELTY"
  ],
  [
    "H-detach is simple , effective , and somewhat novel ( see below ) .",
    "NOVELTY"
  ],
  [
    "The idea of defining weights as samples from a Mixture of Gaussians is interesting .",
    "NOVELTY"
  ],
  [
    "Although the provided novel algorithm looks",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "approach is not new , but seems to be a sensible and simple solution to the problem formulated in this paper . I would see the contributions of the paper : ( 1 ) an interesting problem formulation on how to learn p_t (",
    "NOVELTY"
  ],
  [
    ")",
    "NOVELTY"
  ],
  [
    "The training appaoches/tricks are rather straightforward and not new as well",
    "NOVELTY"
  ],
  [
    "I did n't see any contributions here as the theories developed in section 3 are mostly rather straightforward",
    "NOVELTY"
  ],
  [
    "and this paper makes an interesting contribution in that direction",
    "NOVELTY"
  ],
  [
    "Having an efficient way of performing a bi-directional coding scheme is very interesting .",
    "NOVELTY"
  ],
  [
    "Overall the paper seems like a good contribution .",
    "NOVELTY"
  ],
  [
    "Overall , the idea is quite interesting and new .",
    "NOVELTY"
  ],
  [
    "The approach is innovative",
    "NOVELTY"
  ],
  [
    "An important advantage of the work is that the learned policy is not restricted to a fixed problem size , in contrast to earlier work",
    "NOVELTY"
  ],
  [
    "This insight is simple , elegant",
    "NOVELTY"
  ],
  [
    "2 .Lack of novelty .",
    "NOVELTY"
  ],
  [
    "Summary- This paper proposes a novel and interesting way of training and doing inference in encoder-decoder style deep generative models .",
    "NOVELTY"
  ],
  [
    "The model is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Overall The proposed model is novel and has many desirable properties .",
    "NOVELTY"
  ],
  [
    "I appreciate the use of DPCCA which is definitely new to the neuroimaging data analysis domain .",
    "NOVELTY"
  ],
  [
    "Although I like the idea and it seems a very interesting direction for generalisation to new goals",
    "NOVELTY"
  ],
  [
    "but I think this instantiation is ( fairly ) incremental with respect to the current literature . Even the claimed contributions are a bit thin .",
    "NOVELTY"
  ],
  [
    "is a novel contribution in recommendation systems",
    "NOVELTY"
  ],
  [
    "it is unclear to me if there is any novelty in the approach",
    "NOVELTY"
  ],
  [
    "and the high-level ideas are novel and interesting .",
    "NOVELTY"
  ],
  [
    "I think the proposed approach is a novel way to achieve model bootstrapping ,",
    "NOVELTY"
  ],
  [
    "I believe this work is already a good contribution to NeurIPS",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge it is the first such algorithm to offer any convergence guarantees , and also has the potential to scale to very large problems",
    "NOVELTY"
  ],
  [
    "4976 is a very promising piece of work there is definitely substantial-enough contributions for a NIPS paper",
    "NOVELTY"
  ],
  [
    "Due to these two citations , the novelty of both the problem set-up of learning different embeddings for each covariate and the novelty of the tensor factorization based model are limited .",
    "NOVELTY"
  ],
  [
    "covariate-specific analogies are a creative analysis CONS",
    "NOVELTY"
  ],
  [
    "problem set-up not novel and existing approach not cited",
    "NOVELTY"
  ],
  [
    "While the idea is quite elegant and novel ( I enjoy reading it )",
    "NOVELTY"
  ],
  [
    "Overall , I am convinced with the technical novelty and that the method can be promising .",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "The proposed models seem very basic and do not have much novelty .",
    "NOVELTY"
  ],
  [
    "The idea of addressing finite-sum problems through augmented Lagrangian and ADMM type algorithm is straightforward but new . Convergence results of the new randomized variation for non-convex problems are also novel , to my best knowledge .",
    "NOVELTY"
  ],
  [
    "Overall , the idea of using reinforcement learning for continual learning is an interesting one ,",
    "NOVELTY"
  ],
  [
    "The model is simple , and propose novel attention regularization terms .",
    "NOVELTY"
  ],
  [
    "-There is not much novelty in Theorems 1,2,3 since similar results already appeared in Reddi et al .-Also",
    "NOVELTY"
  ],
  [
    ".This is a great paper that takes a refreshing and a novel view on an interesting line of works",
    "NOVELTY"
  ],
  [
    "learning how to optimize , is very seducing and the experimental evaluations",
    "NOVELTY"
  ],
  [
    "So I judge the technical novelty is somewhat limited .",
    "NOVELTY"
  ],
  [
    "Technical novelty is limited",
    "NOVELTY"
  ],
  [
    "To my best knowledge this is the first rigorous analysis of support stability using L0 and L\\infty losses",
    "NOVELTY"
  ],
  [
    "I like the approach taken by this paper .",
    "NOVELTY"
  ],
  [
    "despite being non-trivial , the results are not very surprising",
    "NOVELTY"
  ],
  [
    "I think",
    "NOVELTY"
  ],
  [
    "that while the paper provides and",
    "NOVELTY"
  ],
  [
    ", it is somewhat lacking in novelty in that it uses a fairly straightforward model parameterization and optimization solution without strong experimental backing .",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is very marginal",
    "NOVELTY"
  ],
  [
    "The network architecture proposed does not differ from previous LISTA-style methods and the only difference is essentially in the way you input the data",
    "NOVELTY"
  ],
  [
    "The methodology itself is a bit trivial to me , since the bi-LSTM-CNN and self-attention mechanism were already proposed previously",
    "NOVELTY"
  ],
  [
    "4 .The network proposed in this paper is just a simple CNN",
    "NOVELTY"
  ],
  [
    "The idea used in this paper for graph nodes sampling is interesting .",
    "NOVELTY"
  ],
  [
    "and to the best of my knowledge I confirm this claim",
    "NOVELTY"
  ],
  [
    "On a skeptical note , these contributions can be viewed as rather straightforward technical adaptations to apply knowledge distillation to a related but novel task , object detection . In this regard , the goal may be considered a low-hanging fruit and the contributions as incremental .",
    "NOVELTY"
  ],
  [
    "The idea using instance selection is not new . The novelty could be improved .",
    "NOVELTY"
  ],
  [
    "This paper presents the first study of tree search for optimal actions in the presence of pretrained value and policy networks .",
    "NOVELTY"
  ],
  [
    "To me the proposed approach does not seem particularly novel and the idea that hierarchy can be useful for multi-task learning is also not new .",
    "NOVELTY"
  ],
  [
    "I have tried going through the paper a few times and the contribution is not immediately obvious",
    "NOVELTY"
  ],
  [
    "If this is the case , I feel like the empirical results are not novel enough to create value for the community and too tied to a particular approach to hierarchy which does not align with much of the past work on HRL .",
    "NOVELTY"
  ],
  [
    "The authors claimed that the proposed new evaluation metrics are novel contributions of the paper",
    "NOVELTY"
  ],
  [
    "Although the novelty is limited ,",
    "NOVELTY"
  ],
  [
    "In my opinion , it is not sufficiently novel to consider acceptance of this work into the paper track at ICLR .",
    "NOVELTY"
  ],
  [
    "In terms of technical contributions , the problem of undefined transitions in the probability tensor has been tackled already in previous work [ 4 ] .",
    "NOVELTY"
  ],
  [
    "This is a original contribution with potential in the field .",
    "NOVELTY"
  ],
  [
    "Since the proposed method is quite incremental over the prior work",
    "NOVELTY"
  ],
  [
    "The idea of using a GAN is to generate images in input space is not novel by itself .",
    "NOVELTY"
  ],
  [
    "because the paper lacks precision and the contribution is not significant",
    "NOVELTY"
  ],
  [
    "but this has little contribution on its own and has little to do with Amharic .",
    "NOVELTY"
  ],
  [
    "Unfortunately this work lacks novelty and is n't",
    "NOVELTY"
  ],
  [
    "yet very interesting .",
    "NOVELTY"
  ],
  [
    "this is a strong paper with a novel coreset construction for least square regression .",
    "NOVELTY"
  ],
  [
    "While generalized forms of self attention are a good idea , the paper strongly emphasizes that it is a novel idea .",
    "NOVELTY"
  ],
  [
    "although the idea is quite incremental",
    "NOVELTY"
  ],
  [
    "I do n't think this paper brings out some real contributions to the community and should not be accepted",
    "NOVELTY"
  ],
  [
    "and present a significant contribution",
    "NOVELTY"
  ],
  [
    "making some technical contributions of the paper not novel .",
    "NOVELTY"
  ],
  [
    "Unfortunately , I believe that the work is a bit incremental , most of the technical contributions having already been published .",
    "NOVELTY"
  ],
  [
    "I would tend to reject this article because there is no innovation in ML that would justify presentation at ICLR",
    "NOVELTY"
  ],
  [
    "the ML aspect of this work is entirely based on prior art , the main innovation consisting in fitting a linear classifier on concatenated features extracted by two existing embedding methods",
    "NOVELTY"
  ],
  [
    "Originality As far as I can tell , this is the first offline contextual bandit algorithm that satisfies a user defined fairness constraints .",
    "NOVELTY"
  ],
  [
    "In general , the goal of developing algorithms that satisfy user defined fairness definitions is not new",
    "NOVELTY"
  ],
  [
    "however , the formulation in this paper is new , challenging , and interesting in the offline batch setting .",
    "NOVELTY"
  ],
  [
    "In terms of novelty , I think the paper passes the required bar .",
    "NOVELTY"
  ],
  [
    "and this paper is one of the first papers that adresses it",
    "NOVELTY"
  ],
  [
    "I really liked the idea of modeling MAML-like approaches using nonparametric Bayesian priors and I am not familiar with other work that does that . Thus , I consider the proposed method novel . More specifically , I consider it a novel combination of existing methods , that exploits an interesting connection between them .",
    "NOVELTY"
  ],
  [
    "This papers propose a novel Siamese network structure and novel losses to ensure the framework learns more pose-invariant features for robust person reID .",
    "NOVELTY"
  ],
  [
    "First I think this mechanism itself 's contribution is kind of incremental because this technique is well under the PGD adversarial training framework",
    "NOVELTY"
  ],
  [
    "Using beam search on tree outputs is a bit of a minor contribution .",
    "NOVELTY"
  ],
  [
    "but I think the paper presents an interesting approach for reducing activation memory requirements of modern CNNs",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "there are new contributions and results",
    "NOVELTY"
  ],
  [
    "With lack of clear novel insights , or at least more systematic study on additional datasets of the 'winning ' techniques and a sensitivity analysis , the paper does not give a valuable enough contribution to the field to merit publication .",
    "NOVELTY"
  ],
  [
    "The motivation using cyclic feedback itself is not so novel for language generation ,",
    "NOVELTY"
  ],
  [
    "the overall technique is not very novel .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is of rather limited novelty , as it is very similar to the work of Lea et al. , 2017 , where now the decoder part also has the deconvolutions smoothened by ( bidirectional ) LSTMs .",
    "NOVELTY"
  ],
  [
    "I believe the paper indeed improves over existing baselines",
    "NOVELTY"
  ],
  [
    "the novelty is insufficient for a publication at this stage .",
    "NOVELTY"
  ],
  [
    "but comes across as an incremental improvement on top of prior work .",
    "NOVELTY"
  ],
  [
    "paper is a bit incremental and the experiments are somewhat simplistic .",
    "NOVELTY"
  ],
  [
    "The idea of considering the reconstruction error of auto-encoders as an energy function is indeed interesting .",
    "NOVELTY"
  ],
  [
    "The novelty content paper is also high",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting and ( to the best of my knowledge ) new approach to investigating the performance of neural networks in terms of kernel methods .",
    "NOVELTY"
  ],
  [
    "The contributions of this work are significant .",
    "NOVELTY"
  ],
  [
    "and I believe that this paper brings a new ( and useful ) angle to the community",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , although they are still under the umbrella of the erasure view , they are the first ones who study the performance of coded computation in terms of computing approximate computation results as a function of \u00e2\u0080\u009cstopping time\u00e2\u0080\u009d .",
    "NOVELTY"
  ],
  [
    "reinforcement learning to object proposals .",
    "NOVELTY"
  ],
  [
    "Evaluation The idea of building multiple layers of gradient boosting models is interesting from an intellectual point of view .",
    "NOVELTY"
  ],
  [
    "new and interesting learning-based approach to intrinsic image decomposition",
    "NOVELTY"
  ],
  [
    "I would say reading through the main part of the paper is enlightening and rather an enjoyable adventure",
    "NOVELTY"
  ],
  [
    "Main Comments\uff1a The proposed conditions are similar to many previous works",
    "NOVELTY"
  ],
  [
    "Contribution seems to be incremental ; the proposed method seems to be a straightforward concatenation of well-known existing results in sparse recovery and nearest-neighbor search .",
    "NOVELTY"
  ],
  [
    "The problem and theories described in this paper are novel and interesting .",
    "NOVELTY"
  ],
  [
    "There are similarities to previously published methods such as from Lee et al .2016 or Wu et al .2017",
    "NOVELTY"
  ],
  [
    "but there are novel contributions",
    "NOVELTY"
  ],
  [
    "I think the paper is a nice contribution to the field of SNN training ,",
    "NOVELTY"
  ],
  [
    "but neither very original nor a major breakthrough .",
    "NOVELTY"
  ],
  [
    "The overall model is a novel and successful attempt to incorporate the structure information of the program into neural networks .",
    "NOVELTY"
  ],
  [
    "The authors of this paper propose a novel adversarial attack for deep reinforcement learning .",
    "NOVELTY"
  ],
  [
    "2 .Model the adversary of reinforcement learning ( RL ) system as another MDP and solve it with RL is novel and interesting .",
    "NOVELTY"
  ],
  [
    "and the application of tensor decomposition methods to this sort of unsupervised risk estimation appears to be novel",
    "NOVELTY"
  ],
  [
    "The inverted Softmax idea is very nice .",
    "NOVELTY"
  ],
  [
    "while it 's hard to call the idea of using partial traces original , it 's not been studied in this extent and setting before .",
    "NOVELTY"
  ],
  [
    "I found the contribution rather limited/unclear .",
    "NOVELTY"
  ],
  [
    "The major novel part here is therefore the sensitivity analysis that is specifically tied to wasserstein distance , which has limited novelty",
    "NOVELTY"
  ],
  [
    "A summary of my rationale for the paper is that the idea in the paper is nice ( not revolutionary but nice )",
    "NOVELTY"
  ],
  [
    "Interpolation and partial evaluation of convolutional filters on a spatial domain are fairly basic ideas",
    "NOVELTY"
  ],
  [
    "This paper does make a potentially useful and novel contribution in terms of the proposed optimization procedure for finding network-specific perforation masks that minimize overall error .",
    "NOVELTY"
  ],
  [
    "The work proposes an interesting framework for distributional reward decomposition .",
    "NOVELTY"
  ],
  [
    "The work is not particularly novel since it is based on several prior works , albeit in a non-trivial way .",
    "NOVELTY"
  ],
  [
    "I believe this is an interesting work that successfully brings together various promising ideas from the existing literature",
    "NOVELTY"
  ],
  [
    "overall : the results are relevant and , as far as I can tell , novel .",
    "NOVELTY"
  ],
  [
    "This is a nice idea",
    "NOVELTY"
  ],
  [
    "To the reviewers knowledge the idea is novel and can definitely have a practical impact .",
    "NOVELTY"
  ],
  [
    "the novelty of the paper in relation to the NIPS audience does not exceed a poster-level presentation",
    "NOVELTY"
  ],
  [
    "and the proposed objective is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "Unfortunately , to the best of our knowledge , there are no policy-based intra-option algorithms for learning a master policy .",
    "NOVELTY"
  ],
  [
    "Overall i like the originality of the paper and feel that it has a potential of reasonable impact within the research community .",
    "NOVELTY"
  ],
  [
    "Comment The idea of this paper is quite interesting for me .",
    "NOVELTY"
  ],
  [
    "The idea of producing distributions in each layer ( i.e. , using stochastic layers ) is not new and is closely related to the work on local reparameterization trick and variational dropout [ 1 ] ( predecessor of the cited sparse variational dropout ) , and various works that directly model neurons as distribution [",
    "NOVELTY"
  ],
  [
    "3 ] .",
    "NOVELTY"
  ],
  [
    "Built on top of the reparameterization trick , the idea of maximizing the entropy of neurons to regularize the network is interesting .",
    "NOVELTY"
  ],
  [
    "The idea is nice",
    "NOVELTY"
  ],
  [
    "There are also some novel aspects in the proof of the lower bound in Theorem 3.6",
    "NOVELTY"
  ],
  [
    "novel with respect to the emerging literature on multi-person 3D sensing from monocular images - cyclic consistency ( `` auto-encoding `` ) of 3D pose is an interesting idea - state-of-the-art results presented on suitable benchmarks",
    "NOVELTY"
  ],
  [
    "The results are novel to my knowledge and well situated in terms of previous literature .",
    "NOVELTY"
  ],
  [
    "My impression is that the results themselves do n't involve significant new technical ideas and are more or less straightforward extensions of previous theorems .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and somewhat reasonable but I still have several concerns",
    "NOVELTY"
  ],
  [
    "3 .The improvement is rather incremental compared with the alternative methods .",
    "NOVELTY"
  ],
  [
    "The application of target propagation in the context of adversarial examples is certainly novel and so are the specific enhancements proposed in the context of adversarial example generation",
    "NOVELTY"
  ],
  [
    "The study of adversarial examples for binarized networks is novel and important and effective attack generation algorithms are a significant first step towards training robust models of this type",
    "NOVELTY"
  ],
  [
    "The proposed model is new",
    "NOVELTY"
  ],
  [
    ", but the authors\u00e2\u0080\u0099 general approach is fairly intuitive and in line with previous work .",
    "NOVELTY"
  ],
  [
    "This is an overall very interesting idea ,",
    "NOVELTY"
  ],
  [
    "The strong point is that the proposed method seems to be appropriate and technically original .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , these are the best robustness numbers published on ImageNet .",
    "NOVELTY"
  ],
  [
    "I think this paper contains an interesting idea",
    "NOVELTY"
  ],
  [
    "I like the entropic GAN formulation and believe it is very interesting as it gives access to the joint distribution of latent and observed variables .",
    "NOVELTY"
  ],
  [
    "Novelty seems small .",
    "NOVELTY"
  ],
  [
    "contributions that",
    "NOVELTY"
  ],
  [
    "valued",
    "NOVELTY"
  ],
  [
    "This itself can be a small , nice contribution .",
    "NOVELTY"
  ],
  [
    "The introspection approach appears to be original .",
    "NOVELTY"
  ],
  [
    "I found the relation to Kanerva \u2019 s original model interesting and well explained .",
    "NOVELTY"
  ],
  [
    "That 's interesting and useful to know , but is still a relatively small contribution , making this paper borderline .",
    "NOVELTY"
  ],
  [
    "Limited novelty .",
    "NOVELTY"
  ],
  [
    "While this work is sufficiently different from prior methods , its novelty is insignificant .",
    "NOVELTY"
  ],
  [
    "The main technical results appear to be formal but straightforward extensions of existing techniques in finite dimensional spaces .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is limited .",
    "NOVELTY"
  ],
  [
    "So I would consider the method quite novel .",
    "NOVELTY"
  ],
  [
    "I like the idea in the paper",
    "NOVELTY"
  ],
  [
    "2 .Using shifting buffer memory looks interesting and novel .",
    "NOVELTY"
  ],
  [
    ", and the ability to fit to a novel speaker is nice .",
    "NOVELTY"
  ],
  [
    "The idea of applying the Fourier-based method to generalization is interesting .",
    "NOVELTY"
  ],
  [
    "I like the simplicity of the proposed method",
    "NOVELTY"
  ],
  [
    "Although the idea itself is not",
    "NOVELTY"
  ],
  [
    "groundbreaking",
    "NOVELTY"
  ],
  [
    "I am not familiar with all the related work , but the idea seems novel .",
    "NOVELTY"
  ],
  [
    "which was not brand new . Some other works should have already exploited this idea although different learning to rank algorithms may have been used",
    "NOVELTY"
  ],
  [
    "Originality The proposed method is original and different from previous work .",
    "NOVELTY"
  ],
  [
    "proposed method seems to be the best existing technique for approximate inference in deep Gaussian process models",
    "NOVELTY"
  ],
  [
    "1 .The reviewer thinks that the novelty of this paper is not enough .",
    "NOVELTY"
  ],
  [
    "Nevertheless , applying Stein 's identity to estimating policy gradient is a novel approach in reinforcement learning community .",
    "NOVELTY"
  ],
  [
    "This paper shows",
    "NOVELTY"
  ],
  [
    "The introduced algorithm , local bits-back , is novel and produces excellent results .",
    "NOVELTY"
  ],
  [
    "Overall , I think this is a nice idea .",
    "NOVELTY"
  ],
  [
    "it is often competitive and the paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "obtaining the result required several novel ideas .",
    "NOVELTY"
  ],
  [
    "the proposed method seems to be promising",
    "NOVELTY"
  ],
  [
    "The idea of decomposing problems into concepts is interesting",
    "NOVELTY"
  ],
  [
    "I think the primary originality of the paper is limited to the engineering set-up specific to obtaining the dataset",
    "NOVELTY"
  ],
  [
    "The biomimetic portion of the network also comes across as novel .",
    "NOVELTY"
  ],
  [
    "The rest of the paper applies standard supervised learning techniques to a labeled dataset and is not novel .",
    "NOVELTY"
  ],
  [
    "although the proposed ideas could be potentially interesting",
    "NOVELTY"
  ],
  [
    "Gated attention is not novel for this paper .",
    "NOVELTY"
  ],
  [
    "The paper does not claim to provide anything new algorithmically",
    "NOVELTY"
  ],
  [
    ", and , to the best of this reviewer 's knowledge , the proposed algorithm and corresponding analysis are novel .",
    "NOVELTY"
  ],
  [
    "one may claim that the level of originality is limited , given that the proposed algorithm is nothing more than the combination of a couple of improvements to IRLS that had been independently proposed before",
    "NOVELTY"
  ],
  [
    "but the way in which they are combined and the corresponding analysis is novel",
    "NOVELTY"
  ],
  [
    "This is an incremental improvement on the idea of label softening/smoothing that has recently been revived , and so the novelty is not that high .",
    "NOVELTY"
  ],
  [
    "It 's an interesting and somewhat appealing idea",
    "NOVELTY"
  ],
  [
    "I think the only contribution of this paper is Theorem 2.1",
    "NOVELTY"
  ],
  [
    "Theorem 2.1 is an interesting observation , and its implication that the Hessian at minima has only d positive eigenvalues is interesting and explains empirical observations",
    "NOVELTY"
  ],
  [
    "Overall the method is very interesting .",
    "NOVELTY"
  ],
  [
    "The analysis regarding the interaction between the SS task and the learning of generator provides insights for other design of GAN training methods",
    "NOVELTY"
  ],
  [
    "To my knowledge , this paper is the first layered generative model that can synthesize real images without mask supervision .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper does not appear to be significant , considering that most of the key techniques used in the paper had already appeared in several related papers",
    "NOVELTY"
  ],
  [
    "this work does not make enough contribution to be accepted",
    "NOVELTY"
  ],
  [
    "The idea of considering the Monge- Ampere equation in its linearized form to formulate generative modeling seems original .",
    "NOVELTY"
  ],
  [
    "Algorithms proposed are not completely new , though they are novel combinations of well-known",
    "NOVELTY"
  ],
  [
    "techniques",
    "NOVELTY"
  ],
  [
    "The main results are original and interesting since there are few studies that focus on whether the recurrent matrix is a normal matrix or non-normal matrix",
    "NOVELTY"
  ],
  [
    "the contribution of non-normal matrix relaxation is not clear",
    "NOVELTY"
  ],
  [
    "Overall , the contribution is good ,",
    "NOVELTY"
  ],
  [
    "but not groundbreaking and the presentation issues bump it below the acceptance threshold for me",
    "NOVELTY"
  ],
  [
    "The paper approaches a high level problem and takes an interesting and novel approach to doing so , integrating mutliple types of learning The paper describes a method for jointly learning a pipeline for parsing physics problems presented as images .",
    "NOVELTY"
  ],
  [
    "However , the ideas are quite incremental ( combining two well-studied approaches ) , there is no new analysis and the experiments are not too impressing .",
    "NOVELTY"
  ],
  [
    "I find this idea of applying series acceleration in optimization is very interesting .",
    "NOVELTY"
  ],
  [
    "As far as I 'm familiar with the literature , the idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "That could make the proposed solution more novel",
    "NOVELTY"
  ],
  [
    "the main drawback of this paper is on the novelty .",
    "NOVELTY"
  ],
  [
    "the graded classifiers were and incremental work and make the main point of paper",
    "NOVELTY"
  ],
  [
    "The reweighting scheme looks very related to importance sampling ratios in off policy evaluation in reinforcement learning and counterfactual analysis",
    "NOVELTY"
  ],
  [
    "I like this idea and have one concern about the experiment",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel method that is an interesting take on imitation learning",
    "NOVELTY"
  ],
  [
    "I think this is an interesting paper that describes a relatively novel paradigm .",
    "NOVELTY"
  ],
  [
    "I found the authors ' way of combining complete techniques and incomplete techniques novel and interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is limited",
    "NOVELTY"
  ],
  [
    "the overall technical contribution in this line is rather marginal .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution is weak .",
    "NOVELTY"
  ],
  [
    "The current manuscript makes the work seem like a straightforward combination of many existing approaches .",
    "NOVELTY"
  ],
  [
    "The paper introduces an elegant way of adding a hierarchical inductive bias",
    "NOVELTY"
  ],
  [
    "Novel . The proposed approach is novel in utilizing the idea of output space gradient descent in making sure it is permutation-invariant .",
    "NOVELTY"
  ],
  [
    "Although similar ideas has been adopted in some other scenarios such as other generative model problems",
    "NOVELTY"
  ],
  [
    "So I believe this paper has sufficient novelty .",
    "NOVELTY"
  ],
  [
    "I find the paper is a useful practical step forward in neural nets for audio generation , incremental on the theoretical side ,",
    "NOVELTY"
  ],
  [
    "I found the submission insightful",
    "NOVELTY"
  ],
  [
    "so my current assumption is that this proposal is pretty novel",
    "NOVELTY"
  ],
  [
    "While the idea and the results seem to be appealing , and the concept is novel to the mainstream deep learning community",
    "NOVELTY"
  ],
  [
    "Novelty is somewhat low , as it is a straightforward application of existing ideas like Gasse et al .NeurIPS",
    "NOVELTY"
  ],
  [
    "strong as far as I know .",
    "NOVELTY"
  ],
  [
    "From this perspective , the contribution is somewhat limited .",
    "NOVELTY"
  ],
  [
    "The idea is nice and novel ,",
    "NOVELTY"
  ],
  [
    "1 .The introduction of belief state in the sequential model is smart .",
    "NOVELTY"
  ],
  [
    "Originality The originality is limited as it is a close extenstion work of Ullman et al .2016",
    "NOVELTY"
  ],
  [
    "given what we learned from the adversarial example research area , the contribution of this work is low because results might not be too surprising .",
    "NOVELTY"
  ],
  [
    "The method proposed in this work is novel and interesting .",
    "NOVELTY"
  ],
  [
    "the study does not make a significant contribution to our understanding of V1",
    "NOVELTY"
  ],
  [
    "the main innovation in ML presented (",
    "NOVELTY"
  ],
  [
    "is quite specific and will thus not likely be of interest for the general audience of ICLR",
    "NOVELTY"
  ],
  [
    "There are interesting ideas in this paper .",
    "NOVELTY"
  ],
  [
    "I felt that this advance was somewhat incremental , especially given that the advantage of this method over existing ones was not clearly demonstrated",
    "NOVELTY"
  ],
  [
    "The idea of using multiple learning rate at the same time in a hierarchical/master-slave architecture seems notably novel .",
    "NOVELTY"
  ],
  [
    "To my knowledge this algorithm is novel , and performs admirably .",
    "NOVELTY"
  ],
  [
    "The paper presents two novel components : 1 ) using the SDU and 2 ) applying the EMD loss on segment detection .",
    "NOVELTY"
  ],
  [
    "One of the strengths of the",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , all of this is very innovative .",
    "NOVELTY"
  ],
  [
    "-- -- I agree with other reviewers that the paper is a combination of existing methodologies",
    "NOVELTY"
  ],
  [
    "I think that 's an interesting idea",
    "NOVELTY"
  ],
  [
    "I think this is an interesting idea",
    "NOVELTY"
  ],
  [
    "While this paper 's idea is creative",
    "NOVELTY"
  ],
  [
    "it does not seem to",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "Though not very",
    "NOVELTY"
  ],
  [
    "exciting , this paper applies the entropy regularization to CTC loss and it seems to be a nice addition to the CTC related technique .",
    "NOVELTY"
  ],
  [
    "To sum up , I think that the general idea looks very natural",
    "NOVELTY"
  ],
  [
    "this paper presents a new notion of regret for non-convex forecasting problems with concept drift",
    "NOVELTY"
  ],
  [
    "The algorithm given is very similar to previous algorithms",
    "NOVELTY"
  ],
  [
    "The contributions seem like small modifications of previous results , and",
    "NOVELTY"
  ],
  [
    "The RIM idea seems to be derived from some ideas from the `` 'causality community '",
    "NOVELTY"
  ],
  [
    "Approximating the pairwise potentials with matrix factorization is also not novel .",
    "NOVELTY"
  ],
  [
    "The idea itself seems novel and addresses an important problem of reducing the memory footprint of deep neural networks .",
    "NOVELTY"
  ],
  [
    "other neural network baselines",
    "NOVELTY"
  ],
  [
    "Methodological novelty is low -- this is a straightforward application of GCN",
    "NOVELTY"
  ],
  [
    "There is little methodological novelty and the QA application is a bit of a niche problem in bioinformatics .",
    "NOVELTY"
  ],
  [
    "but I do n't feel that in itself is a significant enough contribution to warrant publication",
    "NOVELTY"
  ],
  [
    "Using self training is not new in GCN",
    "NOVELTY"
  ],
  [
    "but the way it is used here , computing adaptively a threshold for incorporating pseudo labels and using weights according to the confidence off predictions is new .",
    "NOVELTY"
  ],
  [
    "This paper proposed a novel monocular depth estimation algorithm .",
    "NOVELTY"
  ],
  [
    "The method seems novel .",
    "NOVELTY"
  ],
  [
    "The problem setting considered in the paper seems novel as well as reasonable from a practical perspective .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is marginal .",
    "NOVELTY"
  ],
  [
    "Leveraging the sub-regions of the image to improve performance is not new and has been widely-studied in image classification and retrieval",
    "NOVELTY"
  ],
  [
    "The paper has some interesting contributions and ideas , mainly from the point of view of applications",
    "NOVELTY"
  ],
  [
    "are roughly similar to what is already proposed",
    "NOVELTY"
  ],
  [
    "However , the novelty is hurt by the lack of clarity with respect to the model design .",
    "NOVELTY"
  ],
  [
    "I think the originality of this method is only okay . Methodological novelty of the presented method , I believe , is marginal 2.2",
    "NOVELTY"
  ],
  [
    "The paper proposes no groundbreaking contributions to the reader .",
    "NOVELTY"
  ],
  [
    "The analysis of how the decoder generates data is insightful .",
    "NOVELTY"
  ],
  [
    "Given the current state of the manuscript , the level of methodological novelty and the scope of input perturbations that can be made robust against both appear to be limited .",
    "NOVELTY"
  ],
  [
    "The only weaknesses are , maybe , the limited novelty compared to the previous Word Mover 's Distance paper",
    "NOVELTY"
  ],
  [
    "Overall I like the paper and the approach .",
    "NOVELTY"
  ],
  [
    "The novelty seems very limited compared with previous methods .",
    "NOVELTY"
  ],
  [
    "I think this paper makes a better contribution in this line of researches .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the approach proposed here is new .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first model to achieve this without the use of landmark labels .",
    "NOVELTY"
  ],
  [
    "The idea proposed is fairly straight-forward . Despite being a simple approach , the experimental results are quite promising . The analysis on the gradient correlation coefficient and label leaking phenomenon provide some interesting insights",
    "NOVELTY"
  ],
  [
    "The overall methodology is quite novel and results look good . Merging hierarchical inference into the auto-encoder kind of structure for unsupervised learning is new .",
    "NOVELTY"
  ],
  [
    "I believe this paper makes a novel algorithmic contribution to the body of intelligent exploration literature and",
    "NOVELTY"
  ],
  [
    "And the architecture in this paper is very primitive compare to what researchers consider state-of-the-art these days",
    "NOVELTY"
  ],
  [
    "The authors prove a natural result that seems to be technically nontrivial",
    "NOVELTY"
  ],
  [
    "Lacks in sufficient machine learning related novelty required to be relevant in the main conference 3",
    "NOVELTY"
  ],
  [
    "Design , solving inverse problem using Deep Learning are not quite novel",
    "NOVELTY"
  ],
  [
    "the model-free extensions proposed are an original contribution with respect to existing literature and to NIPS in particular .",
    "NOVELTY"
  ],
  [
    "The approach is not particularly novel as many papers have proposed quantization or compression methods .",
    "NOVELTY"
  ],
  [
    "The technique is not new and indeed there are",
    "NOVELTY"
  ],
  [
    "I still find the theoretical novelty of the work incremental",
    "NOVELTY"
  ],
  [
    "but I think the novelty of this submission is a bit weak to be accepted to the conference .",
    "NOVELTY"
  ],
  [
    "so my main concern is novelty",
    "NOVELTY"
  ],
  [
    "and the framework presented in this paper is by far the clearest and most complete application of hyperbolic geometry in neural networks to date .",
    "NOVELTY"
  ],
  [
    "and the idea is an original refinement of earlier work , justified by its exceeding state-of-the-art approaches .",
    "NOVELTY"
  ],
  [
    "1.The novelty - The method seems to be almost the same as the previous junction tree based formulation . The paper includes a straightforward hierarchical extension and provides limited novelty with respect to deep learning .",
    "NOVELTY"
  ],
  [
    "It 's not tremendously original ( in that it basically combines two ideas that are already in the literature )",
    "NOVELTY"
  ],
  [
    "and I have",
    "NOVELTY"
  ],
  [
    "( not 100 % sure about the originality of the work though )",
    "NOVELTY"
  ],
  [
    "It presents what appears to be a promising approach for this problem .",
    "NOVELTY"
  ],
  [
    "The critical Thm 2 is presented with no insight or discussion whatsoever .",
    "NOVELTY"
  ],
  [
    "The work is original and",
    "NOVELTY"
  ],
  [
    "the novel",
    "NOVELTY"
  ],
  [
    "sampling approaches",
    "NOVELTY"
  ],
  [
    "motivates",
    "NOVELTY"
  ],
  [
    "and makes a couple of interesting architectural/algorithmic contributions .",
    "NOVELTY"
  ],
  [
    "The simulated tasks are novel and difficult ( sorting , clearing a table )",
    "NOVELTY"
  ],
  [
    "Each part of the method is not particularly novel .",
    "NOVELTY"
  ],
  [
    "Though the attention structures in this paper are not original",
    "NOVELTY"
  ],
  [
    ", combining these structures and applying them on dynamic graph embedding is new .",
    "NOVELTY"
  ],
  [
    "The introduced model is elegant and original , and surprisingly flexible to generalize many well-known previous results from disparate fields of learning theory",
    "NOVELTY"
  ],
  [
    "and the introduced model should be of interest",
    "NOVELTY"
  ],
  [
    "Although the paper builds heavily on the previous work of Emamjomeh-Zadeh et al .which contains a significant part of the technical machinery used here , the idea of applying Emamjodeh-Zadeh et al . 's results to interactive learning is a novel and clever idea and several of the applications are technically nontrivial .",
    "NOVELTY"
  ],
  [
    "I really like the idea of transferring edits from one context to another .",
    "NOVELTY"
  ],
  [
    "The methods presented are also not novel .",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , this work is significantly different than common statistical learning theory papers .",
    "NOVELTY"
  ],
  [
    "From my point of view , the reductions from a discrete optimization problem to a continuous one are clever .",
    "NOVELTY"
  ],
  [
    "Dynamic pruning idea is very interesting .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "though new ideas are somewhat marginal , considering the work on previous datasets",
    "NOVELTY"
  ],
  [
    "their so-called RNN-based filter formulation is not anywhere close to the usual RNN models",
    "NOVELTY"
  ],
  [
    "that are currently known in the literature",
    "NOVELTY"
  ],
  [
    "application this is interesting , but not very original .",
    "NOVELTY"
  ],
  [
    "but the proposed method is incremental .",
    "NOVELTY"
  ],
  [
    "and thus is out of novelty",
    "NOVELTY"
  ],
  [
    "which are again not novel",
    "NOVELTY"
  ],
  [
    "the proposed method is incremental , and has limited novelty contributions .",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "The idea is not totally unheard of ( see e.g .references in the paper ) , but the formulation is nice , and the solution is novel .",
    "NOVELTY"
  ],
  [
    "The mathematical proofs provided in the paper are mostly already known or small modifications to existing proofs",
    "NOVELTY"
  ],
  [
    "Including the DP noise into the modelling is a very relevant idea",
    "NOVELTY"
  ],
  [
    "The proposed method is novel , and seems to give well-calibrated posteriors",
    "NOVELTY"
  ],
  [
    "The idea of introducing global memory is novel and experimental results show its",
    "NOVELTY"
  ],
  [
    "encode",
    "NOVELTY"
  ],
  [
    "Novel idea on balancing exploitation ( near-actual-goal sampling ) and exploration ( diverse goal sampling ) for HER .",
    "NOVELTY"
  ],
  [
    "Indeed the protocol as a whole is very close to well-known basic adaptive data analysis protocols .",
    "NOVELTY"
  ],
  [
    "this gives me pause even if I like the paper \u00e2\u0080\u0093 I\u00e2\u0080\u0099m just not sure it\u00e2\u0080\u0099s making a strong contribution to the state of the art",
    "NOVELTY"
  ],
  [
    "Overall , I like the ideas of data-dependent dropout and evolutionary dropout .",
    "NOVELTY"
  ],
  [
    "Distilling a Gaussian autoregressive model to another Gaussian autoregressive model by matching their Gaussian conditionals with an analytical KL is rather straightforward , and , methodologically speaking , I would n't consider it an original contribution on its own . However",
    "NOVELTY"
  ],
  [
    ", I think its application and demonstration in text-to-speech constitutes an original contribution .",
    "NOVELTY"
  ],
  [
    "The paper presents a new method to perform domain adaptation .",
    "NOVELTY"
  ],
  [
    "Summary of the review Overall , the content is very interesting and the results seem new and potentially impactful . Looking at sampling with a fresh optimization eye brings new ideas .",
    "NOVELTY"
  ],
  [
    "the major contributions are subtle and technical",
    "NOVELTY"
  ],
  [
    "The paper has a clear contribution",
    "NOVELTY"
  ],
  [
    "The only concern I have is the novelty of this work . I consider this work as a nice but may be incremental ( relatively small ) contribution to our community .",
    "NOVELTY"
  ],
  [
    "This paper only follow previous work and lacks new insights about the problem .",
    "NOVELTY"
  ],
  [
    "This work addresses an existing problem with a novel approach . The proposed algorithm is intuitive",
    "NOVELTY"
  ],
  [
    "The idea is novel , and the proposed `` insideness `` seems like a valid metric .",
    "NOVELTY"
  ],
  [
    "consider a novel version of hypergraph clustering",
    "NOVELTY"
  ],
  [
    "Also some theoretical contributions are weak , both from a technical perspective and with respect to their generality .",
    "NOVELTY"
  ],
  [
    "The oracle-based algorithm for contextual semibandits problems proposed in this paper is quite novel ( as far as I know ) and interesting .",
    "NOVELTY"
  ],
  [
    "Overall the paper presents a novel application of CNNs to co-evolution Protein Contact Prediction ( PCP ) with state-of-the-art results .",
    "NOVELTY"
  ],
  [
    "I find that leveraging existing solvers that admit closed-form solutions is an attractive and natural choice",
    "NOVELTY"
  ],
  [
    "The idea is natural and attractive .",
    "NOVELTY"
  ],
  [
    "The complexity result is new",
    "NOVELTY"
  ],
  [
    ", but the proof is quite similar to previously known results .",
    "NOVELTY"
  ],
  [
    "The transformation of behavioral to mixed strategy , which is the key component of the proposed method is interesting and I am not aware of a similar construction in previous literature .",
    "NOVELTY"
  ],
  [
    "and the results are , to my knowledge , novel .",
    "NOVELTY"
  ],
  [
    "while I think that the results are certainly not ground-breaking",
    "NOVELTY"
  ],
  [
    "The problem is not new ,",
    "NOVELTY"
  ],
  [
    "I find the work included in this paper to be novel and a valuable contribution to the field .",
    "NOVELTY"
  ],
  [
    "without prior information about",
    "NOVELTY"
  ],
  [
    "to reach the performance of existing optimal strategies ( especially primal-dual approaches",
    "NOVELTY"
  ],
  [
    "But I am not entirely convinced that the paper is making novel contributions in this direction .",
    "NOVELTY"
  ],
  [
    "I think that the algorithmic idea proposed in this paper is interesting , novel , and practical .",
    "NOVELTY"
  ],
  [
    "The technical approach is unfortunately too outdated and obvious and not quite the level of ICLR .",
    "NOVELTY"
  ],
  [
    "This methodology is very similar to the existing methods in the guided policy search literature . My major concern to this paper is its novelty and level of contribution .",
    "NOVELTY"
  ],
  [
    "It is essentially an applied paper that uses existing techniques in a novel way .",
    "NOVELTY"
  ],
  [
    "I think the paper makes solid contributions to the community .",
    "NOVELTY"
  ],
  [
    "since such methodology is not so novel",
    "NOVELTY"
  ],
  [
    "The reviewer really likes the approach proposed in the paper",
    "NOVELTY"
  ],
  [
    "and proposed cross-attention maps for query and support images are novel .",
    "NOVELTY"
  ],
  [
    "I think the idea is novel",
    "NOVELTY"
  ],
  [
    "The integration of variational EM algorithm and MLN has been explored in another work",
    "NOVELTY"
  ],
  [
    "Overall , the work of this paper seems technically sound but I don \u2019 t find the contributions particularly surprising or novel .",
    "NOVELTY"
  ],
  [
    "t find that the paper expands this perspective in any surprising way",
    "NOVELTY"
  ],
  [
    "The method introduced by this paper is a clever probabilistic formulation of Bayesian classification .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this is a novel approach to Bayesian classification .",
    "NOVELTY"
  ],
  [
    "The idea is an interesting new approach to approximate inference for classification",
    "NOVELTY"
  ],
  [
    "The proposed method is a novel approach to classification",
    "NOVELTY"
  ],
  [
    "I still do believe that this method is novel",
    "NOVELTY"
  ],
  [
    "I had previously scored it based on the pipeline itself , but the application to Brainbow data seems novel and potentially interesting . `` This paper describes some very interesting data",
    "NOVELTY"
  ],
  [
    "The approach is elegant and intuitive .",
    "NOVELTY"
  ],
  [
    "The manuscript describes a novel attentional mechanism applied to fine-grained recognition",
    "NOVELTY"
  ],
  [
    "Summary The paper presents some intuitive modifications to Dinh et al 's real NVP model",
    "NOVELTY"
  ],
  [
    "the joining of LTL and RL has been developed previously . The main contribution of this work is limited to the application of the previous techniques .",
    "NOVELTY"
  ],
  [
    "The work is original and significant .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "ORIGINALITY The idea of having a discriminative version of LDA , analogous to logistic regression , is interesting .",
    "NOVELTY"
  ],
  [
    "this work",
    "NOVELTY"
  ],
  [
    "This work is a nice combination of existing ideas .",
    "NOVELTY"
  ],
  [
    "I think that this is a well executed incremental contribution .",
    "NOVELTY"
  ],
  [
    "The idea of using weighted majority votes in lifelong learning setting is novel .",
    "NOVELTY"
  ],
  [
    "because it presents a novel and non-trivial concept ( rotation-equivariant self attention ) .",
    "NOVELTY"
  ],
  [
    "and offer two novel and intriguing solutions .",
    "NOVELTY"
  ],
  [
    "Overall , I do like the paper and the general approach .",
    "NOVELTY"
  ],
  [
    "I think the technical contribution is thin at the moment , and there is",
    "NOVELTY"
  ],
  [
    "The main idea of the paper , however , is an elegant process of first generating a `` sketch `` program which may not necessarily be correct on the first shot",
    "NOVELTY"
  ],
  [
    "This process is a",
    "NOVELTY"
  ],
  [
    "While this paper is quite fun to read",
    "NOVELTY"
  ],
  [
    "it is not innovative enough and it",
    "NOVELTY"
  ],
  [
    "accepted this",
    "NOVELTY"
  ],
  [
    "The idea of using a multi-step reviewer module is very interesting .",
    "NOVELTY"
  ],
  [
    "the combination of components is novel",
    "NOVELTY"
  ],
  [
    "Novelty While each component is by itself not very novel",
    "NOVELTY"
  ],
  [
    ", the proposed combination is novel in this sub-field",
    "NOVELTY"
  ],
  [
    "The ensemble hypothesis is interesting and could be worth presenting at NIPS .",
    "NOVELTY"
  ],
  [
    "There is no algorithmic novelty as such .",
    "NOVELTY"
  ],
  [
    "Some interesting ideas motivating the approach Cons",
    "NOVELTY"
  ],
  [
    "Limited novelty .",
    "NOVELTY"
  ],
  [
    "The claim that per-sample hardness reweighting is novel to this work is a bit of a stretch .",
    "NOVELTY"
  ],
  [
    "The methods are not completely novel",
    "NOVELTY"
  ],
  [
    "the two contributions stated in the introduction are both obvious and not particularly significant -- that having some labels of the type of disentanglement desired helps when used as a validation set and as a small number of labels for learning a disentangled representation space",
    "NOVELTY"
  ],
  [
    "2 .I like the idea of using improper learning to reduce the dimensionality . 3 .It 's novel to use neural network to do sketching decoding .",
    "NOVELTY"
  ],
  [
    "Again , this is not new -- for instance",
    "NOVELTY"
  ],
  [
    "The rate-distortion formulation with fixed input and output marginal in Appendix A , while interesting , is also not new",
    "NOVELTY"
  ],
  [
    "While the main result is not terribly deep or surprising",
    "NOVELTY"
  ],
  [
    ", the general ideas and treatment are novel to me and relevant to the community",
    "NOVELTY"
  ],
  [
    "Novelty I \u2019 m not an expert on the literature of applying machine learning to the problems of reaction { product , mechanism } prediction but the",
    "NOVELTY"
  ],
  [
    "The idea of optimizing the intrinsic graph structure iteratively for down-stream prediction tasks is interesting .",
    "NOVELTY"
  ],
  [
    "1\uff09Compared with LDS [ 1 ] , this work seems to overlook the bi-level optimization problem for learning model parameters based on the optimal graph structure .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the technical novelty is limited .",
    "NOVELTY"
  ],
  [
    "I consider the contributions given by the paper significant",
    "NOVELTY"
  ],
  [
    "Therefore , I think there is no technical originality except that authors found a reasonable combination of existing algorithms and a problem",
    "NOVELTY"
  ],
  [
    "Lack of technical novelty and justification of the approach .",
    "NOVELTY"
  ],
  [
    "The paper also does not give new insights in how to make large-scale RL `` 'work ' .",
    "NOVELTY"
  ],
  [
    "The paper also does not introduce new concrete evaluation metrics that can apply to other tasks / RL problems , skill detection / segmentation methods to learn the structure of auto-curricula .",
    "NOVELTY"
  ],
  [
    "The performance improvements are incremental . The paper lacks sufficient technical contribution .",
    "NOVELTY"
  ],
  [
    "the novelty of the introduced method is somewhat limited",
    "NOVELTY"
  ],
  [
    "The idea of adopting end-to-end learning to solve two-stage stochastic programming is interesting .",
    "NOVELTY"
  ],
  [
    "Although the idea is cute",
    "NOVELTY"
  ],
  [
    "While there have been many studies on non-convergence of Adam , raising an issue on ignoring the gradient decrease information seems novel .",
    "NOVELTY"
  ],
  [
    "Adam 's failure and a novel optimization algorithm",
    "NOVELTY"
  ],
  [
    "Their design includes a number of optimizations that are missing from currently available deep learning engines which can lead to significant benefits",
    "NOVELTY"
  ],
  [
    "Pointer network has been proposed before",
    "NOVELTY"
  ],
  [
    "and to my knowledge the analyses and insights that it contributes are original . Overall , I think this is a solid paper with some interesting contributions to neural network interpretability .",
    "NOVELTY"
  ],
  [
    "However , this DCGAN model itself ( for the distance matrix ) is a straightforward application of DCGANs without any significant methodological contributions . The idea of using an SE ( 3 ) invariant matrix represent is also not new .",
    "NOVELTY"
  ],
  [
    "The proposed solution to the reconstruction problem ( reconstruction of the C_alpha trace from the distance matrix ) using ADDM is an interesting contribution from a protein modelling perspective .",
    "NOVELTY"
  ],
  [
    "However , the contribution is very incremental and it is not part of the learning algorithm .",
    "NOVELTY"
  ],
  [
    "of DCGANs .",
    "NOVELTY"
  ],
  [
    "I liked the clever combination of post double selection methods and score matching to construct such",
    "NOVELTY"
  ],
  [
    "and the authors clearly made some interesting insights",
    "NOVELTY"
  ],
  [
    "While learning stable dynamical systems has been studied in previous literature in the context of neural networks , the training of an additional Lyapunov function to guarantee stability of an architecture is a novel contribution .",
    "NOVELTY"
  ],
  [
    "has already been proposed elsewhere",
    "NOVELTY"
  ],
  [
    "and what parts of the presentation is",
    "NOVELTY"
  ],
  [
    "and the Jacobian idea is clearly very promising",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting contribution .",
    "NOVELTY"
  ],
  [
    "The proposed method is interesting",
    "NOVELTY"
  ],
  [
    "and there is a novel component",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is somewhat limited , in part because learning with SSVM and Lagrangian dual of the inference procedure was done before",
    "NOVELTY"
  ],
  [
    "However , I still think that the contribution is somewhat incremental because the setting is quite limited",
    "NOVELTY"
  ],
  [
    "but my knowledge of the previous work in this area is not deep enough to evaluate technical novelty very well .",
    "NOVELTY"
  ],
  [
    "This seems like a somewhat incremental contribution that would be of interest to a smallish subset of ICLR attendees .",
    "NOVELTY"
  ],
  [
    "2- Turning the meta-RL problem into a supervised learning problem has already been explored .",
    "NOVELTY"
  ],
  [
    "The only difference is the choice of off-the-shelf planning algorithm which is not a significant contribution",
    "NOVELTY"
  ],
  [
    "This is novel to this paper )",
    "NOVELTY"
  ],
  [
    "I believe this to be novel",
    "NOVELTY"
  ],
  [
    "While not a surprising research direction , this is a natural and promising method to consider",
    "NOVELTY"
  ],
  [
    "The new method could be described as an amalgam of several existing approaches .",
    "NOVELTY"
  ],
  [
    "However the various elements have been combined thoughtfully in a novel way , and carefully implemented .",
    "NOVELTY"
  ],
  [
    "This is an interesting paper which proposes a novel angle on the problem of learning long-term dependencies in recurrent nets .",
    "NOVELTY"
  ],
  [
    "variants previously",
    "NOVELTY"
  ],
  [
    "This paper provides interesting connections of some theoretical ideas such as PCA for exponential families by Bregman divergence and reparametrization by Legendre conjugate of cumulant functions , clr transformation and the gauged version of Bregman divergence ( scaled Bregman divergence",
    "NOVELTY"
  ],
  [
    "PCA",
    "NOVELTY"
  ],
  [
    "autoencoders .",
    "NOVELTY"
  ],
  [
    "`` The overall idea is interesting",
    "NOVELTY"
  ],
  [
    "Overall I find the paper very interesting .",
    "NOVELTY"
  ],
  [
    "The paper presents interesting ideas that can be used for other problems with small training datasets .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed architecture is moderate - while each component of the model does not have too much technical novelty ,",
    "NOVELTY"
  ],
  [
    "the idea of separating the model into a proposal network and a classifier seems to be a new approach in the context of NER ( that diverges from the traditional sequence labelling approaches ) , and is reasonably designed for the proposed task .",
    "NOVELTY"
  ],
  [
    "Regime ( i ) is rather classical in the field and there are many",
    "NOVELTY"
  ],
  [
    "The paper is incremental work compared to the Semi-Implicit VAE [ 38 ] .",
    "NOVELTY"
  ],
  [
    "In general , I think it proposes an interesting view of the temporal abstraction .",
    "NOVELTY"
  ],
  [
    "and based on a simple but interesting idea .",
    "NOVELTY"
  ],
  [
    "The proposed method is not completely new : many ideas have been adopted from previous works .",
    "NOVELTY"
  ],
  [
    "The method is somewhat incremental with respect to original work and only compares algorithm 2 years ago without comparing",
    "NOVELTY"
  ],
  [
    "While the novelty is arguably limited ( the paper combines two existing approaches in a rather straightforward manner )",
    "NOVELTY"
  ],
  [
    "it is the first demonstration of an unsupervised approach to learning disentangled continuous and discrete latent variables that works well",
    "NOVELTY"
  ],
  [
    "The discrepancy is novel in the sense that it takes the hypothesis set and the loss function into consideration .",
    "NOVELTY"
  ],
  [
    "and the setup is novel with the solid theoretical analysis .",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is limited , and the current version contains several flaws",
    "NOVELTY"
  ],
  [
    "I like the direction this paper takes",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "The work seems novel , introducing both a new metric for OPPE , and a new way to benchmark deep RL algorithms Quality",
    "NOVELTY"
  ],
  [
    "it could be a very novel way to do OPPE , and might advance the whole domain",
    "NOVELTY"
  ],
  [
    "Under this assumption and the similarity in distributions mentioned in proposition 4.2 make the contribution of this paper significantly weak .",
    "NOVELTY"
  ],
  [
    "The whole model is trained end-to-end by using A3C.This is a very interesting paper that proposes a novel recurrent model",
    "NOVELTY"
  ],
  [
    "the strengths of this paper are : 1 ) Proposes , a novel model that can construct the internal plans for the task in order to accomplish a particular task .",
    "NOVELTY"
  ],
  [
    "I 'm not sure what the contribution of this paper is .",
    "NOVELTY"
  ],
  [
    "but no contribution in terms of the model is made .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "it does n't seem to propose anything new or make any clear contribution",
    "NOVELTY"
  ],
  [
    "The core idea of the paper is not very novel . The usefulness of the GAN discriminative features for semi-supervised learning is already established in previous works such as CatGAN",
    "NOVELTY"
  ],
  [
    "The whole idea is interesting",
    "NOVELTY"
  ],
  [
    "Currently it appears that the additional contribution over Wu 's works is marginal .",
    "NOVELTY"
  ],
  [
    "3 .The analysis of the pruning is interesting .",
    "NOVELTY"
  ],
  [
    "This paper proposes a well-principled distillation method based on contrastive loss maximizing the mutual information between teacher and student models .",
    "NOVELTY"
  ],
  [
    "but seems to be a straightforward application of the existing techniques",
    "NOVELTY"
  ],
  [
    "My concern is that the proposed algorithm seems somewhat incremental , as it is a combination of well-known techniques .",
    "NOVELTY"
  ],
  [
    "I still think that the variational inference scheme derived by the authors is a combination of several ML techniques ; its technical contribution is somewhat low .",
    "NOVELTY"
  ],
  [
    "and method original and sound",
    "NOVELTY"
  ],
  [
    "which I think its important and novel",
    "NOVELTY"
  ],
  [
    "s obvious that this paper is not a typical machine learning paper ; it does not propose a new",
    "NOVELTY"
  ],
  [
    "or provide ( theoretical/empirical",
    "NOVELTY"
  ],
  [
    "and it does not have the scientific quality and depth I",
    "NOVELTY"
  ],
  [
    "Novelty While the general architecture is the same as the ConvLSTM and the paper is somewhat application oriented",
    "NOVELTY"
  ],
  [
    ", the idea of learning trajectories with spatial transformer inspired modules is quite original to me .",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat limited compared to ConvGRU/LSTM EDIT",
    "NOVELTY"
  ],
  [
    "The contribution is incremental .",
    "NOVELTY"
  ],
  [
    "the proposed method looks novel , and the experimental results look",
    "NOVELTY"
  ],
  [
    "Novelty/originality Although not groundbreaking",
    "NOVELTY"
  ],
  [
    "the method proposed in this paper seems sufficiently novel .",
    "NOVELTY"
  ],
  [
    "and issues a classical and well known studied problem from a new point of view .",
    "NOVELTY"
  ],
  [
    "The concept of data augmentation in the embedding space is very interesting .",
    "NOVELTY"
  ],
  [
    "The method is mostly fairly straightforward and not methodologically groundbreaking",
    "NOVELTY"
  ],
  [
    "and the techniques are new and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed approach seems quite interesting",
    "NOVELTY"
  ],
  [
    "but I find the empirical evaluation of this idea for the task of semantic understanding interesting",
    "NOVELTY"
  ],
  [
    "I think the MMES approach is interesting and potentially a good analogue to the DIP",
    "NOVELTY"
  ],
  [
    "even though the paper overstates its contributions",
    "NOVELTY"
  ],
  [
    "This is quite an interesting idea since traditional hyperparameter tuning techniques",
    "NOVELTY"
  ],
  [
    "This again is a novel and interesting idea .",
    "NOVELTY"
  ],
  [
    "I find the idea very interesting and promising",
    "NOVELTY"
  ],
  [
    "I find the proposed approach very appealing because it requires changes only in the optimization procedure while the model and the objective remain the",
    "NOVELTY"
  ],
  [
    "the paper formalizes some intuition that could be found in other papers",
    "NOVELTY"
  ],
  [
    "I find these two approaches a bit similar in spirit",
    "NOVELTY"
  ],
  [
    "Moderate , the task have being studied in previous negotiation competition like D-brane , but the SL+ RL approach to study this problem",
    "NOVELTY"
  ],
  [
    "is new",
    "NOVELTY"
  ],
  [
    "The approach that by collecting a large dataset of human games and do SL on it , later improve with RL is not new , but the execution of this idea on diplomacy is still a non-trivial job",
    "NOVELTY"
  ],
  [
    "but severely overestimates the core contributions embedded in section 3 .",
    "NOVELTY"
  ],
  [
    "the idea of using drop out for matrix sensing seems to be a somewhat trivial extension of the work on dropout for matrix factorization -- http",
    "NOVELTY"
  ],
  [
    "Summary of the review The contribution is interesting and novel ,",
    "NOVELTY"
  ],
  [
    "Useful contribution in terms of using broader context for embedding a sentence .",
    "NOVELTY"
  ],
  [
    "Novel and simple `` trick `` for generating OOV words by mapping them to `` local `` variables and generating those variables .",
    "NOVELTY"
  ],
  [
    "The use of DCTs provide a nontrivial speedup over previous work",
    "NOVELTY"
  ],
  [
    "I remain confident that this paper would make a solid contribution to NIPS this year",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the CW implementation in Cleverhans is specifically set up so that the user does not need to tune a large number of hyperparameters",
    "NOVELTY"
  ],
  [
    "But to the best of my knowledge , there is no comprehensive theory that describes when a fixed perturbation attack should be expected to succeed in attacking a commonly used neural network .",
    "NOVELTY"
  ],
  [
    "There are some interesting ideas here .",
    "NOVELTY"
  ],
  [
    "I think the general idea of going beyond perturbations of pixel values in this paper is interesting",
    "NOVELTY"
  ],
  [
    "I like the idea of SCMs ; I like the idea of counterfactual reasoning ; I like the idea of leveraging models in this unique way .",
    "NOVELTY"
  ],
  [
    "The geometric analysis ( restricted to 2x2 games ) and key results proven in the paper are novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "From a conceptual point of view , I did not find the contribution of the paper significant .",
    "NOVELTY"
  ],
  [
    "Overall , the conceptual and experimental contributions of the paper are rather weak and I thus recommend rejection",
    "NOVELTY"
  ],
  [
    ", and the idea is interesting",
    "NOVELTY"
  ],
  [
    "I think the paper can be accepted as it is an interesting approach",
    "NOVELTY"
  ],
  [
    "However I find the current paper lacking both in terms of conceptual and technical contributions .",
    "NOVELTY"
  ],
  [
    "Overall , I find the contributions of the paper limited both technically and conceptually .",
    "NOVELTY"
  ],
  [
    "I still do not find the contribution of the paper significant enough to cross the ICLR bar",
    "NOVELTY"
  ],
  [
    "The work is clearly novel",
    "NOVELTY"
  ],
  [
    "Further the authors address an interesting and novel problem",
    "NOVELTY"
  ],
  [
    "the work is novel and influential",
    "NOVELTY"
  ],
  [
    "the current version of the paper would be a good contribution",
    "NOVELTY"
  ],
  [
    "My concern on this paper is that the technical contribution of this paper looks weak to me .",
    "NOVELTY"
  ],
  [
    "Some of them are actually not new",
    "NOVELTY"
  ],
  [
    "there are some interesting ideas here",
    "NOVELTY"
  ],
  [
    "The overall novelty of the work is limited though .",
    "NOVELTY"
  ],
  [
    "I generally like the proposal and find the use of submodular optimization for the approximate projection to be interesting .",
    "NOVELTY"
  ],
  [
    "so I am not quite sure if this contribution is sufficient for the ICLR submission",
    "NOVELTY"
  ],
  [
    "I consider that the contributions of their work are novel",
    "NOVELTY"
  ],
  [
    "But I failed to see a clear , new contribution of using this causal regularization , compared to some of the previous methods to achieve invariance ( e.g. , relative to translation",
    "NOVELTY"
  ],
  [
    "I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm .",
    "NOVELTY"
  ],
  [
    "If it were novel , it would be an incremental development",
    "NOVELTY"
  ],
  [
    "The proposed method is a novel dynamic loss re-weighting technique applied to VQA under changing priors condition , aka VQA-CP , where the train and test sets are deliberately constructed to have different distributions .",
    "NOVELTY"
  ],
  [
    "The idea of optimizing metric matrix used for NW regressor by explicitly counteracting the leading term of the bias of regressor is interesting .",
    "NOVELTY"
  ],
  [
    "few novel ideas",
    "NOVELTY"
  ],
  [
    "Briefly , the overall idea of serializing the whole encoding -- environment simulation -- recognition into an end-to-end network is interesting and worth exploration .",
    "NOVELTY"
  ],
  [
    "Overall I think this paper presents an interesting idea in combing model based and model free RL algorithms .",
    "NOVELTY"
  ],
  [
    "1 .The idea for this",
    "NOVELTY"
  ],
  [
    "1 .I \u2019 m not convinced about the magnitude of novelty in this paper . The proposed method seems very similar to ME-TRPO [ 2",
    "NOVELTY"
  ],
  [
    "There is also very limited technical contribution .",
    "NOVELTY"
  ],
  [
    "GAN-type models",
    "NOVELTY"
  ],
  [
    "The problem studied in this paper ( `` how to make an autonomous agent learn to gain maximal control of its environment `` ) is not novel , with much prior work",
    "NOVELTY"
  ],
  [
    "While the algorithm itself is novel",
    "NOVELTY"
  ],
  [
    ", it seems like a bit of an ad hoc combination of ideas",
    "NOVELTY"
  ],
  [
    "all sufficiently complex methods are likely to be original",
    "NOVELTY"
  ],
  [
    "The primary one is that the method is incremental and rather heuristic .",
    "NOVELTY"
  ],
  [
    "which is very good in the originality",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting and the",
    "NOVELTY"
  ],
  [
    "It is worth noting that the idea of applying `` local `` critics (",
    "NOVELTY"
  ],
  [
    "is n't new",
    "NOVELTY"
  ],
  [
    "Originality Although the theoretical framework and method in the paper are not new",
    "NOVELTY"
  ],
  [
    ", the paper derives novel theoretical results and supports them with empirical experiments .",
    "NOVELTY"
  ],
  [
    "which may potentially be quite wasteful and I like the formalization of invariance presented in this paper",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are significant .",
    "NOVELTY"
  ],
  [
    "Although I really like the theoretical contributions of this paper",
    "NOVELTY"
  ],
  [
    "There 's moderate novelty in the methodological contribution mentioned above",
    "NOVELTY"
  ],
  [
    "Overall the idea is interesting but I have some concerns mainly about evaluations and baselines which I am including below",
    "NOVELTY"
  ],
  [
    "the idea of planning with model-free policy has already been discussed by TDM",
    "NOVELTY"
  ],
  [
    "which is incremental to me",
    "NOVELTY"
  ],
  [
    "The paper is interesting and I like it .",
    "NOVELTY"
  ],
  [
    "To this point the paper presents no theoretical contribution , rather empirical findings only , that may or may not be ubiquitous in DNN learning systems",
    "NOVELTY"
  ],
  [
    "While I like the proposal idea",
    "NOVELTY"
  ],
  [
    "the problem , and together with a polynomial time algorithm for this subclass Pros",
    "NOVELTY"
  ],
  [
    "The problem definition is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "the analytic results seem to be trivial",
    "NOVELTY"
  ],
  [
    "and represents some incremental contribution for response generation in short conversations that are not goal-oriented .",
    "NOVELTY"
  ],
  [
    "It is an interesting extension of previous works",
    "NOVELTY"
  ],
  [
    "This paper proposed an interesting and intuitive image generation model .",
    "NOVELTY"
  ],
  [
    "a new generalization bounds based on local Rademacher Complexities , the novelty is relatively thin",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed architecture is novel .",
    "NOVELTY"
  ],
  [
    "Original clever idea .",
    "NOVELTY"
  ],
  [
    "While the technical novelty , as described in the paper , is relatively limited",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper contains very interesting novel ideas .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , modeling hamiltonian of a dynamic system using NN is novel .",
    "NOVELTY"
  ],
  [
    "among them .",
    "NOVELTY"
  ],
  [
    "This work provides a novel , concrete and practical methodology for learning dynamic systems in a physically grounded fashion .",
    "NOVELTY"
  ],
  [
    "Overall this seems like a nice attempt to combine Inverse Reinforcement Learning frameworks with collaborative filtering algorithms .",
    "NOVELTY"
  ],
  [
    "Overall this seems like an interesting approach and a reasonably timely paper , making what seems like a compelling contribution to a current hot",
    "NOVELTY"
  ],
  [
    "Even though the proposed method differs from the existing work in terms of a new normalization , the insights that led to this adjustment is elegant .",
    "NOVELTY"
  ],
  [
    "Even though the work lacks any new theoretical",
    "NOVELTY"
  ],
  [
    "understanding",
    "NOVELTY"
  ],
  [
    "since the fitting criterion in",
    "NOVELTY"
  ],
  [
    "3 ) were both proposed in some other papers , the contribution of the current submission seems merely applying this technique to the music application , which is not significant .",
    "NOVELTY"
  ],
  [
    "The paper presents a nice application of actor-critic method for conditional sequence prediction .",
    "NOVELTY"
  ],
  [
    "and I think it is fairly incremental",
    "NOVELTY"
  ],
  [
    "The recovery algorithm is essentially previous work ( but the application to graph recovery is new ) .",
    "NOVELTY"
  ],
  [
    "1 .Weak technical and theoretical novelty .",
    "NOVELTY"
  ],
  [
    "the proposed model is novel and is supported by strong theory .",
    "NOVELTY"
  ],
  [
    "this is an innovative paper that treats the subject with rigorous mathematical formalism",
    "NOVELTY"
  ],
  [
    "While this is clearly a good idea and the",
    "NOVELTY"
  ],
  [
    "because the contribution is quite incremental and rather application-specific",
    "NOVELTY"
  ],
  [
    "Their proposed algorithm has little in the way of surprising conceptual insights",
    "NOVELTY"
  ],
  [
    "the paper is an excellent contribution to",
    "NOVELTY"
  ],
  [
    "This paper is interesting and well written in general . To the best of my knowledge , this is the first paper that studies contextual ( stochastic ) bandits with context distributions , which is an interesting problem .",
    "NOVELTY"
  ],
  [
    "My only major concern is that this paper might be relatively technically straightforward based on existing literature",
    "NOVELTY"
  ],
  [
    "The contributions are somewhat incremental when the state-of-art is considered , but still",
    "NOVELTY"
  ],
  [
    "they offer improvements that may be useful to other researchers",
    "NOVELTY"
  ],
  [
    "The use of dense connectivity to avoid the loss of performance of using early-exit classifier is very interesting .",
    "NOVELTY"
  ],
  [
    "the paper proves two new",
    "NOVELTY"
  ],
  [
    "Neither map- > estimate- > control pipelines nor end-to-end differentiable Bayesian filtering are new",
    "NOVELTY"
  ],
  [
    "but this application is a novel and promising avenue for this sort of task",
    "NOVELTY"
  ],
  [
    "The action space of the agent is also novel",
    "NOVELTY"
  ],
  [
    "With such low performance results , it is not clear that this work directly advances the field in this area , despite its novelty .",
    "NOVELTY"
  ],
  [
    "The proposed adversarial memory unit is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "This is a natural continuation of multi-task/learning to learn ideas with adding one more layer in the hierarchy that has been mentioned in works of Baxter [ 7 ] .",
    "NOVELTY"
  ],
  [
    "I liked the idea behind the Section 4.3",
    "NOVELTY"
  ],
  [
    "My main reservation with this paper is the limited novelty .",
    "NOVELTY"
  ],
  [
    "although not novel enough according to the literature .",
    "NOVELTY"
  ],
  [
    "it is hard to find the novelty here , since similar comparisons have been already performed",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is modest .",
    "NOVELTY"
  ],
  [
    "to the best of my understanding",
    "NOVELTY"
  ],
  [
    "as far as I can tell , the main idea of the work is novel .",
    "NOVELTY"
  ],
  [
    "However , some minor novel variations of GAIL are also proposed , as well as novel architectural considerations .",
    "NOVELTY"
  ],
  [
    "The proposed concept for dynamic regret is simple and intuitive .",
    "NOVELTY"
  ],
  [
    "but seems rather straight forward and incremental compared with Hazan et al .",
    "NOVELTY"
  ],
  [
    "The conveyed impression is that the proposed methods are mainly incremental additions to the framework of Culpepper and Olshausen .",
    "NOVELTY"
  ],
  [
    "The paper seems to contain an idea which might have",
    "NOVELTY"
  ],
  [
    "the idea just does not seem to have been developed enough .",
    "NOVELTY"
  ],
  [
    "The idea of using backward value functions to model constraints in CMDP is interesting and so far I have not seen it in other places .",
    "NOVELTY"
  ],
  [
    "+It is an interesting idea to use part segmentation masks to align the input image with the target pose .",
    "NOVELTY"
  ],
  [
    "this paper is closely related to [ 1 ]",
    "NOVELTY"
  ],
  [
    "TPS transformation is a novel component .",
    "NOVELTY"
  ],
  [
    "-- No clear contribution of the paper is given ( although the main novelty relies in terms of model architecture",
    "NOVELTY"
  ],
  [
    "Overall , this paper provides novel technical results on a relevant problem in private machine learning ,",
    "NOVELTY"
  ],
  [
    "The problem discussed in this paper is novel and very interesting theoretically .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the state-of-the-art learning rate schedule , which uses a similar computational budget as the proposed method , is one cycle .",
    "NOVELTY"
  ],
  [
    "It seems the idea of online codevector histogram , or online vector histogram , is not new",
    "NOVELTY"
  ],
  [
    "While the contribution is thus in some sense an incremental improvement over this prior work",
    "NOVELTY"
  ],
  [
    "it seems that the algorithmic process can not be considered as completely original",
    "NOVELTY"
  ],
  [
    "Overall , it is my opinion that this submission presents original and interesting results , that complement the existing landscape of algorithms in a meaningful way",
    "NOVELTY"
  ],
  [
    "the use use of the Legendre polynomial seems rather creative",
    "NOVELTY"
  ],
  [
    "Novelty The novelty of the proposed architecture is not strong .",
    "NOVELTY"
  ],
  [
    ".The jumpy prediction was already introduced by",
    "NOVELTY"
  ],
  [
    "Overall Although the proposed architecture is not much novel",
    "NOVELTY"
  ],
  [
    "The idea of BQNs and propagation as tensor contractions is interesting and novel .",
    "NOVELTY"
  ],
  [
    "I think this paper presents interesting and novel ideas",
    "NOVELTY"
  ],
  [
    "I believe this work adds great insight and advances the SOTA in its area .",
    "NOVELTY"
  ],
  [
    "2/ Learning diversified objective through minimising the mutual information between two or among multiple pieces of information is not new .",
    "NOVELTY"
  ],
  [
    "the loss form is an interesting idea .",
    "NOVELTY"
  ],
  [
    "the method is novel ,",
    "NOVELTY"
  ],
  [
    "although it mostly bridges ideas from various fields .",
    "NOVELTY"
  ],
  [
    "and the idea appealing",
    "NOVELTY"
  ],
  [
    "I think the idea of building a set of strategies and trying to adapt the strategies picked based on the observation is an interesting idea .",
    "NOVELTY"
  ],
  [
    "Reusing trajectory data generated from multiple tasks to learn a policy of another task is not a novel idea .",
    "NOVELTY"
  ],
  [
    "The techniques used by this paper and the way they are combined are interesting and this paper directly answers to a question left open in a previous work",
    "NOVELTY"
  ],
  [
    "technical contributions of the paper could be summarized as adding a simple technique to reduce variation in predictions for the same training example due to techniques such as randomization",
    "NOVELTY"
  ],
  [
    "This idea is novel in GCN field .",
    "NOVELTY"
  ],
  [
    "Although it is motivated by a more general framework , the models in the experiment are simply doing frame prediction , which is not very novel .",
    "NOVELTY"
  ],
  [
    "this is an okay paper with incremental technical novelty and clear",
    "NOVELTY"
  ],
  [
    "In general , studying the adversarial examples in the synthetic domain seems not a significant contribution .",
    "NOVELTY"
  ],
  [
    "My main complaint would be the incremental nature of the work , as the contributions here are not as significant advances as some preceding ideas that have gone into this work , but still steadily improve on the vision of NP and appear to be necessary steps to push the model forward giving this work validity on its own",
    "NOVELTY"
  ],
  [
    "and the paper is a good contribution to the theory",
    "NOVELTY"
  ],
  [
    "Strong original contributions are not found in this work while I do not think lack of original contributions is a minus for this type of paper",
    "NOVELTY"
  ],
  [
    "The approach is simple and does not seem to present significant novelty over prior methods",
    "NOVELTY"
  ],
  [
    "of",
    "NOVELTY"
  ],
  [
    "unfortunately I do not believe that the methodological contribution is sufficiently novel and significant nor that the experimental results are sufficiently thorough and compelling to recommend the paper for publication",
    "NOVELTY"
  ],
  [
    "Nonetheless , I do not believe the arguments put forward are sufficiently rigorous or original to consider those as a substantial contribution .",
    "NOVELTY"
  ],
  [
    "The approach in this paper is really interesting since the proposed model is able to maintain a representation of its current state as a complex graph",
    "NOVELTY"
  ],
  [
    "The proposed rational polynomial spectral filter is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The framing of the problem , combination of existing work , and empirical evaluation and analysis appear to be original contributions .",
    "NOVELTY"
  ],
  [
    "Strengths I like the core idea of the paper : assuming some desired distribution of I/O examples",
    "NOVELTY"
  ],
  [
    "but is effectively a different implementation of the same core idea of the paper ,",
    "NOVELTY"
  ],
  [
    "its corpus generation is not a contribution",
    "NOVELTY"
  ],
  [
    "Some parts of section 3 are novel",
    "NOVELTY"
  ],
  [
    "The paper presents a novel ( as far as I am aware ) way to defend against adversarial attacks by cleaning images using a round trip in a bidirectional gan Cons",
    "NOVELTY"
  ],
  [
    "this is the first I have seen that included this fine-grained pairing",
    "NOVELTY"
  ],
  [
    "introduces an original method to the field",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this paper is the first to study this problem in the IRL setting and opens up an interesting direction for future research .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- The contributions are interesting",
    "NOVELTY"
  ],
  [
    "Although the strategy is not very original (",
    "NOVELTY"
  ],
  [
    "it",
    "NOVELTY"
  ],
  [
    "is a new observation for a strategy to be asymptotically optimal and minimax optimal",
    "NOVELTY"
  ],
  [
    "2 .I like the idea of using the hypothesis test result of Wald to come up with the ETC strategy in Algorithm 2 that achieves the lower bound for ETC strategy . This idea is new to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "3 .I feel that Theorem 5 is rather straight forward to see from the results of the optimal BAI algorithm and there is not a lot of novelty in this result",
    "NOVELTY"
  ],
  [
    "4 .Although presented as the main result of this paper , I do not see very novel ideas in the proof of the lower bounds for these strategies .",
    "NOVELTY"
  ],
  [
    "as to the best of my knowledge this is original in the literature",
    "NOVELTY"
  ],
  [
    "The ideas are intuitive",
    "NOVELTY"
  ],
  [
    "The idea of using a learned reward function instead of manually defined one sound sweet .",
    "NOVELTY"
  ],
  [
    "Cons Little conceptual and technical novelty [ Originality ] The major problem I found in this work is the lack of conceptual and technical novelty .",
    "NOVELTY"
  ],
  [
    "Overall , the conceptual originality is little .",
    "NOVELTY"
  ],
  [
    "despite lack of originality",
    "NOVELTY"
  ],
  [
    "The significance of this work is marginal , given the lack of originality .",
    "NOVELTY"
  ],
  [
    "2 .The idea of propagating uncertainty via Wasserstein barycenters is interesting and suggests several concrete realizations .",
    "NOVELTY"
  ],
  [
    "The method looks interesting",
    "NOVELTY"
  ],
  [
    "The paper presents a few novel extensions to existing work that clearly broaden its applicability .",
    "NOVELTY"
  ],
  [
    "in this field as the authors claim",
    "NOVELTY"
  ],
  [
    "While the paper is novel and tackles the problem that the previous variational neural relation inference does n't",
    "NOVELTY"
  ],
  [
    "This bound is to my knowledge novel and puts a useful worst case bound on the divergence of systematic and random scan mixing times .",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting idea for approximating set similarities much faster than MinHash .",
    "NOVELTY"
  ],
  [
    "The attempt to bridge model optimization and deep propagation is",
    "NOVELTY"
  ],
  [
    "somewhat interesting and novel",
    "NOVELTY"
  ],
  [
    "3 .The convergence analysis turns out to be weak and of limited novelty : it mimics largely the conventional PG analysis without introducing any conceptually new proof techniques and/or results",
    "NOVELTY"
  ],
  [
    "Unsupervised learning methods with GANs is certainly a relevant topic but this paper does not propose anything particularly novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "the ideas in this paper",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "The idea of searching network structure for detection with pre-training stage is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The ideas are interesting",
    "NOVELTY"
  ],
  [
    "The major issue of this paper is its novelty .",
    "NOVELTY"
  ],
  [
    "Paper presents interesting ideas on how to make computationally demanding aspects of K-FAC tractable",
    "NOVELTY"
  ],
  [
    "that seems a little incremental , in terms of the contribution",
    "NOVELTY"
  ],
  [
    "It certainly seems original",
    "NOVELTY"
  ],
  [
    "I found the proposed method quite interesting and intuitive .",
    "NOVELTY"
  ],
  [
    "The paper uses confusing notation , oversells the novelty , ignoring some relevant previous results",
    "NOVELTY"
  ],
  [
    "I think because it is a conceptually novel and potentially very influential idea",
    "NOVELTY"
  ],
  [
    "it lacks of innovation and",
    "NOVELTY"
  ],
  [
    "1 .The innovation and technical contribution are weak . The key idea of searching in embedding space has already been proposed and applied in Luo et al .2018 .The authors do not differentiate this work from Luo et al .2018",
    "NOVELTY"
  ],
  [
    "and adds interesting new insights into the performances of the FTL algorithm .",
    "NOVELTY"
  ],
  [
    "good .",
    "NOVELTY"
  ],
  [
    "I greatly enjoyed reading the paper",
    "NOVELTY"
  ],
  [
    "while the obverter idea is not new",
    "NOVELTY"
  ],
  [
    "Pros I found this paper interesting , informative , novel , and useful .",
    "NOVELTY"
  ],
  [
    "the idea proposed in the paper",
    "NOVELTY"
  ],
  [
    ", is rather intuitive",
    "NOVELTY"
  ],
  [
    "The methods used in the paper",
    "NOVELTY"
  ],
  [
    "the decoder network and the segmentation network are all existing methods without any",
    "NOVELTY"
  ],
  [
    "a relatively new",
    "NOVELTY"
  ],
  [
    "Lack of novelty : The data representation , which is presented as one of the core contributions of the paper , is not new .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is n't there , compared to Risi2019 which I feel has a much larger contribution to the line of work .",
    "NOVELTY"
  ],
  [
    "The idea of applying a Kalman filter in a latent space is interesting .",
    "NOVELTY"
  ],
  [
    "I think the paper is a good contribution to the literature .",
    "NOVELTY"
  ],
  [
    "Originality Adding a parametric policy to PETS is not the most original idea ,",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this work is original .",
    "NOVELTY"
  ],
  [
    "I agree that the development of pseudo labels and the objective function has enough novelty and is quite interesting .",
    "NOVELTY"
  ],
  [
    "As addressed in the paper , this approach is novel",
    "NOVELTY"
  ],
  [
    "It offers a novel approach (",
    "NOVELTY"
  ],
  [
    "though less so compared to the concurrent work of Battaglia et .al .2016",
    "NOVELTY"
  ],
  [
    "which represents a significant step forward in the current investigation of intuitive physics",
    "NOVELTY"
  ],
  [
    "because it is ( to my knowledge ) the first that presents a deep implementation of the conformal prediction paradigm",
    "NOVELTY"
  ],
  [
    "the paper is original",
    "NOVELTY"
  ],
  [
    "Derived self-normalizing Conductance-Weighted Averaging ( CWA ) mechanism is interesting in itself ,",
    "NOVELTY"
  ],
  [
    "simplistic",
    "NOVELTY"
  ],
  [
    "the idea is not novel .",
    "NOVELTY"
  ],
  [
    "but do not see novelty in the paper",
    "NOVELTY"
  ],
  [
    "and the proposed architecture is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "In terms of novelty , separating the dataset into normal + outliers/noise is not novel",
    "NOVELTY"
  ],
  [
    "In general , the novelty of the paper is limited and the experimental validation is a",
    "NOVELTY"
  ],
  [
    "the modification on the local adjustment",
    "NOVELTY"
  ],
  [
    "The proposed encoder/decoder model based on multiple SMILES representation is novel up to my knowledge .",
    "NOVELTY"
  ],
  [
    ", although incremental , idea",
    "NOVELTY"
  ],
  [
    "This is an interesting and useful new application of graph convolutional",
    "NOVELTY"
  ],
  [
    "The claim that the ability to handle variable-sized graphs is novel is also not true",
    "NOVELTY"
  ],
  [
    "This is a really novel optimizing technique that replace hand-crafted parameters update rules with learnable update rule .",
    "NOVELTY"
  ],
  [
    "2- The novelty of the work is limited .",
    "NOVELTY"
  ],
  [
    "2 .The idea of using the gradient with respect to the quantization points to learn them is interesting",
    "NOVELTY"
  ],
  [
    "but not entirely new",
    "NOVELTY"
  ],
  [
    "All three of the proposed modifications to the DTP algorithm seem incremental",
    "NOVELTY"
  ],
  [
    "As far as I know , this is the first attempt using such algorithms on ImageNet",
    "NOVELTY"
  ],
  [
    "Overall , the results are novel and very interesting in the setting of neural net distance .",
    "NOVELTY"
  ],
  [
    "The form of neural net distance is very similar to the MMD work in",
    "NOVELTY"
  ],
  [
    "but at the moment it is not clear such originality is necessary .",
    "NOVELTY"
  ],
  [
    "The proposed BatchBALD is a novel extension of one of the most widely studied acquisition function in the Bayesian active learning with disagreement ( BALD ) framework [ 10 ] , but targeting the selection of a joint ( dependent ) batch data samples to improve the data diversity .",
    "NOVELTY"
  ],
  [
    "This new method provides a nice extension of Liu 's algorithm to",
    "NOVELTY"
  ],
  [
    "I found the probabilistic modeling interesting .",
    "NOVELTY"
  ],
  [
    "While I feel that the thread on randomized smoothing is an incredibly promising and interesting research direction towards certifiably robust classifiers",
    "NOVELTY"
  ],
  [
    "this work hardly serves as a standalone result , instead reading like a sequel to the Cohen paper",
    "NOVELTY"
  ],
  [
    "this work provides no such analysis or new theoretical insight",
    "NOVELTY"
  ],
  [
    "The prototypical parts network presented in this work is original and potentially very useful learning framework for domains where process-based interpretability is",
    "NOVELTY"
  ],
  [
    "I have a little concern that the contribution is relatively limited since it is known that KL-divergence is not symmetric and the proposed KA",
    "NOVELTY"
  ],
  [
    "1 .I like the idea of applying the cycle consistency to the deeper layers rather than at the pixel level .",
    "NOVELTY"
  ],
  [
    "Overall , this is a nice contribution to the stochastic gradient MCMC literature with",
    "NOVELTY"
  ],
  [
    "Using this architecture in video game environments is novel .",
    "NOVELTY"
  ],
  [
    "Line 152-158 I think this is a good idea",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "The optimization of such problems appears to be nontrivial .",
    "NOVELTY"
  ],
  [
    "I did not think this mapping was unique",
    "NOVELTY"
  ],
  [
    "This paper is technically flawed .",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge no one else has made an effort to re-use trained proposals even across entirely different models",
    "NOVELTY"
  ],
  [
    "the methods per se are not new",
    "NOVELTY"
  ],
  [
    ", but their combination is new , thus resulting in a new model .",
    "NOVELTY"
  ],
  [
    "thus the method part seems a quite natural extension of the past effort but also sounds rather incremental even though the performance gain exists",
    "NOVELTY"
  ],
  [
    "the proposed architecture is nice",
    "NOVELTY"
  ],
  [
    "but somewhat seems incremental .",
    "NOVELTY"
  ],
  [
    "The technical contribution of the proposed method is not high , because the proposed method seems to be just using existing methods . - The contribution of the non-local operation is not clear to me .",
    "NOVELTY"
  ],
  [
    "the technical contribution of the proposed method is not so high",
    "NOVELTY"
  ],
  [
    "the paper is interesting",
    "NOVELTY"
  ],
  [
    "I understood the basic ideas of the paper and I liked them .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting and believe that it is a good contribution to the literature .",
    "NOVELTY"
  ],
  [
    "Pros 1 .Propose a unified framework for different loss objectives and parameters . 2 .An interesting idea in meta learning for learning loss objectives/schedule .",
    "NOVELTY"
  ],
  [
    "The results , to the best of my knowledge , are very novel and will be potentially interesting to many in the community , both theorists and practitioners .",
    "NOVELTY"
  ],
  [
    "and provides interesting insights",
    "NOVELTY"
  ],
  [
    "The idea is nice and somewhat novel",
    "NOVELTY"
  ],
  [
    "The analysis techniques appear to be rather standard",
    "NOVELTY"
  ],
  [
    "The work shares some similarities with He et al . \u2019 s NIPS 2016 paper on \u201c Dual learning for MT , \u201d but has more than enough new content to address the issues that arise with the fully unsupervised scenario",
    "NOVELTY"
  ],
  [
    "This is a solid first attempt at a new task",
    "NOVELTY"
  ],
  [
    "CONTRIBUTION The main contribution of the paper is not clearly stated .",
    "NOVELTY"
  ],
  [
    "The particular approach of jointly training a specification+grammar graph embedding and learning a policy that acts on different grammars seems original and significant enough for publication .",
    "NOVELTY"
  ],
  [
    "2 The contribution of this paper is not clear .",
    "NOVELTY"
  ],
  [
    "3 The novelty of this paper is insufficient .",
    "NOVELTY"
  ],
  [
    "This paper may have marginal contribution to the existing mini-batch method",
    "NOVELTY"
  ],
  [
    "The setting is very natural",
    "NOVELTY"
  ],
  [
    "The use of pgf for this model is not new , and the theorems/algorithms proposed seem like they are not hard to derive based on existing work",
    "NOVELTY"
  ],
  [
    "they nonetheless give very interesting insights",
    "NOVELTY"
  ],
  [
    "classifiers",
    "NOVELTY"
  ],
  [
    "PCAMNIST is a novel dataset introduced by the authors to understand the factors that influence various verification methods .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , there has been no study that proposes a unified framework for this problem . The authors present a unique and interesting approach that enables us to convert any SMT based verification method or MIP based verification method to a branch and bound based paradigm .",
    "NOVELTY"
  ],
  [
    "although the general idea of using sample compression bounds for condensed nearest neighbor classification has appeared in e.g",
    "NOVELTY"
  ],
  [
    "the idea here using random sampling in each Voronoi cell and noisy binary search the `` correct `` scale to minimize the error bound is",
    "NOVELTY"
  ],
  [
    "novel",
    "NOVELTY"
  ],
  [
    "I think overall this is a nice paper that provides active learning algorithm working in general metric space and providing nontrivial label complexity guarantees",
    "NOVELTY"
  ],
  [
    "my idea is a crude one",
    "NOVELTY"
  ],
  [
    "The notion of the `` local switching cost `` is novel .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel view for stabilising GANs from the perspective of control theory .",
    "NOVELTY"
  ],
  [
    "The construction of the information theoretic lower bound is novel and non-trivial . While the algorithm is inspired by Flaxman et al. , its analysis for approximately convex functions is novel .",
    "NOVELTY"
  ],
  [
    "although the approach is interesting",
    "NOVELTY"
  ],
  [
    "its novelty level seems to be low",
    "NOVELTY"
  ],
  [
    "the idea is intuitively attractive",
    "NOVELTY"
  ],
  [
    "Looking at [ 12,18 ] , the theoretical contribution seems too incremental .",
    "NOVELTY"
  ],
  [
    "While the paper presents a novel and highly effective approach",
    "NOVELTY"
  ],
  [
    "and the work is novel -- to my knowledge",
    "NOVELTY"
  ],
  [
    "There are an interesting and likely important set of ideas here",
    "NOVELTY"
  ],
  [
    "The idea is very interesting .",
    "NOVELTY"
  ],
  [
    "I liked the idea and the intuitions coming from the paper .",
    "NOVELTY"
  ],
  [
    "I think this self-supervised learning objective ( LMP ) is very novel .",
    "NOVELTY"
  ],
  [
    "the main idea of using codes for distributed system speed up seem to be already introduced in references",
    "NOVELTY"
  ],
  [
    "Other than the empirical comparison , there is little novelty to this paper ,",
    "NOVELTY"
  ],
  [
    "It also shows their power by providing a surprisingly large amount of novel theoretical results .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm and analysis seem insightful & novel",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting and to me seems worth exploring more",
    "NOVELTY"
  ],
  [
    "I can not asses how original is the solution from the linear programming perspective",
    "NOVELTY"
  ],
  [
    "However , its application for solving Nash equilibrium refinements is certainly novel .",
    "NOVELTY"
  ],
  [
    "This work could be a bit incremental extension of Nguyen et al , given that",
    "NOVELTY"
  ],
  [
    "I think the results presented in this paper is interesting and novel enough to be accepted",
    "NOVELTY"
  ],
  [
    "While the methods used in the paper exist already , I think the way in which they have been combined is sufficiently novel and interesting .",
    "NOVELTY"
  ],
  [
    "I like the idea of linguistically-controlled perturbations using PoS and NER .",
    "NOVELTY"
  ],
  [
    "The paper is novel in terms of exploring large-scale video generative model .",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "While variants of this idea have been tried with fine-tuning for transferred learning I still",
    "NOVELTY"
  ],
  [
    "think this work can classify as original and novel",
    "NOVELTY"
  ],
  [
    "The proposed TD method is novel .",
    "NOVELTY"
  ],
  [
    "I found the application of VRNN type generative model to financial data very promising .",
    "NOVELTY"
  ],
  [
    "To me , the biggest issue for this paper is that I 'm not sure if the paper contains significant novelty . The RNN-VAE combination has been around for more than a year and this paper does not propose significant changes to it",
    "NOVELTY"
  ],
  [
    "But I 'm concerned with the novelty and contributions of this paper",
    "NOVELTY"
  ],
  [
    "the first contribution of the paper is not new as it has already been recognized by a few paper that SGD exhibits two different regimes",
    "NOVELTY"
  ],
  [
    "To my knowledge , this part is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is in the MHE regularization terms",
    "NOVELTY"
  ],
  [
    "Their proof techniques are different from previous",
    "NOVELTY"
  ],
  [
    "The idea of integrating symbolic methods and neural networks to 1 ) learn better representations or 2 ) perform better search is not new .",
    "NOVELTY"
  ],
  [
    "The idea to combine the symmetrization of NN architectures with path finding algorithms is new to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The main contribution of this paper would be to provide a novel and interesting interpretation of previous ML techniques using an objective function in an information theoretic viewpoint .",
    "NOVELTY"
  ],
  [
    "The proposed decoding objective is not new",
    "NOVELTY"
  ],
  [
    "//www.cs.cmu.edu/~nasmith/papers/gimpel+smith.naacl12.pdf The use of RNNs in this context might be novel",
    "NOVELTY"
  ],
  [
    "though",
    "NOVELTY"
  ],
  [
    "The result is very interesting and novel .",
    "NOVELTY"
  ],
  [
    "This is a novel contribution",
    "NOVELTY"
  ],
  [
    "The work builds on and appears to improve upon a line of work that is emerging in the recent literature",
    "NOVELTY"
  ],
  [
    "I believe that the algorithmic architecture is novel .",
    "NOVELTY"
  ],
  [
    "and it does appear that the work advances the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "Based on the probabilistic model , the paper proposes a new regularizer .",
    "NOVELTY"
  ],
  [
    "The probabilistic explanation of the MLP and the CNN seems novel and was interesting to the reviewer",
    "NOVELTY"
  ],
  [
    "The author proposed a new probabilistic explanation of the neural network , which seems novel and worth reporting .",
    "NOVELTY"
  ],
  [
    "The idea is novel and impactful if its evaluated properly and consistently",
    "NOVELTY"
  ],
  [
    "Their approach and idea is very interesting and relevant",
    "NOVELTY"
  ],
  [
    "A simple idea of adding perturbation error to the counts , known",
    "NOVELTY"
  ],
  [
    "While the method Flush+Reload itself is not novel",
    "NOVELTY"
  ],
  [
    "I really liked the theoretical insights of this paper",
    "NOVELTY"
  ],
  [
    "Nevertheless , this paper provides a very interesting algorithm that advances the state of the art for convex optimization and unifies the analysis of a number of techniques in a clever way .",
    "NOVELTY"
  ],
  [
    "The paper oversells the approach in many ways .",
    "NOVELTY"
  ],
  [
    "yet I will try to contribute with my point of view as kernel svm and deep learning newbie researcher",
    "NOVELTY"
  ],
  [
    "The scattering transform approach is not new",
    "NOVELTY"
  ],
  [
    "This seems to be the biggest novelty of the paper",
    "NOVELTY"
  ],
  [
    "Generalizing the convergence results of ALISTA and ISTC is a nice contribution .",
    "NOVELTY"
  ],
  [
    "my main concern is with respect the novelty of the rest of the paper .",
    "NOVELTY"
  ],
  [
    "in my opinion , the impact of this publication is limited",
    "NOVELTY"
  ],
  [
    "these theoretical results are perhaps only incremental compared to existing results",
    "NOVELTY"
  ],
  [
    "The reviewer believes that this paper presents many interesting and novel results that extend our understanding of provable methods for dictionary learning .",
    "NOVELTY"
  ],
  [
    "the paper provides the first provable guarantees for convolution dictionary learning",
    "NOVELTY"
  ],
  [
    "however these contributions are too limited for publication",
    "NOVELTY"
  ],
  [
    "The modeling is building on pre-existing qa models but has some original aspects that were augmented to accommodate the various tasks .",
    "NOVELTY"
  ],
  [
    "Using the invertibility ( forward-backward ) of flow-based model to do voice conversion is an overall clever idea .",
    "NOVELTY"
  ],
  [
    "The novelty in machine learning/deep learning is limited .",
    "NOVELTY"
  ],
  [
    "The problem formulation is not entirely new",
    "NOVELTY"
  ],
  [
    "While there are already many notions of fairness proposed in past work , I found the proposed definition unique in the sense that it takes an game-theoretic approach to fair decisions",
    "NOVELTY"
  ],
  [
    "I think this is an interesting and novel idea",
    "NOVELTY"
  ],
  [
    "+",
    "NOVELTY"
  ],
  [
    "- not very original Overall , while not groundbreaking",
    "NOVELTY"
  ],
  [
    "this is a serious paper with interesting analysis .",
    "NOVELTY"
  ],
  [
    "The general idea of combining logical reasoning with neural models is quite appealing .",
    "NOVELTY"
  ],
  [
    "the approach is interesting ,",
    "NOVELTY"
  ],
  [
    "clever , interesting",
    "NOVELTY"
  ],
  [
    "I think that the insight from your paper \u00e2\u0080\u0094 pushing the burden of extrapolation to the confounding term \u00e2\u0080\u0094 is a very good one .",
    "NOVELTY"
  ],
  [
    "While the use of information bottleneck is not novel",
    "NOVELTY"
  ],
  [
    "the variable-to-static capsule routing indeed appears novel",
    "NOVELTY"
  ],
  [
    "To my knowledge , the submission is the first sound attempt to adapt this type of Dual-based algorithm for optimization of Deep Neural Network , which employs a proximal-point method that linearizes not the whole loss function but only the DNN ( up to the logits ) to form a convex subproblem and then deal with the loss part in the dual .",
    "NOVELTY"
  ],
  [
    "The attempt is not perfect",
    "NOVELTY"
  ],
  [
    "but the proposed approach is inspiring and I personally would love it published to encourage more development along this thread",
    "NOVELTY"
  ],
  [
    "The technical contribution of the paper is rather small ,",
    "NOVELTY"
  ],
  [
    "The problem and approach is not completely new , but it is a novel combination of",
    "NOVELTY"
  ],
  [
    "familiar techniques .",
    "NOVELTY"
  ],
  [
    "The method proposed in the paper to represent words in context is really interesting",
    "NOVELTY"
  ],
  [
    "I really liked the idea of representing a word in context by a subspace ( as opposed to a weighted sum ) .",
    "NOVELTY"
  ],
  [
    "This paper is marginally novel",
    "NOVELTY"
  ],
  [
    "This type of finite-sample analysis for SARSA is technically interesting to me due to the two challenge mentioned above",
    "NOVELTY"
  ],
  [
    "The method in this paper is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The key insight to deal with this difficulty is novel and clear .",
    "NOVELTY"
  ],
  [
    "Overall , the novel analysis here is indeed interesting and valuable .",
    "NOVELTY"
  ],
  [
    "Though the global idea is rather straightforward from my point of view , it looks to be a novel - effective - application of GANs .",
    "NOVELTY"
  ],
  [
    ".This paper uses the data flow graph of ADMM to construct deep network for MRI image restoration , which I considered as novel and interesting .",
    "NOVELTY"
  ],
  [
    "based on my expertise of DNN , I am not quite confident about how original and how important the idea of using the iteration steps of optimization to guide the construction of network is .",
    "NOVELTY"
  ],
  [
    "proposed",
    "NOVELTY"
  ],
  [
    "The analysis does not particularly involve new ideas",
    "NOVELTY"
  ],
  [
    "I 'm not convinced that is offers significant new results .",
    "NOVELTY"
  ],
  [
    "the only result that remains , being",
    "NOVELTY"
  ],
  [
    "both novel and relevant",
    "NOVELTY"
  ],
  [
    "On the other hand , the theoretical framework connects many existing models in very interesting ways and offers interesting insights as to their relationship .",
    "NOVELTY"
  ],
  [
    "I very much like the idea of giving a high-level overview and providing intuition for a result/proof",
    "NOVELTY"
  ],
  [
    "these ideas ( spectral-filtering ) are quite new/not",
    "NOVELTY"
  ],
  [
    "yet well known",
    "NOVELTY"
  ],
  [
    "In my view , this represents a sufficiently novel/original contribution .",
    "NOVELTY"
  ],
  [
    "I think the technical contribution of this paper is unclear",
    "NOVELTY"
  ],
  [
    "the idea is easy to understand and interesting",
    "NOVELTY"
  ],
  [
    "3 .It seems like the discounted linear regression estimator is not entirely new .",
    "NOVELTY"
  ],
  [
    "and the core method is novel as far as I am aware .",
    "NOVELTY"
  ],
  [
    "Feature matching loss ( Eq 2 ) is presented as a novel contribution without referring to related work in semisupervised learning literature .",
    "NOVELTY"
  ],
  [
    "I also found the new experimental results",
    "NOVELTY"
  ],
  [
    "very insightful",
    "NOVELTY"
  ],
  [
    "The work is clearly a novel combination of well-known techniques . To the best of my knowledge , they are the first group to demonstrate an effective application of the presented methods for these tasks .",
    "NOVELTY"
  ],
  [
    "However , the originality of the paper is rather limited and it is not clear what is the added value to for the community from such paper",
    "NOVELTY"
  ],
  [
    "The RL part of this paper is therefore moderately novel ,",
    "NOVELTY"
  ],
  [
    "In my opinion , the presented approach has a high quality and the results are original and significant .",
    "NOVELTY"
  ],
  [
    "second-order loss approximation are well explored in the gradient boosting literature , applying them to the cost efficient setting is novel .",
    "NOVELTY"
  ],
  [
    "I feel that the novelty of this paper is not that much given the work of XGBoost and GreedyMiser .",
    "NOVELTY"
  ],
  [
    "The proposed method is highly novel and original .",
    "NOVELTY"
  ],
  [
    "While the ideas presented in the paper are interesting",
    "NOVELTY"
  ],
  [
    "The paper has a new approach for fitting posterior distributions in a non-parametric fashion .",
    "NOVELTY"
  ],
  [
    "Overall this paper is novel and interesting",
    "NOVELTY"
  ],
  [
    "The idea of this combination is not surprising but the attendee of ICLR might be interested in the empirical results if the model clearly outperforms the existing method in the experimental results",
    "NOVELTY"
  ],
  [
    "The integration of convnets with the conditional random fields to model the structural dependencies of facial landmarks during face alignment is nice contribution .",
    "NOVELTY"
  ],
  [
    "The paper makes a few new (",
    "NOVELTY"
  ],
  [
    "but small )",
    "NOVELTY"
  ],
  [
    "I can not recommend accepting this paper due to its limited",
    "NOVELTY"
  ],
  [
    "Hence the experimental results seem a bit incremental to me , as far as I can tell .",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u00a2 EINNs are a novel contribution .",
    "NOVELTY"
  ],
  [
    "Overall my impression is this is an incremental advance the state of the art .",
    "NOVELTY"
  ],
  [
    "The primary question is novelty .",
    "NOVELTY"
  ],
  [
    "general , though , it is an interesting and well executed idea . It seems an original idea to use the mutual information in this way and clearly one can see the effect on the agent behaviour to hide/reveal intentions",
    "NOVELTY"
  ],
  [
    "This paper is highly interesting and strong",
    "NOVELTY"
  ],
  [
    "The discovering is coherent with with previous works , and it also brings new theoretical insights",
    "NOVELTY"
  ],
  [
    "I think it is a good work with interesting discoverings for the multi-task learning",
    "NOVELTY"
  ],
  [
    "the approach is clever",
    "NOVELTY"
  ],
  [
    "The algorithm seems novel ,",
    "NOVELTY"
  ],
  [
    "Furthermore the taxonomy did not provide me with any new insights or display a prediction that was actually clairvoyant",
    "NOVELTY"
  ],
  [
    "The problem by itself is new and interesting as it can not be trivially solve by existing best-arm identification algorithms .",
    "NOVELTY"
  ],
  [
    "the paper proposed pruning deep learning weights based on auxiliary parameters , which seems to be novel .",
    "NOVELTY"
  ],
  [
    "Several important novelties",
    "NOVELTY"
  ],
  [
    "this is a major novelty of this paper",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is marginal . The proposed approaches turn out to be a combination of existing active learning strategies for selecting data to query with the existing deep model for NER .",
    "NOVELTY"
  ],
  [
    "since AL itself is a meta learning framework and neural net as the base learner has been shown to be effective for AL , the novelty and contribution of a general discussion of applying AL for deep neural nets is marginal .",
    "NOVELTY"
  ],
  [
    "I think this is a paper with a clear contribution",
    "NOVELTY"
  ],
  [
    "The idea behind the proposed DEE score is nice and",
    "NOVELTY"
  ],
  [
    "The proposed idea is indeed interesting and I find the experimental results surprising",
    "NOVELTY"
  ],
  [
    "to the power consumption data set is a nice demonstration of the scalability of the proposed approach",
    "NOVELTY"
  ],
  [
    "As mentioned previously , this paper represents a novel combination of a number of prior approaches to provide faster inference and learning for the FHMM model class in the sense that these components have not been combined previously in the manner presented .",
    "NOVELTY"
  ],
  [
    "The claimed contribution of this point is somewhat limited .",
    "NOVELTY"
  ],
  [
    "I find the novelty of the system somewhat limited",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "In general this approach seems very interesting and I could imagine that it might be applicable to many other similarly structured problems",
    "NOVELTY"
  ],
  [
    "It is a novel and straightforward way to incorporate phrasal relation in the attention mechanism .",
    "NOVELTY"
  ],
  [
    "but the inclusion of the Radamacher term is new",
    "NOVELTY"
  ],
  [
    "While this is definitely a new result and there are new ideas",
    "NOVELTY"
  ],
  [
    "The discovering in the paper sounds interesting while the work looks like preliminary and unpolished",
    "NOVELTY"
  ],
  [
    "not the first attempt to solve such a problem",
    "NOVELTY"
  ],
  [
    "However this paper proposes a method to learn functions by restricting the function class to lyapunov stable functions with ICNNs -- which is indeed novel and exciting",
    "NOVELTY"
  ],
  [
    "this would qualify for a novel contribution",
    "NOVELTY"
  ],
  [
    "-A novel method for a rather new and understudied so far , the work is then interesting for this setting -Good results reported Cons",
    "NOVELTY"
  ],
  [
    "but this",
    "NOVELTY"
  ],
  [
    "is rather new for Open-set",
    "NOVELTY"
  ],
  [
    "DA",
    "NOVELTY"
  ],
  [
    "The novelty with respect to [ 11 ] is a bit limited .",
    "NOVELTY"
  ],
  [
    "The paper proposed a",
    "NOVELTY"
  ],
  [
    "The main challenging and novel part is in regularizing the model to avoid instabilities .",
    "NOVELTY"
  ],
  [
    "As mentioned above , the approach builds quite heavily on previous ones but",
    "NOVELTY"
  ],
  [
    "it has enough novel elements",
    "NOVELTY"
  ],
  [
    "although the application of L2S to RNN training is not new",
    "NOVELTY"
  ],
  [
    "Presents a new memory-related task .",
    "NOVELTY"
  ],
  [
    "Novelty and Significance The proposed external memory architecture is very similar to MQN [ Oh et al . ]",
    "NOVELTY"
  ],
  [
    "Overall , the methods are novel and interesting .",
    "NOVELTY"
  ],
  [
    "Self-attention is not new",
    "NOVELTY"
  ],
  [
    "The new proposal for a coupling layer seems like a clever way of introducing more parameters in a structured manner .",
    "NOVELTY"
  ],
  [
    "I think it has good ideas",
    "NOVELTY"
  ],
  [
    "the filtering idea and the ellipsoid idea are very similar",
    "NOVELTY"
  ],
  [
    "The presented method is interesting .",
    "NOVELTY"
  ],
  [
    "I am not sure how novel the algorithm is given",
    "NOVELTY"
  ],
  [
    "I would say that each individual piece is not drastically novel",
    "NOVELTY"
  ],
  [
    "but this is the first time I see all the components working successfully together",
    "NOVELTY"
  ],
  [
    "The idea of using non-linear matrix factorization for Bayesian optimization is novel , as well as its application to Automated Machine Learning .",
    "NOVELTY"
  ],
  [
    "The paper uses a scalable and probabilistic method for continuous algorithm selection which is interesting and novel .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well-written and proposes a novel method which is of interest to the AutoML community and should be accepted .",
    "NOVELTY"
  ],
  [
    "\u00c2 I think this submission is interesting and provides a different direction to understand neural network",
    "NOVELTY"
  ],
  [
    "There is little innovation on the part of the detection system ,",
    "NOVELTY"
  ],
  [
    "Overall , there is little novelty on the algorithmic side in this paper",
    "NOVELTY"
  ],
  [
    "The overall architecture is very similar to existing works such as COMA (",
    "NOVELTY"
  ],
  [
    "The numerical improvements seem fairly modest with respect to ( Tran \u2019 19 ) .",
    "NOVELTY"
  ],
  [
    "The bounds for Gaussian processes are relatively similar to the existing ones",
    "NOVELTY"
  ],
  [
    "The results are nevertheless not very different from previously existing ones .",
    "NOVELTY"
  ],
  [
    "with exciting methodological work",
    "NOVELTY"
  ],
  [
    "their application in this context and the leveraging of existing ODE solvers are new ideas in deep learning ) and interesting results .",
    "NOVELTY"
  ],
  [
    "Since the algorithm , dynamic mode decomposition ( DMD ) , has been proposed already in dynamical system literature , the novelty of the paper seems to be limited to kernelize it .",
    "NOVELTY"
  ],
  [
    "the setting , mechanism , and analysis are novel .",
    "NOVELTY"
  ],
  [
    "I like this interesting idea",
    "NOVELTY"
  ],
  [
    "The first result is not new in general ( already appeared in Schoenholz etc .and many follow up mean field papers",
    "NOVELTY"
  ],
  [
    "the results about ReLU ( initializing ( weigh_variance , bias_variance ) = ( 2 , 0 ) ) seems to be new .",
    "NOVELTY"
  ],
  [
    "The second one is a novel part of this paper",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "and insights",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "Originality I believe this work is original",
    "NOVELTY"
  ],
  [
    "though its methods largely overlap with those of [ 1 ]",
    "NOVELTY"
  ],
  [
    "Although the derived results are not likely the ultimate version of the regret bounds",
    "NOVELTY"
  ],
  [
    "they do provide interesting additions to existing results , and clearly contribute to the deeper understanding of the topic",
    "NOVELTY"
  ],
  [
    "Nevertheless , the paper provides enough additional novelties that make it a valuable contribution .",
    "NOVELTY"
  ],
  [
    "The SAL framework with self-play and a comparative discriminator is novel",
    "NOVELTY"
  ],
  [
    "The comparative discriminator is novel and well-suited for comparing pairs of samples .",
    "NOVELTY"
  ],
  [
    "I like the idea in the paper and am happy to vote for acceptance .",
    "NOVELTY"
  ],
  [
    "Although the paper does not have any big novelty",
    "NOVELTY"
  ],
  [
    "the paper may not be of contribution to the community at this stage",
    "NOVELTY"
  ],
  [
    "The novelty part is the new interpretation of such algorithm and the parametrization in",
    "NOVELTY"
  ],
  [
    "In sum , I think the interpretation of the learning to optimization idea in terms of machine teaching is novel and inspiring .",
    "NOVELTY"
  ],
  [
    "The algorithm is as far as I know an original and intuitively appealing combination of techniques previously introduced in this quite active subarea . I quite like it .",
    "NOVELTY"
  ],
  [
    "the methodology seems akin to an adaptive importance sampling approach for reinforcement learning",
    "NOVELTY"
  ],
  [
    "the claimed novelty of the",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is somewhat marginal .",
    "NOVELTY"
  ],
  [
    "I thoroughly enjoyed the paper and think it is a nice addition to the literature",
    "NOVELTY"
  ],
  [
    "The idea has been previously explored by a number of papers",
    "NOVELTY"
  ],
  [
    "It considers a new model , and the algorithm proposed is new",
    "NOVELTY"
  ],
  [
    "but similar to the existing methods in [ 11",
    "NOVELTY"
  ],
  [
    "The proposed method is novel",
    "NOVELTY"
  ],
  [
    "the interpolation idea",
    "NOVELTY"
  ],
  [
    "mostly clear and novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Proposition 3 seems to be trivial and is a supplementary contribution .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper becomes not clear given such situation .",
    "NOVELTY"
  ],
  [
    "This paper show the sMCL method is kind of incremental in novelty .",
    "NOVELTY"
  ],
  [
    "I agree the technical contribution might be a bit incremental comparing with previous works , but",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting idea",
    "NOVELTY"
  ],
  [
    "The contribution is modest , essentially applying the same idea as the one proposed in MAML to a variational objective , but",
    "NOVELTY"
  ],
  [
    "3 .The theoretical analysis is non-trivial and the technical contribution is high .",
    "NOVELTY"
  ],
  [
    "The use of RevNets in this context is an original and novel idea .",
    "NOVELTY"
  ],
  [
    "On the other one could argue that the major novelty of this work is a bit shallow ( a new problem specific loss function ) and that , as the authors admit , use of the method is still restricted to rather specific scenarios",
    "NOVELTY"
  ],
  [
    "A simple , straightforward idea",
    "NOVELTY"
  ],
  [
    "I find the result interesting and it is a nice addition to the literature but I do not find it very surprising in itself",
    "NOVELTY"
  ],
  [
    "The idea of incorporating hashing techniques for speeding up adaptive sampling in SGD is interesting .",
    "NOVELTY"
  ],
  [
    "The techniques themselves are not very original",
    "NOVELTY"
  ],
  [
    "the originality is low .",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are novel and interesting both from a theoretical and experimental point of view .",
    "NOVELTY"
  ],
  [
    "The contributions are novel and will likely lead to future work .",
    "NOVELTY"
  ],
  [
    "The combination between multiple-hypotheses approach with variational autoencoders seems rather artificial to me",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first proper proof of such non-surprising result .",
    "NOVELTY"
  ],
  [
    "but I find the contribution a bit limited .",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "The idea is incremental to multi-task learning and enable",
    "NOVELTY"
  ],
  [
    "to validate intermediate features for additional related tasks",
    "NOVELTY"
  ],
  [
    "The concept of neural stethoscope is interesting and simplify the concepts behind multitask learning .",
    "NOVELTY"
  ],
  [
    "The novelty is limited related to multitask learning , thus it is an incremental paper .",
    "NOVELTY"
  ],
  [
    "There is no innovation in the problem itself",
    "NOVELTY"
  ],
  [
    "but the idea of using meta-learning to address this problem is novel to some degree .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel encoder-based unsupervised representation learning . The network consists an encoder and a discriminator . The encoder learns to generate sample-specific codes , and discriminator tries to assign the generated code to the corresponding sample , given the correct sample and a set of incorrect samples . The method is tested on two relatively small datasets : MNIST and Fashion MNIST . The essence of the method is novel and make sense .",
    "NOVELTY"
  ],
  [
    "The qualitative results in Figures 1-4 do not seem to improve on previous work",
    "NOVELTY"
  ],
  [
    "I am not convinced this structure change meets innovation standard",
    "NOVELTY"
  ],
  [
    "The idea is interesting and straitforward",
    "NOVELTY"
  ],
  [
    "Thus , the theoretical result is not novel .",
    "NOVELTY"
  ],
  [
    "Overall , the method is novel and interesting and may have significant impact on large scale deep learning .",
    "NOVELTY"
  ],
  [
    "3 .The advantage over the prior work is not clear .",
    "NOVELTY"
  ],
  [
    "it is unclear to me if the contribution of the authors is enough , as the method used and its presentation are very close to Lang and al .",
    "NOVELTY"
  ],
  [
    "I think the presented work is too close to the existing literature and that the progress made is very incremental",
    "NOVELTY"
  ],
  [
    "I like the idea and think the paper should be accepted .",
    "NOVELTY"
  ],
  [
    "The training procedure and experimental setting are very similar to the original matching networks .",
    "NOVELTY"
  ],
  [
    "I think it is a simple , straightforward , novel extension",
    "NOVELTY"
  ],
  [
    "The combinatorial property provides novel crucial insights on the problem .",
    "NOVELTY"
  ],
  [
    "My main concern about this paper is its contribution .",
    "NOVELTY"
  ],
  [
    "The approach seems similar to an ensemble learning construct .",
    "NOVELTY"
  ],
  [
    "but its novelty is limited .",
    "NOVELTY"
  ],
  [
    "This idea is an interesting way to use a pretrained network",
    "NOVELTY"
  ],
  [
    "the paper IWGAN",
    "NOVELTY"
  ],
  [
    "This work provides a novel solution for reaction outcome prediction , which does not need prior knowledge of reaction templates .",
    "NOVELTY"
  ],
  [
    "I 'm not really sure what the difference is between their new DN method and standard cross-channel local contrast normalization",
    "NOVELTY"
  ],
  [
    "-- the idea is original to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "This is definitely an interesting idea , and a nice contribution to GNN",
    "NOVELTY"
  ],
  [
    "Interesting new idea",
    "NOVELTY"
  ],
  [
    "I very much enjoyed the simplicity of the approach",
    "NOVELTY"
  ],
  [
    "Defining A_l ( k ) and I_l ( k ) for a refined upper bound , as well as the idea of using a probabilistic lower bound is new compared to prior work .",
    "NOVELTY"
  ],
  [
    "The theoretical results presented in this paper are interesting and novel",
    "NOVELTY"
  ],
  [
    "The paper 's idea of defining a similarity using many RP Trees with different randomization is quite interesting and sounds promising given that the recently reported performance of tree ensembles such as XGBoost and LightGBM is very good",
    "NOVELTY"
  ],
  [
    "this paper also has several problems 1 ) novelty and 2",
    "NOVELTY"
  ],
  [
    "For ( a",
    "NOVELTY"
  ],
  [
    "the novelty is rather small ,",
    "NOVELTY"
  ],
  [
    "and thus the use of RP trees to define the similarity , and applying them to clustering",
    "NOVELTY"
  ],
  [
    "is not new",
    "NOVELTY"
  ],
  [
    "While the idea of incorporating chemical domain knowledge in the interactions of an atomistic neural network is interesting in principle",
    "NOVELTY"
  ],
  [
    "I believe this paper is a good contribution for ICLR . The result is relevant and interesting , and extends recent ideas around reduced-variance policy gradient estimators",
    "NOVELTY"
  ],
  [
    "However , contributions are little simple .",
    "NOVELTY"
  ],
  [
    "because I believe the paper makes a clear and substantial contribution to the CL literature",
    "NOVELTY"
  ],
  [
    "While the conceptual contribution may seem relatively low vis-a-vis PathNets , I would like to argue that using very high capacity models for such problems is actually a novelty on its own which is not covered by PathNets .",
    "NOVELTY"
  ],
  [
    "I believe that not only the combination of previous methods is new",
    "NOVELTY"
  ],
  [
    "incremental deep learning .",
    "NOVELTY"
  ],
  [
    "The new",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- This paper ranks high in novelty as it is the first paper to consider discrete flows and also proposes the first discrete flow transformation layers ( XOR and Additive",
    "NOVELTY"
  ],
  [
    "I believe that this is an innovative model",
    "NOVELTY"
  ],
  [
    "this paper appears to be almost entirely applying existing tools to a mathematically natural variant of",
    "NOVELTY"
  ],
  [
    "while this paper contains",
    "NOVELTY"
  ],
  [
    "As the authors note , parameterizing an exponential family distribution with the outputs of a neural network is not a novel contribution",
    "NOVELTY"
  ],
  [
    "I found this to be the most interesting portion of the paper and the most significant contribution .",
    "NOVELTY"
  ],
  [
    "I do not think the models proposed in section 2 are sufficiently novel to justify publication alone which means that the authors need to either",
    "NOVELTY"
  ],
  [
    "present a convincing evaluation that strongly motivates the proposed model 's use or that provides some novel insight into the model 's behavior",
    "NOVELTY"
  ],
  [
    "The contribution is somewhat significant to this point for providing novel tools for future researches",
    "NOVELTY"
  ],
  [
    "I quite like the main idea of the paper , which is based on the observation in Sec .3.0 - that the authors find many predictable patterns in the independent evolution of weights during neural network training .",
    "NOVELTY"
  ],
  [
    "The novelty and experiments are somewhat limited .",
    "NOVELTY"
  ],
  [
    "Overall nice but simple extension of TT/ TR framework 2",
    "NOVELTY"
  ],
  [
    "and it provides an elegant and generic framework for learning invariant representations",
    "NOVELTY"
  ],
  [
    "and the visualisation of Fig 2 is pretty interesting and original .",
    "NOVELTY"
  ],
  [
    "this contribution seems to be orthogonal to the sparsity regularization ,",
    "NOVELTY"
  ],
  [
    "I suppose",
    "NOVELTY"
  ],
  [
    "is presented gives readers the impression that spatial pairwise regularization is new",
    "NOVELTY"
  ],
  [
    "By the way , the use of histograms ( of patches or super-pixels ) as unsupervised features in pairwise regularization is not new neither",
    "NOVELTY"
  ],
  [
    "So , in summary , the technical contribution is minor , in my opinion",
    "NOVELTY"
  ],
  [
    "I really enjoyed reading this paper .",
    "NOVELTY"
  ],
  [
    "provides the first characterization of limit points of basic first order methods",
    "NOVELTY"
  ],
  [
    "the proposed solution is novel and deserves to be known",
    "NOVELTY"
  ],
  [
    "The paper contains interesting new results .",
    "NOVELTY"
  ],
  [
    "I find the paper to be very incremental in terms of originality of the method .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel model for the recently introduced VCR task .",
    "NOVELTY"
  ],
  [
    "The proposed model is novel and interesting for a novel and useful task .",
    "NOVELTY"
  ],
  [
    "Originality Improving the translation procedure by leveraging error detection on the target programming language is not a new idea , even though the authors do not seem to be aware of this",
    "NOVELTY"
  ],
  [
    "This paper certainly sets a right step in this direction and is a very timely contribution",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "the application and especially the focus on cell-cell interactions is novel .",
    "NOVELTY"
  ],
  [
    "I really like the premise of the paper .",
    "NOVELTY"
  ],
  [
    "Trading penalty parameter ( speed ) for theoretical bound is not a significant contribution .",
    "NOVELTY"
  ],
  [
    "Their methodological contribution may be a bit incremental for a NIPS paper .",
    "NOVELTY"
  ],
  [
    "but the rest of the innovations are rather simple algebra tricks and do n't lead to the same impressive results",
    "NOVELTY"
  ],
  [
    "This is a good multiview representation learning paper with new insights .",
    "NOVELTY"
  ],
  [
    "it seems the extension is not trivial",
    "NOVELTY"
  ],
  [
    "I agree with the second reviewer that the approach is interesting .",
    "NOVELTY"
  ],
  [
    ", and the idea of combining L2 regularizer with desired statistical accuracy , V_n , is novel ( to the best of my knowledge ) .",
    "NOVELTY"
  ],
  [
    "Originality The task is",
    "NOVELTY"
  ],
  [
    "new , though there are related works on autonomous reconstruction of 3D scenes or next-best-view selection for object pose estimation",
    "NOVELTY"
  ],
  [
    "Significance This is a new task .",
    "NOVELTY"
  ],
  [
    "The authors have convinced me that the analysis of the non-smooth loss is novel",
    "NOVELTY"
  ],
  [
    "the improvements in this paper , compared with TWF , seem minimal .",
    "NOVELTY"
  ],
  [
    "and presents a nice idea",
    "NOVELTY"
  ],
  [
    "I weakly reject this paper because although the approach is indeed interesting",
    "NOVELTY"
  ],
  [
    "It is thus very hard to know if this new approach brings any improvement to previous work .",
    "NOVELTY"
  ],
  [
    "The idea is simple",
    "NOVELTY"
  ],
  [
    "Although the contribution is rather incremental",
    "NOVELTY"
  ],
  [
    "I think the theoretical result is novel and timely and would interest many readers in the deep learning community .",
    "NOVELTY"
  ],
  [
    "like the algorithm GTW proposed in this paper",
    "NOVELTY"
  ],
  [
    "re-formulating the Equation ( 3 ) as a max-flow problem is novel",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u0093 The paper provides a novel perspective on how the push-pull feedback mechanism could possibly aid hierarchical information retrieval .",
    "NOVELTY"
  ],
  [
    "after author 's rebuttal == The study of MMD DRO in the submission seems novel ,",
    "NOVELTY"
  ],
  [
    "The theoretically-backed derivation of the truncated loss is nice -- in contrast with several heuristics proposed in this area",
    "NOVELTY"
  ],
  [
    "I think this is a solid contribution and deserves publication",
    "NOVELTY"
  ],
  [
    "the idea is original",
    "NOVELTY"
  ],
  [
    "At first glance the proposed method looks like a simple and straightforward extension t (",
    "NOVELTY"
  ],
  [
    "simplification ) of previous work on feedback alignment",
    "NOVELTY"
  ],
  [
    "the contribution of the paper seems strong .",
    "NOVELTY"
  ],
  [
    "the paper rests on a very clever idea `` Instead of choosing a generic object-classification CNN as a source of visual features",
    "NOVELTY"
  ],
  [
    "It is indeed probably the most clever idea that I have seen on deep features encoding in brain imaging for years .",
    "NOVELTY"
  ],
  [
    "The idea of utilizing GCN on the feature co-occurrence graph is interesting and innovative .",
    "NOVELTY"
  ],
  [
    "2 .It is an interesting idea to combine sample similarity together with feature co-occurrence for better prediction accuracy .",
    "NOVELTY"
  ],
  [
    "Originality I find the simple idea presented by the authors to minimize rather than maximize surprise quite original .",
    "NOVELTY"
  ],
  [
    "The authors succeeded in demonstrating that the combination of counterfactual and active learning requires original ideas",
    "NOVELTY"
  ],
  [
    "2 .This submission proposes new theoretical insight about compression and adaptability .",
    "NOVELTY"
  ],
  [
    "The contribution is therefore limited .",
    "NOVELTY"
  ],
  [
    "The constructions of this paper seem to follow mostly from previous work .",
    "NOVELTY"
  ],
  [
    "The authors address a prevailing research topic and has some novel contributions ( see below ) to the field of audio and music generation .",
    "NOVELTY"
  ],
  [
    "in this contribution , music is modelled directly on the waveform for the first time ,",
    "NOVELTY"
  ],
  [
    "2 .The general idea of integrating measures of predictive uncertainty into a PAC way of thinking seem promising .",
    "NOVELTY"
  ],
  [
    "There are interesting ideas in the paper .",
    "NOVELTY"
  ],
  [
    "The paper is technically very heavy and gives very little insight and intuition behind the results .",
    "NOVELTY"
  ],
  [
    "This is novel and theoretical sounding .",
    "NOVELTY"
  ],
  [
    "which is a novel founding",
    "NOVELTY"
  ],
  [
    "Although it is just an extension of existing works",
    "NOVELTY"
  ],
  [
    "There are certain contribution and originality in the literature .",
    "NOVELTY"
  ],
  [
    "with understandable high level ideas",
    "NOVELTY"
  ],
  [
    "The novelty of this proposal is that it explains a couple of important features of observed data",
    "NOVELTY"
  ],
  [
    "via a MCMC method which was not previously considered as a model for cognition",
    "NOVELTY"
  ],
  [
    "this is a nice conference paper which presents an interesting idea and some preliminary support for it",
    "NOVELTY"
  ],
  [
    "The solution is related to other recently proposed work",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well-written and the ideas are novel .",
    "NOVELTY"
  ],
  [
    "This work is a nice follow up to Neal ( 1994 ) , and recent work considering similar results for neural networks with more than one hidden layer",
    "NOVELTY"
  ],
  [
    "and the algorithm it is packaged with is interesting",
    "NOVELTY"
  ],
  [
    "I will argue it is lacking on the contribution side as the models are all closely related to prior works",
    "NOVELTY"
  ],
  [
    "This work built on a lot of recent works to obtain the results and the techniques are novel in my opinion .",
    "NOVELTY"
  ],
  [
    "since",
    "NOVELTY"
  ],
  [
    "the applications are limited and it is primary theoretical contribution .",
    "NOVELTY"
  ],
  [
    "Following author response -- -- -- -- -- -- -- -- -- -- -- -- -- -- The points the authors make in the response are interesting",
    "NOVELTY"
  ],
  [
    "The insights about inequality are also interesting and natural",
    "NOVELTY"
  ],
  [
    "The proposed causal discovery method is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "The idea of checking whether nearest neighbors are overwhelmingly in-language , is very intuitive , and it is surprising that no one did this before",
    "NOVELTY"
  ],
  [
    "Overall the contributions in terms of lower bounds are significant and almost match the state of the art known upper bounds .",
    "NOVELTY"
  ],
  [
    "and to my knowledge are novel .",
    "NOVELTY"
  ],
  [
    "The paper is an incremental advance on recent work for quantile regression with neural networks [ 1,2 ] .",
    "NOVELTY"
  ],
  [
    "This paper synthesizes recent work on quantile regression and provides a clear , probabilistic interpretation for these",
    "NOVELTY"
  ],
  [
    "but is a good contribution in my opinion",
    "NOVELTY"
  ],
  [
    "It is not novel to infer the learning rules underlying an animal\u00e2\u0080\u0099s behavioral changes during training",
    "NOVELTY"
  ],
  [
    "Using the inferred algorithm for adaptive optimal training seems a nice idea",
    "NOVELTY"
  ],
  [
    "This paper proposes interesting ideas",
    "NOVELTY"
  ],
  [
    "The idea of using hierarchical decoders have been explored before",
    "NOVELTY"
  ],
  [
    "However , the contributions from the general ML point of view is still limited .",
    "NOVELTY"
  ],
  [
    "Mainly an architecture engineering/application paper ( bringing together various well-known techniques ) , not much novelty .",
    "NOVELTY"
  ],
  [
    "These results are sufficient novel for publication .",
    "NOVELTY"
  ],
  [
    "I like the idea of wassersteinizing Mutual information , and the reasoning that enforcing Lipschitz constraint in CPC bounds prevents the encoder to exaggerate small differences .",
    "NOVELTY"
  ],
  [
    "The paper adds a very simple dynamic loss balancing to a joint loss , which has limited novelty",
    "NOVELTY"
  ],
  [
    "The paper outperforms state-of-the-art",
    "NOVELTY"
  ],
  [
    "The role of the task prior and how it emerges from early stopping ( ie a finite number of gradient descent steps ) ( sec 3.2 ) is original and technically non-trivial , and is a contribution of this paper .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "the paper is interesting",
    "NOVELTY"
  ],
  [
    "The separability perspective of representation power seems novel .",
    "NOVELTY"
  ],
  [
    "The coloring based method is interesting and simple to implement .",
    "NOVELTY"
  ],
  [
    "but does not present any substantial contribution to warrant a nips publication .",
    "NOVELTY"
  ],
  [
    "The advantages of the proposed method are not very clear as compared to existing methods .",
    "NOVELTY"
  ],
  [
    "2 .There seems to be a lack of novelty except combining Sinha et al \u2019 s theoretical result with GAN training objective .",
    "NOVELTY"
  ],
  [
    "3 .The proof in this paper shares similar analysis with that in vanilla GAN paper so theoretically there is also not much novelty",
    "NOVELTY"
  ],
  [
    "but lacks novelty and theoretical contribution",
    "NOVELTY"
  ],
  [
    "The material is very original and very useful since it improves the original goal of hyperbolic neural networks ( model graph and tree-like data ) .",
    "NOVELTY"
  ],
  [
    "This is a simple , easy-to-implement idea that could easily be incorporated into existing models and frameworks .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the idea to using Poisson-minibatching to reduce calculating factors is novel .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution is interesting and significant enough for a NIPS paper .",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper seems to be a limitation in novelty .",
    "NOVELTY"
  ],
  [
    "The Mario environment result discussed in section 6.2 is interesting in its own right , and provides some insight into previous work . Despite the limited novelty of the IDE reward term",
    "NOVELTY"
  ],
  [
    "The derivation of the proposed method is not complex but I like the idea that models quantization error as additive perturbation in this context and how it eventually connects with gradient penalty that 's widely used in GAN training and adversarial robustness",
    "NOVELTY"
  ],
  [
    "The paper also proposes two novel RNN architectures",
    "NOVELTY"
  ],
  [
    "NOVELTY This paper is the first to my knowledge to empirically measure the number of bits of information that can be stored per learnable parameter . The idea of measuring network capacity by finding the dataset size and other hyperparameters that maximizes mutual information is a particularly novel experimental setup .",
    "NOVELTY"
  ],
  [
    "The paper suffers from several drawbacks",
    "NOVELTY"
  ],
  [
    "lack of novelty and originality",
    "NOVELTY"
  ],
  [
    "However , the idea is hardly novel regarding to the theme of the conference",
    "NOVELTY"
  ],
  [
    "The suggested idea is great .",
    "NOVELTY"
  ],
  [
    "which is a good contribution to the theory of GAN and should be included in the literature",
    "NOVELTY"
  ],
  [
    "I agree with other reviewers that it is interesting model and nice application of variational inference as well",
    "NOVELTY"
  ],
  [
    "As far as I know , calibration by modeling parameters in the Dirichlet distribution is novel .",
    "NOVELTY"
  ],
  [
    "Theorem 4.1 is to my opinion a novel and interesting result , which defines the core of the paper .",
    "NOVELTY"
  ],
  [
    "I do not see any algorithmic novelty in the paper which I believe s required for a conference like NIPS .",
    "NOVELTY"
  ],
  [
    "the proposed initial solution to this problem is interesting .",
    "NOVELTY"
  ],
  [
    "I liked the idea ,",
    "NOVELTY"
  ],
  [
    "meta-weight-net is interesting",
    "NOVELTY"
  ],
  [
    "The idea of using the previous unused state in ternary neural network is interesting \u2022 Overall",
    "NOVELTY"
  ],
  [
    "The idea of using mixed bit width for neural network quantization is not new .",
    "NOVELTY"
  ],
  [
    "The proposed method is simple , straightforward , yet novel .",
    "NOVELTY"
  ],
  [
    "The approach proposed in the paper is very interesting and perhaps novel",
    "NOVELTY"
  ],
  [
    "this overall approach is very fascinating",
    "NOVELTY"
  ],
  [
    "paper proposes a novel factorisation approach and uses recurrent networks",
    "NOVELTY"
  ],
  [
    "Overall , while I am not an expert in musical composition and machine learning , the paper",
    "NOVELTY"
  ],
  [
    "appears to be advancing the art in a reliable fashion .",
    "NOVELTY"
  ],
  [
    "( if refined further ) , I find the method lacks novelty ,",
    "NOVELTY"
  ],
  [
    "If this is the first attempt that applied rate-distortion theory and channel coding theorem to the crowdsourcing problem , it can be a reasonably important contribution to the field",
    "NOVELTY"
  ],
  [
    "the novelty and practical values of this paper are still questionable",
    "NOVELTY"
  ],
  [
    "The technical contribution is somehow limited",
    "NOVELTY"
  ],
  [
    "It does not sound too novel ,",
    "NOVELTY"
  ],
  [
    "Although the idea is good",
    "NOVELTY"
  ],
  [
    "This itself is a notable achievement",
    "NOVELTY"
  ],
  [
    "My main concern is that the proposed algorithm seems relatively brittle",
    "NOVELTY"
  ],
  [
    "but are not new",
    "NOVELTY"
  ],
  [
    "I am not an expert in ordinal embedding but the results seem quite novel and insightful .",
    "NOVELTY"
  ],
  [
    "Significance/Originality My main concern is that this work seems to nearly directly follow from [ 1 ]",
    "NOVELTY"
  ],
  [
    "significance The technique presented in the paper is quite novel .",
    "NOVELTY"
  ],
  [
    "general , I think the authors ' approach follows an interesting idea , namely using recurrent network to",
    "NOVELTY"
  ],
  [
    "brain .",
    "NOVELTY"
  ],
  [
    "The paper provides nice results some intriguing ideas",
    "NOVELTY"
  ],
  [
    "I like the idea of going toward more complex games than those found on Atari 2600",
    "NOVELTY"
  ],
  [
    "so it is hardly something new",
    "NOVELTY"
  ],
  [
    "the idea of reconstructing hidden activations is not new",
    "NOVELTY"
  ],
  [
    "although",
    "NOVELTY"
  ],
  [
    "the approach seems incremental",
    "NOVELTY"
  ],
  [
    "It is original ,",
    "NOVELTY"
  ],
  [
    "The reasoning using arithmetic circuits seems interesting",
    "NOVELTY"
  ],
  [
    "but a bit incremental .",
    "NOVELTY"
  ],
  [
    ", the contribution of combining Scattering and CNNs is novel and the results seem promising .",
    "NOVELTY"
  ],
  [
    "The paper is highly original in relating recent results from algebra to basic issues about neural networks .",
    "NOVELTY"
  ],
  [
    "Although I found the paper interesting",
    "NOVELTY"
  ],
  [
    "This paper contains several contributions .",
    "NOVELTY"
  ],
  [
    "this paper is rather original .",
    "NOVELTY"
  ],
  [
    "Nevertheless , I believe the methods proposed to be interesting .",
    "NOVELTY"
  ],
  [
    "The idea of DiffOpNets is original and clever .",
    "NOVELTY"
  ],
  [
    "The three applications of DiffOpNets ( Jacobi-Newton iterations , exact log density of neural ODEs , learning SDEs ) are original and exciting . Overall , the originality of the paper is high .",
    "NOVELTY"
  ],
  [
    "The proposed model and learning framework are closely related to previous work ( AIR , SPAIR ) .",
    "NOVELTY"
  ],
  [
    "I think there are quite a few novel and interesting ideas in this work .",
    "NOVELTY"
  ],
  [
    "but I do not see significant novelty of the proposed method from the current manuscript",
    "NOVELTY"
  ],
  [
    "with the NTK and the novelty is limited from a theoretical point of view",
    "NOVELTY"
  ],
  [
    "Overall , the paper presents results that advance the theory of active and passive learning .",
    "NOVELTY"
  ],
  [
    "it is hard to gain scientific insight from them",
    "NOVELTY"
  ],
  [
    "The connection to the concept of free energy in optimization framework seems interesting .",
    "NOVELTY"
  ],
  [
    "To me , the setting is very interesting and according to the paper , it seems that it is the first formalization for this setting",
    "NOVELTY"
  ],
  [
    "Of course both are already proposed by other work",
    "NOVELTY"
  ],
  [
    "I 'm a bit skeptical about the originality of the paper .",
    "NOVELTY"
  ],
  [
    "The hard concrete distribution is a small but nice contribution on its own .",
    "NOVELTY"
  ],
  [
    "this paper is not a technically contributed paper .",
    "NOVELTY"
  ],
  [
    "Given that the approach to rate-distortion optimization has already been published , the novelty of this submission is arguably not very high",
    "NOVELTY"
  ],
  [
    "I think the idea is quite interesting",
    "NOVELTY"
  ],
  [
    "The proposed piece-wise linear relaxation ( PWL ) can be considered as the inverse CDF of the random variable is very interesting .",
    "NOVELTY"
  ],
  [
    "The connection between path Dantzig selector formulation and sensitivity analysis looks interesting to me .",
    "NOVELTY"
  ],
  [
    "A novel connection between high-dimensional linear regression and lattice basis reduction is the main strength of the paper .",
    "NOVELTY"
  ],
  [
    "and the idea sounds interesting .",
    "NOVELTY"
  ],
  [
    "The paper is largely a continuation of the preliminary paper which focuses on the same problem and research question",
    "NOVELTY"
  ],
  [
    "However , the two main methodological contributions of the paper seem quite thin to me .",
    "NOVELTY"
  ],
  [
    "the two main contributions of the work are not so substantial and overall the paper mostly proves an already established fact",
    "NOVELTY"
  ],
  [
    "I like the idea of adversarial training to generate less blurry and realistic looking images of objects from high-level representation .",
    "NOVELTY"
  ],
  [
    "I find this to be a conceptually strong paper with interesting ideas",
    "NOVELTY"
  ],
  [
    "however it is hard to find some novel insights other than the known fact that jitter helps to achieve invariance",
    "NOVELTY"
  ],
  [
    "Provides an interesting architecture compared to ResNet and its variants and investigates the differences to residual networks which can stimulate some other promising analysis cons",
    "NOVELTY"
  ],
  [
    "-this is not the first paper using probabilistic coupling arguments in the setting of differential privacy and few related works are missing",
    "NOVELTY"
  ],
  [
    "the fact that this also suffices to determine * individual * treatment policies was ( at least to me ) a new and unexpected find .",
    "NOVELTY"
  ],
  [
    "Still , as far as I can tell the solution presented is original , interesting , and significant .",
    "NOVELTY"
  ],
  [
    "CDDNwithTDC is new and novel",
    "NOVELTY"
  ],
  [
    "The idea of their methods is very interesting",
    "NOVELTY"
  ],
  [
    "I agree that the paper contains interesting new ideas .",
    "NOVELTY"
  ],
  [
    "While I find the proposed approach interesting",
    "NOVELTY"
  ],
  [
    "I find the proposed ideas",
    "NOVELTY"
  ],
  [
    "This paper does not provide any theoretical or algorithmic contribution .",
    "NOVELTY"
  ],
  [
    "but does not contain theoretical or algorithmic contributions .",
    "NOVELTY"
  ],
  [
    "and the trade-off in the flush operation is innovative",
    "NOVELTY"
  ],
  [
    "Not much technically new or surprising compared to past work on disentangling generative models .",
    "NOVELTY"
  ],
  [
    "The results discussed in the paper are non-trivial extensions to the work of Dasgupta",
    "NOVELTY"
  ],
  [
    "The analysis is original as per my knowledge of the related literature .",
    "NOVELTY"
  ],
  [
    "The approach of this paper is original and insightful .",
    "NOVELTY"
  ],
  [
    "The technical contribution is original . The vision-based agent localization approach is novel compared to the methods of the literature .",
    "NOVELTY"
  ],
  [
    "The paper is original , well written , easy to follow and presented ideas are interesting",
    "NOVELTY"
  ],
  [
    "The presentation also follows an inequitable pattern where the backgrounds and related works are overemphasized and the actual contribution of the paper seems very limited",
    "NOVELTY"
  ],
  [
    "Furthermore , even if the extension for convolutional layers is new , I feel the technical contribution is incremental",
    "NOVELTY"
  ],
  [
    "This work seems to be related to the work on 1",
    "NOVELTY"
  ],
  [
    "I am not convinced about how truly novel the method is when viewed as a whole",
    "NOVELTY"
  ],
  [
    "I had a hard time understanding the contribution of this",
    "NOVELTY"
  ],
  [
    "The originality seems to be limited",
    "NOVELTY"
  ],
  [
    "The idea is interesting and straightforward and I am surprised that no one has done this before",
    "NOVELTY"
  ],
  [
    "The flow reversal layer is somehow novel",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting but there is significant room for improvement",
    "NOVELTY"
  ],
  [
    "Even though there is no groundbreaking novelty in the proposed micro-blocks",
    "NOVELTY"
  ],
  [
    "I like the idea of this paper but I feel there are still gap between the current draft and real working system",
    "NOVELTY"
  ],
  [
    "this is the first data-dependent dropout method proposed with theoretical justification though only for the shallow learning case",
    "NOVELTY"
  ],
  [
    "The idea of providing symbolic descriptions of tasks and learning corresponding `` implementations `` is potentially interesting and the",
    "NOVELTY"
  ],
  [
    "First , the ideas presented in the paper have all been explored in other work ( symbolic specifications , actor-critic , shared representations",
    "NOVELTY"
  ],
  [
    "new here",
    "NOVELTY"
  ],
  [
    "Studying the Granger causality in Wold point processes is novel and can be interesting to several disciplines .",
    "NOVELTY"
  ],
  [
    "The proposed transductive loss that minimizes entropy of query samples is novel in few-shot learning .",
    "NOVELTY"
  ],
  [
    "3 .A novel evaluation metric is proposed to evaluate few-shot learning methods under different difficulties level",
    "NOVELTY"
  ],
  [
    "I think this paper has significant contributions of proposing a novel few-shot baseline that establishes a new state-of-the-art and would recommend weak accept",
    "NOVELTY"
  ],
  [
    "The novelty is not very significant as it is an incremental step from current advances in Bayesian deep learning",
    "NOVELTY"
  ],
  [
    "there is no reason to stick with just one particular RNN variant",
    "NOVELTY"
  ],
  [
    "This idea is interesting and provides some novelty .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and heuristic to the domain adaptation",
    "NOVELTY"
  ],
  [
    "I agree with the other reviewers that the problem formulation is novel",
    "NOVELTY"
  ],
  [
    "Although there are previous works relating ResNets with ODEs , such as [ 1 ] , this paper is original as it is the first work that relates the stability of ODE numerical scheme with the gradient vanishing/exploding issues in RNNs . In general , this paper provides a novel approach to analyze the gradient vanishing/exploding issue in RNNs and provides applicable solutions",
    "NOVELTY"
  ],
  [
    "novel evolution scheme applied to neural network architecture search",
    "NOVELTY"
  ],
  [
    "I find that the idea of unifying QA , text classification and regression is interesting by itself",
    "NOVELTY"
  ],
  [
    "The problem setting is fairly natural and",
    "NOVELTY"
  ],
  [
    "has been studied before",
    "NOVELTY"
  ],
  [
    "This is appealing as no",
    "NOVELTY"
  ],
  [
    "needed to the RL algorithm/architecture .",
    "NOVELTY"
  ],
  [
    "The new connection between TI and the ELBO is insightful and",
    "NOVELTY"
  ],
  [
    "the first two claims of the paper are not novel based on my understanding of the field .",
    "NOVELTY"
  ],
  [
    "The third claim seems novel and intruiging .",
    "NOVELTY"
  ],
  [
    "The first ( main ) claim does not seem novel .",
    "NOVELTY"
  ],
  [
    "This to me seems to undermine novelty of the paper because if the claim of these papers is correct",
    "NOVELTY"
  ],
  [
    "Considering the level to which it is formalized it does not seem novel .",
    "NOVELTY"
  ],
  [
    "Novelty of empirical observations is key , because the theoretical contribution of the submission is arguably limited",
    "NOVELTY"
  ],
  [
    "This is a great theoretical contribution .",
    "NOVELTY"
  ],
  [
    "but I find it hard to argue that this paper significantly contributes to the existing body of work",
    "NOVELTY"
  ],
  [
    "For the second possible contribution , the idea of evaluating language generation along dimensions is not novel and in fact quite standard in the NLP community",
    "NOVELTY"
  ],
  [
    "I personally like this idea .",
    "NOVELTY"
  ],
  [
    "it seems a simple extension of the classical DAE .",
    "NOVELTY"
  ],
  [
    "The work is therefore original and significant .",
    "NOVELTY"
  ],
  [
    "There is very little novelty in this paper",
    "NOVELTY"
  ],
  [
    "the paper presents an interesting approach",
    "NOVELTY"
  ],
  [
    "but the work lacks maturity .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed model is novel for video generation .",
    "NOVELTY"
  ],
  [
    "and the contributions are remarkable",
    "NOVELTY"
  ],
  [
    "Overall , this is an incremental work in the field of supervised I2I .",
    "NOVELTY"
  ],
  [
    "They prove an equivalence between Dykstra and CD that ( to the best of my knowledge ) is novel in its general form .",
    "NOVELTY"
  ],
  [
    "the idea of training a network to be able to perform a secret task on command is very interesting",
    "NOVELTY"
  ],
  [
    "and the ideas are interesting",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge it has not been exploited for structure learning",
    "NOVELTY"
  ],
  [
    "it seems that this paper is the first to actually successfully use it",
    "NOVELTY"
  ],
  [
    "an original contribution .",
    "NOVELTY"
  ],
  [
    "Overall , the approach taken in this work differs significantly from past work .",
    "NOVELTY"
  ],
  [
    "Nonetheless , the approach that the authors take is unique and seems to work reasonably well .",
    "NOVELTY"
  ],
  [
    "the combination limits the novelty of this paper",
    "NOVELTY"
  ],
  [
    "It is unclear what is the major contribution of this paper over the existing work ,",
    "NOVELTY"
  ],
  [
    "The paper presents a well-designed approach that is able to deal with optimization in high dimensionality space , by building a lower order surrogate model build",
    "NOVELTY"
  ],
  [
    "The approach is allowing a nice trade-off between pure random search and guide search through a surrogate model over a subspace of limited dimensionality .",
    "NOVELTY"
  ],
  [
    "The idea of training a network to satisfy an abstract interface is very interesting and promising",
    "NOVELTY"
  ],
  [
    "I think this paper has some nice contribution to the area , by introducing a doubly robust estimator based on the density ratio , and also a new idea to achieve double robustness .",
    "NOVELTY"
  ],
  [
    "The proposed estimator is not using control variate but using dual structure between value function and stationary distribution ratio , which is a novel idea comparing with similar doubly robust estimators .",
    "NOVELTY"
  ],
  [
    "training video-to-video translation",
    "NOVELTY"
  ],
  [
    "Rather complex overall objective - Seems to need a lot of tweaking Questions",
    "NOVELTY"
  ],
  [
    "As such it is very much in the same spirit as existing methods such as ALI/BiGAN",
    "NOVELTY"
  ],
  [
    "In light of the existing literature , this paper 's contribution can be seen as incremental , with relatively low novelty .",
    "NOVELTY"
  ],
  [
    "This difference was a design decision on the part of the InfoGAN authors and , in my opinion , does not represent a significantly novel contribution on the part of this paper .",
    "NOVELTY"
  ],
  [
    "the proposed AIM model is interesting and",
    "NOVELTY"
  ],
  [
    "but I 'm not sure how much impact it will have in light of the existing literature",
    "NOVELTY"
  ],
  [
    "area",
    "NOVELTY"
  ],
  [
    "The way how feature vectors are constructed based on the local region of Gaifman manifold seems both reasonable and novel ( as far as I 'm aware ) ,",
    "NOVELTY"
  ],
  [
    "Overall I think this is a nice contribution .",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is quite limited since the majority of the gains come from simply swapping the KL-divergence penalty with an L1 penalty",
    "NOVELTY"
  ],
  [
    "The combination of MAML and MaxEnt IRL is new to my knowledge .",
    "NOVELTY"
  ],
  [
    "The idea of trading-off predictability with fairness by introducing penalty terms for deviations from fairness within each causal model is natural and intuitive .",
    "NOVELTY"
  ],
  [
    "This is perhaps ok but I found it weakens the contribution of the paper .",
    "NOVELTY"
  ],
  [
    "These eight new environments are minor contributions with limited potential for impact on the field , but still make an independently positive contribution",
    "NOVELTY"
  ],
  [
    "To the best of our knowledge , FouST is the first gradient estimate algorithm that can train very deep stochastic neural networks with Boolean latent variables .",
    "NOVELTY"
  ],
  [
    "But the specific investigation in this work regarding the sufficient conditions for certain structural properties to emerge is useful and novel .",
    "NOVELTY"
  ],
  [
    "and the results seem incremental",
    "NOVELTY"
  ],
  [
    "The contribution is in generally interesting .",
    "NOVELTY"
  ],
  [
    "been circling",
    "NOVELTY"
  ],
  [
    "My major remaining concern is the incremental nature of the work that should be discussed more in the text",
    "NOVELTY"
  ],
  [
    "As far as I know , the combination of several continual learning strategies proposed in this submission is new .",
    "NOVELTY"
  ],
  [
    "it is not clear to me each of these strategies on its own is a novelty",
    "NOVELTY"
  ],
  [
    "I feel this is hardly a `` novel controller `` . The use of core-set points or examplar replay is not new -- this is however not discussed in the main methodology",
    "NOVELTY"
  ],
  [
    "The proposed methodology seems interesting",
    "NOVELTY"
  ],
  [
    ", and the solution proposed here is novel and highly non-trivial .",
    "NOVELTY"
  ],
  [
    "The idea of using pointer networks for reducing search space of generated queries is interesting .",
    "NOVELTY"
  ],
  [
    "Novelty : I think the novelty of this paper is somehow limited .",
    "NOVELTY"
  ],
  [
    "From the modeling perspective , there is no novelty , using the same AAE and ARAE models proposed by previous work .",
    "NOVELTY"
  ],
  [
    "The proposed approach is incremental ,",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the authors propose novel kinds of attacks as well as novel attack algorithms on RL agent .",
    "NOVELTY"
  ],
  [
    "the tensor machines model of Yang and Gittens is relevant prior workThe work is interesting",
    "NOVELTY"
  ],
  [
    "My main issue with the paper was that I had a hard time seeing a contribution . It is unclear what is technically new",
    "NOVELTY"
  ],
  [
    "This work is incremental .",
    "NOVELTY"
  ],
  [
    "This part seems to be the only truly innovative one ( all other components of the pipeline have been described/used before",
    "NOVELTY"
  ],
  [
    "The idea of using macro-level noisy labels as part of the supervision is novel , and it could potentially trigger a paradigm shift",
    "NOVELTY"
  ],
  [
    "The authors propose an attractive and simple way to leverage state-only demonstrations in combination with RL .",
    "NOVELTY"
  ],
  [
    "As far as I can tell , these are the main novel contributions of the authors ' approach .",
    "NOVELTY"
  ],
  [
    "This paper 's main selling point is n't originality -- rather",
    "NOVELTY"
  ],
  [
    "I do n't understand how it substantially deviates from previous work",
    "NOVELTY"
  ],
  [
    "The idea is definitely interesting .",
    "NOVELTY"
  ],
  [
    "The mini-queries idea in 4.1 is especially interesting .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the results are new .",
    "NOVELTY"
  ],
  [
    "The methods used on the other hand are simple and to my understanding relatively standard in the field .",
    "NOVELTY"
  ],
  [
    "and a novel attempt to capture a notion of per-instance optimal rates for SCO",
    "NOVELTY"
  ],
  [
    "I think this is a very interesting new direction which may yield some nice algorithmic ideas in the future .",
    "NOVELTY"
  ],
  [
    "The main idea is new .",
    "NOVELTY"
  ],
  [
    "Theorem 3 guarantees the global convergence of this method and this theoretical result for three-block convex problems is attractive .",
    "NOVELTY"
  ],
  [
    "Considering to address this problem is itself a novel contribution .",
    "NOVELTY"
  ],
  [
    "The topic of learning from few samples is presented as completely new .",
    "NOVELTY"
  ],
  [
    "To my opinion , this paper gives a nice contribution to the litterature and captures several families of generative models as special cases .",
    "NOVELTY"
  ],
  [
    "A nice , easy to read paper , with an original idea .",
    "NOVELTY"
  ],
  [
    "The unification of the complexity-based and stability-based analysis into learning with data-dependent hypothesis set seems a significant contribution .",
    "NOVELTY"
  ],
  [
    "but the contribution is a little incremental and engineering",
    "NOVELTY"
  ],
  [
    "The paper 's contributions seem to be marginal .",
    "NOVELTY"
  ],
  [
    "but it has shortcomings in originality .",
    "NOVELTY"
  ],
  [
    "However , it is still an incremental work on previous methods including activation maximization and deep generator networks , thus leading to the sub-standard novelty .",
    "NOVELTY"
  ],
  [
    "the paper is moderately novel",
    "NOVELTY"
  ],
  [
    "but fairly straightforward",
    "NOVELTY"
  ],
  [
    "The contributions are original",
    "NOVELTY"
  ],
  [
    "The theoretical analysis of section 4 is interesting and illustrative yet based on a particular",
    "NOVELTY"
  ],
  [
    "and provides a nice perspective on the future of learning with quantum computers",
    "NOVELTY"
  ],
  [
    "Novelty While the authors\u00e2\u0080\u0099 proposed algorithm is indeed a novel pipeline",
    "NOVELTY"
  ],
  [
    "it should be noted that none of the component parts of the algorithm are novel",
    "NOVELTY"
  ],
  [
    "Thus the authors present a novel application of existing technologies .",
    "NOVELTY"
  ],
  [
    "The authors present a novel application of GANs in a field where the impact of such a technology could be",
    "NOVELTY"
  ],
  [
    "This paper claims it presents \u201c a new approach for representing and reasoning\u2026 \u201d .",
    "NOVELTY"
  ],
  [
    "and self-attention mechanism are already introduced and the proposed approach is more like a combination of both",
    "NOVELTY"
  ],
  [
    "That being said , the analysis and evaluation of these ideas in RL are new and interesting .",
    "NOVELTY"
  ],
  [
    "The approach is similar in spirit to Niepert , Ahmed , Kutzkov , ICML 2016 and thus incremental .",
    "NOVELTY"
  ],
  [
    "The improvement over the existing",
    "NOVELTY"
  ],
  [
    "While with the benefit of hindsights it might seem simple , it is a clever innovation .",
    "NOVELTY"
  ],
  [
    "The approach is novel and intuitive , while still having enough technical ingenuity to be nonobvious .",
    "NOVELTY"
  ],
  [
    "However , I think the theoretical contribution in this paper on off-policy learning is quite incremental .",
    "NOVELTY"
  ],
  [
    "The first contribution is rather incremental as it 's just a direct application of Theorem 2 in Cortes 's paper .",
    "NOVELTY"
  ],
  [
    "but the technical contribution is rather incremental .",
    "NOVELTY"
  ],
  [
    "It is a interesting idea .",
    "NOVELTY"
  ],
  [
    "However , the novelty of the proposed work is limited , and there is no evidence to show the proposed algorithms can be applied to other related works .",
    "NOVELTY"
  ],
  [
    "the paper is fair and I believe the contribution is sufficient for acceptance",
    "NOVELTY"
  ],
  [
    "However I think there is little novelty in this work .",
    "NOVELTY"
  ],
  [
    ", and to my knowledge are novel",
    "NOVELTY"
  ],
  [
    "Studying the trajectory length as function of transforming the data by a multilayer network is new and interesting idea .",
    "NOVELTY"
  ],
  [
    "This paper is the first ( I believe ) to establish a simple yet important result that Convnets for NMT encoders can be competitive to RNNs .",
    "NOVELTY"
  ],
  [
    "Minimal theoretical novelty",
    "NOVELTY"
  ],
  [
    "The proposed method is novel up to my knowledge .",
    "NOVELTY"
  ],
  [
    "there is little work combing these two ideas",
    "NOVELTY"
  ],
  [
    "to the",
    "NOVELTY"
  ],
  [
    "best of my knowledge",
    "NOVELTY"
  ],
  [
    "but the framework proposed by the authors appears to be new , and the technical contributions seem notable .",
    "NOVELTY"
  ],
  [
    "My main concern is on its novelty .",
    "NOVELTY"
  ],
  [
    "but if they are the special cases of the existing framework , the contributions of this paper might be degraded .",
    "NOVELTY"
  ],
  [
    "for this paper since it presents two interesting contributions ( albeit of incremental novelty",
    "NOVELTY"
  ],
  [
    "The idea of alleviating the class-imbalance problem in object detection by using \u00e2\u0080\u009cbackground elimination ( BE ) \u00e2\u0080\u009d is not new .",
    "NOVELTY"
  ],
  [
    "From a technical standpoint , the work seems novel with interesting results",
    "NOVELTY"
  ],
  [
    "although",
    "NOVELTY"
  ],
  [
    ", in my opinion the paper presents a novel analysis of an important idea of variance reduction applied to Online TD .",
    "NOVELTY"
  ],
  [
    "This seems novel to me and would benefit from emphasis in the main body of the paper .",
    "NOVELTY"
  ],
  [
    "The novelty over the nCRP-VAE approach of Goyal et al . ( 2017 ) is pretty minor .",
    "NOVELTY"
  ],
  [
    "I consider these results to be interesting contributions .",
    "NOVELTY"
  ],
  [
    "of",
    "NOVELTY"
  ],
  [
    "technical depth and novelty is not sufficient",
    "NOVELTY"
  ],
  [
    "This paper itself does not provide novel design in the boosting technique itself .",
    "NOVELTY"
  ],
  [
    "The proposed method seems to be novel",
    "NOVELTY"
  ],
  [
    "While I found the formulation and motivation from Wyner",
    "NOVELTY"
  ],
  [
    "s channel synthesis interesting",
    "NOVELTY"
  ],
  [
    "The technical contribution is very incremental",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", the connection between ReLU DNN and simplified SFNN is novel .",
    "NOVELTY"
  ],
  [
    "The idea to normalize the targets while preserving the outputs is quite interesting .",
    "NOVELTY"
  ],
  [
    "The idea is incremental but creative and useful .",
    "NOVELTY"
  ],
  [
    "An interesting approach for representing tree structure encoding using a series of transformation . The idea of transformation without learnable parameters is novel .",
    "NOVELTY"
  ],
  [
    "The proposed guided search seems similar to ( stochastic )",
    "NOVELTY"
  ],
  [
    "The contribution seems to be relatively small",
    "NOVELTY"
  ],
  [
    "The idea solving dense event captioning as a weakly supervise problem by intertwist sentence localization and captioning is novel .",
    "NOVELTY"
  ],
  [
    "; it also proposes a novel model for the task , building upon SOTA models .",
    "NOVELTY"
  ],
  [
    "and the linkage loss is , to the best of my knowledge , original .",
    "NOVELTY"
  ],
  [
    "This paper presents some interesting ideas and",
    "NOVELTY"
  ],
  [
    "The novelty of this work appears to concentrate on the formulation of the Ising influence maximization",
    "NOVELTY"
  ],
  [
    "I believe this is a very promising direction to invest",
    "NOVELTY"
  ],
  [
    "As far as I can tell , this paper proposes a novel variational inference algorithm with strong theoretical justifications , improving upon the previous best method .",
    "NOVELTY"
  ],
  [
    "and seems like an novel contribution to the variational inference literature .",
    "NOVELTY"
  ],
  [
    "The novelty/contribution and the practical value of this submission are less than NIPS criteria .",
    "NOVELTY"
  ],
  [
    "While the basic mistake bound for matrix exponentiated gradient algorithm makes use of the analysis the previous work on MEG , the embedding of the comparators ( sign-consistent matrices ) to the space of positive matrices , and the outcomes to the space of symmetric matrices looks very interesting and original .",
    "NOVELTY"
  ],
  [
    "the contribution seems incremental .",
    "NOVELTY"
  ],
  [
    "the contribution is only empirical .",
    "NOVELTY"
  ],
  [
    "While all the ideas seem incremental , overall the work seems to make a significant contribution .",
    "NOVELTY"
  ],
  [
    "This work is largely inspired by Blum & Rivest 's work , and builds heavily on some previous work including Megiddo and Edelsbrunner et al .While there is certainly some novelty in extending prior work to the ReLU activation function , it is perhaps fair to say the originality is moderate",
    "NOVELTY"
  ],
  [
    "I do n't know of any prior work that approaches the relationship between RNNs and automata in quite this way",
    "NOVELTY"
  ],
  [
    "and the summary is not necessarily conclusive in terms of gaining any new insights",
    "NOVELTY"
  ],
  [
    "The idea of using Chordal graphs to GCN is novel and interesting .",
    "NOVELTY"
  ],
  [
    "the technical contribution may not enough",
    "NOVELTY"
  ],
  [
    "I find the work incremental specifically after noting that the radius can be deduced from the work of Li et al .where the main contribution here is the tightness of the radius for a binary classifier .",
    "NOVELTY"
  ],
  [
    "I think the main contribution of this paper is that it introduces a new way of robust training by encouraging Jacobian saliency .",
    "NOVELTY"
  ],
  [
    "In general , I like the intuition behind this paper , since it introduces a new perspective of robust training .",
    "NOVELTY"
  ],
  [
    "While the method seems to be mostly a combination of the ideas in 2 referenced previous works",
    "NOVELTY"
  ],
  [
    "As such it could be argued to the core ideas in the paper aren \u2019 t very novel .",
    "NOVELTY"
  ],
  [
    "I found the approach interesting",
    "NOVELTY"
  ],
  [
    "interesting idea",
    "NOVELTY"
  ],
  [
    "pedagogical and the description and examples",
    "NOVELTY"
  ],
  [
    "I really like the basic setting of this paper",
    "NOVELTY"
  ],
  [
    "Looking at the geometry of the boundary of the constraint set is a quite novel approach into this .",
    "NOVELTY"
  ],
  [
    ", this paper seems to propose a novel algorithm to learn the symbolic representations .",
    "NOVELTY"
  ],
  [
    "The method itself is not novel .",
    "NOVELTY"
  ],
  [
    "Despite limitations mentioned above , I think the ideas presented in the paper are intuitively appealing and worth discussing at ICLR .",
    "NOVELTY"
  ],
  [
    "Overall , I like the algorithm .",
    "NOVELTY"
  ],
  [
    "The manuscript presents a novel solution to a general problem",
    "NOVELTY"
  ],
  [
    "The ideas presented in this work are interesting",
    "NOVELTY"
  ],
  [
    "up to my knowledge , these theoretical results and corresponding assumption are very novel .",
    "NOVELTY"
  ],
  [
    "The proposed model of the ORR is novel and allows for key structural insights .",
    "NOVELTY"
  ],
  [
    "The methodology provided in this paper is , to our best knowledge , new . It is an innovative combination of the well-known techniques , namely the SW and Radon Transform .",
    "NOVELTY"
  ],
  [
    "The paper is clearly different from the previous",
    "NOVELTY"
  ],
  [
    "the methodology would advance the state of the art in a demonstratable way . This paper provides unique theoretical approach .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is very well-written and the approach is interesting and novel .",
    "NOVELTY"
  ],
  [
    "The novelty is",
    "NOVELTY"
  ],
  [
    "satisfactory , but not particularly high .",
    "NOVELTY"
  ],
  [
    "The technical novelty of the paper is minor . The approach presented in the paper is a straightforward combination of existing approaches and there does n't appear to be any major technical innovations .",
    "NOVELTY"
  ],
  [
    "given the lack of technical contributions",
    "NOVELTY"
  ],
  [
    "The paper contains several novel contributions regarding designing systems for distributed training of learning trees .",
    "NOVELTY"
  ],
  [
    "The paper contains what seems to be a nice contribution",
    "NOVELTY"
  ],
  [
    "This work appears to be a novel mix of linear programming and matroid constrained subset selection with substantial theoretical contribution .",
    "NOVELTY"
  ],
  [
    "Although the obtained results are interesting",
    "NOVELTY"
  ],
  [
    "the contribution is quite incremental",
    "NOVELTY"
  ],
  [
    "the paper presents first combination of DenseNets with LSTM-based output factorization",
    "NOVELTY"
  ],
  [
    "The framework in its entirety is novel",
    "NOVELTY"
  ],
  [
    ", but the building blocks of the proposed framework are established in prior work and the idea of using normalizing flows for graph generation has been proposed in earlier work",
    "NOVELTY"
  ],
  [
    "Theirs seem to be the first work focusing on manipulating certificates to attack strongly certified networks .",
    "NOVELTY"
  ],
  [
    "The work is novel since most of the current work focus on the imperceptibility and misclassification aspects of the classifier",
    "NOVELTY"
  ],
  [
    "The main strengths of the paper are that it proposes an entirely novel architecture without recurrence or convolutions , and advances state of the art .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the current state of the method is novel in the rendering network .",
    "NOVELTY"
  ],
  [
    "the rest of components have limited novelty .",
    "NOVELTY"
  ],
  [
    "Nothing quite new here .",
    "NOVELTY"
  ],
  [
    "Therefore I believe the contribution of this paper to be somewhat limited .",
    "NOVELTY"
  ],
  [
    "The paper presents a few very interesting findings .",
    "NOVELTY"
  ],
  [
    "I think this is an original and well-written paper",
    "NOVELTY"
  ],
  [
    "There are now numerous flavors of GCNs and the proposed aggregation function in ( 2 ) is not novel .",
    "NOVELTY"
  ],
  [
    "Neither ( 1 ) nor ( 4 ) are novel contributions . The experiments look OK but are not ground-breaking and are not enough to make this paper more than a mere combination of existing methods",
    "NOVELTY"
  ],
  [
    "A new attempt of the attention model that tries to build the attention beyond unigrams .",
    "NOVELTY"
  ],
  [
    "3 .The intuition about the search direction is very nice .",
    "NOVELTY"
  ],
  [
    "4 .The matching behavior between least square gradient and reshaped WF is very interesting",
    "NOVELTY"
  ],
  [
    "Multi-scale image processing is not a novel idea in computer vision and specifically in human pose estimation .",
    "NOVELTY"
  ],
  [
    "The method is interesting as it does not require multiple backward passes such as other gradient-based method and thus prove to be more time-efficient",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is questionable , especially given a published work which propose exactly the same idea of using a Gaussian Mixture as prior for GANs in CVPR 2017",
    "NOVELTY"
  ],
  [
    "== Originality == The idea of matching features/representations across the source domain and target domain is an old idea ,",
    "NOVELTY"
  ],
  [
    "but it is executed in an interesting new way in this paper",
    "NOVELTY"
  ],
  [
    "The novelty of the approach is the main strength of this paper .",
    "NOVELTY"
  ],
  [
    "This made it hard to see whether the new approach represents a true improvement over existing techniques",
    "NOVELTY"
  ],
  [
    "Many citations throughout the paper need to be wrapped in parentheses == Conclusion == This paper presents an interesting new approach for dataset selection and learning domain-invariant representations",
    "NOVELTY"
  ],
  [
    "originality of the approach Cons",
    "NOVELTY"
  ],
  [
    "Propositions and theorems in the paper however are not fundamentally new , following straightforwardly from the geometry approach",
    "NOVELTY"
  ],
  [
    "the paper advances in the promising direction of geometrically interpreting neural networks",
    "NOVELTY"
  ],
  [
    "While the idea of the paper is clear from",
    "NOVELTY"
  ],
  [
    "This work is very related to Wiltschko et al.",
    "NOVELTY"
  ],
  [
    "The decoding of videos purely from neural activity is a very interesting approach .",
    "NOVELTY"
  ],
  [
    "the use of CAE , is one of the main novelties of the paper",
    "NOVELTY"
  ],
  [
    "competitor methods is not very strong even in terms of epochs",
    "NOVELTY"
  ],
  [
    "I am not convinced that this is novel enough for publication at ICLR .",
    "NOVELTY"
  ],
  [
    "Both the problem and the algorithm are novel .",
    "NOVELTY"
  ],
  [
    "The idea of incorporating an external memory store to save previous experiences is interesting especially without the need to backpropagate through the memory at each step .",
    "NOVELTY"
  ],
  [
    "and makes several clean contributions",
    "NOVELTY"
  ],
  [
    "On the negative side , it is incremental over the KDD 17 paper in my opinion , both conceptually and with respect to the experimental gains .",
    "NOVELTY"
  ],
  [
    "The authors introduce a novel novel for collaborative filtering .",
    "NOVELTY"
  ],
  [
    "I found the idea of Figure 1 very good",
    "NOVELTY"
  ],
  [
    "but in its current form I did n't find it particularly insightful",
    "NOVELTY"
  ],
  [
    "Seems original .",
    "NOVELTY"
  ],
  [
    "and presents a number of interesting ideas , which I found very enjoyable . I found the use of the residual architecture to model the diminishing transformations quite interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the idea is novel and well presented .",
    "NOVELTY"
  ],
  [
    "The idea of utilizing edge features looks novel .",
    "NOVELTY"
  ],
  [
    "While I found the idea of marginalizing out the local context interesting",
    "NOVELTY"
  ],
  [
    "The use of properties to summarize some features about the program and the possibility to evaluate them directly from samples seems a very interesting idea",
    "NOVELTY"
  ],
  [
    "and the proposed model is promising",
    "NOVELTY"
  ],
  [
    "All I can say is the approach is intuitively appealing",
    "NOVELTY"
  ],
  [
    "Overall the proposed method is novel .",
    "NOVELTY"
  ],
  [
    "The new algorithmic techniques developed by the authors are also very interesting .",
    "NOVELTY"
  ],
  [
    "I find this paper studies a very interesting theoretical model and proposes a new algorithmic technique that",
    "NOVELTY"
  ],
  [
    "but incremental comparing to previous methods learning eigenoption and learning bottleneck states based on SRs .",
    "NOVELTY"
  ],
  [
    "This work is very interesting and novel .",
    "NOVELTY"
  ],
  [
    ", but is not much innovative .",
    "NOVELTY"
  ],
  [
    "To the best of my understanding the paper proposes some methodological ideas for visualizing and analyzing representations .",
    "NOVELTY"
  ],
  [
    "Metric learning for multi-label problems is not new",
    "NOVELTY"
  ],
  [
    "Using deep neural networks for multi-label problems is also not new",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed method is rather limited .",
    "NOVELTY"
  ],
  [
    "The novelty is limited .",
    "NOVELTY"
  ],
  [
    "A main problem with the paper may be the lack of novelty . The proposed relativistic discriminator seems to be only a small modification of an existing RGANs .",
    "NOVELTY"
  ],
  [
    "I feel the novelty of this approach is a bit limited",
    "NOVELTY"
  ],
  [
    "This work is not novel enough .",
    "NOVELTY"
  ],
  [
    "Residual network is also not new .",
    "NOVELTY"
  ],
  [
    "But it lacks novelty .",
    "NOVELTY"
  ],
  [
    "Still , as an incremental contribution to this literature with reasonable numerics , it looks promising .",
    "NOVELTY"
  ],
  [
    "but the downside of this paper is lack of innovations since most of the methods proposed in this paper are not new to us .",
    "NOVELTY"
  ],
  [
    "But the novelty in the paper is limited .",
    "NOVELTY"
  ],
  [
    "The idea seems to be not very novel since the optimistic optimization techniques are borrowed directly from the online optimization field",
    "NOVELTY"
  ],
  [
    "the experimental results , considering the extensive previous work in this area , are insufficient to establish novel performance in lieu of novel ideas",
    "NOVELTY"
  ],
  [
    "the results are",
    "NOVELTY"
  ],
  [
    "However , the basic setup is not novel enough .",
    "NOVELTY"
  ],
  [
    "This paper is a nice extension on Jin et al 's work .",
    "NOVELTY"
  ],
  [
    "This reduces the novelty of this paper in its technical analysis a little bit",
    "NOVELTY"
  ],
  [
    "Constrained policy optimization is not a new topic",
    "NOVELTY"
  ],
  [
    "I really like the overall idea of comparing convnet representations with human perceptions of images",
    "NOVELTY"
  ],
  [
    ", presents a novel and effective idea that I expect to see used in future SAT-competitions .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel way of representing entities and relations Clarity",
    "NOVELTY"
  ],
  [
    "Overall , the idea is novel and it is presented very",
    "NOVELTY"
  ],
  [
    "this is a very interesting piece of work",
    "NOVELTY"
  ],
  [
    "The inclusion of decimal-expansion equations for relating numeral embeddings to number embeddings is clever",
    "NOVELTY"
  ],
  [
    "The regularization proposed is quite simple and already known",
    "NOVELTY"
  ],
  [
    "Overall nothing really new was discovered or proposed",
    "NOVELTY"
  ],
  [
    "I feel this paper in its current form lacks sufficient novelty to be accepted to ICLR",
    "NOVELTY"
  ],
  [
    "un-rolled networks for iterative inference are n't new",
    "NOVELTY"
  ],
  [
    "I 'd argue that the fundamental idea proposed by the paper is n't new -- -it is just that the paper seeks to 'formalize ' it as an approach for inverse problems",
    "NOVELTY"
  ],
  [
    "It is possible that the proposed method does offer practical benefits beyond prior work -- -but these benefits do n't come from the idea of simply unrolling iterations , which is not novel",
    "NOVELTY"
  ],
  [
    "The novelty of either of those techniques is quite limited as individually they have been suggested before",
    "NOVELTY"
  ],
  [
    "but the combination of both of them is interesting",
    "NOVELTY"
  ],
  [
    "however there are two aspects that make the contribution lacking in novelty .",
    "NOVELTY"
  ],
  [
    "The work appears original to me",
    "NOVELTY"
  ],
  [
    "but it is not the first on GANs using temporal data .",
    "NOVELTY"
  ],
  [
    "The work is interesting , and I like the idea",
    "NOVELTY"
  ],
  [
    "On the whole , I think the paper is inventive ,",
    "NOVELTY"
  ],
  [
    "By defining a different distance function , the",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems quite interesting .",
    "NOVELTY"
  ],
  [
    "The idea of probability generating function achieving similar forms of `` conjugacy `` as Gaussian random variables and ( finite ) discrete random variables is very interesting .",
    "NOVELTY"
  ],
  [
    "I believe this paper contains promising idea .",
    "NOVELTY"
  ],
  [
    "and some new interpretation",
    "NOVELTY"
  ],
  [
    "I like the idea of trying to formulate the feature learning problem as a two-player min-max game and its connection to boosting .",
    "NOVELTY"
  ],
  [
    "\u201c To our knowledge , this is one of the first studies to report improvements via learning for combinatorial algorithms .",
    "NOVELTY"
  ],
  [
    "Overall , I was impressed by this paper and I believe that it makes a strong contribution .",
    "NOVELTY"
  ],
  [
    "The primary intuition of the paper ( that the initial state conveys information about unspecified costs ) and the framing of this problem in terms of IRL is novel .",
    "NOVELTY"
  ],
  [
    "The paper overstates its novelty and",
    "NOVELTY"
  ],
  [
    "The paper overstates its novelty and has done a poor job researching related work .",
    "NOVELTY"
  ],
  [
    "`` To the best of our knowledge , this is the first tree-to-tree neural network architecture in the literature .",
    "NOVELTY"
  ],
  [
    "and the contributions are overstated",
    "NOVELTY"
  ],
  [
    "The technical accomplishment can be considered incremental with respect to this series of works .",
    "NOVELTY"
  ],
  [
    "while the techniques used are not new",
    "NOVELTY"
  ],
  [
    "the performed analysis leads to new insights on the use of batch/layer normalization .",
    "NOVELTY"
  ],
  [
    "and the current contribution adds a reasonable amount of knowledge to the literature",
    "NOVELTY"
  ],
  [
    "their analysis appears to be borrowing heavily from [ 17 ]",
    "NOVELTY"
  ],
  [
    "The main results seem innovative to me in general . Although optimizing information-theoretic objective functions is not new , I find the new objective function adequately novel",
    "NOVELTY"
  ],
  [
    "Overall , I think the manuscript would make a fairly significant contribution .",
    "NOVELTY"
  ],
  [
    "I find the paper novel and interesting",
    "NOVELTY"
  ],
  [
    "This manuscript presents a nice method that can dynamically prune some channels in a CNN network to speed up the training",
    "NOVELTY"
  ],
  [
    "Although modeling both the hidden states and event times in continuous time setting is not new for Bayesian nonparametric modeling",
    "NOVELTY"
  ],
  [
    "I believe modeling the event times as IPP and conditioning that on hidden states is novel and useful .",
    "NOVELTY"
  ],
  [
    "Every piece of the method",
    "NOVELTY"
  ],
  [
    "and the combination of them proposed in this paper does not seem very novel .",
    "NOVELTY"
  ],
  [
    "The idea is quite interesting but there are certain problems in clarity regarding the loss terms and the precise need for them",
    "NOVELTY"
  ],
  [
    "The paper may not have enough contribution to",
    "NOVELTY"
  ],
  [
    "The proposed model is not quite novel ,",
    "NOVELTY"
  ],
  [
    "The problem considered -- the `` collaborative PAC learning `` setting , recently introduced by Blum et al .to capture settings where one wants to learn a target function with respect",
    "NOVELTY"
  ],
  [
    "is quite natural and interesting",
    "NOVELTY"
  ],
  [
    "This paper is quite original and",
    "NOVELTY"
  ],
  [
    "This is a very nice contribution .",
    "NOVELTY"
  ],
  [
    "it seems to be built on an existing system ,",
    "NOVELTY"
  ],
  [
    "This looks new to transfer learning .",
    "NOVELTY"
  ],
  [
    "few novel tricks to improve training",
    "NOVELTY"
  ],
  [
    "I like the idea of using 3D generation , and particularly , 3D printing , as a means of generating adversarial examples -- there is definite novelty in that particular exploration for adversarial examples .",
    "NOVELTY"
  ],
  [
    "the presented framework seems to not be unlike the gross-error model",
    "NOVELTY"
  ],
  [
    "The techniques are not straightforward but not seem to be highly innovative , either .",
    "NOVELTY"
  ],
  [
    "I am not sure if the work can be considered particularly novel",
    "NOVELTY"
  ],
  [
    "The problem of extending the K-FAC algorithm is natural , and the steps taken in this paper seem natural yet also original and non-trivial .",
    "NOVELTY"
  ],
  [
    "So I am also not sure the contribution of this paper , provided the existing methods .",
    "NOVELTY"
  ],
  [
    "There is not much here in the way of new machine learning methods .",
    "NOVELTY"
  ],
  [
    "The dataset used here is not new",
    "NOVELTY"
  ],
  [
    "the paper does not have enough contributions both in terms of new methods and evaluations",
    "NOVELTY"
  ],
  [
    "I maintain my rating because the contributions are limited and",
    "NOVELTY"
  ],
  [
    "I did not find the theoretical analysis to be especially novel , deep , or informative .",
    "NOVELTY"
  ],
  [
    "The result in Theorem 1 is not especially novel and is probably available in the literature in some form",
    "NOVELTY"
  ],
  [
    "and the `` improvement `` offered here is basically a small tweak",
    "NOVELTY"
  ],
  [
    "but I did not find the theoretical or empirical contributions to be sufficiently novel , deep , or informative to merit publication in their present form .",
    "NOVELTY"
  ],
  [
    "This paper is original",
    "NOVELTY"
  ],
  [
    "Adding eligibility traces to RL updates is not novel",
    "NOVELTY"
  ],
  [
    "The idea underpinning the paper is original ,",
    "NOVELTY"
  ],
  [
    "The model is a very modest extension of the original Transformer model and so its value to the community beyond improved numbers is somewhat questionable",
    "NOVELTY"
  ],
  [
    "I find the paper brings nothing new and interesting to the table",
    "NOVELTY"
  ],
  [
    "not novel as other methods such as gradient descent inference use a continuous output variables as a relation of discrete variables and smoothen the inference using L2 or using entropy",
    "NOVELTY"
  ],
  [
    "However , this work presents the idea in a carefully described framework with theoretical guarantees that was missing from previous works .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is interesting",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is almost trivial which is worsen by truly bad writing and questionable experiments",
    "NOVELTY"
  ],
  [
    "such probabilistic formulation does not seem to be new in terms of visual recognition ,",
    "NOVELTY"
  ],
  [
    "my only big concern is about the limited novelty of the method .",
    "NOVELTY"
  ],
  [
    "Novel idea - Relatively",
    "NOVELTY"
  ],
  [
    "The idea of jointly solving the cross-region connectivity within one model is quite interesting",
    "NOVELTY"
  ],
  [
    "The novelty is very limited",
    "NOVELTY"
  ],
  [
    "This only novelty is the zero-delay constraint",
    "NOVELTY"
  ],
  [
    "The ideas are interesting .",
    "NOVELTY"
  ],
  [
    "The idea of integrating autoencoder with continuous clustering is novel , and the optimization part is quite different . The trick used in the paper ( sampling edges but not samples ) looks interesting and seems to be effective .",
    "NOVELTY"
  ],
  [
    "paper is interesting and proposed method seems to be promising .",
    "NOVELTY"
  ],
  [
    "I think this is an interesting method/proposal and is a somewhat novel reformulation of intrinsic error",
    "NOVELTY"
  ],
  [
    "The application seems novel and the use of CycleGAN seems to be an interesting direction .",
    "NOVELTY"
  ],
  [
    "The unification of Taken \u2019 s embedding theorem and deep learning provides a novel perspective into dynamical systems",
    "NOVELTY"
  ],
  [
    "Originality I do not find the paper particularly novel .",
    "NOVELTY"
  ],
  [
    "The choice of surrogate model and uncertainty metric might be new",
    "NOVELTY"
  ],
  [
    "I find the proposed method to be rather incremental and not significant enough for ICLR .",
    "NOVELTY"
  ],
  [
    "the work proposed in this paper looks rather original , since it seems to be the first time that a paper addresses the problem of data poisoning in batch reinforcement learning",
    "NOVELTY"
  ],
  [
    "the paper presents interesting ideas",
    "NOVELTY"
  ],
  [
    "The method is original in the deep learning literature .",
    "NOVELTY"
  ],
  [
    "I find REBAR to be a quite interesting and novel proposal . Using the CD as a CV is a nice idea and might have been worthy of publication on its own",
    "NOVELTY"
  ],
  [
    "I found this paper interesting and novel and expect it\u00e2\u0080\u0099ll have significant impact given the difficulties with REINFORCE and other MC gradient estimators for discrete rvs",
    "NOVELTY"
  ],
  [
    "Overall , the paper is written well , I like the ( second ) idea of the refine gate and the contributions",
    "NOVELTY"
  ],
  [
    "which however I found is not new since it has been conceptually discussed already in the literature",
    "NOVELTY"
  ],
  [
    "From this perspective , the proposed solutions are not novel either .",
    "NOVELTY"
  ],
  [
    "contains interesting ideas",
    "NOVELTY"
  ],
  [
    "novel , feedforward , end-to-end trainable ,",
    "NOVELTY"
  ],
  [
    "The proposed idea is quite original by ensuring three tasks namely theorectical analysis , the model reduction and the interpretation .",
    "NOVELTY"
  ],
  [
    "The proposed method is a novel ( and elegant ) combination of existing techniques from off-policy learning , imitation learning , guided policy search , and meta-learning . The resulting algorithm is new",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and well executed and there are multiple good ideas that go along with it .",
    "NOVELTY"
  ],
  [
    "The idea of the paper interesting .",
    "NOVELTY"
  ],
  [
    "The idea has been proposed before .",
    "NOVELTY"
  ],
  [
    "a weakness of this paper is that the ideas pursued follow easily from prior work",
    "NOVELTY"
  ],
  [
    "the results on online tensor decomposition appear to be of independent interest",
    "NOVELTY"
  ],
  [
    "And while the method of preserving DP may be based on existing proof techniques , its goal ( tensor decomposition with DP ) appears to be novel .",
    "NOVELTY"
  ],
  [
    "This reduces its novelty in terms of fundamental approach .",
    "NOVELTY"
  ],
  [
    "The initial presentation is a little unconventional for a NIPS audience in tone",
    "NOVELTY"
  ],
  [
    "Results are very similar to SW-LinUCB since this work is essentially a replacement of the sliding window by a discounted weighted estimation",
    "NOVELTY"
  ],
  [
    "proposes an adaptation of flows for image-to-image translation problems and as such is an interesting and original work",
    "NOVELTY"
  ],
  [
    "and the method is very interesting extension of MAML",
    "NOVELTY"
  ],
  [
    "the method seems to be an interesting extension of MAML and would be a relevant development",
    "NOVELTY"
  ],
  [
    "from a practical point of view , I think the approach is very interesting and",
    "NOVELTY"
  ],
  [
    "The spectral normalization technique that is actually used in experiments is not new",
    "NOVELTY"
  ],
  [
    "While this paper presents an interesting approach",
    "NOVELTY"
  ],
  [
    "its",
    "NOVELTY"
  ],
  [
    "Provides a novel way to analyze Q learning with nn function approximators that can be applied to other algorithms",
    "NOVELTY"
  ],
  [
    "The novelty is a bit unclear other than the non-iid assumption",
    "NOVELTY"
  ],
  [
    "the present paper complements and strengthens the previous work",
    "NOVELTY"
  ],
  [
    "My main concern here is the technical novelty of the proposed method",
    "NOVELTY"
  ],
  [
    "I like this work",
    "NOVELTY"
  ],
  [
    "While the fast weights approach is not totally original",
    "NOVELTY"
  ],
  [
    ", its application to this problem is novel and very well-suited to it .",
    "NOVELTY"
  ],
  [
    "Their proposed solution of functional composition is exceedingly clever",
    "NOVELTY"
  ],
  [
    "the proposed algorithm feels natural",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting and novel approach for transductive zero-shot learning .",
    "NOVELTY"
  ],
  [
    "While the paper includes an interesting novel transductive approach for zero shot learning , with",
    "NOVELTY"
  ],
  [
    "There is just the single primary contribution of the paper",
    "NOVELTY"
  ],
  [
    "The technical contribution here is limited as it is not significantly challenging to apply minimax tree search algorithm to the rectangular uncertainty set after the relaxation .",
    "NOVELTY"
  ],
  [
    "The proposed approach is new and neat",
    "NOVELTY"
  ],
  [
    "This work seems very similar to Search on the replay buffer ( Eysenbach et al 2019 ) .",
    "NOVELTY"
  ],
  [
    "the idea of this formulation and doubly SGD is not new .",
    "NOVELTY"
  ],
  [
    "The idea itself is very inspiring",
    "NOVELTY"
  ],
  [
    "The method is novel and the basic innovation is in the new objective function , which has encoder-decoder dynamics that are intriguing .",
    "NOVELTY"
  ],
  [
    "While I liked the somewhat elegant formulation of dynamic test-time scaling proposed by the following work , I do n't think this work introduced many novel results nor insights -Multiscale test-time inference is already standard in state-of-the-art architectures such as DeepLab",
    "NOVELTY"
  ],
  [
    "-Using entropy as a measure of network uncertainty is a good idea",
    "NOVELTY"
  ],
  [
    "but also not a novel finding",
    "NOVELTY"
  ],
  [
    "I maintain that I think the optimization-based scale inference solution they present is interesting",
    "NOVELTY"
  ],
  [
    "from an",
    "NOVELTY"
  ],
  [
    "implementation standpoint",
    "NOVELTY"
  ],
  [
    "but the findings in this work did not yield sufficient new insight for the task .",
    "NOVELTY"
  ],
  [
    "the main contributions are clear . I find the theoretical results of the paper interesting and",
    "NOVELTY"
  ],
  [
    "This approach is not novel .",
    "NOVELTY"
  ],
  [
    "like the core idea of this paper",
    "NOVELTY"
  ],
  [
    "direction",
    "NOVELTY"
  ],
  [
    "The problem addressed in the paper seems new and the proposed `` BaSE `` algorithm seems novel for the purpose .",
    "NOVELTY"
  ],
  [
    "The paper offers fresh insights into the well studied problem of learning word embeddings .",
    "NOVELTY"
  ],
  [
    "Just showing results",
    "NOVELTY"
  ],
  [
    "I like the idea of using an attention model to help pick learn a weighting for the combination of a number of sub-policies .",
    "NOVELTY"
  ],
  [
    "this use of differentiable programing language technique is not new",
    "NOVELTY"
  ],
  [
    "The proposed language HOUDINI is quite original thanks to its combination of functional language and symbolic synthesis . Also using types to reduce research is quite creative .",
    "NOVELTY"
  ],
  [
    "As it stands the impact is limited",
    "NOVELTY"
  ],
  [
    "While I find",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is rather low . There is no new idea introduced in this paper",
    "NOVELTY"
  ],
  [
    "The idea of using graph lasso to prune weights is simply not novel enough an idea to be publishable at NIPS .",
    "NOVELTY"
  ],
  [
    "So the contribution of the paper is limited .",
    "NOVELTY"
  ],
  [
    "These two literature are the first work to propose to learn optical flow inside a CNN for action recognition .",
    "NOVELTY"
  ],
  [
    "In terms of novelty",
    "NOVELTY"
  ],
  [
    "In terms of performance , there is no obvious advantage over previous work like S3D and R (",
    "NOVELTY"
  ],
  [
    "The technical novelty seems incremental as cross-validating and using a set of models under particular performance constraints does not constitutes a novel contribution .",
    "NOVELTY"
  ],
  [
    "I dont see a lot of novelty to the method .",
    "NOVELTY"
  ],
  [
    "there is no significant novelty in the paper .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the proposed method is new .",
    "NOVELTY"
  ],
  [
    "The results is interesting and novel .",
    "NOVELTY"
  ],
  [
    "With the exception of the choice of the reward function , the formulation of an optimization of a DP problem is not new .",
    "NOVELTY"
  ],
  [
    "This paper , despite studying an interesting problem , is limited in terms of its technical innovations and experimental results .",
    "NOVELTY"
  ],
  [
    "I think the formulation is new that is coupled with the training procedure based on imitation learning with two policies",
    "NOVELTY"
  ],
  [
    "The originality is weak .",
    "NOVELTY"
  ],
  [
    "There is some originality in the proof which differs from recent related papers .",
    "NOVELTY"
  ],
  [
    "the paper argues that this representation allows for better generalization and can also guide exploration by rewarding actions that change multiple entities I really like the overall idea i.e .jointly learning the scene representation and the transition model , while enforcing sparse transitions",
    "NOVELTY"
  ],
  [
    "and I don \u2019 t think this paper \u2019 s approach is novel in context of these .",
    "NOVELTY"
  ],
  [
    "The proposed technique is not particularly novel and it is not clear whether the technique can be used to get speed-ups beyond 2x",
    "NOVELTY"
  ],
  [
    "The amount of innovation is on the low side , as it involves mostly just fairly minor architectural changes .",
    "NOVELTY"
  ],
  [
    "Even when looking at the specific case of word/context embeddings , the method is not novel either",
    "NOVELTY"
  ],
  [
    "This work presents novel idea and solid supporting experiments .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel strategy to deal with dynamic computation graphs . They arise , when the computation is dynamically influenced by the input data , such as in LSTMs . The authors propose an ` unrolling ' strategy over the operations done at every step , which allows a new kind of batching of inputs . The presented idea is novel",
    "NOVELTY"
  ],
  [
    "Overall , the paper introduces a novel and significant idea .",
    "NOVELTY"
  ],
  [
    "The paper seems to be a summary of existing work reinterpreting variational autoencoding objectives from an information theoretic standpoint .",
    "NOVELTY"
  ],
  [
    "Using uncertainty to drive data acquisition and exploration is not a new idea",
    "NOVELTY"
  ],
  [
    "This technique is an interesting variation of memory augmented neural networks with a number of advantages to many of the standard memory augmented architectures .",
    "NOVELTY"
  ],
  [
    "The idea of using Tumblr data seems interesting , allowing to work with a large set of emotion categories , instead of considering just the binary task positive vs. negative .",
    "NOVELTY"
  ],
  [
    "The main novelties of the paper are",
    "NOVELTY"
  ],
  [
    "the use of Tumblr data",
    "NOVELTY"
  ],
  [
    "I find this paper to be very interesting as it provides novel insights into the optimization process of ResNets even though in a very restricted setting .",
    "NOVELTY"
  ],
  [
    "The method introduced in this paper is novel and interesting and can in principle be extended to tackle different problems in population genetics .",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper scores low on novelty and original contribution .",
    "NOVELTY"
  ],
  [
    "are standard applications of existing techniques and I would n't consider them particularly novel",
    "NOVELTY"
  ],
  [
    "my decision is weak reject because of the lack of novelty and original contribution",
    "NOVELTY"
  ],
  [
    "A novel algorithm for computing unregularized Wasserstein barycenters via a different interior point method to solve the associated linear program .",
    "NOVELTY"
  ],
  [
    "In light of submission with ID 6290 , the method proposed in this paper is not novel .",
    "NOVELTY"
  ],
  [
    "Although the idea of importance weighting and estimating density ratios with a classifier is not new",
    "NOVELTY"
  ],
  [
    "This paper presents a novel approach to transfer learned representations to new but related domains .",
    "NOVELTY"
  ],
  [
    "The method is original and novel .",
    "NOVELTY"
  ],
  [
    "the approach is a simple combination of the existing approaches",
    "NOVELTY"
  ],
  [
    "I believe the combination of these constraint handling technique and evolutionary approaches are not new .",
    "NOVELTY"
  ],
  [
    "This seems like",
    "NOVELTY"
  ],
  [
    "This is a nice algorithm",
    "NOVELTY"
  ],
  [
    "the paper still lacks enough content and novelty , in my opinion , to warrant acceptance .",
    "NOVELTY"
  ],
  [
    "Novel combination of recurrent skip connections with attention .",
    "NOVELTY"
  ],
  [
    "the combination of recurrent skip connections and attention appears to be novel",
    "NOVELTY"
  ],
  [
    "I think the approach is quite interesting and as such I am revising my rating from 4 to 5",
    "NOVELTY"
  ],
  [
    "I think such generalization is interesting but the innovation seems to be very limited .",
    "NOVELTY"
  ],
  [
    "I do not believe the paper fully meets the bar for novelty and potential impact for acceptance at ICLR",
    "NOVELTY"
  ],
  [
    "The novelty of the approach also seems quite limited , and the findings do not seem particularly surprising or insightful",
    "NOVELTY"
  ],
  [
    "Overall I found the paper interesting but not ground-breaking .",
    "NOVELTY"
  ],
  [
    "A nice application of the separable principle to GCN .",
    "NOVELTY"
  ],
  [
    "and this paper does not add any novel insights to that",
    "NOVELTY"
  ],
  [
    "1 .The proposed method is straightforward and lacks of significant novelty .",
    "NOVELTY"
  ],
  [
    "The paper appears to be rather original , in terms of task and architecture",
    "NOVELTY"
  ],
  [
    "although conventional in terms of machine learning theory",
    "NOVELTY"
  ],
  [
    "A new approach for multi-task learning by analysing average regret-upper-bound * A general performance bound ( Theorem 1 ) that",
    "NOVELTY"
  ],
  [
    "2 ) into two online learning problem that can be studied separately",
    "NOVELTY"
  ],
  [
    "This work presents interesting and novel ideas in these settings .",
    "NOVELTY"
  ],
  [
    "Novel video-based loss functions for feature disentanglement .",
    "NOVELTY"
  ],
  [
    "The idea of using differential renderers to produce physically consistent adversarial perturbations is novel .",
    "NOVELTY"
  ],
  [
    "Good paper , illustrates the utility of differentiable rendering and simulations to generate adversarial examples and to use them for improving robustness",
    "NOVELTY"
  ],
  [
    "and the results seem highly non-trivial",
    "NOVELTY"
  ],
  [
    "I found it that the contribution of the paper is very limited .",
    "NOVELTY"
  ],
  [
    "I continue thinking that the contribution is limited .",
    "NOVELTY"
  ],
  [
    "My impression is theoretical results are mostly a combination of proof techniques used in other SG-MCMC and asynchronous SGD papers",
    "NOVELTY"
  ],
  [
    "The ideas are interesting",
    "NOVELTY"
  ],
  [
    "not convey clearly what are novel tasks and could be significantly improved",
    "NOVELTY"
  ],
  [
    "The idea of using R hash functions to remap K-way classification into R B-way classification problems is fairly novel",
    "NOVELTY"
  ],
  [
    "There are not many theoretical innovations as the main contribution is a combination of several well known techniques such as MDNs and RNNs , applied to the specific temporal point process formulation",
    "NOVELTY"
  ],
  [
    "The paper is incremental and does not have much technical substance .",
    "NOVELTY"
  ],
  [
    "but it is incremental and does not have much technical substance .",
    "NOVELTY"
  ],
  [
    "The authors provide novel generalization bounds based on finite quantitiesfor ordinal embedding , as far as I understand the fiel , this is novel .",
    "NOVELTY"
  ],
  [
    "-Interesting and a priori novel theoretical analysis for Ordinal Embedding Cons",
    "NOVELTY"
  ],
  [
    "Good and interesting theoretical results that are novel for this topic",
    "NOVELTY"
  ],
  [
    "-The bounds proposed in this paper appear to be novel and are interesting .",
    "NOVELTY"
  ],
  [
    "provided a nice approach with sublinear",
    "NOVELTY"
  ],
  [
    "and lack of novel insight",
    "NOVELTY"
  ],
  [
    "and makes a clear contribution to the field",
    "NOVELTY"
  ],
  [
    "I found this paper contains some solid contributions",
    "NOVELTY"
  ],
  [
    "Studying the linear networks is interesting by itself",
    "NOVELTY"
  ],
  [
    "The choice of random projection on the top layer is brilliant .",
    "NOVELTY"
  ],
  [
    "As far as I know the approach proposed is innovative \u00e2\u0080\u0093\u00e2\u0080\u0093 it uses ideas from the partial identification literature , but adapts them to a new setting in a novel way .",
    "NOVELTY"
  ],
  [
    "to the estimation of point processes is not so obvious and the originality of the contribution comes from proposing a reasonable approach to do this adaptation , along with some insights regarding the implementation of the Lipschitz constraint which I find interesting",
    "NOVELTY"
  ],
  [
    "Although the approximation in itself has been used and applied extensively in other papers , to the best of my knowledge , this paper is the first in applying it to the GPFA model in particular .",
    "NOVELTY"
  ],
  [
    "The contributions themselves are fairly modest and application-specific",
    "NOVELTY"
  ],
  [
    "Overall , the results of the paper at hand seem incremental compared to those from the Bubeck line of research -- I feel that the recent manuscript by Bubeck/Eldan/Lee efficiently obtaining \\sqrt",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "Certainly , it 's a novel contribution to the existing literature of DNN .",
    "NOVELTY"
  ],
  [
    "The idea to predict the parameters of the convolutions is interesting",
    "NOVELTY"
  ],
  [
    "Novelty is rather low .",
    "NOVELTY"
  ],
  [
    "I found the results of the paper very surprising and interesting .",
    "NOVELTY"
  ],
  [
    "The technical contribution of the paper is very limited . I do not see many novel contributions in terms of both network architecture and learning perspective .",
    "NOVELTY"
  ],
  [
    "however the overall contribution ( both technical quality and novelty ) is doubtful .",
    "NOVELTY"
  ],
  [
    "The extension to mixture of supermodular and submodular is really nice .",
    "NOVELTY"
  ],
  [
    "On a technical level , the variational inference approach does not seem provide any novel conceptual contributions , and the main technical ideas come from the previous work .",
    "NOVELTY"
  ],
  [
    "To start with , the contributions are not clear .",
    "NOVELTY"
  ],
  [
    "The main Figure",
    "NOVELTY"
  ],
  [
    "is also not new",
    "NOVELTY"
  ],
  [
    "This work is original as",
    "NOVELTY"
  ],
  [
    "most of the model-based RL works are focusing on learning one environment instead of common rules of physics",
    "NOVELTY"
  ],
  [
    "The proofs seem novel and are really a great combination of simple but insightful ideas .",
    "NOVELTY"
  ],
  [
    "this paper",
    "NOVELTY"
  ],
  [
    "I think the paper is a valuable and novel contribution",
    "NOVELTY"
  ],
  [
    "I think the paper is well written and the idea novel",
    "NOVELTY"
  ],
  [
    "All in all , I do like the idea as a concept but",
    "NOVELTY"
  ],
  [
    "the approach itself is similar to Edwards & Storkey 2015",
    "NOVELTY"
  ],
  [
    "but I doubt whether the novelty is significant in this case",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting , and the analysis offers insights into related areas",
    "NOVELTY"
  ],
  [
    "the novelty is not enough for acceptance at ICLR",
    "NOVELTY"
  ],
  [
    "As claimed by the authors , the novel approach has a number of advantages compared to existing methods such as PCCs .",
    "NOVELTY"
  ],
  [
    ".In general I find the method proposed in this paper interesting .",
    "NOVELTY"
  ],
  [
    "I very much like the manuscript and the science",
    "NOVELTY"
  ],
  [
    "Overall , the novelty of this paper is in doubt .",
    "NOVELTY"
  ],
  [
    "The novelty and scalability are both limited .",
    "NOVELTY"
  ],
  [
    "Weak novelty in terms of model design .",
    "NOVELTY"
  ],
  [
    "The use generated samples as negative samples is interesting but mysterious",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "line of",
    "NOVELTY"
  ],
  [
    "I really like the idea",
    "NOVELTY"
  ],
  [
    "though the methods will not revolutionize current practice",
    "NOVELTY"
  ],
  [
    "this",
    "NOVELTY"
  ],
  [
    "Among the many proposal , I find this one particularly interesting for its simplicity that makes it a good candidate to become a reference for future systems .",
    "NOVELTY"
  ],
  [
    "So the paper falls in a very active area but presents an approach that is nevertheless novel and promising .",
    "NOVELTY"
  ],
  [
    "The algorithm and analysis for MCMC for 2-regular loop series is novel and a clear improvement over the previous state of the art PTAS which only worked for planar graphs .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel model for neural speed reading .",
    "NOVELTY"
  ],
  [
    "The basic idea of the paper , the concepts of skip and jump , and the reinforcement learning formulation are not completely new ,",
    "NOVELTY"
  ],
  [
    "but the paper combined them in an effective way",
    "NOVELTY"
  ],
  [
    "that bad , but the novelty of the paper is not that good either .",
    "NOVELTY"
  ],
  [
    "The expressivity results are interesting and novel .",
    "NOVELTY"
  ],
  [
    "The discussion of Section 5 and 6 might be new in this context and somewhat interesting .",
    "NOVELTY"
  ],
  [
    "I very much like the underlying idea for this paper .",
    "NOVELTY"
  ],
  [
    "STG is the most convincing one",
    "NOVELTY"
  ],
  [
    ".However , the particular loss-function ( Eq . ( 8 ) ) proposed in this paper is unique and very intriguing .",
    "NOVELTY"
  ],
  [
    "Although the tricks introduced in the paper ( mixup and changing the mini-batch selection rules ) themselves are not novel",
    "NOVELTY"
  ],
  [
    "paper presents a novel way of doing state-visit counts for exploration in deep RL",
    "NOVELTY"
  ],
  [
    "While the idea of using adaptive parameterization is not new",
    "NOVELTY"
  ],
  [
    "and its accelerated versions is widely studied in the literatures , this paper proposes 4 novel algorithms which I have not seen in the literature .",
    "NOVELTY"
  ],
  [
    "I believe that the results of the paper are non-trivial and have significant theoretical contribution to optimization and machine learning community",
    "NOVELTY"
  ],
  [
    "Overall , the idea is interesting to me .",
    "NOVELTY"
  ],
  [
    "Originality The limited novelty of the paper is mainly on the algorithm part .",
    "NOVELTY"
  ],
  [
    "the paper studies a well-defined semi-supervised problem , without any new insights or problem setting .",
    "NOVELTY"
  ],
  [
    "it only adds a small modification to existing algorithms",
    "NOVELTY"
  ],
  [
    "the paper does not give too much new information",
    "NOVELTY"
  ],
  [
    "to the community",
    "NOVELTY"
  ],
  [
    "I find the overall approach to be quite interesting and definitely worth publishing .",
    "NOVELTY"
  ],
  [
    "Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting .",
    "NOVELTY"
  ],
  [
    "though",
    "NOVELTY"
  ],
  [
    "and the new contributions seemingly small",
    "NOVELTY"
  ],
  [
    "Therefore the novel contribution of this paper over Lee 2018 is not clearly outlined .",
    "NOVELTY"
  ],
  [
    "This seems like a nice contribution to the GAN theory literature",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "This work is a novel and smart combination of well-known techniques , concerning both statistics and optimization .",
    "NOVELTY"
  ],
  [
    "it is not clear how it differs from previous studies",
    "NOVELTY"
  ],
  [
    "This paper builds on an LSTM model without enough work or idea to show novelty .",
    "NOVELTY"
  ],
  [
    ", and to my knowledge , original .",
    "NOVELTY"
  ],
  [
    "The techniques of proving the regret bound ( highlighted on Page 2 ) indeed seem novel .",
    "NOVELTY"
  ],
  [
    "One thing I was n't entirely certain of was the amount of novelty in the work since it leverages existing works like NID",
    "NOVELTY"
  ],
  [
    "for some of the key aspects of the method",
    "NOVELTY"
  ],
  [
    "The idea to incorporate memory mechanism into GAN is interesting",
    "NOVELTY"
  ],
  [
    "1.the results is rather incremental relatively to ref [ 2 ] and [ 9,10 ] .",
    "NOVELTY"
  ],
  [
    "This step is largely incremental .",
    "NOVELTY"
  ],
  [
    "using neural network on a new domain .",
    "NOVELTY"
  ],
  [
    "but this looks like a nice advance",
    "NOVELTY"
  ],
  [
    "The paper is of modest originality",
    "NOVELTY"
  ],
  [
    "From a technical point of view the contribution is not that significant -- -the ideas behind it are relatively simple , or are extensions of non-trivial ideas that have become `` normalized `` as they have matured .",
    "NOVELTY"
  ],
  [
    "is natrual from numerical linear algebra",
    "NOVELTY"
  ],
  [
    "The proposed normalization is somewhat novel .",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed method is very marginal -",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed method seems to be very marginal , which simply applies the GCN for link prediction .",
    "NOVELTY"
  ],
  [
    "But the essential idea is very similar .",
    "NOVELTY"
  ],
  [
    "The method proposed in this paper are novel and",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel method for multi-metric learning .",
    "NOVELTY"
  ],
  [
    "The framework looks promising as it is quite general and could be adapted to several problems",
    "NOVELTY"
  ],
  [
    "As there are no architectural or theoretical contributions of the paper",
    "NOVELTY"
  ],
  [
    "However , the authors also note that this in itself is not novel",
    "NOVELTY"
  ],
  [
    "However , the technical contributions of this paper are rather limited \u2013 thus",
    "NOVELTY"
  ],
  [
    "I think the main result , that speaker agents learn to only convey as much information as is needed to solve the task , is interesting and insightful .",
    "NOVELTY"
  ],
  [
    "I do , however , have a slight concern about the novelty of this result .",
    "NOVELTY"
  ],
  [
    "Novelty is limited : The two algorithms are essentially small modification of the semantic consistency term used in Hoffman et al .2018 .They involve making use of both the source and target classifiers",
    "NOVELTY"
  ],
  [
    "but I feel that novelty is too limited and the current set of experiments not sufficient to warrant publication at ICLR",
    "NOVELTY"
  ],
  [
    "I still feel that the contribution is a bit weak for ICLR",
    "NOVELTY"
  ],
  [
    "It seems that explicit learning of underlying factors that are described in ( Hassanpour & Greiner , 2019 ) is a nice idea",
    "NOVELTY"
  ],
  [
    "The paper presents a novel approach of getting attention at a given time by modeling infinitesimal change of attention as a continuous function .",
    "NOVELTY"
  ],
  [
    "I found the idea using Neural ODEs in the MAC framework to model attention as a continuous system is definitely interesting .",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "the model does not offer much novelty .",
    "NOVELTY"
  ],
  [
    "In my opinion , the main problem of the paper is that the contributions are not clear .",
    "NOVELTY"
  ],
  [
    "it is poorly written and do not contribute much in terms of novelty of the approach .",
    "NOVELTY"
  ],
  [
    ") , however , it does not contribute much in terms of novelty or new ideas .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "The algorithmic techniques proposed in this work seem new , and impactful .",
    "NOVELTY"
  ],
  [
    "Perhaps with the exception of Theorem 3 , there appears not to be much technical contribution in the paper .",
    "NOVELTY"
  ],
  [
    "-- The two theoretical results are , to the best of my knowledge , novel and make use of well-established ideas from information and probability theory in an interesting manner for their proofs .",
    "NOVELTY"
  ],
  [
    "The notion of attributing final layer biases to input layer is novel .",
    "NOVELTY"
  ],
  [
    "I find the idea interesting",
    "NOVELTY"
  ],
  [
    "However , this step is nontrivial .",
    "NOVELTY"
  ],
  [
    "none of the proposed types of intrinsic motivation are novel , and it \u2019 s arguable whether the application to deep RL is novel",
    "NOVELTY"
  ],
  [
    "Though the approach is interesting",
    "NOVELTY"
  ],
  [
    "-The extension to visual planning/imitation learning was very interesting -Explores differences between sequential and hierarchical prediction models Weaknesses/questions/suggestions",
    "NOVELTY"
  ],
  [
    "I enjoyed this paper -- - I thought the idea was original",
    "NOVELTY"
  ],
  [
    "While establishing new lower bounds on the marginal likelihood is a common subject at this point , the authors manage to approach this with originality .",
    "NOVELTY"
  ],
  [
    "but it does not seem to be a breakthrough .",
    "NOVELTY"
  ],
  [
    "and also introduces several important concepts from Manifold theory",
    "NOVELTY"
  ],
  [
    "The idea of learning disentangled representation is being adopted in many domains and hence this contribution is timely and very interesting to the community",
    "NOVELTY"
  ],
  [
    "The trick use to compose the latent variables is not novel and considering that variational IB is also available , the paper lacks overall novelty .",
    "NOVELTY"
  ],
  [
    "This paper 's motivating insight , the symmetry between maximum likelihood and reinforcement learning objectives when viewed as a variational minimization , is very insightful .",
    "NOVELTY"
  ],
  [
    "This is a very nice idea",
    "NOVELTY"
  ],
  [
    "The contributions of the paper in terms of theory are somewhat not significant .",
    "NOVELTY"
  ],
  [
    "The work is lack of novelty and the results do not show significant improvement over existing approaches .",
    "NOVELTY"
  ],
  [
    "but lacks enough originality .",
    "NOVELTY"
  ],
  [
    "This module is very similar to the Recall gate of the E3D-LSTM [ Wang et al .2018b ] .Besides , the Double LH-STM looks like an incremental extension of the Single LH-STM .",
    "NOVELTY"
  ],
  [
    "and yet has limited novelty for an ICLR paper .",
    "NOVELTY"
  ],
  [
    "I am convinced that the paper contributes sufficiently to the theoretical understanding of the FA algorithm and should be accepted as a conference paper",
    "NOVELTY"
  ],
  [
    "The method improves the current state of the art .",
    "NOVELTY"
  ],
  [
    "Overall I find this paper incremental .",
    "NOVELTY"
  ],
  [
    "and the proposed method is a simple combination of well-established existing works without problem-specific adaptation",
    "NOVELTY"
  ],
  [
    "The approach is simple and",
    "NOVELTY"
  ],
  [
    "Though the approach seems novel and well crafted",
    "NOVELTY"
  ],
  [
    "the approach seems novel and seem to fit well with the RL planning framework .",
    "NOVELTY"
  ],
  [
    "Although the paper presents an interesting and reasonable idea",
    "NOVELTY"
  ],
  [
    "However , my main concern is the novelty in that the proposed approach is just an extension of [ 1 ] .",
    "NOVELTY"
  ],
  [
    "From the methodology aspect , the techniques used in the paper is not new , but a combination of existing methods .",
    "NOVELTY"
  ],
  [
    "The proposed method significantly outperformed existing methods .",
    "NOVELTY"
  ],
  [
    "3 .The proposed method is also quite similar to a previous work (",
    "NOVELTY"
  ],
  [
    "but it is not very surprising , nor is the proof technique itself very novel .",
    "NOVELTY"
  ],
  [
    "I believe the theoretical contribution is nice",
    "NOVELTY"
  ],
  [
    "but not very strong .",
    "NOVELTY"
  ],
  [
    "the idea of computing Hessian vector products with automatic differentiation is not an original idea of this work",
    "NOVELTY"
  ],
  [
    "The first idea is sensible but rather trivial as a contribution",
    "NOVELTY"
  ],
  [
    "but is conceptually not novel .",
    "NOVELTY"
  ],
  [
    "This problem seems like a very natural extension of the rank-one matrix sensing problem .",
    "NOVELTY"
  ],
  [
    "Conceptually speaking , the ideas used in both steps are not new",
    "NOVELTY"
  ],
  [
    "Although the fact that both ideas are not new may be the main weakness of the current manuscript",
    "NOVELTY"
  ],
  [
    "I like the model architecture since it has two clear improvements over traditional approaches \u2014",
    "NOVELTY"
  ],
  [
    "The idea is novel and sensible .",
    "NOVELTY"
  ],
  [
    "I like the idea",
    "NOVELTY"
  ],
  [
    "Overall , the paper is of high technical quality and presents an interesting and non-trivial combination of state-of-the-art advancements in Deep Learning ( DL ) and Deep Reinforcement Learning ( DRL ) .",
    "NOVELTY"
  ],
  [
    "The authors also make a novel use of analogy making and parameter prediction .",
    "NOVELTY"
  ],
  [
    "I still feel the core methodological contribution is marginal because pairwise clustering is an well-studied approach to clustering in general",
    "NOVELTY"
  ],
  [
    "However , because the idea and effectiveness of channel grouping for fine-grained recognition are proposed in MA-CNN [ 9 ] and not novel , the contribution of the paper seems rather incremental : just performs the standard bilinear pooling on top of the grouped features .",
    "NOVELTY"
  ],
  [
    "and the extensions proposed are to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "and I believe that",
    "NOVELTY"
  ],
  [
    "there is sufficient novelty in the work to justify publication",
    "NOVELTY"
  ],
  [
    "ideas",
    "NOVELTY"
  ],
  [
    "The technical implementation of the proposition is somewhat trivial",
    "NOVELTY"
  ],
  [
    "The idea of exploiting derivative w.r.t .the input image is interesting",
    "NOVELTY"
  ],
  [
    "The proposed idea of adaptive cut-off and predicting joint worker runtime through amortized inference with variational auto encoder loss is novel and very interesting .",
    "NOVELTY"
  ],
  [
    "QUALITY I like the approach but I have one fundamental problem in understanding the method",
    "NOVELTY"
  ],
  [
    "ORIGINALITY The paper introduces some fundamental concepts and combines them into a novel algorithm type .",
    "NOVELTY"
  ],
  [
    "With regards to the technical assessment of this work , the idea of using a nearest neighbors objective for learning a generative model is both intriguing and appealing .",
    "NOVELTY"
  ],
  [
    "I believe there are major theoretical",
    "NOVELTY"
  ],
  [
    "I believe the introduction of the notion of effective receptive field size and its detailed analysis is novel and something the community is unaware of and would benefit knowing about",
    "NOVELTY"
  ],
  [
    "and conveys some possibly useful insights",
    "NOVELTY"
  ],
  [
    "I think both the related work and experiments sections are missing many substantial contributions",
    "NOVELTY"
  ],
  [
    "comparison to previous works .",
    "NOVELTY"
  ],
  [
    "Trying to shed light at comparison between different GAN variants , but the metrics introduced are not very novel",
    "NOVELTY"
  ],
  [
    "Overall I think the theory presented in the paper is promising .",
    "NOVELTY"
  ],
  [
    "The obvious weakness of the paper is technical novelty .",
    "NOVELTY"
  ],
  [
    "I would have to say just comparing two known averaging methods would not have strong novelty",
    "NOVELTY"
  ],
  [
    "this is a novel contribution in that it is the application of the existant imagenet reconstruction GAN to faces",
    "NOVELTY"
  ],
  [
    "No part of the reconstruction method proposed seems novel ( as claimed ) and validation is shaky in parts .",
    "NOVELTY"
  ],
  [
    "But even this innovation only successes on some specific problems",
    "NOVELTY"
  ],
  [
    "There are too few innovations .",
    "NOVELTY"
  ],
  [
    "The idea of pre-stabilization is interesting , and seems related to this paper",
    "NOVELTY"
  ],
  [
    "The use of a grammar in the context of semantic parsing is not novel",
    "NOVELTY"
  ],
  [
    "but also nothing novel",
    "NOVELTY"
  ],
  [
    "Especially , the conditional graph generation direction under the deep learning context is novel .",
    "NOVELTY"
  ],
  [
    "The idea of looking at the distribution over states seems very similar to the recent work on Generative Adversarial Imitation Learning ( GAIL ) , where the discriminator network looks at the distribution over states or state-actions to classify whether the policy is from the demonstrations or the generating network .",
    "NOVELTY"
  ],
  [
    "I think this is a good contribution to the imitation learning literature",
    "NOVELTY"
  ],
  [
    "Although the similar idea has appeared in prior works",
    "NOVELTY"
  ],
  [
    "which is also cited by the authors , applying it for the case of overlapping clusters with modification for numbers of settings is still novel",
    "NOVELTY"
  ],
  [
    "while the central idea is interesting and novel with a clean implementation",
    "NOVELTY"
  ],
  [
    "Its empirical contributions are fairly minimal",
    "NOVELTY"
  ],
  [
    "This is a very nice application of guided attention over an image for identifying a sequence of handwritten text lines",
    "NOVELTY"
  ],
  [
    "The architecture used in the paper is not particularly novel as graph neural networks have",
    "NOVELTY"
  ],
  [
    "previously been tried and",
    "NOVELTY"
  ],
  [
    "but I think the impressive results can make up for a lack of novelty",
    "NOVELTY"
  ],
  [
    ", there does not seem to be much innovation in the architecture .",
    "NOVELTY"
  ],
  [
    "I find the idea of converting such combinatorial problems to differentiable , specially when gradient methods can succeed in optimizing them afterward , very fascinating .",
    "NOVELTY"
  ],
  [
    "The algorithm itself is not novel . The straight through approach for training quantized network has been used in previous papers",
    "NOVELTY"
  ],
  [
    "The biggest factor in my review is the lack of novelty in this work -- in my view",
    "NOVELTY"
  ],
  [
    "But methodologically there is not much contribution to the current literature .",
    "NOVELTY"
  ],
  [
    "The method developed in Section 3 and proposed explicitly in Eqs 7 to 11 is novel per se ,",
    "NOVELTY"
  ],
  [
    "though not groundbreaking",
    "NOVELTY"
  ],
  [
    "This paper makes some interesting conceptual contributions to this discussion .",
    "NOVELTY"
  ],
  [
    "ODP",
    "NOVELTY"
  ],
  [
    "is a new concept",
    "NOVELTY"
  ],
  [
    "The use of oblivious shuffling to hide dummy and fake records in the histogram algorithm is interesting and the proof is non-trivial",
    "NOVELTY"
  ],
  [
    "The idea of weakening definitions like obliviousness ( and , as has occurred elsewhere in the literature , secure multi-party computation ) to allow DP leakage is an interesting idea that has a lot of potential .",
    "NOVELTY"
  ],
  [
    "Apart from that there is no other main contribution / novelty",
    "NOVELTY"
  ],
  [
    "The dataset is novel and would be of interest to the character recognition community",
    "NOVELTY"
  ],
  [
    "The machine learning techniques applied are of limited novelty",
    "NOVELTY"
  ],
  [
    "however , the dataset is certainly a novel contribution",
    "NOVELTY"
  ],
  [
    "To the best of my understanding ,",
    "NOVELTY"
  ],
  [
    "The paper is not proposing technical novelties of any kind throughout .",
    "NOVELTY"
  ],
  [
    "Overall , this paper handles an interesting collection of data , but does not add much interesting novelty to the field of representation learning and fails to leverage some opportunities in those datasets to do sth .",
    "NOVELTY"
  ],
  [
    "as a similar problem too simplistic",
    "NOVELTY"
  ],
  [
    "The main contribution of this work is just a combination of LSH schemes and SGD updates .",
    "NOVELTY"
  ],
  [
    "Finally , most findings are not even new or surprising",
    "NOVELTY"
  ],
  [
    "In terms of originality , the main contribution of the paper is the introduction of the ODE-RNN , which is novel if not extremely original .",
    "NOVELTY"
  ],
  [
    "and is less original than the ODE-RNN",
    "NOVELTY"
  ],
  [
    "proposes an interesting and original idea , provides experiments with real graph datasets from two domains",
    "NOVELTY"
  ],
  [
    "However , the proposed algorithms as well as their analysis are very similar to Bateni et al .2013 .I think the paper is overall",
    "NOVELTY"
  ],
  [
    ". My biggest concern is the novelty of this work",
    "NOVELTY"
  ],
  [
    "AdaptiveStream , on the other hand , is only trivial modification of AdaptiveSecretary",
    "NOVELTY"
  ],
  [
    "This paper presents a novel metacontroller optimization system that learns the best action for a one-shot learning task",
    "NOVELTY"
  ],
  [
    "approach is weak starting from the construction of the training set .",
    "NOVELTY"
  ],
  [
    "and the new method is innovative and certainly relevant to the recommendation systems research . I think it should be accepted because it presents a novel idea that is considered in depth , and is likely to make an",
    "NOVELTY"
  ],
  [
    "and thus the result is not surprising or novel",
    "NOVELTY"
  ],
  [
    "I found the music and speech experiments very interesting .",
    "NOVELTY"
  ],
  [
    "On the whole I thought this paper was quite interesting",
    "NOVELTY"
  ],
  [
    "The problem formalisation and the model are interesting and , as far as I know , the results regarding upper and lower bounds on the influence function in various contagion models are novel .",
    "NOVELTY"
  ],
  [
    "the paper constitutes a significant contribution to the theoretical understanding of meta-learning .",
    "NOVELTY"
  ],
  [
    "the experimental results are not significant enough to compensate the lack of conceptual novelty .",
    "NOVELTY"
  ],
  [
    "In a work that has been mostly empirical and focused on DNNs , this line of work stands out by being mostly theoretical , taking its seeds from work with boosting with abstention",
    "NOVELTY"
  ],
  [
    "The originality of the paper is very limited since the paper simply combines the existing image denoising technique with the idea of gating .",
    "NOVELTY"
  ],
  [
    "Originality This paper presents a new way to use GANs in hypothesis testing .",
    "NOVELTY"
  ],
  [
    "The proof technique is interesting .",
    "NOVELTY"
  ],
  [
    "I think this is a good idea",
    "NOVELTY"
  ],
  [
    "but it 's a very small contribution .",
    "NOVELTY"
  ],
  [
    "and it is not particularly novel",
    "NOVELTY"
  ],
  [
    "but it does not present substantively new ideas .",
    "NOVELTY"
  ],
  [
    "but personally I am not sure that whether the novelty of this paper is enough for the main conference track .",
    "NOVELTY"
  ],
  [
    "The idea looks interesting to me .",
    "NOVELTY"
  ],
  [
    "This paper presents a new , practical approach to a field with a huge number of previous papers .",
    "NOVELTY"
  ],
  [
    "The idea of using the similarity of neurophysiological data to regularize the representation of artificial neural networks is interesting and novel .",
    "NOVELTY"
  ],
  [
    "novelty is limited since most pieces were already present in previous work .",
    "NOVELTY"
  ],
  [
    "Regularizing a target model against a source model is not a new idea .",
    "NOVELTY"
  ],
  [
    "Figure 3 and the discussion of linear dependence with the original model in general seems does not add much to the paper",
    "NOVELTY"
  ],
  [
    "In short , the proposed disentangle method is simple , novel and very",
    "NOVELTY"
  ],
  [
    "the paper 's key idea is really good",
    "NOVELTY"
  ],
  [
    "some kind of human evaluation supporting claims The paper 's novelty is also quite limited",
    "NOVELTY"
  ],
  [
    "However to this reader 's knowledge , this is a new variant that is both creative and motivated by an actual real-world study , which is exciting and alone warrants presentation at the conference in my opinion",
    "NOVELTY"
  ],
  [
    "Nonetheless , the paper is a very good contribution and",
    "NOVELTY"
  ],
  [
    "accepted .",
    "NOVELTY"
  ],
  [
    "I 'm not sure if the paper is really novel as the authors themselves point out that it corresponds to adding adversarial component in R2P2",
    "NOVELTY"
  ],
  [
    "The setting is new to my knowledge .",
    "NOVELTY"
  ],
  [
    "The results on the exact top-k problem are particularly striking .",
    "NOVELTY"
  ],
  [
    "although it appears as a straightforward combination of existing approaches",
    "NOVELTY"
  ],
  [
    "In conclusion the paper presents an interesting , though",
    "NOVELTY"
  ],
  [
    "not particularly novel",
    "NOVELTY"
  ],
  [
    "I believe that this paper is a novel and important contribution in the direction of understanding the global convergence properties of non-convex methods in machine learning and hence I strongly recommend acceptance if the following comments are addressed",
    "NOVELTY"
  ],
  [
    "a novel approximation approach that uses captures local and global properties for K",
    "NOVELTY"
  ],
  [
    "and the results seem new",
    "NOVELTY"
  ],
  [
    "The idea of using GANs for this goal is smart and interesting + The results seem interesting too Weaknesses",
    "NOVELTY"
  ],
  [
    "and the proposed idea seems interesting",
    "NOVELTY"
  ],
  [
    "Yes this is an original contribution .",
    "NOVELTY"
  ],
  [
    "The work feels like a significant new contribution and I can envision practitioners using these ideas and other theoretical research building on this work",
    "NOVELTY"
  ],
  [
    "The idea presented is theoretically interesting and novel in an ML context .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the contribution is not significant enough .",
    "NOVELTY"
  ],
  [
    "I like the idea of using Grice \u2019 s Maxims of communication to improve the language generation .",
    "NOVELTY"
  ],
  [
    "The formulation of a time series GP as a state space-model with the corresponding computational savings is not novel . Similarly , using EP ( or in this case , ADF ) to handle non-Gaussian likelihoods is not new .",
    "NOVELTY"
  ],
  [
    "as it presents substantial contributions to Bayesian Optimization that are at the same time elegant and practically efficient .",
    "NOVELTY"
  ],
  [
    "the approach with the enveloppe theorem is really nice .",
    "NOVELTY"
  ],
  [
    "Although its technical contribution is not large",
    "NOVELTY"
  ],
  [
    "The network combines several promising previous research directions into an interesting approach ( to the best of my knowledge , the architecture is novel ) .",
    "NOVELTY"
  ],
  [
    "They propose a complete system which addresses these concerns , combining approaches from the literature and novel improvements",
    "NOVELTY"
  ],
  [
    "I am not as familiar with the RL for robotics literature , but from some minor snooping around I believe these ideas to be novel and useful for the community .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "describes an interesting approach to continual learning ( namely , meta-learning good initial representation to facilitate online learning",
    "NOVELTY"
  ],
  [
    "My main problem with the paper as it stands is that it a ) arguably oversells the contribution , and b ) is",
    "NOVELTY"
  ],
  [
    "The reviewer is not entirely sure of the originality of this work .",
    "NOVELTY"
  ],
  [
    "According to the sparse 'related work ' section , the contribution is novel",
    "NOVELTY"
  ],
  [
    "I 'm not entirely sure of its novelty/originality , leaving this part open to others .",
    "NOVELTY"
  ],
  [
    "The analysis is highly nontrivial compared with existing work .",
    "NOVELTY"
  ],
  [
    "This would be a sufficient contribution by itself",
    "NOVELTY"
  ],
  [
    "It has very clear contributions to meta-learning .",
    "NOVELTY"
  ],
  [
    "While the idea has been proposed before in Shmelkov2018 , it was not widely used in the field .",
    "NOVELTY"
  ],
  [
    "Despite the questionable novelty of the proposed metric , the paper provides a nice and interesting empirical evaluation with sota level generative",
    "NOVELTY"
  ],
  [
    "definitely is",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , analyzing the convergence of ULA for target distributions under LSI is novel as is measuring convergence in Renyi-divergence .",
    "NOVELTY"
  ],
  [
    "This work simply applies it for the data augmentation where the novelty is limited",
    "NOVELTY"
  ],
  [
    "The proposed adaptive averaging strategy is interestingly new and comes with a good intuition .",
    "NOVELTY"
  ],
  [
    "While the paper looks nice overall , the originality and usefulness remains a big concern .",
    "NOVELTY"
  ],
  [
    "strong , clarity : strong , originality : strong , significance : strong",
    "NOVELTY"
  ],
  [
    "it has little contributions that are justifiable to be published",
    "NOVELTY"
  ],
  [
    ". The visualization of filters is hardly any contribution over [ 1 ] .",
    "NOVELTY"
  ],
  [
    "The proposed filter pruning is a simplistic approach that bears little technical novelty",
    "NOVELTY"
  ],
  [
    "the method is built upon existing ideas , however",
    "NOVELTY"
  ],
  [
    ", the exact algorithm seems to be novel",
    "NOVELTY"
  ],
  [
    "Originality To my knowledge , this is the first study of the transfer properties of tickets found in one dataset to a different dataset .",
    "NOVELTY"
  ],
  [
    "This paper is the first to characterize the explicit direction to which adagrad converges for linear classification problems with logisitic or exponential loss .",
    "NOVELTY"
  ],
  [
    "My main concern is that the idea of the paper does not seem significantly novel .",
    "NOVELTY"
  ],
  [
    "The method is not sufficiently novel since the steps of Deep Incremental Boosting are slightly adopted .",
    "NOVELTY"
  ],
  [
    "This paper adopts DIB to Res Nets and provides some empirical analysis however the contribution is not sufficiently novel",
    "NOVELTY"
  ],
  [
    "Pros -provides some preliminary results for boosting of Res Nets Cons -not sufficiently novel : an incremental approach -empirical",
    "NOVELTY"
  ],
  [
    "Much of the technical leverage exploited in this paper comes from earlier work",
    "NOVELTY"
  ],
  [
    "There is some interesting new content in the paper , even if",
    "NOVELTY"
  ],
  [
    "on the whole , it is a bit conceptually and technically incremental .",
    "NOVELTY"
  ],
  [
    "The framework of not relying on pretrained features is a novel contribution .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is questionable given the significant amount of existing work in hierarchical VAEs .",
    "NOVELTY"
  ],
  [
    "It 's also unclear how this work is novel with regards to the works below .",
    "NOVELTY"
  ],
  [
    "While the idea of a nearest neighbor graph may be novel for the MIPS problem , it already exists for the NNS problem for metric spaces . The originality is probably the weakest part of this paper .",
    "NOVELTY"
  ],
  [
    "with interesting ideas",
    "NOVELTY"
  ],
  [
    "The method does n't seem fully developed from a theoretical perspective",
    "NOVELTY"
  ],
  [
    "The results seem very similar to some of the work in `` Universal Planning Networks `` that did not need a more complex HRL design to achieve subgoal specification via images",
    "NOVELTY"
  ],
  [
    "the proposed techniques do not appear substantially novel and I have several concerns/questions that I hope the authors can address",
    "NOVELTY"
  ],
  [
    "Overall , the technical contribution of the paper is minor , the gains in performance with respect to a single state of the art are minimal , and the authors oversell their contribution specially in comparison with the related literature",
    "NOVELTY"
  ],
  [
    "and in any case this seems like a minor technical contribution",
    "NOVELTY"
  ],
  [
    "This paper clearly makes advances in the theory of non-interactive local differential privacy , directly motivated by [ 19 ] and improving on their results .",
    "NOVELTY"
  ],
  [
    "Bayesian , probabilistic approach contrasts with many of the deterministic methods of rule induction",
    "NOVELTY"
  ],
  [
    "identifies a problem , introduces a novel solution",
    "NOVELTY"
  ],
  [
    "but the ideas seem novel in rule learning",
    "NOVELTY"
  ],
  [
    "but some elements such as feature clustering and efficient sampling from misclassifications are clever",
    "NOVELTY"
  ],
  [
    "The goals and techniques of this community , parsimonious models that maximize likelihood while bounding model complexity , seem very similar to this technique .",
    "NOVELTY"
  ],
  [
    "my main concern is on the contributions of this paper .",
    "NOVELTY"
  ],
  [
    "I find the",
    "NOVELTY"
  ],
  [
    "paper interesting but a little bit incremental",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "It is both novel and interesting .",
    "NOVELTY"
  ],
  [
    "The main strengths of this paper are as follows",
    "NOVELTY"
  ],
  [
    "It is a novel and well motivated idea to design a new deep learning architecture which can perform relational reasoning .",
    "NOVELTY"
  ],
  [
    "This is a good paper with novel contribution . It propose a novel algorithm called TrailBlazer with good sampling complexity .",
    "NOVELTY"
  ],
  [
    "The approach has some novelty in the method of generating new images and in the framework",
    "NOVELTY"
  ],
  [
    "itself",
    "NOVELTY"
  ],
  [
    "The paper proposes a nice idea for speeding up WMD , using a hierarchy .",
    "NOVELTY"
  ],
  [
    "This idea although was applied to several problems long time ago",
    "NOVELTY"
  ],
  [
    "but it is novel for this problem",
    "NOVELTY"
  ],
  [
    "Although the main idea is nice",
    "NOVELTY"
  ],
  [
    "I find this paper interesting and somewhat novel",
    "NOVELTY"
  ],
  [
    "This paper alleviates the mode collapse problem occurred in the prior work and generates diverse samples with latent codes . - The proposed method is novel",
    "NOVELTY"
  ],
  [
    "the paper has room to improve",
    "NOVELTY"
  ],
  [
    "1 .The novelty of the paper is not very clear .",
    "NOVELTY"
  ],
  [
    "BTW , as presented in the related work , using RL to optimize non-differentiable metric is not new .",
    "NOVELTY"
  ],
  [
    "The main weaknesses of the paper are that none of the methodological contributions are very significant",
    "NOVELTY"
  ],
  [
    "Furthermore , the proposed technique despite the simplicity appears as a rather incremental contribution .",
    "NOVELTY"
  ],
  [
    "While the authors put forward several interesting ideas",
    "NOVELTY"
  ],
  [
    "there are some shortcomings to the present version of the paper",
    "NOVELTY"
  ],
  [
    "From a machine learning perspective , the reviewer finds the contribution made in this paper to advance ML methodology very limited as the components used in the algorithmic design of the proposed method are already available in the existing literature .",
    "NOVELTY"
  ],
  [
    "which the paper doesn \u2019 t compare to ) for the representational closeness , and as such appears rather incremental",
    "NOVELTY"
  ],
  [
    "Analysis seems quite preliminary , and no novel",
    "NOVELTY"
  ],
  [
    "The result of Theorem 2 is nice and seems new in term of probabilistic bound .",
    "NOVELTY"
  ],
  [
    "I think the paper needs to be improved in its novelty",
    "NOVELTY"
  ],
  [
    "However , it does not seem that there is much novelty in the BNN architecture per se , but rather in the training procedure .",
    "NOVELTY"
  ],
  [
    "and this paper appears to make an advance in this regard",
    "NOVELTY"
  ],
  [
    "I understand that it is the combination of",
    "NOVELTY"
  ],
  [
    "c ) that is the most novel aspect of the paper",
    "NOVELTY"
  ],
  [
    "The contributions made by this paper is unclear .",
    "NOVELTY"
  ],
  [
    "the paper lacks any novel technical insight , contributions are not explained well",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proof of global convergence in the mini-batch setting is novel and might be of independent interest for other work .",
    "NOVELTY"
  ],
  [
    "I felt that the technical contribution was not accompanied by corresponding insight into applied problems .",
    "NOVELTY"
  ],
  [
    "Hyperbolic and Riemannian embeddings are a promising research area that fits well into ICLR .",
    "NOVELTY"
  ],
  [
    "The only problem I see with the submission is the novelty . The",
    "NOVELTY"
  ],
  [
    "I am a little bit concerned that the theoretical contribution seems weak . As discussed in the related work , the idea of using neural network to learn the random field is not new . Using inclusive-divergence is also not new",
    "NOVELTY"
  ],
  [
    "The novelty , however , is not strong as the simple summation provides reasonable performance as convinced in the progressive growing GAN paper",
    "NOVELTY"
  ],
  [
    "however I am not convinced about its novelty",
    "NOVELTY"
  ],
  [
    "A lot of ideas in this work seem to be borrowed from the aforementioned papers thus limiting the novelty of the proposed approach and formulation",
    "NOVELTY"
  ],
  [
    "found the causal idea intriguing",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "New insights to support cross-modality matching from covariates .",
    "NOVELTY"
  ],
  [
    "I found the observation very interesting",
    "NOVELTY"
  ],
  [
    "The submitted work is original , and clearly cites earlier work .",
    "NOVELTY"
  ],
  [
    "The major concern about the paper is the originality of the method . Encoding hierarchies with high dimensional balls and encoding inclusion and exclusion as constraints on those balls is a neat and powerful idea from modeling perspective . However , it is not novel",
    "NOVELTY"
  ],
  [
    "The incorporation of sampling distribution embeddings within BO for hyperparameter selection is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "the attractor networks are novel ,",
    "NOVELTY"
  ],
  [
    "the loss functions introduced are pretty straight-forward",
    "NOVELTY"
  ],
  [
    "The paper presented a novel way of detecting adversarial examples .",
    "NOVELTY"
  ],
  [
    "I find the underlying ideas to be insightful and potentially more generally applicable to a wider range of tasks/DNN models as well",
    "NOVELTY"
  ],
  [
    "The efficacy of the identified witness neurons was also demonstrated through empirical studies and I think this in its own right makes it an interesting enough contribution .",
    "NOVELTY"
  ],
  [
    "Although the main idea is different from the existing methods UNIT and cycleGAN , the framework with VAE and GAN somehow follows UNIT and cycleGAN",
    "NOVELTY"
  ],
  [
    "Section 4 seems to support the main claim in a novel way as well .",
    "NOVELTY"
  ],
  [
    "the unified framework and the theoretical studies are novel in this field .",
    "NOVELTY"
  ],
  [
    "The problem description is novel and appealing , both in its possible practical relevance and as an interesting new model for consideration in algorithm analysis .",
    "NOVELTY"
  ],
  [
    "The paper is original in my opinion .",
    "NOVELTY"
  ],
  [
    "is difficult to assess as a significant contribution as even the authors claim that it is not fundamentally novel and is a rather new/more compact/better proof than that of other similar results",
    "NOVELTY"
  ],
  [
    "But the paper may be slightly lacking in terms of novelty expected from a NIPS paper . Twisting the function is not a new idea , adapting it for PGM and working out the details is not exactly trivial but its contribution appears to be incremental compared to previous work in this field by Naesseth et al .",
    "NOVELTY"
  ],
  [
    "I still think there is not much novelty in the NFL theorem .",
    "NOVELTY"
  ],
  [
    "I liked",
    "NOVELTY"
  ],
  [
    "and that the authors didn\u00e2\u0080\u0099t try to oversell their ideas",
    "NOVELTY"
  ],
  [
    "I found the paper interesting and refreshing .",
    "NOVELTY"
  ],
  [
    "I think that MNIST is almost a toy experiment",
    "NOVELTY"
  ],
  [
    "I find both the proposed model and optimization algorithm interesting",
    "NOVELTY"
  ],
  [
    "From my perspective , the work is very immature and seems away from current state of the art on object detection , both in the vocabulary , performance or challenges .",
    "NOVELTY"
  ],
  [
    "This paper seems to me like an interesting and significant contribution .",
    "NOVELTY"
  ],
  [
    "CR estimators",
    "NOVELTY"
  ],
  [
    "2 .All these improvements are not very significant considering a few previous papers on this topic .",
    "NOVELTY"
  ],
  [
    "I believe that this is one of the first papers to explicitly use the Taylor approximation ( neural tangent kernel ) in a transfer learning setting , making the approach timely and potentially practically useful .",
    "NOVELTY"
  ],
  [
    "The paper proposes original and rigorous approach toward an important problem .",
    "NOVELTY"
  ],
  [
    "solution/certificate for norm-based defense , which is original as far as I know",
    "NOVELTY"
  ],
  [
    "However , there seems to be no novelty in the method , over Jonschkowki & Brock .",
    "NOVELTY"
  ],
  [
    "this paper lacks novelty and significance , as the paper implements an existing method and demonstrates results on only one simple task",
    "NOVELTY"
  ],
  [
    "this paper does not introduce any novel contributions to state representation learning for solving challenges in this domain .",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    "This paper proposes a new reweighted-RNN by unfolding a reweighted L1-L1 minimization problem .",
    "NOVELTY"
  ],
  [
    "The approach of studying generalization through the lens of Lipschitz stability over the data is interesting",
    "NOVELTY"
  ],
  [
    "Therefore , the contribution is a bit thin .",
    "NOVELTY"
  ],
  [
    "It shares the foundational concepts and notation with these articles , but proposes a novel `` fused `` approach combining the strengths of these two prior publications . While not entirely novel in its details , the combination of two approaches seems to be a successful idea and as such a promising `` step in the",
    "NOVELTY"
  ],
  [
    "In my opinion , this is one of the crucial contributions of this paper .",
    "NOVELTY"
  ],
  [
    "it is not clear how much benefit the model can get from them and the work is basically incremental",
    "NOVELTY"
  ],
  [
    "The most expected contribution of this work is barely explained",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea of using \u00e2\u0080\u009chidden\u00e2\u0080\u009d structure to improve a model and I like the idea of using the auxiliary loss function .",
    "NOVELTY"
  ],
  [
    "The method presented here is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "This is a nice problem and the proposed approach is interesting but I would tend to reject the paper",
    "NOVELTY"
  ],
  [
    "The general idea of approximating BMF with NMF is interesting and could be investigated independently and more deeply",
    "NOVELTY"
  ],
  [
    "Although the paper is definitely good",
    "NOVELTY"
  ],
  [
    "the results involving the linear threshold model are lack of novelty .",
    "NOVELTY"
  ],
  [
    "The value of the contribution is thus confined to the computational and algorithmic developments The proposed approach seems rather elegant",
    "NOVELTY"
  ],
  [
    "and is innovative on the definition of policy-adaptive submodularity .",
    "NOVELTY"
  ],
  [
    "I enjoyed reading this work and found the ideas interesting",
    "NOVELTY"
  ],
  [
    "as the task is interesting and novel",
    "NOVELTY"
  ],
  [
    "and there is a lack of novelty on the modeling side .",
    "NOVELTY"
  ],
  [
    "Interesting new application of GNNs Reasons to reject",
    "NOVELTY"
  ],
  [
    "Antisymmetric RNN",
    "NOVELTY"
  ],
  [
    "previous RNN variants that also aims at solving exploding/vanishing gradient",
    "NOVELTY"
  ],
  [
    "idea is fun , original , useful ( especially in remote sensing )",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this line of research was dated back to the paper by Jordan et al in 1998",
    "NOVELTY"
  ],
  [
    "In terms of theoretical contributions , I see that this paper contains some novel ideas in connecting gradient flow with Wasserstein distance regularization to the Fokker-Planck equation .",
    "NOVELTY"
  ],
  [
    "I am not experienced enough in this field to judge whether these contributions are significant enough for a standalone contribution",
    "NOVELTY"
  ],
  [
    "Improvements in computational efficiency",
    "NOVELTY"
  ],
  [
    "are active areas of research and this work contributes a novel approach using summary statistics .",
    "NOVELTY"
  ],
  [
    "The meta-learning formalization is an interesting and intuitive contribution .",
    "NOVELTY"
  ],
  [
    "In itself this is not very novel",
    "NOVELTY"
  ],
  [
    "it still is a novel and good technique",
    "NOVELTY"
  ],
  [
    "The highlighted phenomenon ( the convergence of a short-run MCMC while training EBMs ) seems to be novel and very interesting .",
    "NOVELTY"
  ],
  [
    ", but not particularly novel .",
    "NOVELTY"
  ],
  [
    "sampling initial states from demonstrations is a tried-and-true strategy in RL , and the manually designed curriculum is also not particularly novel . Therefore the method is mainly a minor tweak to longstanding techniques .",
    "NOVELTY"
  ],
  [
    "The novelty of the model is rather limited .",
    "NOVELTY"
  ],
  [
    "The model studied in this paper is very interesting and there has been a long line of work on posted pricing for selling items",
    "NOVELTY"
  ],
  [
    "1 .The extension of SGGMC from previous work ( SGRHMC ) [ 1 ] are in two folds .",
    "NOVELTY"
  ],
  [
    "However , unfortunately none of extensions have a clear and convincing novelty as far as I can see .",
    "NOVELTY"
  ],
  [
    "thus the contribution seems marginal .",
    "NOVELTY"
  ],
  [
    "The idea of linking affordances to 3D object generation is interesting , and relevant to the machine learning and computer vision communities .",
    "NOVELTY"
  ],
  [
    "The technical approach ( combining VAE vectors to make new shapes ) is not particularly novel",
    "NOVELTY"
  ],
  [
    "and the novel class of network models clearly of importance .",
    "NOVELTY"
  ],
  [
    "The paper describes an interesting approach to reasoning over which aspects of a given instruction have been correctly followed and which aspect to act on next",
    "NOVELTY"
  ],
  [
    "I think this is an okay paper with legitimate contribution",
    "NOVELTY"
  ],
  [
    "but perhaps not novel enough for NIPS .",
    "NOVELTY"
  ],
  [
    "The use of contraction-type arguments to bound vector norm Rademacher complexities is interesting .",
    "NOVELTY"
  ],
  [
    "The community was already moved from MFCC to log mel filterbank",
    "NOVELTY"
  ],
  [
    "there is no doubt of its originality and quality",
    "NOVELTY"
  ],
  [
    "but study of inference dynamics for the SBM appears novel .",
    "NOVELTY"
  ],
  [
    "There is no significant theoretical innovation in this paper .",
    "NOVELTY"
  ],
  [
    "I remain of the opinion that this is a nice contribution",
    "NOVELTY"
  ],
  [
    "I find the relationship to the prior works partly unclear",
    "NOVELTY"
  ],
  [
    "The proposed auto-encoder scheme is very similar to a host of other auto-encoders that have been out in the literature for some time .",
    "NOVELTY"
  ],
  [
    "it certainly seems like an empirically unproven and incremental improvement to an old idea .",
    "NOVELTY"
  ],
  [
    "and brings up an interesting first theoretical result regarding speed of posterior concentration for Bayesian regression histograms",
    "NOVELTY"
  ],
  [
    "The idea is interesting and",
    "NOVELTY"
  ],
  [
    "up to my knowledge this method seems to be the first of its kind based on a fully end-to-end trainable method where the motion estimators , the decomposition and the motion decoders are learned jointly .",
    "NOVELTY"
  ],
  [
    "These are new",
    "NOVELTY"
  ],
  [
    "The distillation approach and curricula are novel .",
    "NOVELTY"
  ],
  [
    "While this is a straightforward and expected extension , I think this is a nice contribution .",
    "NOVELTY"
  ],
  [
    "The technical novelty is somewhat limited .",
    "NOVELTY"
  ],
  [
    "This paper is not a breakthrough paper",
    "NOVELTY"
  ],
  [
    "it still contains some novelty inside",
    "NOVELTY"
  ],
  [
    "the oob idea is nice .",
    "NOVELTY"
  ],
  [
    "The results are interesting and novel .",
    "NOVELTY"
  ],
  [
    "The results are sufficiently novel and",
    "NOVELTY"
  ],
  [
    "The results and proof techniques are sufficiently novel and",
    "NOVELTY"
  ],
  [
    "It seems as if the improvement over the PL baseline ( pseudo labels ) is incremental ?",
    "NOVELTY"
  ],
  [
    "novel solution to an existing challenge of RNNs based on already known techniques with the goal of improving interpretability and expressivity of the machine learning model",
    "NOVELTY"
  ],
  [
    "The experimental setting is very non-trivial and novel .",
    "NOVELTY"
  ],
  [
    "The technique complements the PSI-based independence testing approach recently proposed by Yamada et al. , 2018 .The submission is a well-organized , clearly written , nice contribution",
    "NOVELTY"
  ],
  [
    "but the novelty is limited .",
    "NOVELTY"
  ],
  [
    "It has some novelty , but the novelty is incremental .",
    "NOVELTY"
  ],
  [
    "the novelty is limited . This paper only simply combines two well-known approach BP and DFA together .",
    "NOVELTY"
  ],
  [
    "The combination is new and the result is encouraging . I find this paper is interesting",
    "NOVELTY"
  ],
  [
    "I like the idea the paper is exploring .",
    "NOVELTY"
  ],
  [
    "The idea of online distillation is not new",
    "NOVELTY"
  ],
  [
    ", but the proposal to share layers when co-distilling base networks is interesting and to the best of my knowledge original .",
    "NOVELTY"
  ],
  [
    "Overall , I found the ideas presented in this paper interesting and novel ,",
    "NOVELTY"
  ],
  [
    "Though the contributions are not groundbreaking",
    "NOVELTY"
  ],
  [
    "This paper is incremental in nature , with a natural generalization of ( Tschannen et al . ( 2018 ) ) .",
    "NOVELTY"
  ],
  [
    "Overall , I think the contribution of this paper is significant .",
    "NOVELTY"
  ],
  [
    "Overall , I think the contribution of this paper is significant .",
    "NOVELTY"
  ],
  [
    "I am not sure its usage can be claimed as a significant contribution .",
    "NOVELTY"
  ],
  [
    "The idea of embedding the evaluation of loss functions into matrices is interesting .",
    "NOVELTY"
  ],
  [
    "This is a very interesting idea",
    "NOVELTY"
  ],
  [
    "The proposed deep kernel learning model and inference procedure are novel .",
    "NOVELTY"
  ],
  [
    "-the novelty of the proof technique seems to be incremental ; it seems to be a combination of the results in",
    "NOVELTY"
  ],
  [
    "for linear convergence of linear inverse problems with nonconvex regularization .",
    "NOVELTY"
  ],
  [
    "While I am not aware of any prior work on learning physical derivatives , the actual methods used are not novel in of themselves beyond being applied towards learning derivatives with respect to the policy .",
    "NOVELTY"
  ],
  [
    "Since word order might change across languages the idea of using position based supervision seems promising .",
    "NOVELTY"
  ],
  [
    "and to the best of my knowledge contains relatively novel results , and therefore suitable for publication",
    "NOVELTY"
  ],
  [
    "My one concern is that in my opinion the technicality of the paper is above the expected level for NIPS .",
    "NOVELTY"
  ],
  [
    "Overall , the notion of finding the minimal distortion attacker as opposed to finding the best attacker inside a fixed distortion ball is quite interesting to me .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "I find the approach proposed in the paper interesting",
    "NOVELTY"
  ],
  [
    "but a little bit thin in content .",
    "NOVELTY"
  ],
  [
    "The idea has some novelty",
    "NOVELTY"
  ],
  [
    "overall the paper is a nice contribution to dialogue and QA system research by pointing out a simple way of handling named entities by dynamically updating their embeddings .",
    "NOVELTY"
  ],
  [
    "The paper augments an existing method with a well understood attention mechanism , so the novelty of the approach is relatively low",
    "NOVELTY"
  ],
  [
    "The introduction of the meta learning paradigm and its use to learn the RPN and classification networks are incremental in novelty but",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "While the idea of modeling exchangeability for block-structure is not new in itself",
    "NOVELTY"
  ],
  [
    ", the perspective the authors follow seems novel because they extend Kallenberg exchangeability to model block-structure",
    "NOVELTY"
  ],
  [
    "This is to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "Without demonstrating any practical advance , this work becomes simply another one of the multitude of V/W-AE-variants that already exist .",
    "NOVELTY"
  ],
  [
    "I think the advances in this paper are both original and significant .",
    "NOVELTY"
  ],
  [
    "The main drawback of the paper is that it is essentially a longer technical project that has been shoehorned into a 10-page paper",
    "NOVELTY"
  ],
  [
    "these are great ideas",
    "NOVELTY"
  ],
  [
    "very",
    "NOVELTY"
  ],
  [
    "The method proposed in the paper seems original to my knowledge .",
    "NOVELTY"
  ],
  [
    "Brings in nice intuition from forward feature selection",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the",
    "NOVELTY"
  ],
  [
    "afaik original .",
    "NOVELTY"
  ],
  [
    "The concept underlying the paper is interesting , and leverages on very recent advances in the field . The idea of learning the dynamics required to evolve segmentation contours is original and certainly appealing .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is clearly written and seems to provide new interesting results for this problem .",
    "NOVELTY"
  ],
  [
    "effort in the paper is appreciated",
    "NOVELTY"
  ],
  [
    "but the novelty is lacking .",
    "NOVELTY"
  ],
  [
    "Overall , the novelty is limited .",
    "NOVELTY"
  ],
  [
    "The paper introduces a very simple modification to existing algorithms with surprisingly",
    "NOVELTY"
  ],
  [
    "the simplicity of the method quite appealing",
    "NOVELTY"
  ],
  [
    "I found the results interesting and I like the fact that the achieved bounds are actually the minimum of the new regularity and the one used before",
    "NOVELTY"
  ],
  [
    "The idea to use a language model and hence a non-binary discriminator is very nice , and is novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "The proposed idea is not exceptional original",
    "NOVELTY"
  ],
  [
    "Their analysis technique is novel but the paper seems to be `` nearly the same `` as another submission",
    "NOVELTY"
  ],
  [
    "I believe that the interlacing greedy method is the most novel contribution and the thresholding technique is also a very nice addition which allows for the nearly linear run time .",
    "NOVELTY"
  ],
  [
    "1 .This paper does not present any novel methods ,",
    "NOVELTY"
  ],
  [
    "but the novelty of the architecture itself is limited .",
    "NOVELTY"
  ],
  [
    "While previous work has performed adversarial attacks against ASR systems and incorporated robustness to reverberation into it , this appears to be the first to work against a commercial system over the air .",
    "NOVELTY"
  ],
  [
    "The idea presented here appears too simplistic relative to the existing ones .",
    "NOVELTY"
  ],
  [
    "The GSNR is promising as a measure of",
    "NOVELTY"
  ],
  [
    "Overall the paper gives a fresh ( as far as I know ) and nice idea on generalization of neural networks .",
    "NOVELTY"
  ],
  [
    "I like the idea presented in the paper and encourage the authors to resubmit a more tidy draft",
    "NOVELTY"
  ],
  [
    "as I think the authors bring a fresh ( as far as I know ) and interesting idea with regards to empirical generalization",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper makes a novel contribution which would be of interest to the wider community even though some more work on addressing the shortcomings of the presented approach would make for an even stronger submission",
    "NOVELTY"
  ],
  [
    "there lacks some insightful analysis of the proposed approach ,",
    "NOVELTY"
  ],
  [
    "good originality : nice significance",
    "NOVELTY"
  ],
  [
    "The idea behind the paper is quite interesting and enticing .",
    "NOVELTY"
  ],
  [
    "to be biologically innovative",
    "NOVELTY"
  ],
  [
    "I find the idea interesting",
    "NOVELTY"
  ],
  [
    "as far as I can understand this paper advances the work of [ 4 ] by introducing conditonal GPMs , and implementing them in Venturescript",
    "NOVELTY"
  ],
  [
    "it \u2019 s not clear how novel the retrieval model is",
    "NOVELTY"
  ],
  [
    "but the use seems remarkably similar to (",
    "NOVELTY"
  ],
  [
    "The residual adapters modules and their motivation",
    "NOVELTY"
  ],
  [
    "seem fairly related to the MTZ approach",
    "NOVELTY"
  ],
  [
    "it is difficult to understand the contributions",
    "NOVELTY"
  ],
  [
    "The method is quite original ,",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting technique",
    "NOVELTY"
  ],
  [
    "Second concern is limited novelty (",
    "NOVELTY"
  ],
  [
    "I understood ) .",
    "NOVELTY"
  ],
  [
    "the methods is very simple ( combining multiple segment prediction to perform document classifications ) making the contribution of this paper quite weak",
    "NOVELTY"
  ],
  [
    "The relative novelty over VEEGAN is also limited",
    "NOVELTY"
  ],
  [
    "and I believe it would be an excellent addition to the NIPS program .",
    "NOVELTY"
  ],
  [
    "and this paper is an exciting contribution to it",
    "NOVELTY"
  ],
  [
    "it seems to me that combining momentum with an existing algorithm is not extremely novel -- I would defer to reviewers who are experts in the optimization area to fully assess the novelty and technical difficulty of the proposed solution",
    "NOVELTY"
  ],
  [
    "The approach is novel as far as I can tell",
    "NOVELTY"
  ],
  [
    "but it seems like a useful , novel method of analyzing perceptual discrimination tasks",
    "NOVELTY"
  ],
  [
    "The paper 's idea of the benchmarking salience methods on retrained models is simple , original , and clever .",
    "NOVELTY"
  ],
  [
    "The amount of novelty in the paper is limited as this paper is far from the first to consider a mix of recurrent neural networks and generation .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , numerous methods ( i.e. , targeting on applications ) address this problem by augmenting A [ 1 ] or X [ 2 ] with similarity of feature representation learned from other sources .",
    "NOVELTY"
  ],
  [
    "I consider this work is generally novel .",
    "NOVELTY"
  ],
  [
    "also unique since different with CNNs where data are independent , the data instance within GNNs are highly correlated",
    "NOVELTY"
  ],
  [
    "The feature replay algorithm has good novelty .",
    "NOVELTY"
  ],
  [
    "I like the idea",
    "NOVELTY"
  ],
  [
    "To sum up , this paper introduce interesting results .",
    "NOVELTY"
  ],
  [
    "The contributions of the paper seem very limited .",
    "NOVELTY"
  ],
  [
    "I believe this paper is limited in its contribution and also has major",
    "NOVELTY"
  ],
  [
    "The algorithm is n't super novel ,",
    "NOVELTY"
  ],
  [
    "though the efficient implementation is , as far as I know , new",
    "NOVELTY"
  ],
  [
    "Overall , the introduced method is interesting and novel",
    "NOVELTY"
  ],
  [
    "it is not sufficiently explained how the presented approach differs from existing methods",
    "NOVELTY"
  ],
  [
    "The results presented in Table 3 are interesting but the presented approach only marginally improve upon existing work or not at all",
    "NOVELTY"
  ],
  [
    "The authors have come up with an interesting novel strategy of embracing what was seen as undesired property ( non-convergent etc MCMC ) , and built a complete and interesting work exploring the results of said strategy .",
    "NOVELTY"
  ],
  [
    "Therefore , I am not sure about the technical contribution of this paper to the area .",
    "NOVELTY"
  ],
  [
    "I have not learned anything new by reading this work",
    "NOVELTY"
  ],
  [
    "Neither the method nor the results are novel contributions to the study of GANs .",
    "NOVELTY"
  ],
  [
    "The idea of measuring invariance , equivariance and equivalence of representations is not new",
    "NOVELTY"
  ],
  [
    "1 .Novelty Applying variational dropout for model compression is not a new idea . As this paper only combines variational dropout and distributed training , I think the novelty is a little thin .",
    "NOVELTY"
  ],
  [
    "there is a significant lack of novelty from a machine learning perspective .",
    "NOVELTY"
  ],
  [
    "3 .In terms of practical applications , to the best of my knowledge there are sophisticated physics-based and graphics based approaches that perform very fast fluid simulations .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "The theory/methodology contribution is limited .",
    "NOVELTY"
  ],
  [
    "I think the proposed initialization is very interesting",
    "NOVELTY"
  ],
  [
    "This algorithm is nice .",
    "NOVELTY"
  ],
  [
    "The realted work is already comprehensive",
    "NOVELTY"
  ],
  [
    "the idea is not brand new .",
    "NOVELTY"
  ],
  [
    "the formulation is very similar to ``",
    "NOVELTY"
  ],
  [
    "In terms of causal inference , the paper is highly original ,",
    "NOVELTY"
  ],
  [
    "I do n't think the model itself is wholly original .",
    "NOVELTY"
  ],
  [
    "The main algorithm itself can not be considered to be novel .",
    "NOVELTY"
  ],
  [
    "Proposed an RL formulation of a unified framework for static and dynamic channel pruning .",
    "NOVELTY"
  ],
  [
    "getting the implementation of that idea right is far from trivial",
    "NOVELTY"
  ],
  [
    "In this context it hard to pinpoint the main innovation of the manuscript .",
    "NOVELTY"
  ],
  [
    "The presentation of the model is mixing existing ideas with details that are original to the present paper .",
    "NOVELTY"
  ],
  [
    "The paper is describes a very nice new method and",
    "NOVELTY"
  ],
  [
    "limits somewhat the originality and significance of the work",
    "NOVELTY"
  ],
  [
    "But I do not consider the theoretical contribution groundbreaking",
    "NOVELTY"
  ],
  [
    "Nicely motivates the approach of separating foreground and background + Fewer landmarks are needed than in previous work",
    "NOVELTY"
  ],
  [
    "The changes and improvements feel somewhat incremental",
    "NOVELTY"
  ],
  [
    "this is the first one based on a variational autoencoder",
    "NOVELTY"
  ],
  [
    "The way in which they address the problem of being insensitive to the ordering in which the graph is generated (",
    "NOVELTY"
  ],
  [
    "is novel .",
    "NOVELTY"
  ],
  [
    "The proposed model includes significant novel contributions as mentioned above",
    "NOVELTY"
  ],
  [
    "paper is interesting with some theory that is lacking for LISTA",
    "NOVELTY"
  ],
  [
    "The main idea from this paper is simple and intuitive .",
    "NOVELTY"
  ],
  [
    "While the overall contribution of this work appears rather narrow",
    "NOVELTY"
  ],
  [
    "the idea is intuitive",
    "NOVELTY"
  ],
  [
    "Leveraging spatial distortions ( or other visually meaningful transformations ) to generate adversarial attacks is not a new idea",
    "NOVELTY"
  ],
  [
    "Using GAN-like transformation models to generate attacks is also not a new idea .",
    "NOVELTY"
  ],
  [
    "So as such , the conceptual novelty of the contribution seems to be low",
    "NOVELTY"
  ],
  [
    "Overall , the idea of using Lanczos algorithm to bypass the computation of the eigendecomposition , and thus simplify filtering operations in graph signal processing is not new [",
    "NOVELTY"
  ],
  [
    ".However",
    "NOVELTY"
  ],
  [
    ", using this algorithm in the framework of graph convents is new , and certainly interesting",
    "NOVELTY"
  ],
  [
    ", and the analogy with manifold learning are",
    "NOVELTY"
  ],
  [
    "I believe that this paper has made a novel contribution .",
    "NOVELTY"
  ],
  [
    "1 .The problem that this paper addresses seems to be new and interesting .",
    "NOVELTY"
  ],
  [
    "I really like the work on semantic segmentation , I",
    "NOVELTY"
  ],
  [
    "The authors present the semantic loss as novel",
    "NOVELTY"
  ],
  [
    "The paper also introduces some interesting concepts like a partial permutation invariant set function .",
    "NOVELTY"
  ],
  [
    "we propose a novel graph node embedding method ( namely P2IR ) via developing a novel notion , namely partial permutation invariant set function",
    "NOVELTY"
  ],
  [
    "is also interesting and clever",
    "NOVELTY"
  ],
  [
    "I still feel the central idea of the work is quite strong .",
    "NOVELTY"
  ],
  [
    "heuristic",
    "NOVELTY"
  ],
  [
    "Still , the approach is original",
    "NOVELTY"
  ],
  [
    "as far as I am aware the approach itself is novel",
    "NOVELTY"
  ],
  [
    "Although the use of affect lexica is innovative , the idea of extending the training objective function with lexica information is not new .",
    "NOVELTY"
  ],
  [
    "this paper provides convergence rates , which seem to be the first work of this kind for non-linear models .",
    "NOVELTY"
  ],
  [
    "In my opinion , the contributions in both theoretical techniques and algorithmic ideas of the paper are quite minimal .",
    "NOVELTY"
  ],
  [
    "As far as I know , this is a novel way of analyzing multi-pathway architectures ,",
    "NOVELTY"
  ],
  [
    "The extension the authors propose is a natural one and give the long history of block modeling one worth pursing",
    "NOVELTY"
  ],
  [
    "the RDP analysis and modified acceptance test is a novel contribution .",
    "NOVELTY"
  ],
  [
    "After RecoverKL and the spectral algorithm , this paper brings a very novel and useful perspective into the topic inference problem for LDA , without apparently making strong assumptions about topics ,",
    "NOVELTY"
  ],
  [
    "Aspects of this work were known before",
    "NOVELTY"
  ],
  [
    "the novel aspect of this paper is that it has used these connections to propose an inference algorithm for LDA completely based on the geometry of the topic and word simplexes",
    "NOVELTY"
  ],
  [
    "It is also a fairly simple metric",
    "NOVELTY"
  ],
  [
    ", but nonetheless represents a novel contribution",
    "NOVELTY"
  ],
  [
    "Overall- The use of VQ to work with discrete latent variables in VAEs is a novel contribution .",
    "NOVELTY"
  ],
  [
    "The paper is overselling its contributions .",
    "NOVELTY"
  ],
  [
    "Although the novelty of the method is not impressive",
    "NOVELTY"
  ],
  [
    "My main concern with this paper is regarding the novelty",
    "NOVELTY"
  ],
  [
    "The authors seem to claim a novel GAN architecture by using an auto-encoder-based network architecture with a pre-trained face recognition network and multi-image perceptual loss",
    "NOVELTY"
  ],
  [
    "and while a somewhat natural extension , it is still novel and justified .",
    "NOVELTY"
  ],
  [
    "but the approaches which they compare with are not very new to me",
    "NOVELTY"
  ],
  [
    "In general , the model is contrived and the novelty of the paper is incremental .",
    "NOVELTY"
  ],
  [
    "the model is just an trivial extension of VAE and all key techniques are borrowed from existing work",
    "NOVELTY"
  ],
  [
    "is by far not the first paper aimed at answering this question , but it makes important innovations to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "This seems like an obvious idea but to the best of my knowledge it has n't been done before and is actually a potentially very useful model .",
    "NOVELTY"
  ],
  [
    "but it seems that extension of VAE to multiple views is a very interesting idea",
    "NOVELTY"
  ],
  [
    "Although BPTI has been applied in many previous works , the present work is novel principally in that it applies to a",
    "NOVELTY"
  ],
  [
    "general class of energy-based models over continuous-valued states , whereas previous works either applied only to",
    "NOVELTY"
  ],
  [
    "discrete problems , or more restricted classes of continuous problems",
    "NOVELTY"
  ],
  [
    "this would be novel to anyone who is not a specialist in both those fields .",
    "NOVELTY"
  ],
  [
    "but there are no fundamentally new methods here",
    "NOVELTY"
  ],
  [
    "Although no fundamentally new methods are developed here , this work constitutes a clever way to combine state-of-the-art techniques from different fields ( high-dimensional convex optimization and deep learning ) .",
    "NOVELTY"
  ],
  [
    "the proposed sampling scheme enables learning BNNs of complex forms and seems novel .",
    "NOVELTY"
  ],
  [
    "I liked the idea of a two-stage process in order to incorporate contextual knowledge and being more efficiently in the selection .",
    "NOVELTY"
  ],
  [
    "This paper has the feature of being one of the first ( arguably the first ) to address the problem of sparse isotonic regression",
    "NOVELTY"
  ],
  [
    "The convex relaxation is novel , especially in dealing with the quadratic constraints .",
    "NOVELTY"
  ],
  [
    "Overall , there convex relaxation and the analysis are interesting , despite the precursors that are very relevant",
    "NOVELTY"
  ],
  [
    "this was a clear paper that presented an interesting idea of combining multiple scales and types of noise to stabilize",
    "NOVELTY"
  ],
  [
    "Interesting idea of combining multiple noise types along with learned noise",
    "NOVELTY"
  ],
  [
    "Consequently , there is not a great degree of novelty in terms of the proposed method , and the results are only",
    "NOVELTY"
  ],
  [
    "I think the paper is interesting and proposes a novel idea",
    "NOVELTY"
  ],
  [
    "No significant contribution .",
    "NOVELTY"
  ],
  [
    "for all this work the improvements seem a little weak .",
    "NOVELTY"
  ],
  [
    "but the novelty is a bit limited since it is an incremental work beyond EFE .",
    "NOVELTY"
  ],
  [
    "Overall , the novelty in this paper is limited and",
    "NOVELTY"
  ],
  [
    "Maximum entropy methods have become popular in RL , so the idea of using them with MCTS is promising .",
    "NOVELTY"
  ],
  [
    "but the approach is novel",
    "NOVELTY"
  ],
  [
    "Originality The derivation of the information dropout optimization problem using IB Lagrangian is novel .",
    "NOVELTY"
  ],
  [
    "to be limited",
    "NOVELTY"
  ],
  [
    "There are some stylistic shortcomings as well",
    "NOVELTY"
  ],
  [
    "I feel that the paper has enough originality and significance .",
    "NOVELTY"
  ],
  [
    "and the proposed method is elegant , intuitive , novel ( to the best of my knowledge ) , seemingly well motivated , and widely",
    "NOVELTY"
  ],
  [
    "As far as I can tell , the approach is quite original and the results proved are new .",
    "NOVELTY"
  ],
  [
    "The method provides a new way to learn discriminative features",
    "NOVELTY"
  ],
  [
    "underlying intuition is brilliant",
    "NOVELTY"
  ],
  [
    "The proposed QHM looks quite similar to a special case of Aggregated Momentum",
    "NOVELTY"
  ],
  [
    "I am not sure that the QHAdam algorithm adds much to the paper .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the paper presents original findings and places itself well amongst existing work .",
    "NOVELTY"
  ],
  [
    "Good topic with a few interesting observations",
    "NOVELTY"
  ],
  [
    "Although I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "Its contents are n't particularly novel in terms of ideas",
    "NOVELTY"
  ],
  [
    "Overall , I think the idea of the proposed method is interesting .",
    "NOVELTY"
  ],
  [
    "The application of object detection techniques to extreme weather event detection problem is unique , to my knowledge .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is well-written and applies some interesting underutilized techniques to a relatively unique domain .",
    "NOVELTY"
  ],
  [
    "is directly from previous works , I doubt if the contribution",
    "NOVELTY"
  ],
  [
    "The idea of using meta-objectives to learn unsupervised representation learning is a very interesting idea .",
    "NOVELTY"
  ],
  [
    "brings new ideas and perfoms interesting experiments",
    "NOVELTY"
  ],
  [
    "The contributions in your appendix are interesting .",
    "NOVELTY"
  ],
  [
    "Appendix B and C are not extremely novel in my mind",
    "NOVELTY"
  ],
  [
    "but the contribution is limited",
    "NOVELTY"
  ],
  [
    "The contributions in this paper do not seem too significant .",
    "NOVELTY"
  ],
  [
    "Both findings do not seem quite new .",
    "NOVELTY"
  ],
  [
    "The second conclusion is also not quite new and there were several approaches to overcome it e.g .SWA",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the findings are not quite new .",
    "NOVELTY"
  ],
  [
    "written with an ok level of originality and significance .",
    "NOVELTY"
  ],
  [
    "Somewhat incremental relative to the papers mentioned above .",
    "NOVELTY"
  ],
  [
    "The paper deals with a very interesting problem by proposing a novel solution involving graph theory",
    "NOVELTY"
  ],
  [
    "Although no ingredient in the proposed pipeline is new",
    "NOVELTY"
  ],
  [
    "their combination is indeed clever",
    "NOVELTY"
  ],
  [
    "This work is not the first to explore a deep learning approach to automatic code completion",
    "NOVELTY"
  ],
  [
    "Lossy image compression using neural networks is a rapidly advancing field and of considerable interest to the ICLR community . I like the approach of using a hierarchical entropy model , which may inspire further work in this direction .",
    "NOVELTY"
  ],
  [
    "Overall , it is an interesting paper that reuses a few good ideas to develop a novel training objective .",
    "NOVELTY"
  ],
  [
    "'s model improves over previous neural models for answer sentence selection",
    "NOVELTY"
  ],
  [
    "It was hard for me to determine the novelty of the contribution .",
    "NOVELTY"
  ],
  [
    "Instead , the model appears to be very similar to the QA-LSTM of Tan et al. , 2015 except that there are additional terms in the objective to handle conclusion and supplementary sentences",
    "NOVELTY"
  ],
  [
    ", the technical contributions do not strike me as novel enough for publication at ICLR .",
    "NOVELTY"
  ],
  [
    "The conceptual contribution therefore seems incremental .",
    "NOVELTY"
  ],
  [
    "The work seems to be an incremental extension of Yu & Huang ( 2019b ) and phrased as a NAS algorithm .",
    "NOVELTY"
  ],
  [
    "paper is good , and is a solid contribution to the literature on approximate Newton methods .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge there is no prior work looking deep into this area and this paper does bring new insights to the community .",
    "NOVELTY"
  ],
  [
    "-some new coefficients are identified and testable constraints produced -contribution seems incremental to already established results",
    "NOVELTY"
  ],
  [
    "In my opinion the paper makes a good contribution and I see no problems",
    "NOVELTY"
  ],
  [
    "The experiments seem very similar to Wu et al .2018 , which is considered to be prior work under the ICLR guidelines",
    "NOVELTY"
  ],
  [
    "given that the proposed algorithms seem incremental compared to the existing algorithms",
    "NOVELTY"
  ],
  [
    "The paper is therefore not very original and methodologically novel",
    "NOVELTY"
  ],
  [
    "overall .",
    "NOVELTY"
  ],
  [
    "The only real methodological contribution",
    "NOVELTY"
  ],
  [
    "The whole methodological contribution and novelty are quite thin . Despite its low novelty",
    "NOVELTY"
  ],
  [
    "and the novelty of the paper remains limited ( as it heavily relies on prior work , i.e. , BERT ) .",
    "NOVELTY"
  ],
  [
    "the key contributions of this paper are mainly based on [ 17 ]",
    "NOVELTY"
  ],
  [
    "The problem setting of this paper is interesting and the theoretical contribution is nice",
    "NOVELTY"
  ],
  [
    "fairly straightforward and builds off of previous techniques introduced in e.g .SPAIR .The lack of demonstrating usefulness on a downstream application limits this paper 's significance",
    "NOVELTY"
  ],
  [
    "I find the main contribution of the paper very interesting .",
    "NOVELTY"
  ],
  [
    "I quite liked the central idea of the paper , and demonstrating that for stochastic block models",
    "NOVELTY"
  ],
  [
    "This notion of allowing mixing weights on the learner is a change from previous work .",
    "NOVELTY"
  ],
  [
    "I feel the main contributions of the paper are theoretical",
    "NOVELTY"
  ],
  [
    "and makes valuable contributions",
    "NOVELTY"
  ],
  [
    "It is a novel idea to couple together two linear systems of half size compared to the two previous approaches .",
    "NOVELTY"
  ],
  [
    "The novelty is the application of tree-based reparametrization in the context of PPC.Overall",
    "NOVELTY"
  ],
  [
    "The idea of using multiple time scales in loopy belief propagation to counteract overcounting is nice",
    "NOVELTY"
  ],
  [
    "weight-sharing and pruning are not new to neural network compression .",
    "NOVELTY"
  ],
  [
    "However the contributions are interesting and significant .",
    "NOVELTY"
  ],
  [
    "The main idea of this paper is really interesting ,",
    "NOVELTY"
  ],
  [
    "while I think the main idea is relatively clear",
    "NOVELTY"
  ],
  [
    "A potential weakness is that some of the main results come across as rather simple combinations of existing ideas/results",
    "NOVELTY"
  ],
  [
    "with the main limitation probably being the level of novelty",
    "NOVELTY"
  ],
  [
    "While this paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "The characterization of optimal policy and bounds on the value functions are new .",
    "NOVELTY"
  ],
  [
    "Although some techniques are analogous to previous work ( which is not bad per se",
    "NOVELTY"
  ],
  [
    "this work differs significantly from previous work",
    "NOVELTY"
  ],
  [
    "and yields new insights how to obtain sparse policies or not",
    "NOVELTY"
  ],
  [
    "and I feel that others can build upon and benefit from the ideas presented therein",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting",
    "NOVELTY"
  ],
  [
    "The idea in this paper is novel",
    "NOVELTY"
  ],
  [
    "but experiments do not seem to be enough .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is nice , while the high-level picture is relatively",
    "NOVELTY"
  ],
  [
    "The method is original , and the key idea behind the stable basis for trembling equilibrium seem to be novel",
    "NOVELTY"
  ],
  [
    "The marginal technical contributions are not especially deep",
    "NOVELTY"
  ],
  [
    "Though the original KERMIT approach is very interesting",
    "NOVELTY"
  ],
  [
    "This seems like a non-trivial extension to the previous work of ( Linderman et al. , 2017 )",
    "NOVELTY"
  ],
  [
    "I tend to consider this a novel contribution",
    "NOVELTY"
  ],
  [
    "the method is very novel and creative , some of the best ML papers I recently read .",
    "NOVELTY"
  ],
  [
    "My first concern about this work is its novelty .",
    "NOVELTY"
  ],
  [
    "The contributions are interesting",
    "NOVELTY"
  ],
  [
    "Nevertheless , the technical novelty seems a bit weak to me .",
    "NOVELTY"
  ],
  [
    "That by itself is a substantial contribution",
    "NOVELTY"
  ],
  [
    "Originality The problem , i.e. , policy evaluation in presence of unobserved confounders , is not quite new and there exist a great deal of previous works on this topic",
    "NOVELTY"
  ],
  [
    "The main strengths of the paper are",
    "NOVELTY"
  ],
  [
    "Seemingly new idea how to use random walks to derive graph kernels .",
    "NOVELTY"
  ],
  [
    "Simply summing up the running time over all data sets is not very insightful .",
    "NOVELTY"
  ],
  [
    "while there are some concerns and the contributions are not entirely novel",
    "NOVELTY"
  ],
  [
    "This work contains some original ideas . The major step of a noisy threshold seems somewhat familiar but it\u00e2\u0080\u0099s application in this setting is , to my knowledge , new .",
    "NOVELTY"
  ],
  [
    "Although it is not an original result",
    "NOVELTY"
  ],
  [
    "I do like this idea .",
    "NOVELTY"
  ],
  [
    "The paper makes an interesting contribution .",
    "NOVELTY"
  ],
  [
    "The decomposition of orthogonally decoupled basis and residual of the mean and covariance parameterization is entirely novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "I think that the contribution of this paper is still significant .",
    "NOVELTY"
  ],
  [
    "I like the originality of the work , as the authors propose the principle of a growing machine , that is able to yield a functional architecture from a limited set of rules .",
    "NOVELTY"
  ],
  [
    "This approach is highly original and clearly exposed .",
    "NOVELTY"
  ],
  [
    "With regards to the motivation : It is not clear what substantive technical novelty there is in the idea of \u201c adding fake nodes \u201d , compared to existing approaches that simply modify existing nodes in an adversarial way .",
    "NOVELTY"
  ],
  [
    "While I think that the core idea of the paper is original and has some interest",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper is , that the novelty seems marginal .",
    "NOVELTY"
  ],
  [
    "even if we call it a minor modification , we would have very little novelty in the approach",
    "NOVELTY"
  ],
  [
    "I think that the contribution is too minor",
    "NOVELTY"
  ],
  [
    "The utility of solid harmonic wavelets to achieve transformation invariance seems like a novel contribution to this application ( e.g .molecular energy regression ) .",
    "NOVELTY"
  ],
  [
    "The contribution to the molecular energy prediction seems interesting and novel",
    "NOVELTY"
  ],
  [
    "the contributions of this paper are not clearly explained .",
    "NOVELTY"
  ],
  [
    "This approach is appealing both for its generality and its computational simplicity",
    "NOVELTY"
  ],
  [
    "In general , the multidimensional action methods either seem incremental or non novel to me .",
    "NOVELTY"
  ],
  [
    "and the smoothed entropy technique is as far as I know , novel",
    "NOVELTY"
  ],
  [
    "The technical novelty is limited .",
    "NOVELTY"
  ],
  [
    "The application of the Frank-Wolfe algorithm is not particularly novel , given the large set of related work that the paper cites",
    "NOVELTY"
  ],
  [
    "I found this move interesting and novel",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel and interesting task that learn to retarget human actions with few-shot samples .",
    "NOVELTY"
  ],
  [
    "Though the proposed problem is novel and somewhat interesting",
    "NOVELTY"
  ],
  [
    "The novelty of methodology is somewhat limited .",
    "NOVELTY"
  ],
  [
    "the overall contribution is not significant .",
    "NOVELTY"
  ],
  [
    "The theoretical results and the algorithm are new , and it 's clear how they are",
    "NOVELTY"
  ],
  [
    "I think the idea of the paper is novel and inspiring .",
    "NOVELTY"
  ],
  [
    "The idea of learning \\alpha-coverings is nice , and to the best of my knowledge , new .",
    "NOVELTY"
  ],
  [
    "The idea of using GAN for active query synthesis isn \u2019 t new .",
    "NOVELTY"
  ],
  [
    "So the novelty of the paper isn \u2019 t significant .",
    "NOVELTY"
  ],
  [
    "The idea seems slightly novel , simple , and elegant ,",
    "NOVELTY"
  ],
  [
    "the construction of the adversarial objective and attacks seems novel .",
    "NOVELTY"
  ],
  [
    "The presented algorithmic techniques are somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The work proposes an interesting approach : first cluster the network , then learning distinct GANs over each cluster .",
    "NOVELTY"
  ],
  [
    "There is no contribution in the GAN / neural network aspect .",
    "NOVELTY"
  ],
  [
    "The contribution for ICLR is rather minimal , unfortunately .",
    "NOVELTY"
  ],
  [
    "The approach taken in proving this result based on a variance reduction method that estimates the difference of gradients in the non-oblivious stochastic setting is novel . The ideas developed in Section 4 are very interesting and useful .",
    "NOVELTY"
  ],
  [
    "The datasets used in the experiments are quite old .",
    "NOVELTY"
  ],
  [
    "from the NIPS community",
    "NOVELTY"
  ],
  [
    "The approach is not particularly novel ; it is mostly a case of applying a range of existing neural network components to the premise selection problem",
    "NOVELTY"
  ],
  [
    "The improvements achieved over a k-NN baseline are small",
    "NOVELTY"
  ],
  [
    "I raise my score since I think the paper is interesting",
    "NOVELTY"
  ],
  [
    "To my best knowledge , this is the first mapping of LSTMs to spiking networks 2 .",
    "NOVELTY"
  ],
  [
    "Although the results appear to be promising the overall structure of the paper and the method presented are based upon established techniques , therefore the technical contribution is rather limited .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems novel",
    "NOVELTY"
  ],
  [
    "The problem setting and the contributions listed earlier are novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The setting of a manipulative attacker featured here is ( to the best of my knowledge ) fairly novel .",
    "NOVELTY"
  ],
  [
    "and somewhat new though not revolutionary",
    "NOVELTY"
  ],
  [
    "but it 's not really a new thing",
    "NOVELTY"
  ],
  [
    "The method per se is not novel ,",
    "NOVELTY"
  ],
  [
    "but the combination of method and application is",
    "NOVELTY"
  ],
  [
    "It seems to be a novel approach to optimize drawing actions .",
    "NOVELTY"
  ],
  [
    "Using the differentiable `` canvas `` networks to avoid non-differentiable `` renderer `` is a novel approach as far as I know .",
    "NOVELTY"
  ],
  [
    "Compared with existing work [ 8 ] , the contribution of this work is incremental .",
    "NOVELTY"
  ],
  [
    "Compared with u-AGD [ 8 ]",
    "NOVELTY"
  ],
  [
    "he proposed algorithm does not show clear difference and improvement in terms of empirical performance",
    "NOVELTY"
  ],
  [
    "This work is a novel combination of established techniques , such as word embedding and adversarial training . The unsupervised method to compute speech embedding is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "Though the contribution seems to be incremental , it is a reasonable improvement upon Matching Networks and Prototypical Networks .",
    "NOVELTY"
  ],
  [
    "I am concerned about the originality of the proposed model .",
    "NOVELTY"
  ],
  [
    "Using k-nearest neighbors for memory access is not completely new .",
    "NOVELTY"
  ],
  [
    "The idea of transferring the variational to deterministic autoencoders is interesting .",
    "NOVELTY"
  ],
  [
    "my first concern is that from the methodological point of view , the novelty of the proposed method seems small .",
    "NOVELTY"
  ],
  [
    "Novelty of the proposed method",
    "NOVELTY"
  ],
  [
    "Algorithmic contributions are modifications to a previously developed Bayesian model .",
    "NOVELTY"
  ],
  [
    "it 's hard to believe that no one has used a similar strategy before , and the algorithm does not seem like a substantial theoretical contribution .",
    "NOVELTY"
  ],
  [
    "ExactLine did not `` provide novel insights into the behavior of neural networks ``",
    "NOVELTY"
  ],
  [
    "The paper applies tensor decomposition methods on a novel application of estimating the brain contectome to improve the potentiality on the big data , which could be",
    "NOVELTY"
  ],
  [
    "From the methodology aspect , the novelty of paper appears to be rather limited .",
    "NOVELTY"
  ],
  [
    "The originality is not very clear because it seems that a lot of ideas are borrowed from Schulman et al",
    "NOVELTY"
  ],
  [
    "is not clear where the contribution of this paper separates from existing work",
    "NOVELTY"
  ],
  [
    "I \u2019 m not sure exactly where this work diverges from that",
    "NOVELTY"
  ],
  [
    "Overall this paper introduces some interesting ideas .",
    "NOVELTY"
  ],
  [
    "My main concerns were",
    "NOVELTY"
  ],
  [
    "the originality ,",
    "NOVELTY"
  ],
  [
    "The method is novel and appears to be",
    "NOVELTY"
  ],
  [
    "most of the components are not new to the community",
    "NOVELTY"
  ],
  [
    "But I do not believe the paper brings insightful ideas that are worthy to be discussed in ICLR , either from the",
    "NOVELTY"
  ],
  [
    "I like the idea proposed in the paper and strongly encourage the authors to seriously address the raised questions regarding experiments and comparisons",
    "NOVELTY"
  ],
  [
    "The idea of sharing or tying weights between input and output word embeddings is not new",
    "NOVELTY"
  ],
  [
    "The proposed justification appears new to me though",
    "NOVELTY"
  ],
  [
    ", and certainly interesting .",
    "NOVELTY"
  ],
  [
    "my bigger concern is that the contribution of this work is highly limited ,",
    "NOVELTY"
  ],
  [
    "this work is a timely contribution that could augment the ML pipeline",
    "NOVELTY"
  ],
  [
    "the work seems to be lacking in novelty in several respects .",
    "NOVELTY"
  ],
  [
    "the techniques developed here represent a fairly straightforward merger of DP and FL tools without much in the way of qualitatively new offerings",
    "NOVELTY"
  ],
  [
    "While the particular combination",
    "NOVELTY"
  ],
  [
    "I still hold that the paper offers very little in the way of new conceptual or technical contributions",
    "NOVELTY"
  ],
  [
    "2 .The idea of the interaction between objects is interesting .",
    "NOVELTY"
  ],
  [
    "The main idea presented in this work , a novel polynomial representation form for the decision trees , is interesting .",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are marginal : both learning centroids for each meta-training class and projecting the few-shot features have been used before in published work",
    "NOVELTY"
  ],
  [
    "I see little novelty in the paper .",
    "NOVELTY"
  ],
  [
    "and the bounds are very interesting",
    "NOVELTY"
  ],
  [
    "The difference to a standard model-based RL algorithm is",
    "NOVELTY"
  ],
  [
    "The basic idea here seems like a good one",
    "NOVELTY"
  ],
  [
    "paper .",
    "NOVELTY"
  ],
  [
    "the contributions up to Section 6 seem very incremental .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "advantage/novelty of the proposed method is unclear for me .",
    "NOVELTY"
  ],
  [
    "and thus here no technical novelty is shown",
    "NOVELTY"
  ],
  [
    "but the novelty would be weak as mentioned above",
    "NOVELTY"
  ],
  [
    "However , the approach is not new",
    "NOVELTY"
  ],
  [
    "but it is not clear to me that this paper has made a substantive contribution to it",
    "NOVELTY"
  ],
  [
    "The main concern however is novelty .",
    "NOVELTY"
  ],
  [
    "but not a major",
    "NOVELTY"
  ],
  [
    "in my humble opinion the paper is moderately original",
    "NOVELTY"
  ],
  [
    "There are major algorithmic and empirical contributions in this paper .",
    "NOVELTY"
  ],
  [
    "the paper presents an interesting approach to use third-person views as demonstrations for a robot",
    "NOVELTY"
  ],
  [
    "; learning from demonstrations , including from videos , is not a novel contribution , as well as learning modular controllers in the form of an inverse model . Despite limited novelty",
    "NOVELTY"
  ],
  [
    "is interesting with respect to more classical approaches based on hand-crafted models or task-specific solutions",
    "NOVELTY"
  ],
  [
    "paper , the methodological novelty of the proposed approach is minimal .",
    "NOVELTY"
  ],
  [
    "Although this is an incremental work built upon",
    "NOVELTY"
  ],
  [
    "I really liked the idea about more detailed search for kernel-wise configurations .",
    "NOVELTY"
  ],
  [
    "I find this paper provides interesting insights",
    "NOVELTY"
  ],
  [
    "the multi-head interactive attention mechanism proposed in the paper is a marginal innovation regarding SoA of this domain that seems related to self attention mechanism which has been heavily used in the context of machine reading recently",
    "NOVELTY"
  ],
  [
    "this application is obvious and does not have enough novelty merits to be accepted to this ICLR .",
    "NOVELTY"
  ],
  [
    "The tasks used in experiments are somewhat small but not entirely unreasonable when compared against other recent work in this area",
    "NOVELTY"
  ],
  [
    "4 .I liked the idea of budgeted uncertainty sets",
    "NOVELTY"
  ],
  [
    "The notions of local stability and transfer learn-ability are intuitive",
    "NOVELTY"
  ],
  [
    "2 .The proposed method is interesting and appears to be very different from existing approaches based on RL and evolution .",
    "NOVELTY"
  ],
  [
    "an interesting idea and shows that cross-lingual data augmentation works well",
    "NOVELTY"
  ],
  [
    "I also feel like this paper lacks novelty and further evaluation to be accepted at ICLR",
    "NOVELTY"
  ],
  [
    "and the main idea of this attack is interesting",
    "NOVELTY"
  ],
  [
    "The proposed approach combines ideas from",
    "NOVELTY"
  ],
  [
    "in a straightforward manner",
    "NOVELTY"
  ],
  [
    "The idea of harnessing spatial relations for image captioning is not new [ B , C ] . The proposed approach is not particularly technically innovative",
    "NOVELTY"
  ],
  [
    "Overall , this seems like a very nice application of modern ML techniques to an application in cognition / psychology .",
    "NOVELTY"
  ],
  [
    "The results of this work seem to be original .",
    "NOVELTY"
  ],
  [
    "Thus , the insight about the temperature effect on the embedding from the second last layer , can not be novel any more .",
    "NOVELTY"
  ],
  [
    "I like the idea to use an iterative training algorithm to jointly improve classifier parameter \\theta and segment boundaries b",
    "NOVELTY"
  ],
  [
    "This reviewer is unsure what the paper claims as a novel contribution .",
    "NOVELTY"
  ],
  [
    "This paper is technically not very novel",
    "NOVELTY"
  ],
  [
    "However ,",
    "NOVELTY"
  ],
  [
    "The introduction of a circular buffer is not very novel .",
    "NOVELTY"
  ],
  [
    "If this is the first work which successfully integrates the signature transform into deep learning , the novelty is high",
    "NOVELTY"
  ],
  [
    "I like the idea of having an easy way of building BNNs .",
    "NOVELTY"
  ],
  [
    "I have the feeling that the proposed toolkit is a bit too similar to the existing toolkits such as Aboleth",
    "NOVELTY"
  ],
  [
    "In my opinion , the contribution of this paper is quite substantial and non-trivial .",
    "NOVELTY"
  ],
  [
    "1 .The idea of multi-level binarization is not new .",
    "NOVELTY"
  ],
  [
    "Besides , such conversion could be one of the most significant technical novelty in this paper , which makes me",
    "NOVELTY"
  ],
  [
    "this submission .",
    "NOVELTY"
  ],
  [
    "The authors have not clearly demonstrated that SPU provides novel insights beyond the existing literature .",
    "NOVELTY"
  ],
  [
    "This work presents a novel way of utilizing GCN and I believe it would be interesting to the community .",
    "NOVELTY"
  ],
  [
    "I liked the idea of using local variations of the graph signals as quality of the signal . It was new to me",
    "NOVELTY"
  ],
  [
    "which are brought together in a way that appears novel",
    "NOVELTY"
  ],
  [
    "+/- this work builds largely on previous work",
    "NOVELTY"
  ],
  [
    "while somewhat similar to [ Adler et al 2018 ] , which they compare against , this submission does seem to make novel contributions both in their theoretical framing of the problem and in their practical solution , which feel like solid improvements .",
    "NOVELTY"
  ],
  [
    "I do feel like this paper provides one of the first mostly-fleshed-out solutions to an extremely important",
    "NOVELTY"
  ],
  [
    "the paper has several experiments and insights that would be interesting to the community",
    "NOVELTY"
  ],
  [
    "The general idea is great and the authors should definitely place their simulator online and actively advertise is to the interested group of researchers",
    "NOVELTY"
  ],
  [
    "the proposed algorithm is a fairly straightforward extension of previous ideas",
    "NOVELTY"
  ],
  [
    "which more than exceeds any sort of originality bar in this reviewer 's opinion",
    "NOVELTY"
  ],
  [
    "The work is original in the approach , i.e .randomization as a way to get rid of learning rates is a novel method .",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is clear",
    "NOVELTY"
  ],
  [
    "The contribution is new . This is the first work that tries to provide a formal langauge for the space definition .",
    "NOVELTY"
  ],
  [
    "The idea of hierachycal 'substitution module ' has already appears in some deep learning frameworks",
    "NOVELTY"
  ],
  [
    "It seems to be the first work that leverages the variance in Bayesian Neural Nets ( BNN ) to prevent forgetting .",
    "NOVELTY"
  ],
  [
    "task and proposed model seems novel",
    "NOVELTY"
  ],
  [
    "The task of image manipulation through bounding boxes seems somewhat novel",
    "NOVELTY"
  ],
  [
    "and the proposed model going from a box input through an intermediate semantic segmentation is new ( although semantics has been used before to generate images",
    "NOVELTY"
  ],
  [
    "though ideas as such are not novel .",
    "NOVELTY"
  ],
  [
    "Originality The presented work is original as it introduces a new routing principle for capsule networks .",
    "NOVELTY"
  ],
  [
    "this paper is however the first to empirically study the robustness of ensembles against adversarial examples",
    "NOVELTY"
  ],
  [
    "I find the contribution limited in general .",
    "NOVELTY"
  ],
  [
    "I think this paper should be accepted as it proposes a novel idea , which does not seem too difficult to reproduce",
    "NOVELTY"
  ],
  [
    "In general I find the paper novel ( to the best of my somewhat limited knowledge ) , interesting",
    "NOVELTY"
  ],
  [
    "These results are a significant progress with respect to existing work .",
    "NOVELTY"
  ],
  [
    "the construction and analysis of the algorithms are highly non-trivial .",
    "NOVELTY"
  ],
  [
    "Such a strong focus on the complexity of the algorithms in this problem is novel ( as far as I know ) and very interesting .",
    "NOVELTY"
  ],
  [
    "The space of learning embeddings to optimize nearest neighbor classification has been explored before , but",
    "NOVELTY"
  ],
  [
    "the idea of averaging the propotypes is interesting",
    "NOVELTY"
  ],
  [
    "I like the idea of using a specifically designed prior distribution in PAC-Bayes framework to show a",
    "NOVELTY"
  ],
  [
    "The presented results are new to my best knowledge .",
    "NOVELTY"
  ],
  [
    "approach for mixing PAC-Bayes with stability arguments and should have a positive impact",
    "NOVELTY"
  ],
  [
    "The proposed method is a slight variant of the widely studied nuclear norm regularized formulation such a RPCA",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel and interesting method to adapt the weights over different auxiliary objectives .",
    "NOVELTY"
  ],
  [
    ".Nevertheless , I think this is a novel application of meta-gradient for tuning auxiliary task weights .",
    "NOVELTY"
  ],
  [
    "The idea behind this paper is novel and interesting .",
    "NOVELTY"
  ],
  [
    "the way the authors introduce this pseudo-Bayesian objective function",
    "NOVELTY"
  ],
  [
    "Demonstrating that an agent trained with a human model performs better than an agent assuming an optimal human is not necessarily a new idea and is quite well-studied in HRI and human-AI collaboration",
    "NOVELTY"
  ],
  [
    "The model of the human is basic , which is fine if the idea itself is very novel",
    "NOVELTY"
  ],
  [
    "While the work is set in the context of more recent algorithms , the idea of modelling humans and not assuming humans are optimal in training is not a new concept .",
    "NOVELTY"
  ],
  [
    "The main concern is the originality of the work compared to prior work on modelling humans in collaborative tasks for better team performance .",
    "NOVELTY"
  ],
  [
    "I thought the paper was well-written and made some nice theoretical contributions to this area .",
    "NOVELTY"
  ],
  [
    "new ideas",
    "NOVELTY"
  ],
  [
    "The approach in the form of the chain graph missingness model is new , with an elegant connection to log-linear models for parameterization",
    "NOVELTY"
  ],
  [
    "the overall setup is interesting",
    "NOVELTY"
  ],
  [
    "The work is original with a significant contribution",
    "NOVELTY"
  ],
  [
    "The integration of generative adversarial networks with auto-encoding loss is not really a novel contribution .",
    "NOVELTY"
  ],
  [
    "the iterative training ( section 3.4 ) is not a novel contribution since it was explored in the literature before",
    "NOVELTY"
  ],
  [
    ". The proof developed in the",
    "NOVELTY"
  ],
  [
    "but can not be considered as a significant contribution .",
    "NOVELTY"
  ],
  [
    "The technical contribution of the proposed method is not high , because the architecture space of neural network is similar to the prior works .",
    "NOVELTY"
  ],
  [
    "especially the well-defined optimization problem in Sec .2.3 .The idea of consolidating transitivity relationships into batches is an interesting angle in similarity learning",
    "NOVELTY"
  ],
  [
    "Overall , the authors came up with an interesting approach to the standard BA",
    "NOVELTY"
  ],
  [
    "The technique seems to be simple to apply yet",
    "NOVELTY"
  ],
  [
    "powerful and promising",
    "NOVELTY"
  ],
  [
    "is slightly different , the novelty is a little incremental .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is a good contribution given the current great interest of transformer-based models .",
    "NOVELTY"
  ],
  [
    "This is a nice advance to this fairly new , rapidly growing , and important literature on social biases in AI systems , that has very deep connections to regularities in human cognition",
    "NOVELTY"
  ],
  [
    "and huge implications for machine learned AI systems .",
    "NOVELTY"
  ],
  [
    "This style of paper and",
    "NOVELTY"
  ],
  [
    "there 's basically no technical novelty in this paper",
    "NOVELTY"
  ],
  [
    "I think this paper brings good existing ideas from images to volumetric data , which pushes the state of the art in that field",
    "NOVELTY"
  ],
  [
    "However , the limited technical novelty reduce the potential impact of the paper .",
    "NOVELTY"
  ],
  [
    "My major concern is that there is not much novelty in the proposed method compared with GDUAP .",
    "NOVELTY"
  ],
  [
    "while lacking novelty may be fine in and of itself",
    "NOVELTY"
  ],
  [
    "Overall the paper is well written , and presents some interesting novel ideas on aggregating reinforcement learning algorithms .",
    "NOVELTY"
  ],
  [
    "- the proposed approach is novel as far as I know",
    "NOVELTY"
  ],
  [
    "My main concerns are the following",
    "NOVELTY"
  ],
  [
    "Representing words by distributions is not a novel idea",
    "NOVELTY"
  ],
  [
    "while the algorithm is making a nice contribution for the DRL community by itself",
    "NOVELTY"
  ],
  [
    "the paper presents an interesting and novel approach to robustness in FL , using a robust regression estimator to aggregate the model coefficients",
    "NOVELTY"
  ],
  [
    "Although the method is interesting and novel , and seems principled",
    "NOVELTY"
  ],
  [
    "Overall , this paper presents a nice idea to use program states ( dynamic environments ) for predicting next functions .",
    "NOVELTY"
  ],
  [
    "The idea of using dynamic state information and variable dropping for learning to search in synthesis is novel .",
    "NOVELTY"
  ],
  [
    "The IAN model itself is interesting as standard GAN-based approaches do not simultaneously train an autoencoder .",
    "NOVELTY"
  ],
  [
    "The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new ,",
    "NOVELTY"
  ],
  [
    "The originality of the main method was not immediately apparent to me",
    "NOVELTY"
  ],
  [
    "I think the major argument I have is this method is lack of technical novelty",
    "NOVELTY"
  ],
  [
    "for a major publication",
    "NOVELTY"
  ],
  [
    "natural modifications of these existing approaches to active learning .",
    "NOVELTY"
  ],
  [
    "The theoretical issues that arise in handling these abstentions and quantifying their effect on the query complexity are at times nontrivial",
    "NOVELTY"
  ],
  [
    "I like the presented approach of learning the skill embeddings using the variational lower bound .",
    "NOVELTY"
  ],
  [
    "Interesting new approach for hiearchical reinforcement learning that focuses on skill versatility - The variational lower bound is one of the most principled formulations for hierarchical RL that I have seen so far",
    "NOVELTY"
  ],
  [
    "This is an interesting deep reinforcement learning paper that introduces a new principled framework for learning versatile skills",
    "NOVELTY"
  ],
  [
    "This is an interesting and original idea .",
    "NOVELTY"
  ],
  [
    "Overall , this paper provides a novel idea of training BNN with latent-free weights , which is interesting and insightful and might open a new way train BNN .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the proposed method is new .",
    "NOVELTY"
  ],
  [
    "This paper presents an interesting approach to ASR in a memory constrained setting",
    "NOVELTY"
  ],
  [
    "The paper proposed a novel feature transfer network , that optimizes domain adversarial loss and domain separation loss .",
    "NOVELTY"
  ],
  [
    "The proposed approach on Feature Transfer Network was novel and interesting .",
    "NOVELTY"
  ],
  [
    "and novel",
    "NOVELTY"
  ],
  [
    "I am not convinced if the main results are novel .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is novel and well-presented",
    "NOVELTY"
  ],
  [
    "The idea is novel ( some prior work is cited by the authors ) and interesting .",
    "NOVELTY"
  ],
  [
    "but this is not a new result",
    "NOVELTY"
  ],
  [
    "I find the idea of the paper interesting",
    "NOVELTY"
  ],
  [
    "The theory proved in the paper does not provide additional quantitive insight beyond intuition",
    "NOVELTY"
  ],
  [
    "My major concern is on its novelty and how directly it can provide benefit to computation",
    "NOVELTY"
  ],
  [
    "although the findings are interesting",
    "NOVELTY"
  ],
  [
    "the methods used in this paper are not new . Various pruning techniques have been explored in prior work , which makes the novelty contribution of this paper somewhat limited .",
    "NOVELTY"
  ],
  [
    "The paper presents a nice idea of directly finding rules such as brother ( father ) = > uncle in knowledge bases , by directly searching in embedding space .",
    "NOVELTY"
  ],
  [
    "The work is fairly original",
    "NOVELTY"
  ],
  [
    "The second technical contribution mentioned above is fairly minor and not particularly novel",
    "NOVELTY"
  ],
  [
    "The idea of using the relaxed version of the circuit for training is nice . Combining ideas from DAG-RNNs and Deep Sets is interesting",
    "NOVELTY"
  ],
  [
    "although incremental",
    "NOVELTY"
  ],
  [
    "The idea of applying Bayesian optimisation within probabilistic programming seems novel and potentially very useful . The implementation also introduces some improvements to the Bayesian optimisation method .",
    "NOVELTY"
  ],
  [
    "The interaction net is very new to me",
    "NOVELTY"
  ],
  [
    "While the use of inference networks proposing positions for the network as a means of improving the disentanglement is clever and seems novel",
    "NOVELTY"
  ],
  [
    "I think the ideas presented in the paper deserve attention and provide a novel view on how to combine macro-goals along with micro-actions using memory networks .",
    "NOVELTY"
  ],
  [
    "but the underlying ideas ( i.e. , iterative sampling from uncovered points ) look to be very similar",
    "NOVELTY"
  ],
  [
    "2 and its analysis are very incremental .",
    "NOVELTY"
  ],
  [
    "To my understanding , this is the most significant contribution for the paper .",
    "NOVELTY"
  ],
  [
    "The novelty is significant , and it discloses several non-trivial facts .",
    "NOVELTY"
  ],
  [
    "I appreciate the novel insights from the paper",
    "NOVELTY"
  ],
  [
    "Overall though , the paper seems like a solid step in a good direction with some clearly novel ideas .",
    "NOVELTY"
  ],
  [
    "The method builds on the previous work on capsule networks but is highly original in its own right . The architecture and learning algorithm of the Constellation Autoencoder are a clever innovation that avoids iterative routing while still learning part-whole relations .",
    "NOVELTY"
  ],
  [
    "advance for unsupervised learning of object semantics",
    "NOVELTY"
  ],
  [
    "A major concern is the amount of novelty between this work and the author 's previous publication at NIPs 2016",
    "NOVELTY"
  ],
  [
    "However , the work is n't quite novel enough from NIPs 2016 .",
    "NOVELTY"
  ],
  [
    ".Totally this paper gives good contribution to this topic",
    "NOVELTY"
  ],
  [
    "In sum , I like the idea to exploit the Hamiltonian updates to construct posterior .",
    "NOVELTY"
  ],
  [
    "This limits the novelty of the paper and thus make the contribution marginal",
    "NOVELTY"
  ],
  [
    "The idea of using smoothness and saturation to bridge the gap between the MNIST and CIFAR10 datasets was also very interesting .",
    "NOVELTY"
  ],
  [
    "The application of this model to document classification seems to be new ( I am not a direct expert in document classification",
    "NOVELTY"
  ],
  [
    "but the model itself and the components are not",
    "NOVELTY"
  ],
  [
    "So this raises a concern about novelty ( although the experimental results are new )",
    "NOVELTY"
  ],
  [
    "The proposed approach and focus on sampling is original as far as I can tell .",
    "NOVELTY"
  ],
  [
    "The novel aspect is the introduction of a scene discriminator and a pose encoder network .",
    "NOVELTY"
  ],
  [
    "The idea of using GAN to learn a mapping between two domains is novel , which is effective to train the model without paired examples .",
    "NOVELTY"
  ],
  [
    "approach",
    "NOVELTY"
  ],
  [
    "I still see that the contribution is somewhat limited",
    "NOVELTY"
  ],
  [
    "Use of double sampling method for estimating the loss and second order penalty appears to be novel",
    "NOVELTY"
  ],
  [
    "The approach is rather a mix of previous works and hence not novel .",
    "NOVELTY"
  ],
  [
    "and its contributions are interesting .",
    "NOVELTY"
  ],
  [
    "To my knowledge contributions ( i ) - ( iv ) above are novel .",
    "NOVELTY"
  ],
  [
    "the contribution of this work is theoretical -- it presents a technique",
    "NOVELTY"
  ],
  [
    "and even though working on this project is a great idea",
    "NOVELTY"
  ],
  [
    "The technical novelty is very limited .",
    "NOVELTY"
  ],
  [
    "The novel of this paper is relatively small .",
    "NOVELTY"
  ],
  [
    "From that perspective , the solution proposed in this paper is not that different from previous work .",
    "NOVELTY"
  ],
  [
    "But since RNN/LSTM can be simply interpreted as a probabilistic model , I would consider it a small novelty",
    "NOVELTY"
  ],
  [
    "the proposed solution in this paper seems to be simplistic for a paper .",
    "NOVELTY"
  ],
  [
    "good , originality : borderline",
    "NOVELTY"
  ],
  [
    "I feel the novelty or take away messages from the experiment section is limited",
    "NOVELTY"
  ],
  [
    "The main contribution is proposing the first ( as far as I know ) consistent and distribution free test for the multivariate case",
    "NOVELTY"
  ],
  [
    "Therefore , in my opinion the paper is novel has a high potential impact",
    "NOVELTY"
  ],
  [
    "for which the data at hand together with improved independence tests , enable getting novel findings",
    "NOVELTY"
  ],
  [
    "paper presents a nice theory that demonstrates that a certain class of neural network has a global optimal which can be achieved in a linear convergence rate",
    "NOVELTY"
  ],
  [
    "As claimed by the authors , this is the first work that proposed a potentially practical neural work with optimal guarantee and convergence guarantee",
    "NOVELTY"
  ],
  [
    "I think that the paper proposes some interesting ideas",
    "NOVELTY"
  ],
  [
    "in its current form I do not",
    "NOVELTY"
  ],
  [
    "but I think the authors may be overselling these ideas as a brand new algorithm",
    "NOVELTY"
  ],
  [
    "One drawback is that the idea of dropping a spatial region in training is not new .",
    "NOVELTY"
  ],
  [
    "The improvement over previous methods is small , about 0.2",
    "NOVELTY"
  ],
  [
    "The papers contains interesting novel ideas and extensions for linear oracle based optimization methods",
    "NOVELTY"
  ],
  [
    "While the proposed penalty is described as a novel contribution , there are multiple instances of previous work which use the same type of penalty",
    "NOVELTY"
  ],
  [
    "I found the idea to be elegant and",
    "NOVELTY"
  ],
  [
    "this seems to be a solid contribution ( even if the",
    "NOVELTY"
  ],
  [
    "empirical results are a bit incremental",
    "NOVELTY"
  ],
  [
    "I recommend acceptance",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "There is no technique contribution .",
    "NOVELTY"
  ],
  [
    "The contribution is quite limited since the authors only apply multi-task learning to the three MNIST-like datasets and there is no technique contribution .",
    "NOVELTY"
  ],
  [
    "the improvement brought by the framework is marginal , even if it seems general .",
    "NOVELTY"
  ],
  [
    "is that even though it touches a",
    "NOVELTY"
  ],
  [
    "it neither is written well nor it contains much of a novelty in terms of algorithms , methods or network architectures .",
    "NOVELTY"
  ],
  [
    "all the individual components combined here have been explored in some form in past work",
    "NOVELTY"
  ],
  [
    ", the combination and application to the language-conditioned navigation task is , to my knowledge , novel",
    "NOVELTY"
  ],
  [
    "2 ) A generalization gap in novel environments .",
    "NOVELTY"
  ],
  [
    "So the results in this subsection are somewhat trivial and do not necessarily contribute any new understanding .",
    "NOVELTY"
  ],
  [
    "I over all find the idea of GHN interesting",
    "NOVELTY"
  ],
  [
    "the experimental results seem very incremental and I \u2019 m not convinced there is a genuine signal there .",
    "NOVELTY"
  ],
  [
    "Table 2 tells me that PBA seems incremental both for the teacher and the student",
    "NOVELTY"
  ],
  [
    "The proposed work is novel",
    "NOVELTY"
  ],
  [
    "I view",
    "NOVELTY"
  ],
  [
    ", which provides novel results . The proposed algorithm appears to include novel features ,",
    "NOVELTY"
  ],
  [
    "with an interesting idea .",
    "NOVELTY"
  ],
  [
    "the novelty of the proposal seems limited",
    "NOVELTY"
  ],
  [
    "the paper is original in the way it uses flow based generative models for 1-to-many image to image translation .",
    "NOVELTY"
  ],
  [
    "Overall the proposed method is novel and the research direction is a very interesting one to explore .",
    "NOVELTY"
  ],
  [
    "nontrivial",
    "NOVELTY"
  ],
  [
    "the novelty and contribution are rather limited",
    "NOVELTY"
  ],
  [
    "The novelty and contribution of the paper are rather limited .",
    "NOVELTY"
  ],
  [
    "The proposed network architecture and loss function are interesting .",
    "NOVELTY"
  ],
  [
    "Despite these minor issues , the paper contributes significantly novel task , dataset , and results .",
    "NOVELTY"
  ],
  [
    "While the motivation is quite different , the key schema of this submission is still quite close to [ 8 ] / [ 20",
    "NOVELTY"
  ],
  [
    "While the method is intuitive and appealing at a high level",
    "NOVELTY"
  ],
  [
    "Although the discovery that adding this regularization term for the LLP problem increases generalization performance is novel , using this term for data without ground truth labels",
    "NOVELTY"
  ],
  [
    "in image datasets such as CIFAR10/100 and SVHN itself has low novelty , since these datasets satisfy the smoothness assumption used by consistency regularization methods",
    "NOVELTY"
  ],
  [
    "idea",
    "NOVELTY"
  ],
  [
    "the paper does not propose a new model , but an instantiation of an existing model to a particular case",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is thus quite light .",
    "NOVELTY"
  ],
  [
    "Although phoneme duration prediction is widely adopted in conventional TTS systems , jointly training it in a neural TTS model is new . This paper is one of the first works on non-autoregressive text-to-spectrogram modeling",
    "NOVELTY"
  ],
  [
    "and idea seemed novel to me .",
    "NOVELTY"
  ],
  [
    "presents an interesting method for explaining image similarity models",
    "NOVELTY"
  ],
  [
    "While this work is conceptually interesting",
    "NOVELTY"
  ],
  [
    "the technical novelty and contributions do n't stand out as much as they could .",
    "NOVELTY"
  ],
  [
    "affects III Conclusion The idea is interesting",
    "NOVELTY"
  ],
  [
    "which makes the contribution of this submission limited",
    "NOVELTY"
  ],
  [
    "This paper and other permutation-based causal discovery approaches seem to provide a novel and interesting alternative to previous methods Cons",
    "NOVELTY"
  ],
  [
    "The submission is original and very clearly",
    "NOVELTY"
  ],
  [
    "The approach is novel .",
    "NOVELTY"
  ],
  [
    "Method is an amalgamation of bunch other recent work , which gives the impression of creating complexity for its own sake",
    "NOVELTY"
  ],
  [
    "I find the ideas presented in this paper interesting and novel .",
    "NOVELTY"
  ],
  [
    "this is a",
    "NOVELTY"
  ],
  [
    "it is quite niche and -- -while the authors frame it as a form of NAS -- -in my view",
    "NOVELTY"
  ],
  [
    "Relatively niche contribution incorrectly framed as general contribution to NAS",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper however",
    "NOVELTY"
  ],
  [
    "paper provides novel theorems",
    "NOVELTY"
  ],
  [
    "By adapting experimental methodology from psychology to test that have been used to understand and explain the internal workings of the mind , the authors approach the problem in a novel and innovative manner",
    "NOVELTY"
  ],
  [
    "learning weakly-communicating MDPs was already attempted in Bartlett and Tewari who give a very similar result to the one given in this paper",
    "NOVELTY"
  ],
  [
    "Overall the manuscript is well-written and to my knowledge the methodology is a novel application to Kronecker-factored approximation .",
    "NOVELTY"
  ],
  [
    "The idea that formulates the problem of approximating the Laplacian engenfunctions as constraint optimization is interesting .",
    "NOVELTY"
  ],
  [
    "Though the idea of learning a state representation seems interesting and might be of interest within the RL research",
    "NOVELTY"
  ],
  [
    "In terms of an application of the learnt representation , reward-shaping looks interesting and promising .",
    "NOVELTY"
  ],
  [
    "But another possible answer is that there is sufficient ( marginal ) novelty in either of them",
    "NOVELTY"
  ],
  [
    "The sparse connection is not new",
    "NOVELTY"
  ],
  [
    "simply because the idea is not new",
    "NOVELTY"
  ],
  [
    "The idea seems interesting and novel ,",
    "NOVELTY"
  ],
  [
    "Most of the proofs are very technical and lack of insights .",
    "NOVELTY"
  ],
  [
    "3 .My major concern is the novelty of this paper .",
    "NOVELTY"
  ],
  [
    "and a novel algorithm which is applied to a very relevant problem .",
    "NOVELTY"
  ],
  [
    "the developments here are not that surprising",
    "NOVELTY"
  ],
  [
    "There appears to be little in the way of algorithmic or computational innovations",
    "NOVELTY"
  ],
  [
    "CAML seems an interesting meta-learning algorithm .",
    "NOVELTY"
  ],
  [
    "and the loss function based on probability ratio is novel .",
    "NOVELTY"
  ],
  [
    "paper tackles the problem of efficient inference and test-time generalization",
    "NOVELTY"
  ],
  [
    "and the proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "The novelty is limited in my opinion as execution trace is a standard programming construct and it is not surprising that addition of such feature improves overall performance",
    "NOVELTY"
  ],
  [
    "While the overall workflow of hypernets + random search resembles that of SMASH ( Brock et al. , 2018 ) , the architecture of GHN itself is a nontrivial and useful contribution .",
    "NOVELTY"
  ],
  [
    "Nevertheless , the proposed method is not very novel ,",
    "NOVELTY"
  ],
  [
    "There is no too much new here",
    "NOVELTY"
  ],
  [
    "and no too much new here",
    "NOVELTY"
  ],
  [
    "The key technical contributions look mostly like an application of the existing theory on implicit bias of gradient descent , thus I would rate the originality of this work as moderate .",
    "NOVELTY"
  ],
  [
    "The intuition presented at the beginning of Section 4 is interesting",
    "NOVELTY"
  ],
  [
    "The idea itself is interesting and complements existing training and finetuning approaches , although I think there are a few baseline approaches that can be compared against",
    "NOVELTY"
  ],
  [
    "Overall I think it is an interesting idea",
    "NOVELTY"
  ],
  [
    "The paper builds on recent works viewing dropout as a Bayesian approximation to the predictive posterior distribution .",
    "NOVELTY"
  ],
  [
    "The result that dropout simultaneously optimizes a lower bound to an entire family of conditional distributions is novel .",
    "NOVELTY"
  ],
  [
    "although I think the novelty and contribution is slightly too low for ICLR .",
    "NOVELTY"
  ],
  [
    "from a scientific perspective it provides no significant contribution .",
    "NOVELTY"
  ],
  [
    "This is an interesting approach",
    "NOVELTY"
  ],
  [
    "the idea is novel and interesting",
    "NOVELTY"
  ],
  [
    "The idea in the paper is interesting and worth reading .",
    "NOVELTY"
  ],
  [
    "( or ellipse ) estimation is not new",
    "NOVELTY"
  ],
  [
    "some strong contributions to the knowledge of GCNs",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "The main shortcoming of the paper is that its key contribution : that of training deep networks in the presence of a k-means clustering term is fairly underwhelming in terms of technical novelty when compared to typical NIPS papers .",
    "NOVELTY"
  ],
  [
    "The main contribution is the introduction of a novel architecture that effectively uses convolutional and recurrent layers .",
    "NOVELTY"
  ],
  [
    "I have not seen this exact approach proposed before",
    "NOVELTY"
  ],
  [
    "The authors are not the first to propose dynamically generating filters",
    "NOVELTY"
  ],
  [
    "Reject .Although the high-level approach is interesting",
    "NOVELTY"
  ],
  [
    "Therefore , I consider this paper a novel and original extension of previous work for Lipschitz networks ( on fully-connected networks ) .",
    "NOVELTY"
  ],
  [
    "The connection of functional gradients of the KLD with respect to the transformations in RKHS and Stein discrepancy is very interesting and provides a bridge between variational and kernel methods .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge * the main contribution of this paper was to provide a new bridge between kernel and variational methods .",
    "NOVELTY"
  ],
  [
    "While the paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "The idea of using CPD for unsupervised metric learning is quite interesting 2 ) The exploration into the convexity of the CPD parameter learning -- although straightforward -- is also perhaps interesting .",
    "NOVELTY"
  ],
  [
    "Novelty/Significance I think the novelty of this paper is perhaps marginal .",
    "NOVELTY"
  ],
  [
    "the improvements are marginal",
    "NOVELTY"
  ],
  [
    "while there is a minor novelty in connecting two separate ideas ( CPD and UML ) into a joint UML setup",
    "NOVELTY"
  ],
  [
    "I found the observations in the paper interesting",
    "NOVELTY"
  ],
  [
    "This is a well-written theory paper about a novel problem that has not been addressed in this form in earlier literature .",
    "NOVELTY"
  ],
  [
    "The technical novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "the contribution w.r.t .to novelty and approach is limited",
    "NOVELTY"
  ],
  [
    "and introduces a novel parameter-free algorithm",
    "NOVELTY"
  ],
  [
    "overall and the work is interesting , novel , and well-motivated .",
    "NOVELTY"
  ],
  [
    "This reviewer feels that the approach taken in this work has some degrees of novelty and that some of the ideas in the proposed method can improve the image capturing process",
    "NOVELTY"
  ],
  [
    "1 .Learning the multiplexing pattern by encoding it as a layer in a deep network is novel .",
    "NOVELTY"
  ],
  [
    "proposed modifications make this contribution particularly interesting as it",
    "NOVELTY"
  ],
  [
    "In my opinion the paper has minimal novelty in terms of techniques used",
    "NOVELTY"
  ],
  [
    "Still , the novelty is limited .",
    "NOVELTY"
  ],
  [
    "the novelty of the submission is limited . 1 .My main concern is on the novelty of this paper .",
    "NOVELTY"
  ],
  [
    "and has some nice contributions",
    "NOVELTY"
  ],
  [
    "While I believe ( my interpretation of ) the basic idea of this paper is interesting",
    "NOVELTY"
  ],
  [
    "The paper makes a novel contribution and makes it well .",
    "NOVELTY"
  ],
  [
    "lack of novelty .",
    "NOVELTY"
  ],
  [
    "but the raising of Top-K algorithm is not novel .",
    "NOVELTY"
  ],
  [
    "The contribution",
    "NOVELTY"
  ],
  [
    "is marginal",
    "NOVELTY"
  ],
  [
    "but interesting as a summary This paper analyzes the effectiveness of model pruning for deployment in resource constrained environments",
    "NOVELTY"
  ],
  [
    "To the best of my understanding",
    "NOVELTY"
  ],
  [
    "The idea seems on a high level to be interesting and simple ; train floating point models that can fit",
    "NOVELTY"
  ],
  [
    "Overall this is significant and original work because it is one of the first works to formulate keypoint detection and description as an end-to-end learning problem without relying on the output of hand-crafted detector for supervision .",
    "NOVELTY"
  ],
  [
    "The ideas on their own are rather incremental .",
    "NOVELTY"
  ],
  [
    "As pointed out above the ideas are not really groundbreaking on their own .",
    "NOVELTY"
  ],
  [
    "The techniques of asynchronous update and multiple replay steps may have limited novelty , building closely on previous work and applying it to this new problem .",
    "NOVELTY"
  ],
  [
    "I think this is a high quality paper with a nice new idea",
    "NOVELTY"
  ],
  [
    "I believe the paper presents original idea , algorithm , formalization and experimental results . I am quite happy with the originality of this paper .",
    "NOVELTY"
  ],
  [
    "I am also impressed by the formalized definition of mode collapse",
    "NOVELTY"
  ],
  [
    "The algorithmic ideas feel a bit too incremental and the experimental evaluation could be stronger",
    "NOVELTY"
  ],
  [
    "I still think this is too incremental",
    "NOVELTY"
  ],
  [
    "This part contribution is limited since the techniques involved are very common in the domain adaptation",
    "NOVELTY"
  ],
  [
    "It is a novel combination of well-known techniques . It is novel ,",
    "NOVELTY"
  ],
  [
    "but not a radically new idea .",
    "NOVELTY"
  ],
  [
    "provide a new state-of-the-art comparison point",
    "NOVELTY"
  ],
  [
    "While the approach is new",
    "NOVELTY"
  ],
  [
    "In my opinion , the connection between dual volume sampling and Strongly Rayleigh measures is interesting .",
    "NOVELTY"
  ],
  [
    "While my recent expertise has been more NLP than Vision , I think this algorithm is original , and could have a significant impact",
    "NOVELTY"
  ],
  [
    "I like the idea of constructing general approximation strategies for complex posterior distribution and the proposed approach inherits all the scalability properties of modern deep learning techniques .",
    "NOVELTY"
  ],
  [
    "I believe that the novelty is fairly limited",
    "NOVELTY"
  ],
  [
    "however without contributing significant innovations",
    "NOVELTY"
  ],
  [
    "Overall , the paper is a significant algorithmic contribution . The related work section provides thorough review of different methods to decrease computational costs , including not only knowledge distillation , but also pruning , compressing and decomposition approaches . The idea is elegant and , to the best of my knowledge , has never been suggested in other works .",
    "NOVELTY"
  ],
  [
    "Overall , there just is not enough innovation or substance to warrant publication at this point .",
    "NOVELTY"
  ],
  [
    "The training architecture presented here is novel as far as I know",
    "NOVELTY"
  ],
  [
    "the model does not seem to be among the state-of-the-art on CelebA that have been reported in the literature",
    "NOVELTY"
  ],
  [
    "contribution",
    "NOVELTY"
  ],
  [
    "The proposed model ( Molecule-Chef ) is a novel combination of existing deep learning models - like Graph Neural Networks , RNNs",
    "NOVELTY"
  ],
  [
    "Overall , I think the idea to improve GANs is interesting .",
    "NOVELTY"
  ],
  [
    "I like the concept of the paper ,",
    "NOVELTY"
  ],
  [
    "I can not find a strong or unique contribution from this paper .",
    "NOVELTY"
  ],
  [
    "Overall , this paper proposes a novel method",
    "NOVELTY"
  ],
  [
    "The approach is novel , as far as I know no previous work addresses semi-supervised learning with consistency regularization for object detection .",
    "NOVELTY"
  ],
  [
    "Technically , it is a bit incremental as this type of loss already existed for image classification and the extension to localization is rather trivial .",
    "NOVELTY"
  ],
  [
    "The ideas in this",
    "NOVELTY"
  ],
  [
    "this is not a new idea by any means",
    "NOVELTY"
  ],
  [
    "Another important contribution is the learned data augmentation strategy , which as far as I understand is novel and overcomes some of the limitations of existing learned data augmentation techniques .",
    "NOVELTY"
  ],
  [
    "This paper seems to be the first work exploring the regularities such as curvature of the boundary of the domain in online learning -- which is fairly new .",
    "NOVELTY"
  ],
  [
    "Overall this paper is an incremental research work .",
    "NOVELTY"
  ],
  [
    "The idea is intuitive",
    "NOVELTY"
  ],
  [
    "The novelty in this paper is limited .",
    "NOVELTY"
  ],
  [
    "-- There is sufficient amount of novelty .",
    "NOVELTY"
  ],
  [
    "While the idea of SAG or SGD is not new",
    "NOVELTY"
  ],
  [
    "which provides little technical contribution",
    "NOVELTY"
  ],
  [
    "Non parametric estimation with adversarial losses as well as Gans are clearly the focus of numerous current ML research and in my opinion this work is a significant contribution on these subjects",
    "NOVELTY"
  ],
  [
    "the idea proposed in the paper is incremental and not new to the field .",
    "NOVELTY"
  ],
  [
    "Overall I think this paper presents some interesting ideas but I am unsatisfied with the issues above",
    "NOVELTY"
  ],
  [
    "the proof strategy is not novel enough",
    "NOVELTY"
  ],
  [
    "The idea of using priors to improve adversarial gradient attacks is an enticing idea .",
    "NOVELTY"
  ],
  [
    "The main issue I have with the approach is that it does not bring a very novel way to perform deep learning on graphs , but rather improves marginally upon a well established one .",
    "NOVELTY"
  ],
  [
    "Overall , the presented idea is novel to the best of my knowledge and",
    "NOVELTY"
  ],
  [
    "The neural network architecture is entirely standard with nothing new .",
    "NOVELTY"
  ],
  [
    "The particular contributions are not",
    "NOVELTY"
  ],
  [
    "The idea to leverage the parameters of a meta-optimizer for adaptation instead of using model parameters is novel and interesting .",
    "NOVELTY"
  ],
  [
    "I would argue that this very simple model does not provide any valuable insight into the problem due to its construction .",
    "NOVELTY"
  ],
  [
    "The authors propose a novel idea of learning representations that improves the performance of the subsequent fixed discretization method .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and new .",
    "NOVELTY"
  ],
  [
    "On the positive side , this paper proposes a novel algorithm that seems reasonably well-motivated .",
    "NOVELTY"
  ],
  [
    "The algorithm is novel and",
    "NOVELTY"
  ],
  [
    "I believe the strong point of this paper is the novel idea",
    "NOVELTY"
  ],
  [
    "I believe the idea of the paper is interesting too .",
    "NOVELTY"
  ],
  [
    "The methodology is n't very original : The GAN architecture is essentially a slightly modified CycleGAN trained with Wasserstein loss",
    "NOVELTY"
  ],
  [
    "I appreciated that the authors were clear on their",
    "NOVELTY"
  ],
  [
    "I think as-is this paper is a nice contribution and deserves to be accepted",
    "NOVELTY"
  ],
  [
    "But this is not a novel observation .",
    "NOVELTY"
  ],
  [
    "The algorithm proposed itself isnt novel",
    "NOVELTY"
  ],
  [
    "This work introduces a novel method for optimizing the selection of quantiles to minimize error in the return distribution .",
    "NOVELTY"
  ],
  [
    "This would be a nice small contribution to add to the paper that could influence future research .",
    "NOVELTY"
  ],
  [
    "which , unlike other `` incremental `` papers on graph kernels , provides a refreshingly new perspective on the problem .",
    "NOVELTY"
  ],
  [
    "The paper contains several interesting ideas",
    "NOVELTY"
  ],
  [
    "Novelty and potential impact . The paper sounds novel to me and it can have a great impact .",
    "NOVELTY"
  ],
  [
    "Overall , I really like the theoretical contribution of the paper .",
    "NOVELTY"
  ],
  [
    "This is a clever and useful idea",
    "NOVELTY"
  ],
  [
    "The PA method is novel and surprisingly effective",
    "NOVELTY"
  ],
  [
    "2 .The use of 3d convolution for protein 3d structures is not new",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed method is limited .",
    "NOVELTY"
  ],
  [
    "Although this is a fairly known technique in online convex optimization ( OCO ) , carrying it out in DR-submodular optimization seems nontrivial .",
    "NOVELTY"
  ],
  [
    "I believe that its technical contributions are strong enough to accept in NeurIPS",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel way to model correlations separately from tail dependence .",
    "NOVELTY"
  ],
  [
    "Originality I believe this is a novel approach to model tail dependency .",
    "NOVELTY"
  ],
  [
    "The main concern is the novelty of this work . The method is very similar to SCDV (",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the contributions in this paper seem to be incremental .",
    "NOVELTY"
  ],
  [
    "The proposed method is simple and lacks novelty .",
    "NOVELTY"
  ],
  [
    "Originality The model learning approach they proposed is merely a simple variant of ensemble learning .",
    "NOVELTY"
  ],
  [
    "From a conceptual point of view , the idea proposed in the paper is very interesting .",
    "NOVELTY"
  ],
  [
    "First-order optimization algorithms have two main advantages",
    "NOVELTY"
  ],
  [
    "The novelty is incremental . No new insight is provided toward this topic",
    "NOVELTY"
  ],
  [
    "But the novelty is still not significant .",
    "NOVELTY"
  ],
  [
    "The originality of the work , the importance of the problem and the clarity of the presentation outweighs the previously mentioned point .",
    "NOVELTY"
  ],
  [
    "In that sense the work is original and interesting .",
    "NOVELTY"
  ],
  [
    "while",
    "NOVELTY"
  ],
  [
    "From the perspective , the problem formulation is a nice contribution .",
    "NOVELTY"
  ],
  [
    "I do not see this contribution enough for a ICLR paper .",
    "NOVELTY"
  ],
  [
    "I thinks that a representation of a binary net based on a continuation approach is quite interesting",
    "NOVELTY"
  ],
  [
    "and the idea seems fairly original",
    "NOVELTY"
  ],
  [
    "although the regularisation approach itself is not new .",
    "NOVELTY"
  ],
  [
    "Introduced a regularization technique that had not been previously used in this field , and that improves on the group lasso in terms of compression , without apparent loss of accuracy .",
    "NOVELTY"
  ],
  [
    "The work focuses on a novel problem of generating text sample using GAN and a novel in-filling mechanism of words .",
    "NOVELTY"
  ],
  [
    "The work indeed use a novel mechanism of in-filling via a conditioning approach to overcome the difficulties of GAN training in text settings .",
    "NOVELTY"
  ],
  [
    "Using a novel in-filling procedure to overcome the complexities in GAN training",
    "NOVELTY"
  ],
  [
    "The results are not a strict improvement over existing works .",
    "NOVELTY"
  ],
  [
    "outstanding",
    "NOVELTY"
  ],
  [
    "I view the technical contributions of this work to be at best incremental ; it does not seem to address any significant technical challenge to be able to integrate the various known tools in their work .",
    "NOVELTY"
  ],
  [
    "This new convergence study is very interesting .",
    "NOVELTY"
  ],
  [
    "I think it 's a solid contribution which warrants publication",
    "NOVELTY"
  ],
  [
    "while the proposed methodology seems interesting/novel",
    "NOVELTY"
  ],
  [
    "Overall this paper has an interesting idea and does some preliminary work to evaluate it",
    "NOVELTY"
  ],
  [
    "Originality This idea is fairly original , proposing to implicitly learn what is recognizably a predictive model of the environment without a prediction objective .",
    "NOVELTY"
  ],
  [
    "It has a clever idea but",
    "NOVELTY"
  ],
  [
    "The UPS optimizer by itself is not new .",
    "NOVELTY"
  ],
  [
    "The use of residual learning combined with entropy minimization learning criterion to jointly learn the source and target classifier is new and smart",
    "NOVELTY"
  ],
  [
    "It is then partially incremental in my opinion but still it is a nice use of residual learning idea .",
    "NOVELTY"
  ],
  [
    "The setup and result proven here are very similar to those of previous works",
    "NOVELTY"
  ],
  [
    "Since the improvements are ultimately incremental",
    "NOVELTY"
  ],
  [
    "I believe they do carry some novelty",
    "NOVELTY"
  ],
  [
    "the overall improvements are not ground-breaking in terms of PSNR values",
    "NOVELTY"
  ],
  [
    "One could think that it makes a somewhat incremental contribution with respect to the more complete work ( both theory and practice ) from [ Bartlett et al .2017 ]",
    "NOVELTY"
  ],
  [
    "The method of neighbor prediction is a simple and small modification of the original auto-encoder , but seems to provide a way to augment the targets such that intra-class distance of decoder targets can be tightened",
    "NOVELTY"
  ],
  [
    "Filling missing values is not new .",
    "NOVELTY"
  ],
  [
    "To put",
    "NOVELTY"
  ],
  [
    "it in a nutshell , they present a nice ( but not so novel",
    "NOVELTY"
  ],
  [
    ") idea",
    "NOVELTY"
  ],
  [
    "It proposes a new solution to one of the fundamental problems in the field , which significantly improves previous solutions",
    "NOVELTY"
  ],
  [
    "While the discussion of",
    "NOVELTY"
  ],
  [
    "the idea of minimizing Hellinger distance is I believe novel",
    "NOVELTY"
  ],
  [
    "a new loss with potential for improvement over other losses",
    "NOVELTY"
  ],
  [
    "much of the analysis is not new - unclear if the proposed loss will improve the state of the art",
    "NOVELTY"
  ],
  [
    "While the idea proposed in the paper is somewhat novel",
    "NOVELTY"
  ],
  [
    "proposed approach , I thought the paper is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "-- -- The contribution and novelty of the paper is relatively limited other than the use of Shapley value .",
    "NOVELTY"
  ],
  [
    "I think the idea of using this to harden existing DNNs is a good one",
    "NOVELTY"
  ],
  [
    "its contribution to the high accuracy is unclear",
    "NOVELTY"
  ],
  [
    "I believe that the idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "In general i find the paper interesting , with nice ideas and I believe that will be appreciated from researchers that are interested on control theory/signal processing and information theory",
    "NOVELTY"
  ],
  [
    "The focus on structured classifiers ( decision trees in this case ) is novel",
    "NOVELTY"
  ],
  [
    "This makes the contribution somewhat limited",
    "NOVELTY"
  ],
  [
    "The result is a bit incremental , since they shave the approximation ratio from O",
    "NOVELTY"
  ],
  [
    "the contributions are not enough for this venue .",
    "NOVELTY"
  ],
  [
    "The paper takes a fairly novel approach to establish approximate maximum entropy .",
    "NOVELTY"
  ],
  [
    "The introduction of the differentiable approximation of the sorting operator is interesting and seems novel .",
    "NOVELTY"
  ],
  [
    "The techniques described in the paper range from only mildly novel",
    "NOVELTY"
  ],
  [
    "to very obvious",
    "NOVELTY"
  ],
  [
    ".Additionally , the paper 's contributions amount to tweaks to a previously existing algorithm .",
    "NOVELTY"
  ],
  [
    "The quality of the results make this a significant contribution in my view",
    "NOVELTY"
  ],
  [
    "Only presents ( in some cases obvious ) tweaks to a previous algorithm",
    "NOVELTY"
  ],
  [
    "This seems to be the major contribution of the paper and should be given prominence",
    "NOVELTY"
  ],
  [
    "The idea of including the output information on least-square problems is new .",
    "NOVELTY"
  ],
  [
    ", albeit a bit incremental in its approach .",
    "NOVELTY"
  ],
  [
    "they can easily generalise to novel tasks",
    "NOVELTY"
  ],
  [
    "This makes the approach not applicable to novel objects or even objects with minor color changes .",
    "NOVELTY"
  ],
  [
    "with solid contributions : to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "Overall , I do like the paper 's key ideas .",
    "NOVELTY"
  ],
  [
    "Overall the originality of the method is marginal .",
    "NOVELTY"
  ],
  [
    "The work is a nice combination of developments in a few fields -- applying analysis and concepts from machine teaching to concept learning in forgetful humans . To the best of my knowledge , the theoretical analysis is novel .",
    "NOVELTY"
  ],
  [
    "there is not much theoretical insight or `` recreative `` introduction of the DIM method from the authors ' perspectives",
    "NOVELTY"
  ],
  [
    "The proposed idea is novel , and a very interesting take on forcing internal models upon function approximators which begs for future work .",
    "NOVELTY"
  ],
  [
    "this work is limited in several ways",
    "NOVELTY"
  ],
  [
    "To my knowledge , the idea of coupling perturbations across examples is a new idea , and worthy of additional exploration . This paper makes a nice contribution in that direction .",
    "NOVELTY"
  ],
  [
    "this paper would be a strong contribution in originality , quality , and significance",
    "NOVELTY"
  ],
  [
    "black box attacks are extremely weak",
    "NOVELTY"
  ],
  [
    "the paper proposes a promising idea ( computing perturbations which are coupled across examples",
    "NOVELTY"
  ],
  [
    "It is a novel approach , obtained through relatively straightforward extension of previously introduced ones .",
    "NOVELTY"
  ],
  [
    "My only concern about this paper is the novelty",
    "NOVELTY"
  ],
  [
    "The derived bounds and procedures are interesting and nontrivial ,",
    "NOVELTY"
  ],
  [
    "I like the idea of exploiting graph decomposition .",
    "NOVELTY"
  ],
  [
    "Again , I like this idea and believe better exploiting structure in the propagation could improve the inference in many ways",
    "NOVELTY"
  ],
  [
    "The iterative quantization approach has limited novelty .",
    "NOVELTY"
  ],
  [
    "The idea that additional errors are revealed and allow classifiers to adapt , thus boosting classifier performance , is appealing and intuitive .",
    "NOVELTY"
  ],
  [
    "The discussion and extensions in Sec 3.2 are interesting",
    "NOVELTY"
  ],
  [
    "Overall , I consider this submission a very positive contribution to NIPS .",
    "NOVELTY"
  ],
  [
    "this paper seems like a potentially significant advance",
    "NOVELTY"
  ],
  [
    "and insightful",
    "NOVELTY"
  ],
  [
    "As the authors point out , the idea of using a batch-normalization like strategy to set an adaptive learning rate has already been explored in the WNGrad paper",
    "NOVELTY"
  ],
  [
    "and insightful discussion of batch normalization",
    "NOVELTY"
  ],
  [
    "although I would be prepared to concede in relation to the NIPS reviewer guidelines that in some sense the progress is incremental rather than revolutionary",
    "NOVELTY"
  ],
  [
    "But this is well beyond the scope of a single NIPS contribution",
    "NOVELTY"
  ],
  [
    "And the contribution is original .",
    "NOVELTY"
  ],
  [
    "The proposed approach strikes me as quite similar to One-Shot Imitation Learning by Domain-Adaptive Meta-Learning ( Yu et al .2018",
    "NOVELTY"
  ],
  [
    "The work introduces a beautiful formalism and a host of reasoning-related operations .",
    "NOVELTY"
  ],
  [
    "Nevertheless , it appears to me as an honest , original and rigorous theoretical study",
    "NOVELTY"
  ],
  [
    "-- An interesting proposal for a smaller CNN architecture designed for embedded CNN applications",
    "NOVELTY"
  ],
  [
    "albeit small )",
    "NOVELTY"
  ],
  [
    "find the proposed methods intuitive and the experiment evaluations interesting",
    "NOVELTY"
  ],
  [
    "Although the proposed method is of limited novelty ( a straightforward extension to TLSTM ) and the proposed methods for static/decay features feels somehow trivial",
    "NOVELTY"
  ],
  [
    "Overall , I found the idea of learning controllable parameters interesting .",
    "NOVELTY"
  ],
  [
    "The paper seems overall a bit incremental with respect to prior work on style transfer .",
    "NOVELTY"
  ],
  [
    "in terms of novelty , most of the techniques utilized in this work were developed in existing works",
    "NOVELTY"
  ],
  [
    "I think the idea is fairly unique \u00e2\u0080\u0093 having a general algorithm that provably works with high probability for different models given enough samples is meritorious",
    "NOVELTY"
  ],
  [
    "While the contributions are clear",
    "NOVELTY"
  ],
  [
    "The identification results themselves are not particularly novel as similar results have been proven in other settings , but",
    "NOVELTY"
  ],
  [
    "the context is new",
    "NOVELTY"
  ],
  [
    "but relatively lack the novelty in terms of the algorithm",
    "NOVELTY"
  ],
  [
    "The proposed algorithm lack novelty .",
    "NOVELTY"
  ],
  [
    "from the reviews it seems that all the reviewers agree that the novelty of this paper is limited , and the contribution is incremental .",
    "NOVELTY"
  ],
  [
    "However , from the modeling perspective , I still think the novelty is limited .",
    "NOVELTY"
  ],
  [
    "Novelty : I would say the novelty of this paper is rather limited .",
    "NOVELTY"
  ],
  [
    "I think this paper is not novel enough .",
    "NOVELTY"
  ],
  [
    "The idea of heating up the temperature in softmax is interesting , and seems novel in the literature of metric learning .",
    "NOVELTY"
  ],
  [
    "The formulation of tempered softmax with normalization is already presented in [ Wang et al. , 2017 ] .",
    "NOVELTY"
  ],
  [
    "The results are novel as far as I can tell , and interesting .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is limited or not clear at all ,",
    "NOVELTY"
  ],
  [
    "Overall , The paper should be rejected because the paper have minor extensions to each of their modules but lacking any major important contribution .",
    "NOVELTY"
  ],
  [
    "The bidirectional gated GNN doesn \u2019 t seem novel enough in comparison to previous work 2 ) I believe RL to Graph2Seq is a minor extension from Seq2Seq",
    "NOVELTY"
  ],
  [
    "Overall , this is a good paper that presents an important contribution .",
    "NOVELTY"
  ],
  [
    "This surprising result , to the best of my knowledge , is new and of genuine interest .",
    "NOVELTY"
  ],
  [
    "Extension of the relativistic GAN [ 1 ] to the proposed setting is interesting .",
    "NOVELTY"
  ],
  [
    "The idea of additionally supporting the latent embedding , created by a VAE , by using available textual descriptors seems promising .",
    "NOVELTY"
  ],
  [
    "It is a relatively novel method for network de-noising \u00e2\u0080\u0093 combining multiple networks from noisy observations of the true underlying networks , in particular network that is made of more or less clear clusters .",
    "NOVELTY"
  ],
  [
    "I think the architecture proposed is certainly interesting .",
    "NOVELTY"
  ],
  [
    "There appears to be sufficient originality .",
    "NOVELTY"
  ],
  [
    "but it is original in that it minimizes a symmetric KL divergence",
    "NOVELTY"
  ],
  [
    "new problem that has not been considered previously in NAS and object detection research",
    "NOVELTY"
  ],
  [
    "The contributions of the paper to the literature are significant .",
    "NOVELTY"
  ],
  [
    "The authors introduce several new geometrical concepts and tools for the subspace clustering problem that do not seem to have been utilized before in the literature , and could potentially be of interest in other problems as well .",
    "NOVELTY"
  ],
  [
    "given the lack of theoretical novelty",
    "NOVELTY"
  ],
  [
    "I liked this idea very much and I even think that everyone should also use this version instead of the standard ones",
    "NOVELTY"
  ],
  [
    "From a machine learning / representation learning perspective , I do not consider the paper is innovative enough .",
    "NOVELTY"
  ],
  [
    "Currently a generic bound is employed which is not very insightful in my opinion",
    "NOVELTY"
  ],
  [
    "The idea of explicitly appending the patch positions to the representations is interesting",
    "NOVELTY"
  ],
  [
    "The novelty of this work is lacking .",
    "NOVELTY"
  ],
  [
    "I assume that that the idea of using an approximate Newton method based on relative approximations as in Definition 2 is * not* new -- -is this correct",
    "NOVELTY"
  ],
  [
    "From my understanding , this paper does not show a significant contribution to the related research area .",
    "NOVELTY"
  ],
  [
    "I really like this approach , that tries to find methods that converge globally to ( mixed ) Nash equilibriums .",
    "NOVELTY"
  ],
  [
    "the concept and methodology and not very new ( but well thought-out )",
    "NOVELTY"
  ],
  [
    "I feel it is a significant contribution and this paper is worth accepted .",
    "NOVELTY"
  ],
  [
    "The basic idea of this work is not new ,",
    "NOVELTY"
  ],
  [
    "I think with the promised fixes this will be a strong paper with an original idea that could be simple enough to be used in practice",
    "NOVELTY"
  ],
  [
    "The visual results and motivation from the view of compression are nice",
    "NOVELTY"
  ],
  [
    "The idea of maintaining the uncertainty for each hidden node is actually interesting .",
    "NOVELTY"
  ],
  [
    "I think the proposed method in this paper focuses on the modification on the regularization which only provides incremental improvement with respect to VCL",
    "NOVELTY"
  ],
  [
    "While I am not familiar with the corpus of work on this particular",
    "NOVELTY"
  ],
  [
    "assuming they are the first to tackle it in this particular context I find their idea to be quite interesting and worthy of inclusion in NIPS this year .",
    "NOVELTY"
  ],
  [
    "the use of binary indicator with Gumbel-softmax relaxation has been utilized in a lot of previous works",
    "NOVELTY"
  ],
  [
    "The idea of reimplementing an iterative algorithm in a deep architecture is not new , and the combination of safegarding with KM has already been analyzed",
    "NOVELTY"
  ],
  [
    "This is an interesting and promising method",
    "NOVELTY"
  ],
  [
    "While this work is conceptually interesting",
    "NOVELTY"
  ],
  [
    ", the technical novelty and contributions seem fairly minimal .",
    "NOVELTY"
  ],
  [
    "The technical novelty of the proposed approach is fairly minimal . The experiments also do not support a lot of novelty claims",
    "NOVELTY"
  ],
  [
    "I liked this paper : there",
    "NOVELTY"
  ],
  [
    "creative component in the overall proposed solution",
    "NOVELTY"
  ],
  [
    "I also liked the idea of `` similar-encoder ``",
    "NOVELTY"
  ],
  [
    "The approach proposed is novel to my knowledge . The work is a good continuation of the line of research that focuses on embedding into",
    "NOVELTY"
  ],
  [
    "Style I like the idea of testing many different factorisation structures .",
    "NOVELTY"
  ],
  [
    "I find the general direction of the paper very interesting and I",
    "NOVELTY"
  ],
  [
    "This formulation seems interesting and novel to me",
    "NOVELTY"
  ],
  [
    "The analysis and a bound on matrix recovery using the spectral k-support norm appear to be novel .",
    "NOVELTY"
  ],
  [
    "As far as I can see , the paper contains almost no novelty as it crudely puts together three existing algorithms without presenting enough",
    "NOVELTY"
  ],
  [
    "the algorithm itself is a just simple addition of well-known techniques",
    "NOVELTY"
  ],
  [
    "none of which is proposed in the current paper",
    "NOVELTY"
  ],
  [
    "The work is original ,",
    "NOVELTY"
  ],
  [
    "but I would say incremental",
    "NOVELTY"
  ],
  [
    "The novelty of the idea and the contribution of the theoretical analysis is somewhat limited",
    "NOVELTY"
  ],
  [
    "I think the idea of inferring programmatic descriptions of handwritten diagrams is really cool , and that the combination of SMC-based inference with constraint-based synthesis is nice .",
    "NOVELTY"
  ],
  [
    "The key idea of BP , searching on the class boundary manifold , is interesting and promising .",
    "NOVELTY"
  ],
  [
    "and presents some though-provoking ideas",
    "NOVELTY"
  ],
  [
    "Technical novelty is limited .",
    "NOVELTY"
  ],
  [
    "the idea of comparing the novel solution just with AlexNet is not adding much to the present landscape of methods to tackle this problem .",
    "NOVELTY"
  ],
  [
    "Applying meta-learning to this setting is a novel and interesting approach and appears to have",
    "NOVELTY"
  ],
  [
    "As such It has questionable novelty and limited potential impact .",
    "NOVELTY"
  ],
  [
    "but lacks any depth or clear important contribution .",
    "NOVELTY"
  ],
  [
    "I find the significance low as the work is incremental and has technical rather than theoretical statements , and lacks a clear contribution .",
    "NOVELTY"
  ],
  [
    "The models seems to advance the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "It significantly improves over previous state-of-the-art on two popular video action recognition",
    "NOVELTY"
  ],
  [
    "The downside of this paper is the limited novelty .",
    "NOVELTY"
  ],
  [
    "and the temporal convolution is not new either [",
    "NOVELTY"
  ],
  [
    "Since this paper mainly consists of incremental ideas on previous work",
    "NOVELTY"
  ],
  [
    "The approach proposed in section 3.2 uses dropout logits and the sensitivity criterion between two softmax probability distributions which seems novel .",
    "NOVELTY"
  ],
  [
    "which is novel and enable interesting applications on image retrieval",
    "NOVELTY"
  ],
  [
    "The major concern of mine is its weaknesses in clarity and technical novelty .",
    "NOVELTY"
  ],
  [
    "The proposed technique itself is not new but a straightforward extension of an existing work",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "There is some novelty to the ideas presented and the",
    "NOVELTY"
  ],
  [
    "The paper builds upon existing spectral methods for parametric HMMs but introduces novel techniques to extend those approaches to the non-parametric case .",
    "NOVELTY"
  ],
  [
    "The combination of deep Koopman operator with graph neural nets is very novel and interesting .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is a novel and interesting idea , which is a neat application of ideas from the neural programs space .",
    "NOVELTY"
  ],
  [
    "The technique that relates the two trajectories through a differential equation is easy-to-use and",
    "NOVELTY"
  ],
  [
    "and I consider it the main highlight of the paper . I also like the idea of using the known results for l2-regularized ERM to analyze GD with early stopping .",
    "NOVELTY"
  ],
  [
    "On the positive side , the proposed technique seems novel and clever",
    "NOVELTY"
  ],
  [
    "The technique , however , resembles greatly the image decomposition problem , e.g. , for separating mixtures of the intrinsic and reflection layers in previous literatures",
    "NOVELTY"
  ],
  [
    "I think the proposed approach is interesting but",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "the paper contains an interesting idea",
    "NOVELTY"
  ],
  [
    "the proposed model is a slight variation of the previous work [ 1",
    "NOVELTY"
  ],
  [
    "The improved upper bound for maxout networks follows a similar intuition but appears to be novel",
    "NOVELTY"
  ],
  [
    "this is the first work combining it for attention for image captioning .",
    "NOVELTY"
  ],
  [
    "Open-sourcing the platform is a good contribution to the community .",
    "NOVELTY"
  ],
  [
    "and appears interesting",
    "NOVELTY"
  ],
  [
    "the streaming setting",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "the experiments showing that perm-set prediction handles them well is interesting and promising .",
    "NOVELTY"
  ],
  [
    "-- Related work To the best of my knowledge it 's representative .",
    "NOVELTY"
  ],
  [
    "I think the paper is original .",
    "NOVELTY"
  ],
  [
    "Although the idea of this paper seems to be natural",
    "NOVELTY"
  ],
  [
    "The proposed improved DPN is very incremental",
    "NOVELTY"
  ],
  [
    "The technical novelty and contribution is not significant .",
    "NOVELTY"
  ],
  [
    "However the theoretical analysis on complexity is original to my knowledge and",
    "NOVELTY"
  ],
  [
    "The datasets used for evaluation are quite old .",
    "NOVELTY"
  ],
  [
    "I think that this application of adversarial networks is novel and interesting for the community of NIPS .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "presents an interesting addition to the literature and opens the",
    "NOVELTY"
  ],
  [
    "of other quadrature rules and classes of kernels .",
    "NOVELTY"
  ],
  [
    "but the conclusion that negative transfer exists is not novel .",
    "NOVELTY"
  ],
  [
    "Originality The paper provides a very non-standard approach to Bayesian inference for deep neural networks . The method is very original and interesting .",
    "NOVELTY"
  ],
  [
    "Significance The paper proposes a new ingenious approach to Bayesian deep learning .",
    "NOVELTY"
  ],
  [
    "While there is not much contribution in terms of technical novelty",
    "NOVELTY"
  ],
  [
    ", I think this is an interesting paper that sheds new lights on limitations of existing methods for learning sentence and document representations .",
    "NOVELTY"
  ],
  [
    "The idea that introduces labels in VAE is not novel .",
    "NOVELTY"
  ],
  [
    "the application of the Riesz-Torin theorem is non-trivial",
    "NOVELTY"
  ],
  [
    "so I think this is a decent contribution",
    "NOVELTY"
  ],
  [
    "The paper improves upon the main work from Yaida et",
    "NOVELTY"
  ],
  [
    "I think the",
    "NOVELTY"
  ],
  [
    "I am afraid the ML contribution of this work is in my opinion almost non existent .",
    "NOVELTY"
  ],
  [
    "I found the paper and the idea very exciting . Injecting domain knowledge by forcing the output ( or differentiable transformations thereof ) to be consistent with the physics is a quite relevant and appealing",
    "NOVELTY"
  ],
  [
    "Framing the problem of completing missing flow data as an inpainting task is also original .",
    "NOVELTY"
  ],
  [
    "While quite exciting , I am not confident the contribution is original enough from an ML point of view for ICLR , although it is certainly novel for fluid dynamics .",
    "NOVELTY"
  ],
  [
    "The idea of measuring the uniformity of mini-batch gradients through VMF distribution seems interesting .",
    "NOVELTY"
  ],
  [
    "Originality The theoretical results are original , and the SGD approach is a",
    "NOVELTY"
  ],
  [
    "priori original as well",
    "NOVELTY"
  ],
  [
    "the development of each of them appears limited Comments",
    "NOVELTY"
  ],
  [
    "Introducing features and an actor/critic setup is n't an amazing innovation",
    "NOVELTY"
  ],
  [
    "I believe that the paper makes a significant contribution and should be accepted for publication",
    "NOVELTY"
  ],
  [
    "I had a hard time understanding the contributions of this paper .",
    "NOVELTY"
  ],
  [
    "I\u00e2\u0080\u0099m unsure about the originality of the content",
    "NOVELTY"
  ],
  [
    "Just using a continuous time representation ( that get discretized later anyways ) would not convince me of sufficient novelty",
    "NOVELTY"
  ],
  [
    ", with very interesting ideas but for the moment the concerns that I have raised prevent me from giving it a clear accept",
    "NOVELTY"
  ],
  [
    "and presents an elegant approach",
    "NOVELTY"
  ],
  [
    "The two-phase analysis is interesting and novel",
    "NOVELTY"
  ],
  [
    "Originality The originality is low .",
    "NOVELTY"
  ],
  [
    "The method 's improvement over other intrinsic reward approaches is minor",
    "NOVELTY"
  ],
  [
    "Nevertheless the paper does not propose by itself any novel idea for text classification .",
    "NOVELTY"
  ],
  [
    "Strengths of the paper",
    "NOVELTY"
  ],
  [
    "nice overview of the problem motivation",
    "NOVELTY"
  ],
  [
    "simple and straight-forward idea behind the algorithm Weaknesses of the paper",
    "NOVELTY"
  ],
  [
    "s nice a nice study of the query completion application",
    "NOVELTY"
  ],
  [
    "Overall I think that this paper has some interesting ideas .",
    "NOVELTY"
  ],
  [
    "This is an interesting and novel paper .",
    "NOVELTY"
  ],
  [
    "The idea of an accelerated version of variance reduced stochastic extragradient method is novel .",
    "NOVELTY"
  ],
  [
    "As far as I understand , the algorithms presented in the paper are not substantially new ,",
    "NOVELTY"
  ],
  [
    "but the analysis of these algorithms is novel",
    "NOVELTY"
  ],
  [
    "To my knowledge , the authors are the first to attempt this and I expect more similar methods in the future",
    "NOVELTY"
  ],
  [
    "While the Ising influence maximization problem is a novel departure from the traditional epidemic process",
    "NOVELTY"
  ],
  [
    "the work is interesting",
    "NOVELTY"
  ],
  [
    "Because the general idea of the paper is very interesting and the first results are promising",
    "NOVELTY"
  ],
  [
    "The proposed method is not very original in the sense that it is a combination of several known techniques .",
    "NOVELTY"
  ],
  [
    "The proposed approach is a combination of well known methods .",
    "NOVELTY"
  ],
  [
    "However , this contribution is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "these papers are very new ,",
    "NOVELTY"
  ],
  [
    "The idea is very interesting and",
    "NOVELTY"
  ],
  [
    "I think this paper can be a good contribution to",
    "NOVELTY"
  ],
  [
    "The proposed method produces impressive samples of high quality and high diversity , with a novel approach .",
    "NOVELTY"
  ],
  [
    "However the proposed approach of requesting expert feedback for the top ranked anomalies is straightforward and unsurprising , given past work on active learning",
    "NOVELTY"
  ],
  [
    "I think this combination is new for the semantic image synthesis task",
    "NOVELTY"
  ],
  [
    "and the combination seems novel",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are unclear to me",
    "NOVELTY"
  ],
  [
    "I agree that this is a contribution",
    "NOVELTY"
  ],
  [
    "but since this dataset is built upon an existing dataset with source code , and the dataset construction techniques themselves are not novel , especially for machine learning community , I do not see a significant contribution in this part .",
    "NOVELTY"
  ],
  [
    "The proposed approach is new",
    "NOVELTY"
  ],
  [
    ", but the technical novelty is marginal .",
    "NOVELTY"
  ],
  [
    "1 has already been explored by previous works which should be discussed in the paper",
    "NOVELTY"
  ],
  [
    "But I think the aspect of using this for the studying learning problems , such as sequential testing and multi-arm bandit problem , is a new and interesting perspective .",
    "NOVELTY"
  ],
  [
    "The approaches are interesting and smart .",
    "NOVELTY"
  ],
  [
    "To my knowledge , it \u2019 s the first time that the RL algorithm is applied to causal discovery area for structure searching .",
    "NOVELTY"
  ],
  [
    "Overall , the idea of this paper is novel ,",
    "NOVELTY"
  ],
  [
    "The lower bound and adaptive upper bound for this problem are novel .",
    "NOVELTY"
  ],
  [
    "and the proposed approach seems interesting and novel enough .",
    "NOVELTY"
  ],
  [
    "Whether the work is very novel is not clear : both of the main contributions ( shape of the generative distribution and using the context / attention ) have already been done before ( albeit maybe not in exactly the same context ) .",
    "NOVELTY"
  ],
  [
    "This mismatch problem is not new",
    "NOVELTY"
  ],
  [
    "Section 3 does not actually provide a new insight .",
    "NOVELTY"
  ],
  [
    "The proposed method is a novel combination of well-known techniques .",
    "NOVELTY"
  ],
  [
    "1 .I have a difficult time identifying the ( large enough ) novel contribution .",
    "NOVELTY"
  ],
  [
    "The `` selfish `` setting of the paper is novel and well-motivated by real-world scenarios .",
    "NOVELTY"
  ],
  [
    "one of the main components in the proposed method is based on Tulsiani et al .CVPR'18 .The remaining components of the proposed method are not very new",
    "NOVELTY"
  ],
  [
    "I am not very sure whether the novelty of the paper is significant .",
    "NOVELTY"
  ],
  [
    "my feeling about this paper is that the link between the different contributions does not stand out so clearly",
    "NOVELTY"
  ],
  [
    "Based on the widely used GLM model , the authors explicitly model different connectivity patterns , which is novel",
    "NOVELTY"
  ],
  [
    "Overall , this paper makes some progress , improving previous results on over-parametrized networks .",
    "NOVELTY"
  ],
  [
    "CNN was covered in previous related works ( so weight sharing is not a new contribution )",
    "NOVELTY"
  ],
  [
    "Given that the oblivious shuffle is from prior work , the novelty of the proposed algorithms seems incremental at best .",
    "NOVELTY"
  ],
  [
    "The significance of the proposed algorithms seems minor given prior work .",
    "NOVELTY"
  ],
  [
    "I think that the contribution of the proposed algorithms over prior works is non-trivial",
    "NOVELTY"
  ],
  [
    "The results presented are well known and there is no clear contribution algorithmic-wise to the field of RL .",
    "NOVELTY"
  ],
  [
    "The originality comes from the conciseness of the proof and how it relates to other works outside ML",
    "NOVELTY"
  ],
  [
    "Thus , this contribution seems minor and out of the scope of the conference which focus on representation learning for ML and RL .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is therefore minor .",
    "NOVELTY"
  ],
  [
    "The task of building real-life attack on Alexa was nontrivial ,",
    "NOVELTY"
  ],
  [
    "and I like the approach presented",
    "NOVELTY"
  ],
  [
    "Overall the paper combines ideas from several previous works in ways that are not sufficiently novel in the opinion of this reviewer",
    "NOVELTY"
  ],
  [
    "this is definitely not the first work on semi-supervised formed few-shot learning .",
    "NOVELTY"
  ],
  [
    "Another concern is that the novelty . This work is highly incremental since it is an extension of existing prototypical networks by adding the way of leveraging the unlabeled data .",
    "NOVELTY"
  ],
  [
    "-- Since CounMin is closely related to Bloom filters the idea of using machine learning to speed it up appears to be noticeably less novel given that for Bloom filters this has already been done by Mitzenmacher",
    "NOVELTY"
  ],
  [
    "This is a good idea",
    "NOVELTY"
  ],
  [
    "but the work itself may be too incremental as it lacks some global analysis of the algorithms presented",
    "NOVELTY"
  ],
  [
    "Overall the strength of this paper is that the main insight is quite interesting",
    "NOVELTY"
  ],
  [
    "I think the contributions of this work is incremental compared with [ Luo et al ( 2018 ) ] in which the major difference is the partial zero sum reward structure is used and the observations and actions information from the tracker are incorporated into the target network , while the network architecture is quite similar to [ Luo et al ( 2018",
    "NOVELTY"
  ],
  [
    "The proposed approach and angle being looked at in the paper is novel in the sense that while prior work has mostly focused on characterizing concepts which are salient .",
    "NOVELTY"
  ],
  [
    "While the proposed approach and evaluation metrics are novel",
    "NOVELTY"
  ],
  [
    "10 This is a novel paper that is well motivated and executed .",
    "NOVELTY"
  ],
  [
    "all of its components are not novel alone -- grid linear mixture for image augmentation",
    "NOVELTY"
  ],
  [
    "The proposed pipeline itself is new and does provide insight that end-to-end image-augmentation is feasible with a strong generator initialization .",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "I find the originality to be good .",
    "NOVELTY"
  ],
  [
    "The contrast module seems novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "there is clear architectural novelty",
    "NOVELTY"
  ],
  [
    "introduce a novel tunable class of losses for ( DNN ) classification by replacing the usual logistic loss .",
    "NOVELTY"
  ],
  [
    "In this perspective , the paper is novel .",
    "NOVELTY"
  ],
  [
    "The idea , and perhaps more so the applications thereof , is seemingly novel and its explanation is given straightforwardly while avoiding getting bogged down in technical details",
    "NOVELTY"
  ],
  [
    "In terms of novelty I find the method somewhat lacking",
    "NOVELTY"
  ],
  [
    "The other types of constraints add some more novelty , however .",
    "NOVELTY"
  ],
  [
    "Still , the contribution is relatively minor and does n't really provide large empirical wins in large data settings .",
    "NOVELTY"
  ],
  [
    "a promising approach and I look forward to seeing it applied in problems like inverse reinforcement learning and deterministic policy gradients for continuous control",
    "NOVELTY"
  ],
  [
    "The paper is original and",
    "NOVELTY"
  ],
  [
    "It is a wonderful combination of relatively simple tools to achieve something unexpected .",
    "NOVELTY"
  ],
  [
    "Originality To the best of my knowledge , both the graphics-to-statements method as well as the biased statements-to-program method are new contributions that pull together ideas from a wide range of different fields .",
    "NOVELTY"
  ],
  [
    "The idea paper is nice however",
    "NOVELTY"
  ],
  [
    "However , I am not very certain about the novelty of the paper",
    "NOVELTY"
  ],
  [
    "and I find the contribution simple , but interesting .",
    "NOVELTY"
  ],
  [
    "correctly identified .",
    "NOVELTY"
  ],
  [
    "The proposed model is interesting",
    "NOVELTY"
  ],
  [
    "Nice extension of existing line of work tensor-factorisation based MTL .",
    "NOVELTY"
  ],
  [
    "Novelty/significance is limited .",
    "NOVELTY"
  ],
  [
    "However , such architecture is not really new",
    "NOVELTY"
  ],
  [
    "The paper introduces a relatively simple method for imitation learning",
    "NOVELTY"
  ],
  [
    "I find the idea proposed by the authors to be interesting .",
    "NOVELTY"
  ],
  [
    "Looking at density estimation through the adversarial losses is quite new and the results of the paper are the ones we are looking for",
    "NOVELTY"
  ],
  [
    "the ideas are quite classical and I am confident that the results can be reproduced",
    "NOVELTY"
  ],
  [
    "I like the idea and the proposed applications .",
    "NOVELTY"
  ],
  [
    "Some of the suggested insights in the analysis of defense techniques are interesting",
    "NOVELTY"
  ],
  [
    "The is not much technical novelty .",
    "NOVELTY"
  ],
  [
    "it looks like a very interesting approach to use copula decomposition in the center of autoencoder for generative models",
    "NOVELTY"
  ],
  [
    "I agree that the paper scores high on novelty/contribution",
    "NOVELTY"
  ],
  [
    "so in that sense it may be original",
    "NOVELTY"
  ],
  [
    "The idea that there are two phases of optimization is not particularly new",
    "NOVELTY"
  ],
  [
    "this paper is very clear originality : this paper combines original ideas with existing approaches for pruning to obtain dramatic space reduction in NN parameters",
    "NOVELTY"
  ],
  [
    "the universality of this selection across a layer",
    "NOVELTY"
  ],
  [
    "Overall , the idea of formulating graph representation learning as a language model is interesting .",
    "NOVELTY"
  ],
  [
    "2 .The techniques seems novel and innovative which is different from past work .",
    "NOVELTY"
  ],
  [
    "3 .The idea of a pseudo loss and coupling that to the true loss is interesting .",
    "NOVELTY"
  ],
  [
    "I think this paper makes strong contributions to NeurIPS community as commented below",
    "NOVELTY"
  ],
  [
    "In this paper , there are two interesting theoretical contributions .",
    "NOVELTY"
  ],
  [
    "exposition is insightful",
    "NOVELTY"
  ],
  [
    "It is hard to assess `` novelty `` of this work , as the individual pieces are not novel ,",
    "NOVELTY"
  ],
  [
    "and yet the exposition of all of them in the same space with clear outline of the connections between them is novel",
    "NOVELTY"
  ],
  [
    "So I 'm not sure that Theorem 1 is really that much of an insightful breakthrough , even if it may be nice to work through the precise details in the specific case of a BN layer and the relationship to gradients",
    "NOVELTY"
  ],
  [
    "The contribution is imho rather original .",
    "NOVELTY"
  ],
  [
    "In terms of impact the result is rather technical and",
    "NOVELTY"
  ],
  [
    "Overall , the writing of this paper is good , the idea is novel and the contribution is sufficient .",
    "NOVELTY"
  ],
  [
    "While I would not call the use of masked transformations particularly novel in this setting",
    "NOVELTY"
  ],
  [
    "and I think the idea of connecting the PAC-Bayes and differential privacy is interesting .",
    "NOVELTY"
  ],
  [
    "the novelty of the approach is limited -- the approach amounts to using a sparse integer layer instead of a floating-point layer within a feed-forward architecture",
    "NOVELTY"
  ],
  [
    "This paper is not the first to propose working on the compressed domain of an image .",
    "NOVELTY"
  ],
  [
    "Their idea to utilize a decision tree for domain adaptation sounds novel .",
    "NOVELTY"
  ],
  [
    "The KL-divergence-based method is novel and has the advantage of not requiring to define any hyper-parameter .",
    "NOVELTY"
  ],
  [
    "The proposed regularization of InfoGAN is novel that assigns latent codes to contribute certain aspects of factors of variation in image generation .",
    "NOVELTY"
  ],
  [
    "The new quantile function seems novel ,",
    "NOVELTY"
  ],
  [
    "Coupling the GARCH-type models with heavy tailed models for the innovation terms is not new",
    "NOVELTY"
  ],
  [
    "I 'm not sure how much innovation there is over the existing convex method of Blum et al , and over the existing hardness results for NMF in Arora et al .",
    "NOVELTY"
  ],
  [
    "but the paper feels a little incremental ) .",
    "NOVELTY"
  ],
  [
    "In general , these approaches either are minor modifications of existing networks ( different FractalNet pooling strategies ) or are novel architectures that do not perform well .",
    "NOVELTY"
  ],
  [
    "proposes a novel approach to construct",
    "NOVELTY"
  ],
  [
    ".The paper is very interesting in general . To the best of my knowledge , the proposed feature construction ( encoding ) algorithm is novel .",
    "NOVELTY"
  ],
  [
    "The idea is quite interesting and the results at first intriguing",
    "NOVELTY"
  ],
  [
    "Although this paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "features have been previously used to improve recommender systems",
    "NOVELTY"
  ],
  [
    "Positively , the idea of combining many heterogeneous feature types into RS is ambitious and fairly novel .",
    "NOVELTY"
  ],
  [
    "The main contribution of this work is only the integration of existing models .",
    "NOVELTY"
  ],
  [
    "The conceptual advances in this submission are modest",
    "NOVELTY"
  ],
  [
    "the proposed has many differences from existing methods",
    "NOVELTY"
  ],
  [
    "Overall , I found the idea of modeling uncertainty with an ensemble of networks with possibly different structures and parameters interesting .",
    "NOVELTY"
  ],
  [
    "This weakness could have been outweighed by technical novelty , but the method is very similar to the B2N approach ( with B-RAI instead of RAI ) which in my opinion makes the novelty incremental .",
    "NOVELTY"
  ],
  [
    "I 'm still not convinced that the contribution is significant enough to pass the conference acceptance standard",
    "NOVELTY"
  ],
  [
    "This works presents yet another incremental modification of well-known architectures ( i.e. , inception network ) .",
    "NOVELTY"
  ],
  [
    "The technical contribution of this work is rather limited , being the main contribution the application of deep classification models to underwater image classification .",
    "NOVELTY"
  ],
  [
    "Overall , this paper presents an incremental contribution with respect to existing networks , just to improve 1 % the classification performance on an easy task",
    "NOVELTY"
  ],
  [
    "The proposed technique provides limited but useful contributions over existing work as in SET and DeepR .",
    "NOVELTY"
  ],
  [
    "and it is hard to get lot of new insight from the results , or a better understanding of GANs",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is marginal .",
    "NOVELTY"
  ],
  [
    "The authors proposed a novel method for cryo-EM reconstruction that extends naturally to modeling continuous generative factors of structural heterogeneity .",
    "NOVELTY"
  ],
  [
    "the thorough empirical survey ( and simple , but novel , contribution of a new semi-supervised representation learning objective )",
    "NOVELTY"
  ],
  [
    "While I am not sure whether this was the first such work on this question",
    "NOVELTY"
  ],
  [
    "I don\u00e2\u0080\u0099t see that the novelty of this work is terribly impressive though I appreciate the efforts in conducting and reporting the experiments in this paper",
    "NOVELTY"
  ],
  [
    "the 'stability training ' procedures derived based on this bounds is quite similar to some previous methods",
    "NOVELTY"
  ],
  [
    "the main algorithms are very similar to some existing methods",
    "NOVELTY"
  ],
  [
    "This idea is not new was already proposed by Clevert et at .",
    "NOVELTY"
  ],
  [
    "The parametrization of the 3D box is clever and , while it is simple geometry , I do not think I have seen it before .",
    "NOVELTY"
  ],
  [
    "It also seems to be a bit skewed towards recent",
    "NOVELTY"
  ],
  [
    "The model , algorithm and analysis seems to be novel ,",
    "NOVELTY"
  ],
  [
    "but as a standard generalisation of previous results .",
    "NOVELTY"
  ],
  [
    "The result seems novel and well motivated both in application and literature .",
    "NOVELTY"
  ],
  [
    "It is however incremental , and the scope of the paper is rather small .",
    "NOVELTY"
  ],
  [
    "I believe this paper has its contribution to the community",
    "NOVELTY"
  ],
  [
    "I like the idea that we can create some high-level supervision from unlabeled data rather than just using the low-level pixel-level supervision like in the autoencoder",
    "NOVELTY"
  ],
  [
    "The problem is that ( 1 ) is a basic compilation technique , there is not much new in it .",
    "NOVELTY"
  ],
  [
    "The originality of the paper is relatively low ( optimization of an existing algorithm ) and the contributions are incremental .",
    "NOVELTY"
  ],
  [
    "Limited contribution .",
    "NOVELTY"
  ],
  [
    "I think the contribution is to low for ICLR",
    "NOVELTY"
  ],
  [
    "a slightly above-average quality",
    "NOVELTY"
  ],
  [
    "The perspective is novel and interesting",
    "NOVELTY"
  ],
  [
    "paper proposes a nice algorithm for risk-aware reinforcement learning",
    "NOVELTY"
  ],
  [
    "I do n't think this is sufficiently novel nor interesting for the community .",
    "NOVELTY"
  ],
  [
    "The novelty only comes from the problem approximation which only uses very limited space to elaborate the contributions .",
    "NOVELTY"
  ],
  [
    "It is an incremental work with limited novelty .",
    "NOVELTY"
  ],
  [
    "Overall the proposed method does not seem very novel",
    "NOVELTY"
  ],
  [
    "this is a nice contribution .",
    "NOVELTY"
  ],
  [
    "The techniques used are straightforward and are similar to some previous work in active learning that also deals with unknown parameters",
    "NOVELTY"
  ],
  [
    "The authors suggest a very interesting idea for CRF optimization . As far as I know , this is an original direction which certainly should be explored .",
    "NOVELTY"
  ],
  [
    "Comparing with the paper by Yin et al . ( 2019 ) , it seems to me that the technical contribution is rather incremental",
    "NOVELTY"
  ],
  [
    "The idea is nice .",
    "NOVELTY"
  ],
  [
    "While the novelty of the individual algorithms is relatively meager ,",
    "NOVELTY"
  ],
  [
    "their combination is very synergistic and makes a significant contribution to the field",
    "NOVELTY"
  ],
  [
    "is widely understood and not novel",
    "NOVELTY"
  ],
  [
    "Though widely applied on the task of segmentation , the use of only uncalibrated input and extremely sparse label for depth estimation is novel .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is a nice addition to the literature on one- or few-shot learning .",
    "NOVELTY"
  ],
  [
    "The name of the paper is overly grandiose relative to what was done",
    "NOVELTY"
  ],
  [
    "The paper is a solid contribution .",
    "NOVELTY"
  ],
  [
    "The idea to use hand-crafted rewards in such a way is great and seems",
    "NOVELTY"
  ],
  [
    "I do like the paper and idea and I can imagine that such RL based fine-tuning approaches will indeed be useful for musicians",
    "NOVELTY"
  ],
  [
    "Even though the novelty might be limited",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "and although the model itself seems a somewhat incremental extension with respect to [ 5 ]",
    "NOVELTY"
  ],
  [
    ", the algorithmic approach is interesting",
    "NOVELTY"
  ],
  [
    "While the improved convergence rates for",
    "NOVELTY"
  ],
  [
    "the problem of graph reconstruction derived in the paper",
    "NOVELTY"
  ],
  [
    "does advance",
    "NOVELTY"
  ],
  [
    "the literature of",
    "NOVELTY"
  ],
  [
    "graph reconstruction , the result does n't seem to be surprising or novel altogether",
    "NOVELTY"
  ],
  [
    "This part seems like a collection of previous works and contains minimal information about the proposed method",
    "NOVELTY"
  ],
  [
    "each improvement appears to be quite incremental .",
    "NOVELTY"
  ],
  [
    "The idea is not particularly original",
    "NOVELTY"
  ],
  [
    "It proposes an original and novel solution to achieve universal node embedding based on partially permutation invariant function .",
    "NOVELTY"
  ],
  [
    "Since the core of graph generation model is not original of the authors",
    "NOVELTY"
  ],
  [
    "This makes the proposal less convincing in terms of the novelty and the contribution compared to the recent dissent-VAEs .",
    "NOVELTY"
  ],
  [
    "I think this paper is novel and significant .",
    "NOVELTY"
  ],
  [
    "as far as I understand the paper , the tools used to analyze the last iterate of SGD are not new ,",
    "NOVELTY"
  ],
  [
    "yet the results on least square are novel and deserve some attention",
    "NOVELTY"
  ],
  [
    "I think the contribution of this paper is incremental and the idea is of less novelty .",
    "NOVELTY"
  ],
  [
    "In terms of novelty , the combination of auto-encoder RNNs and hyper-networks is not entirely novel and it has previously been developed",
    "NOVELTY"
  ],
  [
    "the two architectures are sufficiently different",
    "NOVELTY"
  ],
  [
    "and the current work is novel enough in my opinion",
    "NOVELTY"
  ],
  [
    "To my best knowledge the proposed approach in the paper is new .",
    "NOVELTY"
  ],
  [
    "The technical novelty ( considering the two-step solution ) is limited though",
    "NOVELTY"
  ],
  [
    "The Gauss-LDA and glove-DMM work is fairly dated (",
    "NOVELTY"
  ],
  [
    "The idea of using the hierarchical structure of the labels is innovative and",
    "NOVELTY"
  ],
  [
    "This paper presents a novel and interesting MCMC method on top of the belief propagation solution for approximating the partition function in binary graphical models",
    "NOVELTY"
  ],
  [
    "and makes several interesting discoveries",
    "NOVELTY"
  ],
  [
    "Overall , I believe this paper is a nice contribution to the deep learning theory literature .",
    "NOVELTY"
  ],
  [
    "A novel loss function that considers the loss functions for both strong and weak classifiers is proposed .",
    "NOVELTY"
  ],
  [
    "The deep ensemble method considered in this paper is just one of the existing ensemble approaches",
    "NOVELTY"
  ],
  [
    "The idea is interesting and novel by extending a previous unsupervised sequence modeling approach to speech recognition and exploiting the segmental structure of the problem .",
    "NOVELTY"
  ],
  [
    "Furthermore , the specific form of addition here is novel .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution to the literature of neural graph nets is clear and significant .",
    "NOVELTY"
  ],
  [
    "This is a very creative new and important idea in the space of adversarial attacks .",
    "NOVELTY"
  ],
  [
    "While none of the underlying techniques here are strikingly novel in themselves",
    "NOVELTY"
  ],
  [
    ", the combination of them and the details necessary for getting it to work as well as LSTMs is a major achievement .",
    "NOVELTY"
  ],
  [
    "I like the underlying idea of keeping it simple when the model allows it",
    "NOVELTY"
  ],
  [
    "and the proposed model lacks of novelty",
    "NOVELTY"
  ],
  [
    "The encoder and decoder are not novel",
    "NOVELTY"
  ],
  [
    "Although this machinery is standard , I found the setup of the hypothesis test creative and interesting and novel .",
    "NOVELTY"
  ],
  [
    "with a significant advance over prior results in the area .",
    "NOVELTY"
  ],
  [
    "The idea of global pruning based on BN is not new .",
    "NOVELTY"
  ],
  [
    "I view the contribution of the paper as primarily theoretical",
    "NOVELTY"
  ],
  [
    "However , my main concern is that the paper offers an incremental improvement over the early work FedAvg ( McMahan et al. , 2017 ) .",
    "NOVELTY"
  ],
  [
    "the improvements obtained from the proposed approach are relatively small compared to the \u201c simple \u201d attention models",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first method that surpasses human performance in a multi-player game where actions can be hidden during the game .",
    "NOVELTY"
  ],
  [
    "As a result , the novelty of the paper is not justified .",
    "NOVELTY"
  ],
  [
    "The major contribution of the work is not clear .",
    "NOVELTY"
  ],
  [
    "Even the concept of using Thompson sampling is not new",
    "NOVELTY"
  ],
  [
    "and provides substantial improvements over previous works (",
    "NOVELTY"
  ],
  [
    "The Bayesian framework helps because it offers an elegant way to use a prior",
    "NOVELTY"
  ],
  [
    "and the idea of modulating early visual processing by language is novel and interesting for VQA task .",
    "NOVELTY"
  ],
  [
    "But the experimental results in the paper are not advancing the state-of-art in VQA",
    "NOVELTY"
  ],
  [
    "Originality The task being addressed is in fact quite novel and also well motivated .",
    "NOVELTY"
  ],
  [
    "The task of image animation is not new",
    "NOVELTY"
  ],
  [
    ", but the proposed motion model is novel",
    "NOVELTY"
  ],
  [
    "It demonstrably advances the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "I think it 's quite a nice idea considering it 's designed for structures like mixture models which I think is quite novel for this type of work .",
    "NOVELTY"
  ],
  [
    "The problem is , however , that the proposed approach seems to be a slight variation of the already known methods .",
    "NOVELTY"
  ],
  [
    "This seems to be a rather weak contribution .",
    "NOVELTY"
  ],
  [
    "Such analysis of styles is novel as it gives a way to discover structure in the space of styles , while prior work mostly focused on synthesis and not on decompositions of styles .",
    "NOVELTY"
  ],
  [
    "The idea of combining VI and BMC is interesting",
    "NOVELTY"
  ],
  [
    "The idea of combining variational inference and Bayesian Monte Carlo is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- In terms of novelty over previous works on equivariant CNNs , this paper is a mild step forward , bringing in sections of associated vector bundles for feature spaces and allowing for general representations there",
    "NOVELTY"
  ],
  [
    "The clarity of this mathematical language is admittedly nice and I think it will help researchers think about general equivariant CNNs in the future",
    "NOVELTY"
  ],
  [
    "and insightful )",
    "NOVELTY"
  ],
  [
    "AND * the analysis provides insight into other network flow problems",
    "NOVELTY"
  ],
  [
    "Among all the papers trying to contribute to the theory of deep learning this seems to me to be a very important contribution . This paper solves one of the open problems in random matrix theory that allows to describe spectral density of matrices that went trough a non-linearity such as used in neural nets . It is a very nice piece of work in random matrix theory with some interesting speculations about consequences for training of deep neural nets",
    "NOVELTY"
  ],
  [
    "Thus no new idea is proposed in this work .",
    "NOVELTY"
  ],
  [
    "as a rather direct application of known IP methods , the technical novelty is a bit low .",
    "NOVELTY"
  ],
  [
    "there is the novelty concern .",
    "NOVELTY"
  ],
  [
    "The core idea here seems to be a good one and the paper cleverly brings representation learning into causal inference which is both original and likely to have a significant impact by bringing two distinct communities closer together .",
    "NOVELTY"
  ],
  [
    "overly",
    "NOVELTY"
  ],
  [
    "The authors show that it learns co-bindings already known in the literature which is a good sanity check but does not offer any new biological insight",
    "NOVELTY"
  ],
  [
    "the adaptation to dueling bandits is not trivial .",
    "NOVELTY"
  ],
  [
    "It is very refreshing to see a submission",
    "NOVELTY"
  ],
  [
    "I believe this line of thinking is original to some extent",
    "NOVELTY"
  ],
  [
    ", although bears some similarity with ideas in Dropout , DropConnect , however",
    "NOVELTY"
  ],
  [
    "Weakness The novelty of the paper is limited .",
    "NOVELTY"
  ],
  [
    "such a study is",
    "NOVELTY"
  ],
  [
    "idea",
    "NOVELTY"
  ],
  [
    "The paper offers several theoretical contributions .",
    "NOVELTY"
  ],
  [
    "this work is somewhat incremental on R-GCN ( `` Modeling relational data with graph convolutional networks `` ) .",
    "NOVELTY"
  ],
  [
    "the overall technical contribution is limited .",
    "NOVELTY"
  ],
  [
    "I think building the connection between the norm of weight matrices and gradient is original",
    "NOVELTY"
  ],
  [
    "However , the idea is simple and the originality seems incremental .",
    "NOVELTY"
  ],
  [
    "The novelty of the algorithm is limited .",
    "NOVELTY"
  ],
  [
    "I do n't think it 's novel enough to be a new algorithm .",
    "NOVELTY"
  ],
  [
    "While I think the ideas per se have relatively minor novelty",
    "NOVELTY"
  ],
  [
    ", the combination seems novel to me",
    "NOVELTY"
  ],
  [
    "The theory in this paper improve bounds for multi-source DA in previous paper . The new bound provides new insight and helps the design of algorithm .",
    "NOVELTY"
  ],
  [
    "however it is a straight-forward application of greedy optimization on discrete data and is not very novel or interesting .",
    "NOVELTY"
  ],
  [
    "Some discoveries of this work are interesting",
    "NOVELTY"
  ],
  [
    "the combination of ideas is novel",
    "NOVELTY"
  ],
  [
    "but the algorithms proposed are not novel and the question of whether the method will scale to more unknown parameters is not answered",
    "NOVELTY"
  ],
  [
    "The paper is definitely interesting and presents an promising direction .",
    "NOVELTY"
  ],
  [
    "However , the submission is weak in terms of novelty and the manuscript should be polished carefully",
    "NOVELTY"
  ],
  [
    "Limited novelty and performance improvement - The main idea is already introduced in previous work on the task and the feature map level KD has been studied widely for various applications , their combination is somewhat new though .",
    "NOVELTY"
  ],
  [
    "this line of research seems very recent , and this paper appears as a natural and timely continuation of",
    "NOVELTY"
  ],
  [
    "While the general pattern of mapping a specification to abstraction with a neural net and then mapping the abstraction to a full program with a combinatorial technique is not necessarily novel",
    "NOVELTY"
  ],
  [
    "I think this paper adds an interesting new take on the pattern",
    "NOVELTY"
  ],
  [
    "I do not think the word `` novel `` is proper here since it is not something total new",
    "NOVELTY"
  ],
  [
    "The continuous relaxation of KNN that this paper introduced is novel .",
    "NOVELTY"
  ],
  [
    "The approach appears to be novel .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well-written and the results appear to be novel and interesting .",
    "NOVELTY"
  ],
  [
    "The overall approach maybe novel in context of pose estimation",
    "NOVELTY"
  ],
  [
    "but this idea of learning a disentangled generative model is not",
    "NOVELTY"
  ],
  [
    "I found this approach quite exciting and it has potential to be further improved",
    "NOVELTY"
  ],
  [
    "ORIGINALITY To the best of my non-expert knowledge the contribution seems to be original .",
    "NOVELTY"
  ],
  [
    "this is an interesting work by introducing new idea of sliced-Wasserstein distance",
    "NOVELTY"
  ],
  [
    "The results and proofs are a mish-mash of existing results and techniques",
    "NOVELTY"
  ],
  [
    "nevertheless the results are novel and should spark interest for discussions and further research directions .",
    "NOVELTY"
  ],
  [
    "In my professional opinion , the idea of using pretrained node embeddings and training only the neural network is not enough of a contribution .",
    "NOVELTY"
  ],
  [
    "not novel",
    "NOVELTY"
  ],
  [
    "The use of ErrP in RL appears novel",
    "NOVELTY"
  ],
  [
    "their system just receives a binary signal which indicates the presence of ErrP and the methodological contribution in this paper is minimal",
    "NOVELTY"
  ],
  [
    "makes a clear technical contribution",
    "NOVELTY"
  ],
  [
    "I think that this work presents an interesting and very promising approach for performing unsupervised domain transfer in zero-shot instances when dealing with images",
    "NOVELTY"
  ],
  [
    "The originality of the connection between TD dynamics and MJLS is a good contribution that could increase the flow of ideas from control theory to RL .",
    "NOVELTY"
  ],
  [
    "Related to the above point about significance , the results lack originality .",
    "NOVELTY"
  ],
  [
    "And while the connection to MJLS is novel in reinforcement learning",
    "NOVELTY"
  ],
  [
    "it seems to have been inspired by a similar connection made in optimization in the paper by Hu et al",
    "NOVELTY"
  ],
  [
    "The analysis is novel and the tight rates are nice",
    "NOVELTY"
  ],
  [
    "I agree that I missed the distinction with prior work that the authors raise and I think that this MJLS perspective is a nice idea to bring to the RL community .",
    "NOVELTY"
  ],
  [
    "Despite the fact that the overall idea is new",
    "NOVELTY"
  ],
  [
    "I like the idea of `` bounding `` the dual W-distance estimate",
    "NOVELTY"
  ],
  [
    "RMH method is an interesting one",
    "NOVELTY"
  ],
  [
    "As a non-expert",
    "NOVELTY"
  ],
  [
    "I found this result of this paper",
    "NOVELTY"
  ],
  [
    "This is not a minor incremental contribution",
    "NOVELTY"
  ],
  [
    "I do n't understand whether these are novel contributions or not",
    "NOVELTY"
  ],
  [
    "These changes are incremental",
    "NOVELTY"
  ],
  [
    "offers useful contributions",
    "NOVELTY"
  ],
  [
    "novel enough in the techniques introduced",
    "NOVELTY"
  ],
  [
    "My main concern regarding this paper is whether it is sufficiently novel . The majority of technical work is an almost direct adaptation of [ 1 ] , and the paper does not seem to offer a significantly novel approach for the analysis of structured prediction problems .",
    "NOVELTY"
  ],
  [
    "Overall , I think that while this paper makes nice contributions , it is not clear if they amount to a significantly novel submission .",
    "NOVELTY"
  ],
  [
    "The RNN approach is novel to this setting",
    "NOVELTY"
  ],
  [
    ", if somewhat incremental",
    "NOVELTY"
  ],
  [
    "I believe the main novelty of this paper lies in the problem it is considering",
    "NOVELTY"
  ],
  [
    "The use of wavelet based features for this , to my knowledge is novel and while the DRNN the authors propose does not appear to be highly novel , the application to the problem of robust BCI in PPC , to the best of my knowledge , is .",
    "NOVELTY"
  ],
  [
    "As far as I know , this submission is not the first work to introduce GCN for taking advantages of prior knowledge in Action Units .",
    "NOVELTY"
  ],
  [
    "Despite their newness",
    "NOVELTY"
  ],
  [
    "As far as I could determine , the contributions presented in this paper represent significant steps for OOMs ,",
    "NOVELTY"
  ],
  [
    "As a whole , I think the idea in the paper is a good one",
    "NOVELTY"
  ],
  [
    "While the ideas used in this paper are not new",
    "NOVELTY"
  ],
  [
    "Though there has been work in self-assembling robots or training modular robots with graph neural networks , training modular robots that can change its morphology through self-assembling is novel in my knowledge .",
    "NOVELTY"
  ],
  [
    "The novelty in this paper lies in the usage of a novel loss ,",
    "NOVELTY"
  ],
  [
    "; the idea is novel , simple and effective",
    "NOVELTY"
  ],
  [
    "this work is a continuation of the work by Carmon et al ( 2016 ) in the deterministic setting",
    "NOVELTY"
  ],
  [
    "For the stochastic setting , the AdaNCD+SCSG result seems very similar to the so-called Neon+SCSG method",
    "NOVELTY"
  ],
  [
    "The proposed architecture is an interesting inspiration from Neuroscience which fits into the sequential recommendation problem",
    "NOVELTY"
  ],
  [
    "The originality of this paper is low as the authors just replace any regression method with neural networks",
    "NOVELTY"
  ],
  [
    "Therefore , the technical contributions are somewhat limited .",
    "NOVELTY"
  ],
  [
    "That being said , the paper is a nice and interesting contribution to the NTK regime",
    "NOVELTY"
  ],
  [
    "-- A novel High Fidelity Pose Invariant Model ( HF-PIM ) is proposed to produce more realistic and identity-preserving frontalized face images with a higher resolution",
    "NOVELTY"
  ],
  [
    "I enjoyed the presented ideas",
    "NOVELTY"
  ],
  [
    "I liked the idea quite a lot and would not mind seeing it in the conference",
    "NOVELTY"
  ],
  [
    "As far as I know , the results on risk bounds for Bayes predictor are novel .",
    "NOVELTY"
  ],
  [
    "The model is interesting",
    "NOVELTY"
  ],
  [
    "Weaknesses The work seems incremental without any major new insights beyond the work on R-SPENs .",
    "NOVELTY"
  ],
  [
    "To my opinion , the setting and the algorithm lack a bit of originality and might seem as incremental combinations of methods of graph labelings prediction and online learning in a switching environment . Yet",
    "NOVELTY"
  ],
  [
    "the algorithm for graph labelings is efficient , new and seem different from the existing ones .",
    "NOVELTY"
  ],
  [
    "I 'm not currently convinced that the paper provides substantially more theoretical insight than before due to differences between the theoretical and empirical SVRG methods applied in this paper and the theoretical algorithm 's similarity to large-batch SGD",
    "NOVELTY"
  ],
  [
    "The use of Lyanpov functions to directly model delays is , to the best of my knowledge , a new approach in literature .",
    "NOVELTY"
  ],
  [
    "The G-SGD approach used in this work is not new and has been initially applied by Meng et al.",
    "NOVELTY"
  ],
  [
    "The structure , the methodology , and the content of this paper is highly similar to the work published by Meng et al. , 2018 .This paper claims to obtain significantly more effective RNN models than using optimization methods in the weight space without providing any statistically significant measures",
    "NOVELTY"
  ],
  [
    "The paper presents a novel and interesting regularization method , theoretical analysis",
    "NOVELTY"
  ],
  [
    "yet I fear its main contributions might be limited to recommendation systems or other fields where knowledge graphs are available",
    "NOVELTY"
  ],
  [
    "The paper provides novel results and an interesting line of work that allows us to tradeoff good behavior of the function space and of the MRP in order to have TD converge , in the sense that as the MDP becomes less and less reversible we can make up for it by having properly conditioned matrices .",
    "NOVELTY"
  ],
  [
    "its originality seems to derive chiefly from the interface design .",
    "NOVELTY"
  ],
  [
    "I believe the Langevin-based prediction is a significant and clever contribution .",
    "NOVELTY"
  ],
  [
    "The work is a novel combination of known techniques ,",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is not clear .",
    "NOVELTY"
  ],
  [
    "but the state of the art study presented later on shows that this idea by itself is not new",
    "NOVELTY"
  ],
  [
    "and found it very interesting",
    "NOVELTY"
  ],
  [
    "Approach seems fairly incremental . Overall , the results are interesting but the technique seems relatively incremental .",
    "NOVELTY"
  ],
  [
    "This is a good contribution .",
    "NOVELTY"
  ],
  [
    "Originality== The work is original in that it is the first rigorous study of the MetaKaggle dataset as pertaining to the problem of adaptive overfitting .",
    "NOVELTY"
  ],
  [
    "I did not get many new insights from the analyses presented in the study",
    "NOVELTY"
  ],
  [
    "The proposed method combines several existing works",
    "NOVELTY"
  ],
  [
    "but the results seems interesting .",
    "NOVELTY"
  ],
  [
    "the design appears novel relative to recent work ,",
    "NOVELTY"
  ],
  [
    "The paper is , overall , interesting .",
    "NOVELTY"
  ],
  [
    "this draft did not make significant contributions to this field , neither in theory nor practice",
    "NOVELTY"
  ],
  [
    "though clearly the empirical contribution has more space to improve",
    "NOVELTY"
  ],
  [
    "this is a good paper , introducing a novel algorithm , for a previously studied problem",
    "NOVELTY"
  ],
  [
    "but seems lacking in originality and novelty .",
    "NOVELTY"
  ],
  [
    "The application of Titsias 2009 seems straightforward , I can not see the novelty there",
    "NOVELTY"
  ],
  [
    "the novelty of this work lies in two points",
    "NOVELTY"
  ],
  [
    "However , the whole paper still gives me a faint feeling that the core ideas are not very original and not very solid",
    "NOVELTY"
  ],
  [
    "I believe the paper elegantly merges two interesting ideas in the optimal transport literature , and provides an efficient algorithm for computing a solution to their new problem .",
    "NOVELTY"
  ],
  [
    "The paper makes a small contribution over the work of Guy Van den Broeck .",
    "NOVELTY"
  ],
  [
    "From the theoretical point of view ,",
    "NOVELTY"
  ],
  [
    "The idea of using patches in domain adaptation is not completely new .",
    "NOVELTY"
  ],
  [
    "The clustering Figure 6 in particular is very insightful .",
    "NOVELTY"
  ],
  [
    "Interesting overall approach , investigating the broad viability of latent space editing via activation maximization in NLP and specifically for text style transfer",
    "NOVELTY"
  ],
  [
    "2 .In terms of impact , the paper is somehow incomplete -- it only demonstrates that the Fisher information is important",
    "NOVELTY"
  ],
  [
    "this is a nice observation",
    "NOVELTY"
  ],
  [
    "2 .I do n't believe the proposed transductive method is very novel as I believe its related to a common way to incorporate unlabeled data in semi-supervised methods",
    "NOVELTY"
  ],
  [
    "The proposed method is not much novel .",
    "NOVELTY"
  ],
  [
    "The proposed method is not much novel .",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting alternative to recent approaches to learning from logged bandit feedback ,",
    "NOVELTY"
  ],
  [
    ".Implementing the approach using recent f-GANs is an interesting contribution and may spur follow-up work",
    "NOVELTY"
  ],
  [
    "The paper provides a very interesting new approach for mixing approximate and exact inference",
    "NOVELTY"
  ],
  [
    "in the equations The paper provides an original approach for combining exact and approximate inference by sampling , integrating collapsed sampling with exact inference by knowledge compilation",
    "NOVELTY"
  ],
  [
    "WaveVAE is an interesting approach to a parallel neural vocoding .",
    "NOVELTY"
  ],
  [
    "I commend the authors for taking a multi-disciplinary perspective and bringing the information synergy ideas",
    "NOVELTY"
  ],
  [
    "the resulting Non-Syn VAE objective function is effectively a different derivation of the original beta-VAE objective .",
    "NOVELTY"
  ],
  [
    ".I like the main idea of the paper",
    "NOVELTY"
  ],
  [
    "I think that the general idea is nice and can influence others",
    "NOVELTY"
  ],
  [
    "The proposed method seems relatively similar to that of",
    "NOVELTY"
  ],
  [
    "and therefore the proposed algorithm can achieve the similar performance as PixelRNN in much less time than PixelCNN.I like the nice idea presented in this paper",
    "NOVELTY"
  ],
  [
    "Bayesian perspective on the multi-task learning is not a novel concept .",
    "NOVELTY"
  ],
  [
    "I think the ideas presented in this paper show good potential",
    "NOVELTY"
  ],
  [
    "I 'm not sure if it is novel because I think that it is not much different from KL penalize proposed in RL",
    "NOVELTY"
  ],
  [
    "All in all , this work is a simple and nice modification of Gatys at al",
    "NOVELTY"
  ],
  [
    "which is worth publishing but does not constitute a major breakthrough",
    "NOVELTY"
  ],
  [
    "The idea",
    "NOVELTY"
  ],
  [
    "is very inspiring for",
    "NOVELTY"
  ],
  [
    "applying it to other similar visual surveillance applications such as of view-point invariance or outfit-invariance",
    "NOVELTY"
  ],
  [
    "The idea is straight-forward and novel .",
    "NOVELTY"
  ],
  [
    "but I am not sure about whether the developments and results are relevant/novel enough yet at this point to publish at ICLR .",
    "NOVELTY"
  ],
  [
    "Since the proposed idea is not new",
    "NOVELTY"
  ],
  [
    "C since this was not the best configuration in the experiments in DMlab Originality The idea of keeping data from previous tasks is not that original ,",
    "NOVELTY"
  ],
  [
    "The direction , however , is novel as far as I can tell : using MDP algorithms to solve an inference problem .",
    "NOVELTY"
  ],
  [
    "but the paper seems to have missed a few other methods designed to do this",
    "NOVELTY"
  ],
  [
    "improve standard ABC so that it can be extended to higher dimensions",
    "NOVELTY"
  ],
  [
    "The idea of empirically studying the manifold / topological / group structure in the space of filters is interesting .",
    "NOVELTY"
  ],
  [
    "This work is not the first to apply machine learning to auto-vectorization",
    "NOVELTY"
  ],
  [
    "has a solid contribution",
    "NOVELTY"
  ],
  [
    "the novelty of the method appears limited .",
    "NOVELTY"
  ],
  [
    "Although it is not the first empirical study on this topic",
    "NOVELTY"
  ],
  [
    "To my knowledge the results in this work are clearly new and interesting .",
    "NOVELTY"
  ],
  [
    "Using it in combination",
    "NOVELTY"
  ],
  [
    "the proposed method is closely related to recent works",
    "NOVELTY"
  ],
  [
    "The idea of generating an abstraction or a summary of a video via a sequence of important frames is attractive and could probably be used in different contexts . The proposed model is new and the authors introduce some clever ideas in order to train it .",
    "NOVELTY"
  ],
  [
    "Overall , I think that there are several interesting ideas and realizations .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is original research and the method is new .",
    "NOVELTY"
  ],
  [
    "The separation loss is a novel contribution , and encourages the effect of the latents on behavior to be separable .",
    "NOVELTY"
  ],
  [
    "The separation loss is quite novel .",
    "NOVELTY"
  ],
  [
    "My main concern comes from the novelty of this paper . The two main contributions of the paper : ( 1 ) using codes and codebooks to compress weights ; and ( 2 ) minimizing layer reconstruction error instead of weight approximation error are both not new .",
    "NOVELTY"
  ],
  [
    "and therefore seems somewhat incremental",
    "NOVELTY"
  ],
  [
    "The proposed approach is intuitive and relates",
    "NOVELTY"
  ],
  [
    "The idea is fairly natural",
    "NOVELTY"
  ],
  [
    "so the results of Section 5.1 aren\u00e2\u0080\u0099t too novel",
    "NOVELTY"
  ],
  [
    "The sample complexity bound for spectral k-support norm-regularization in Section 5.2 seems to be new and interesting",
    "NOVELTY"
  ],
  [
    "2 .The novelty in their contribution is moderate - the idea of long-term future prediction is not new",
    "NOVELTY"
  ],
  [
    ", the architecture choice is not significantly new .",
    "NOVELTY"
  ],
  [
    "The paper explores an interesting area of learning representations for cross-domain tasks such as image captioning and text-to-image synthesis .",
    "NOVELTY"
  ],
  [
    "The analysis with a truncated beta distribution is inspiring and promising . The results on decision tree are new ( to the best of my knowledge ) .",
    "NOVELTY"
  ],
  [
    "Although this paper relies heavily on the well-established field of dynamic systems analysis , I found this paper to be refreshingly innovative in that it takes these tools an applies them in a new way . This is a refreshingly research focused paper compared to the other papers I 've reviewed for NeurIPS this year",
    "NOVELTY"
  ],
  [
    "The two-way interpolation with block motion vectors and the fusion of interpolated features are novel and seem effective .",
    "NOVELTY"
  ],
  [
    "The use of Block Motion Vectors has been proposed before in [ i ] and the main novelty of the paper remains only the interpolation of feature maps using BMVC .",
    "NOVELTY"
  ],
  [
    "At a high level , the proposed idea is interesting .",
    "NOVELTY"
  ],
  [
    "while the high-level idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "I see a few serious flaws in this work",
    "NOVELTY"
  ],
  [
    "but in this respect the paper does not contribute anything",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the idea of using unsupervised keypoints for reinforcement learning is novel and promising .",
    "NOVELTY"
  ],
  [
    "Reducing the search space to the most controllable keypoints instead of raw actions is a promising idea",
    "NOVELTY"
  ],
  [
    "It sounds like an interesting idea",
    "NOVELTY"
  ],
  [
    "especially the use of group lasso ) well thought out and original , and",
    "NOVELTY"
  ],
  [
    "It is not clear whether this is a new contribution of this paper or whether the authors merely adopt this idea",
    "NOVELTY"
  ],
  [
    "and it presents and interesting heuristic approach that",
    "NOVELTY"
  ],
  [
    "this not a terribly original paper",
    "NOVELTY"
  ],
  [
    "The paper is a significant contribution .",
    "NOVELTY"
  ],
  [
    "CP representation does not have universality",
    "NOVELTY"
  ],
  [
    "This paper is clearly original ,",
    "NOVELTY"
  ],
  [
    "although other papers have hinted at similar high-level results",
    "NOVELTY"
  ],
  [
    "This paper contains some valuable insights that could be readily applied to existing machine learning workflows , a rare achievement for FATML papers .",
    "NOVELTY"
  ],
  [
    "and its main idea is both novel and appears to be effective in practice .",
    "NOVELTY"
  ],
  [
    "Although their benchmarks are weak due to a lack of other similar works",
    "NOVELTY"
  ],
  [
    ", their approach is a new concept applying for DPP and valuable for other works related to DPP .",
    "NOVELTY"
  ],
  [
    "As a technical contribution , this work makes a simple but nice connection to the notion of margin complexity",
    "NOVELTY"
  ],
  [
    "It presents an interesting idea",
    "NOVELTY"
  ],
  [
    "The method is relatively new although it is similar to some conditional GAN works in the literature .",
    "NOVELTY"
  ],
  [
    "It is a nice idea",
    "NOVELTY"
  ],
  [
    "does not",
    "NOVELTY"
  ],
  [
    "introduce any new",
    "NOVELTY"
  ],
  [
    "Overall I think the contribution is nice . The paper is well written and presented . The main idea is a good one and appears novel .",
    "NOVELTY"
  ],
  [
    "While the idea itself is interesting",
    "NOVELTY"
  ],
  [
    "To my knowledge , the work is original ,",
    "NOVELTY"
  ],
  [
    "Besides , the extension of HyperGCNs with mediators and the Fast version are incremental and straightforward without any effort based on previous works .",
    "NOVELTY"
  ],
  [
    "I would say the originality and significance of the paper are mediocre . There is not a lot of novelty in the paper .",
    "NOVELTY"
  ],
  [
    "All the other components in the system are not novel .",
    "NOVELTY"
  ],
  [
    "the matching procedure is novel for federated training of neural networks",
    "NOVELTY"
  ],
  [
    "the MAP update for the weights given the assignment matrix is interesting and resembles exactly how the Bayesian committee machine algorithm of Tresp",
    "NOVELTY"
  ],
  [
    "and the main idea is rather interesting",
    "NOVELTY"
  ],
  [
    "as the core methodological contribution is a very simple combination of the existing techniques",
    "NOVELTY"
  ],
  [
    "The proposed setup is indeed novel and very ecologically-valid",
    "NOVELTY"
  ],
  [
    "Combination of MaxEnt IRL and MAML is novel .",
    "NOVELTY"
  ],
  [
    "Overall , I find the novelty of this work overly incremental and its impact potential very limited .",
    "NOVELTY"
  ],
  [
    "While the proposed idea is novel and the first results are very promising",
    "NOVELTY"
  ],
  [
    "that to the best of their knowledge this is the first work that makes this combination allowing also for transparency and explanations in the reasoning process",
    "NOVELTY"
  ],
  [
    "The idea is novel , is",
    "NOVELTY"
  ],
  [
    "The contribution is",
    "NOVELTY"
  ],
  [
    "although not earth shattering given previous work on such metrics .",
    "NOVELTY"
  ],
  [
    "Because of these I would judge the contribution of this paper not strong",
    "NOVELTY"
  ],
  [
    "albeit some of the related work seems a little unrelated to the task at hand",
    "NOVELTY"
  ],
  [
    "The bucketization idea is not something out of the park novel .",
    "NOVELTY"
  ],
  [
    "The entropy regularization approach is interesting .",
    "NOVELTY"
  ],
  [
    "I 'm not 100 % sure if it is original enough .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this work is a rather unique foray into solving this problem ( original ) .",
    "NOVELTY"
  ],
  [
    "Qualitative Assessment The idea that generalization of KSD to Lr norm combined with importance sampling seems interesting .",
    "NOVELTY"
  ],
  [
    ", the idea seems novel and promising",
    "NOVELTY"
  ],
  [
    "My concern to this paper is that the landscape of linear neural networks",
    "NOVELTY"
  ],
  [
    "has already been analyzed in the literature . The final results of this paper , though derived using a different approach , are not new .",
    "NOVELTY"
  ],
  [
    "I am not sure the contribution of this paper is enough for ICLR .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited and the experimental results are weird for me",
    "NOVELTY"
  ],
  [
    "and the derived theoretical results that this multinomial logistic regression results in an estimation of nonlinear independent components under some assumptions is quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "The exact setting proposed in the paper , as well as the proposed model , are novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The main contribution of the paper is empirical .",
    "NOVELTY"
  ],
  [
    "As a result , the improvement caused by the proposed method is incremental compared with its variants .",
    "NOVELTY"
  ],
  [
    "The originality of the paper is also somewhat limited ,",
    "NOVELTY"
  ],
  [
    "the idea , though",
    "NOVELTY"
  ],
  [
    "somewhat straightforward and less elegant",
    "NOVELTY"
  ],
  [
    "presented",
    "NOVELTY"
  ],
  [
    "the paper does not present sufficiently new information worthy of a regular conference paper",
    "NOVELTY"
  ],
  [
    "I still do not see sufficient contribution here worthy of a regular ICLR paper",
    "NOVELTY"
  ],
  [
    "I like the idea of a betting framework to tune learning rates over the course of training .",
    "NOVELTY"
  ],
  [
    "The idea of using SSIM as a unified measure for noise in the context data augmentation in images is novel AFAIK and is neat IMO",
    "NOVELTY"
  ],
  [
    "Specifically , the established minimax rate-optimal results for stochastic/adaptive gradient methods are novel and interesting",
    "NOVELTY"
  ],
  [
    "It is a significant observation but not entirely new .",
    "NOVELTY"
  ],
  [
    "the contribution is unclear to me",
    "NOVELTY"
  ],
  [
    "I think this is interesting theoretical work with some limitations -- the results for 2-layer networks may make a significant difference in this regard",
    "NOVELTY"
  ],
  [
    "I think the paper is an interesting extension of the work on k-means [ 9 ]",
    "NOVELTY"
  ],
  [
    "The dataset collected in this work is original and I do not know of a large dataset containing news media articles and affiliations",
    "NOVELTY"
  ],
  [
    "but the rate is somewhat new",
    "NOVELTY"
  ],
  [
    "The approach taken by the authors is interesting and promising",
    "NOVELTY"
  ],
  [
    "paper from prior work",
    "NOVELTY"
  ],
  [
    "While apparently the warm-start approximate solutions are novel work in this direction",
    "NOVELTY"
  ],
  [
    "it is not properly explained how this compares to the homotopy approach described especially in",
    "NOVELTY"
  ],
  [
    "Although this is not novel in itself",
    "NOVELTY"
  ],
  [
    "I recommend to reject the paper -- as the contribution in my opinion is incremental , not principled",
    "NOVELTY"
  ],
  [
    "and not very convincing",
    "NOVELTY"
  ],
  [
    "I like the proposed idea , which sounds a straightforward solution to compound question answering .",
    "NOVELTY"
  ],
  [
    "This is an exciting new result",
    "NOVELTY"
  ],
  [
    "The score matching approach which has received recent interest overcomes the challenging of requiring knowledge of the log-partition function which is a useful contribution .",
    "NOVELTY"
  ],
  [
    "It provides interesting view of the these existing popular reinforcement learning algorithms that is widely used in DRL .",
    "NOVELTY"
  ],
  [
    "it can not be claimed that this paper is a \u201c first attempt to study the convergence of online reinforcement learning algorithms with nonlinear function approximation in general",
    "NOVELTY"
  ],
  [
    "but the authors propose a new approach for that that vastly improves over existing attacks",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach ( optimizing an ensemble of network instead of a single network ) is limited .",
    "NOVELTY"
  ],
  [
    "Although I think some of the empirical results provided in the paper are interesting",
    "NOVELTY"
  ],
  [
    "I doubt the scientific contribution of this paper is significant .",
    "NOVELTY"
  ],
  [
    "This is not the first paper that suggests adding a regularization",
    "NOVELTY"
  ],
  [
    "From my personal knowledge I think the method is new",
    "NOVELTY"
  ],
  [
    "and the result is appealing",
    "NOVELTY"
  ],
  [
    "The interpretation as a follow-the-regularized leader strategy is interesting .",
    "NOVELTY"
  ],
  [
    "the proposed approach is a straightforward application of existing techniques to this problem",
    "NOVELTY"
  ],
  [
    "the scholarship is somewhat shoddy",
    "NOVELTY"
  ],
  [
    "-To the best of my knowledge , the authors are the first to propose such changes and implement and test the updated algorithm , as well as compare the updated SVRG to SGD on a ResNet on ImageNet .",
    "NOVELTY"
  ],
  [
    "The basic approach ( which appeared in a previous paper ) is very interesting and relatively novel",
    "NOVELTY"
  ],
  [
    "in a really interesting and novel way",
    "NOVELTY"
  ],
  [
    "the argument that BN decreases exponential condition number is not new",
    "NOVELTY"
  ],
  [
    "The Spatial net architecture is similar to convolutional LSTM \u2014 and I therefore don \u2019 t think that is a significantly novel technical contribution . The application of spatial net to augment frames in the state is although novel in my best knowledge .",
    "NOVELTY"
  ],
  [
    "While I believe the method described might not be significantly novel technically",
    "NOVELTY"
  ],
  [
    ", I believe the paper made nice contributions in terms of the autonomous driving application .",
    "NOVELTY"
  ],
  [
    "find this to be an important innovation",
    "NOVELTY"
  ],
  [
    "I find the depth regularization is particularly interesting .",
    "NOVELTY"
  ],
  [
    "The novelty is not so great as structured sparsity is a well established idea .",
    "NOVELTY"
  ],
  [
    "The basic idea of this paper may be a good one",
    "NOVELTY"
  ],
  [
    "The main selling point is that the proposed inference strategy does not require HMM message passing as would be needed for the standard structured mean field",
    "NOVELTY"
  ],
  [
    "In contrast to other recent papers on this topic , the approach here does not rely on any specific model of the underlying learning curves and therefore makes fewer assumptions about the nature of the model",
    "NOVELTY"
  ],
  [
    "Overall I think this paper is a good contribution to the hyperparameter optimization literature .",
    "NOVELTY"
  ],
  [
    "while the concept of a frontier set is not novel , the authors propose a concrete instantiation that has promising results on continuous state spaces",
    "NOVELTY"
  ],
  [
    "the general idea of fitting a new model to the latest trajectory and using KL as reward seems like a promising principle that could on its own scale .",
    "NOVELTY"
  ],
  [
    "The questions asked in this paper are novel and I found the solutions to be quite interesting and clever .",
    "NOVELTY"
  ],
  [
    "I think that the paper has significant theoretical novelty and some potential for applications .",
    "NOVELTY"
  ],
  [
    "2 .The stochastic rounding method is very intuitive .",
    "NOVELTY"
  ],
  [
    "The novelty seems really incremental as a combination of two existing concepts and thus there is no clear conceptual improvement .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , such a difference does have an effect on the perplexity metric .",
    "NOVELTY"
  ],
  [
    "most of the key ideas have already been there in previous work by Cohen et al. , Papailiopoulos et al .etc .I find this work incremental and borderline for NIPS",
    "NOVELTY"
  ],
  [
    "Overall I feel that this paper has two interesting contributions",
    "NOVELTY"
  ],
  [
    "From a methodology point-of-view , the paper has limited novelty (",
    "NOVELTY"
  ],
  [
    "Limited methodology contribution .",
    "NOVELTY"
  ],
  [
    "provided novel covariance matrix approximation method",
    "NOVELTY"
  ],
  [
    "I did not see the contribution of this part to the whole model as a topic model",
    "NOVELTY"
  ],
  [
    "2 .Using adversarial training for topic models seems to be an interesting idea .",
    "NOVELTY"
  ],
  [
    "The idea of using adversarial calibration training is interesting and promising",
    "NOVELTY"
  ],
  [
    "contribution",
    "NOVELTY"
  ],
  [
    "The fundamental idea behind this paper ( disregarding the magnitude of a characteristic function ) is not terribly revolutionary ,",
    "NOVELTY"
  ],
  [
    "but it is elegant , interesting , and likely to be useful so I think worthy of publication",
    "NOVELTY"
  ],
  [
    "Overall I think the idea is interesting enough to be worthy of publication",
    "NOVELTY"
  ],
  [
    "it certainly seems to be the first time someone has tackled BNNs and adversarial examples",
    "NOVELTY"
  ],
  [
    "The authors present a novel variant of minibatch-SGD which tackles the difficulty the dealing with Byzantine machines .",
    "NOVELTY"
  ],
  [
    "the algorithmic techniques used in this current paper seems to be quite different than those in [ 31",
    "NOVELTY"
  ],
  [
    "in terms of techniques the current paper seems sufficiently novel .",
    "NOVELTY"
  ],
  [
    "The results themselves are very interesting",
    "NOVELTY"
  ],
  [
    "The idea of using reference models to guide query-based search is original and quite important in bridging the two lines of approaches to black-box attacks .",
    "NOVELTY"
  ],
  [
    "I found the",
    "NOVELTY"
  ],
  [
    "The paper solves a previously unsolved problem and the methods seem novel .",
    "NOVELTY"
  ],
  [
    "the tools and ideas",
    "NOVELTY"
  ],
  [
    "already quite difficult and sophisticated",
    "NOVELTY"
  ],
  [
    "but is not a significant contribution",
    "NOVELTY"
  ],
  [
    "The idea is simple but novel and effective .",
    "NOVELTY"
  ],
  [
    "the dense reward design for the MDP is quite interesting .",
    "NOVELTY"
  ],
  [
    "However , I do not think the proposed method is novel enough .",
    "NOVELTY"
  ],
  [
    "The notion of doing efficient CI tests with appropriate assumptions accompanied with the EEG experiment and final results corroborating with neuroscience literature makes it very original .",
    "NOVELTY"
  ],
  [
    "and offers an interesting combination of ideas motivated from statistical analysis .",
    "NOVELTY"
  ],
  [
    "While this work is interesting and to my knowledge somewhat novel .",
    "NOVELTY"
  ],
  [
    "I really like the idea of using graph networks with RL , though I",
    "NOVELTY"
  ],
  [
    "\u2019 m not sure if it \u2019 s novel to this work .",
    "NOVELTY"
  ],
  [
    "While this is",
    "NOVELTY"
  ],
  [
    "an interesting application , I \u2019 m not sure about the novelty .",
    "NOVELTY"
  ],
  [
    "but I thought it was a clever idea in the context of NAS where hard selections among finite sets must be made",
    "NOVELTY"
  ],
  [
    "I found the decision to replace the PSR\u00e2\u0080\u0099s optimization criterion",
    "NOVELTY"
  ],
  [
    "Markovian predictions ) with the more limited constraints on possible observations quite interesting",
    "NOVELTY"
  ],
  [
    "This paper proposes a cute idea as suggesting ensembles of Q-function approximations rather than a singular DQN .",
    "NOVELTY"
  ],
  [
    "this paper lacks enough novelty for publication",
    "NOVELTY"
  ],
  [
    "I am not entirely convinced that the proposed writing scheme is a substantial addition over this past work",
    "NOVELTY"
  ],
  [
    "The idea of learning a \u201c residual \u201d with the stitched connnections is very similar in spirit to the ResNet work",
    "NOVELTY"
  ],
  [
    "All of these ideas are very original .",
    "NOVELTY"
  ],
  [
    "*originality* The paper is very original , and",
    "NOVELTY"
  ],
  [
    "A natural and good idea .",
    "NOVELTY"
  ],
  [
    "could be improved , the main contribution -- the TVO -- is very refreshing and of high significance .",
    "NOVELTY"
  ],
  [
    "As said in my original review , I find the proposed approach refreshing , original and creative",
    "NOVELTY"
  ],
  [
    ", combining ideas",
    "NOVELTY"
  ],
  [
    "My assessment of this paper is that the level of novelty is relatively low . On the technical side , I do not believe this paper makes any significant contributions .",
    "NOVELTY"
  ],
  [
    "closely parallels the proof of Cohen et al .Algorithmically , the proposals of the authors are also minor tweaks of the algorithms in Cohen et al. , since the types of perturbations considered in this paper are essentially single-parameter problems .",
    "NOVELTY"
  ],
  [
    "However , I do not think that this change is particularly novel .",
    "NOVELTY"
  ],
  [
    "paper introducing a novel problem applying techniques of multi-agent reinforcement learning to model possible mechanisms by which intelligent agents can learn to avoid `` tragedy of the commons `` .",
    "NOVELTY"
  ],
  [
    "The usage of chordal sparsity is interesting and innovative .",
    "NOVELTY"
  ],
  [
    "The submission is the first one to tackle the two challenges , unknown transition and bandit feedback",
    "NOVELTY"
  ],
  [
    "The submission provides insights and solutions to the bandit online MDP learning .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel way to detect overfitting via adversarial examples .",
    "NOVELTY"
  ],
  [
    "The connection this paper makes between neural networks and algebraic varieties seems like a fascinating and promising direction for studying neural networks .",
    "NOVELTY"
  ],
  [
    "The main idea seems similar to adopting active learning for the test set selection",
    "NOVELTY"
  ],
  [
    "This is nice theoretical progress .",
    "NOVELTY"
  ],
  [
    "although its contribution can be seen as an improvement of previously proposed regression techniques",
    "NOVELTY"
  ],
  [
    "The approach is not very novel because actor-critic for more general sequence-to-sequence models",
    "NOVELTY"
  ],
  [
    "Major difference in the proposed approach is the use of stepwise hamming-loss based reward and it is unclear whether this is a major contribution which sets it apart from the previous work on AC for sequence modeling .",
    "NOVELTY"
  ],
  [
    "They propose a novel bound that involves trainable terms taking into account some compression information and a novel interpretation of adaptability .",
    "NOVELTY"
  ],
  [
    "The ideas are novel and the result brings novel and interesting light on the difficult problem of unsupervised domain adaptation .",
    "NOVELTY"
  ],
  [
    "The paper is original .",
    "NOVELTY"
  ],
  [
    "My major concern about this paper is the novelty and significance of its results",
    "NOVELTY"
  ],
  [
    "I think the idea/thought of using a \u201c role interaction layer \u201d is interesting .",
    "NOVELTY"
  ],
  [
    "This is an interesting and plausible idea .",
    "NOVELTY"
  ],
  [
    "of GCN that interprets graph convolutions as integral transforms of embedding functions",
    "NOVELTY"
  ],
  [
    "and as far as I know the results are both new and significant .",
    "NOVELTY"
  ],
  [
    "The results are novel and even better , they are fun .",
    "NOVELTY"
  ],
  [
    "The idea of having polynomial energy functions such that the associative memory can be dense is intriguing .",
    "NOVELTY"
  ],
  [
    "and the idea is quite nice .",
    "NOVELTY"
  ],
  [
    "7 .I did n't understand the novelty of the MCMC method relative to vanilla M-H updates",
    "NOVELTY"
  ],
  [
    "I think this paper is an accept -- the premise of using a classification model for predicting search fixations is clever",
    "NOVELTY"
  ],
  [
    "This method is a novel extension of existing work .",
    "NOVELTY"
  ],
  [
    "While",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "this paper has done some nice improvement over prior work along similar lines , but novelty is limited and more analysis of the model is needed .",
    "NOVELTY"
  ],
  [
    "improving existing methods of contrastive disentanglement",
    "NOVELTY"
  ],
  [
    "My major concern is the novelty in this paper since all the contributions can be summarized into adding two additional loss terms",
    "NOVELTY"
  ],
  [
    "The solution seems novel , simple/elegant , yet efficient .",
    "NOVELTY"
  ],
  [
    "The theoretical results ( Theorem 1 and 2 ) are new and study practical use cases of these",
    "NOVELTY"
  ],
  [
    "However , the level of technical novelty is relatively low .",
    "NOVELTY"
  ],
  [
    "I think the paper is incremental in that it brings together 2 existing blocks ( CMH test and Tarone testability criterion ) as it has been done before for the chisquare test with Tarone testability criterion . However bringing together CMH and Tarone is not trivial",
    "NOVELTY"
  ],
  [
    "Overall , I find that this is a very good idea .",
    "NOVELTY"
  ],
  [
    "The most important part for me is the novelty of this approach .",
    "NOVELTY"
  ],
  [
    "I also realized that the technical novelty - including the Kronecker factored approximation of the Hessian - is low",
    "NOVELTY"
  ],
  [
    "I find the proposed formulation to be novel and a positive contribution .",
    "NOVELTY"
  ],
  [
    "The proposed methods and variations appear to be simple",
    "NOVELTY"
  ],
  [
    "and the insight that decoupling representation and classifier learning performs well on long-tailed classification seems novel .",
    "NOVELTY"
  ],
  [
    "because it is essentially a generalization of ResNets , stochastic depth , and droput , it is lacking in novelty .",
    "NOVELTY"
  ],
  [
    "they do not provide much new insight .",
    "NOVELTY"
  ],
  [
    "the calibration results here seem novel )",
    "NOVELTY"
  ],
  [
    "The decoupling of uncertainty via BLR of rewards is an interesting direction for driving exploration .",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel and not standard",
    "NOVELTY"
  ],
  [
    "it hard to be sure whether the proposed methods meaningfully improve existing methods",
    "NOVELTY"
  ],
  [
    "Theory of Robust regression is gently introduced , with relevant and not too technical introduction of the statistical guarantees of the existing estimators .",
    "NOVELTY"
  ],
  [
    "A general and novel approach to anomaly detection with SOT results .",
    "NOVELTY"
  ],
  [
    "Overall this paper provides a novel approach to classification-based semi-supervised anomaly detection of general data",
    "NOVELTY"
  ],
  [
    "I know of no prior work extending this class of models to opinion dynamics , so the model presented seems reasonably novel .",
    "NOVELTY"
  ],
  [
    "However the novelty is somewhat limited by the fact that the main property that makes this model one of opinion dynamics is that the input data consists of sentiment scores",
    "NOVELTY"
  ],
  [
    "Overall paper seems reasonably solid though perhaps a bit incremental and includes an acceptable number of minor flaws",
    "NOVELTY"
  ],
  [
    "Pros .- The idea of switching small and standard RNNs for skimming and full reading respectively is quite simple and intuitive .",
    "NOVELTY"
  ],
  [
    "Cons .- The idea is quite simple and the novelty is incremental by considering the difference from skip-RNN .",
    "NOVELTY"
  ],
  [
    "This seems to be very interesting phenomena",
    "NOVELTY"
  ],
  [
    "and effective way to reduce the number of parameters for models that require handling of large vocabularies",
    "NOVELTY"
  ],
  [
    "very interesting idea",
    "NOVELTY"
  ],
  [
    "on this type of data exist , to the best of my knowledge the proposed method and combination with ATE estimates is novel , with promising results and should be relevant to a wide audience .",
    "NOVELTY"
  ],
  [
    "The proved lower bound is novel , which not only improves upon the existing work , but also confirms the recent proposed step-size schemes are optimal . The proof of the theorem is very clever . The construction of the function class to be studied when only strong-convexity and smoothness parameters are given is creative , and the way of deriving the optimal step-size sequence is cute .",
    "NOVELTY"
  ],
  [
    "I like the overall direction and the idea of being able to perform uncertainty sampling in sub-linear time . The approach is interesting .",
    "NOVELTY"
  ],
  [
    "This is an interesting idea .",
    "NOVELTY"
  ],
  [
    "very little insight is provided .",
    "NOVELTY"
  ],
  [
    "is unclear what is novel in this work",
    "NOVELTY"
  ],
  [
    "They are not the first to integrate GANs for generating goals in RL , but do so in a new and interesting way .",
    "NOVELTY"
  ],
  [
    "Novel idea , clear explanation of the method and the tensor factorization",
    "NOVELTY"
  ],
  [
    "The proposed method is just a modification of the existing neural network architecture .",
    "NOVELTY"
  ],
  [
    "From these perspectives , the proposed method is not innovative .",
    "NOVELTY"
  ],
  [
    "I believe the paper will be a nice contribution to NIPS however authors can do a better job motivating the problem they analyze",
    "NOVELTY"
  ],
  [
    "Pros The proposed approach is novel and broadly applicable .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is clear and the proposed method is sensible , novel , and evaluated reasonably",
    "NOVELTY"
  ],
  [
    "It proposes two novel algorithms with convergence guarantees . Although other works with similar guarantees exist , these algorithms are very appealing for their simplicity .",
    "NOVELTY"
  ],
  [
    "The paper is interesting that it proposes a unique combination of existing methods iteratively to improve the compression rates in modern CNNs .",
    "NOVELTY"
  ],
  [
    "However , given that these methods already exist , the novelty aspect of this paper is low .",
    "NOVELTY"
  ],
  [
    "`` Rube-Goldberg `` -esque",
    "NOVELTY"
  ],
  [
    "This is an amusing original idea",
    "NOVELTY"
  ],
  [
    "I really liked the paper , and enjoyed thoroughly reading it . Although people have looked into this idea of combining rule-based and KGE approaches in several papers , the idea of combining a pure SRL model like Markov Logic is new AFAIK .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the work presented in this paper is quite novel .",
    "NOVELTY"
  ],
  [
    "the authors proposed techniques to approximate it ( which seems to be novel",
    "NOVELTY"
  ],
  [
    "While the application is interesting",
    "NOVELTY"
  ],
  [
    "there is not much novelty in the method and factoring that",
    "NOVELTY"
  ],
  [
    "There does n't seem to be much novelty method-wise other than the input representation of the game state",
    "NOVELTY"
  ],
  [
    "The concept is interesting and grounded in human communication .",
    "NOVELTY"
  ],
  [
    ", featuring significant and novel results",
    "NOVELTY"
  ],
  [
    "Even though the analysis contains sufficiently novel elements , it is quite similar in structure with some of the papers already appearing in the references .",
    "NOVELTY"
  ],
  [
    "Overall a strong contribution .",
    "NOVELTY"
  ],
  [
    "The idea of transforming the ultrametric fitting in a way conducive to gradient based methods is novel .",
    "NOVELTY"
  ],
  [
    ", offers novel ideas",
    "NOVELTY"
  ],
  [
    "The paper is novel as the authors claimed they provide the first analysis of privacy benefits of causal models .",
    "NOVELTY"
  ],
  [
    "Even though the observations presented are very interesting",
    "NOVELTY"
  ],
  [
    "In terms of overall technique , this paper uses techniques that have already been developed in previous mean field papers . However",
    "NOVELTY"
  ],
  [
    ", the application of these techniques to the fisher information is a novel , challenging , and worthwhile contribution .",
    "NOVELTY"
  ],
  [
    "looking at the fisher information in combination with normalization techniques is a sufficiently novel perspective that it leads me to believe this paper is",
    "NOVELTY"
  ],
  [
    "sufficiently novel to warrant publication",
    "NOVELTY"
  ],
  [
    "I think the notion of normalizing the last layer is quite novel ( especially since one need only perform mean subtraction",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "think there is sufficient novelty w.r.t . [ 21",
    "NOVELTY"
  ],
  [
    "and the new experiment seems interesting !",
    "NOVELTY"
  ],
  [
    "This work raises a novel problem , i.e. , analyzing the theoretical generalization ability of existing KG embedding methods .",
    "NOVELTY"
  ],
  [
    "analysis , which is original and very interesting",
    "NOVELTY"
  ],
  [
    "and with clever contributions to PAC-Bayesian learning , with a significant impact to the NIPS community .",
    "NOVELTY"
  ],
  [
    "there are certainly some interesting ideas here : the notion of goal-conditioned value functions as proxies for a model , and as a means of merging model-free and model-based approaches is very really interesting , and hints at a deeper structure to goal-conditioned value functions in general .",
    "NOVELTY"
  ],
  [
    "While the paper doesn\u00e2\u0080\u0099t introduce a completely novel concept or approach",
    "NOVELTY"
  ],
  [
    "Originality The paper does n't introduce a fundamentally novel idea , but the way it combines previous ideas is not entirely trivial",
    "NOVELTY"
  ],
  [
    "The work is fairly similar to several existing extensions to auto-encoders ,",
    "NOVELTY"
  ],
  [
    "I believe the proposed method , HAL ( Hierarchical Abstraction with Language ) , is an interesting approach for HRL .",
    "NOVELTY"
  ],
  [
    "In my opinion , HIR is an adaptation of HER in the proposed environment and not very original .",
    "NOVELTY"
  ],
  [
    "The problem to solve in this paper is an existing topic , but",
    "NOVELTY"
  ],
  [
    "the method is novel . They propose a novel framework as well as a novel operator to exact the geometric feature for vanishing points .",
    "NOVELTY"
  ],
  [
    "While safe interactive machine learning has been investigated before , I really like the reductionist approach taken here which uses any unsafe IML algorithm as an oracle and combines it with safety testing to make provably safe decisions . This reductionist approach is original .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is good and has an interesting idea .",
    "NOVELTY"
  ],
  [
    "I think the author proposed an interesting approach",
    "NOVELTY"
  ],
  [
    "( treatment )",
    "NOVELTY"
  ],
  [
    "I like the paper quite a lot",
    "NOVELTY"
  ],
  [
    "This paper presents a nice idea .",
    "NOVELTY"
  ],
  [
    "Not an inspiring , or world changing idea",
    "NOVELTY"
  ],
  [
    "but a worthy enough idea",
    "NOVELTY"
  ],
  [
    "To my best knowledge , this combination of convolution and TT decomposition is new .",
    "NOVELTY"
  ],
  [
    "Novelty of the idea : The idea of using concentration inequalities to explain vulnerability is novel in the field of adversarial examples and is a relevant/meaningful angle on understanding this phenomenon .",
    "NOVELTY"
  ],
  [
    "this seems to be new to my knowledge",
    "NOVELTY"
  ],
  [
    "but the technical contribution in the proof is limited",
    "NOVELTY"
  ],
  [
    "As such , some of the technical content is similar to the original paper",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "The framework itself is new",
    "NOVELTY"
  ],
  [
    "I like such unifying framework very much , which builds connection among the existing mature knowledge",
    "NOVELTY"
  ],
  [
    "The framework is simple yet ingenious .",
    "NOVELTY"
  ],
  [
    "The proposed entropy-based method for relaxation of discrete constraints is intuitive and potentially adaptable for further constraints .",
    "NOVELTY"
  ],
  [
    "While it is a compelling ( but",
    "NOVELTY"
  ],
  [
    "not novel",
    "NOVELTY"
  ],
  [
    "the analogy to system 1 and system 2 does not benefit the proposed work in the slightest",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "I do n't think the demonstration of how to compute the MMD with an importance sampling estimate is a",
    "NOVELTY"
  ],
  [
    "sufficient contribution on",
    "NOVELTY"
  ],
  [
    "its own",
    "NOVELTY"
  ],
  [
    "This is an interesting",
    "NOVELTY"
  ],
  [
    "There are noteworthy contributions in terms of theory and applications in ML .",
    "NOVELTY"
  ],
  [
    "Interesting idea with novelty .",
    "NOVELTY"
  ],
  [
    "I consider the idea of this paper novel and interesting",
    "NOVELTY"
  ],
  [
    "I am not very clear on the incremental contribution over Loftus and Taylor , 2015 .",
    "NOVELTY"
  ],
  [
    "This is a clever variant of the original HBE by Charikar and Siminelakis .",
    "NOVELTY"
  ],
  [
    "While the paper reports some interesting improvements with respect to previous gradient matching approaches and the paper is interesting",
    "NOVELTY"
  ],
  [
    "I think that the lack of novelty is a major issue . Gradient matching has been extensively studied in various works referenced in the paper , so there is not much novelty from the modeling perspective .",
    "NOVELTY"
  ],
  [
    "so again there is no particular innovation apart from the specialization of this particular inference technique to this model",
    "NOVELTY"
  ],
  [
    "the novel idea of using contingency awareness",
    "NOVELTY"
  ],
  [
    "Tackles a long-standing problem in RL : efficient exploration in sparse reward environments Novel idea , which opens up new research directions Comparison experiments with competitive baselines Cons",
    "NOVELTY"
  ],
  [
    "This paper presents a novel way for efficiently exploring environments with sparse rewards",
    "NOVELTY"
  ],
  [
    "the paper is interesting and promising",
    "NOVELTY"
  ],
  [
    "The perspective from importance sampling coming from f-divergence for discrete GAN has some novelty although the foundations of this work relate also to previous work",
    "NOVELTY"
  ],
  [
    "The method is novel and solves a couple of prominent instances of an important open problem in deep learning for NLP and similar domains with latent structure",
    "NOVELTY"
  ],
  [
    "Modifications to existing methods are minor since the same relaxation and additional non-smooth regularization have been used on the same problem in the literature",
    "NOVELTY"
  ],
  [
    "The contribution of this work is incremental but not significant .",
    "NOVELTY"
  ],
  [
    "The idea introduced in this paper is interesting",
    "NOVELTY"
  ],
  [
    "I thought",
    "NOVELTY"
  ],
  [
    "with some nice ideas",
    "NOVELTY"
  ],
  [
    "The idea of using checkpoints as free samples of models is new and practical .",
    "NOVELTY"
  ],
  [
    "This is the only novelty in the paper .",
    "NOVELTY"
  ],
  [
    "In my opinion the work is very limited in originality with limited scope that it only applies to one type of RL algorithm combined with the very few set of experiments for supporting the claim fails to make the cut for publication",
    "NOVELTY"
  ],
  [
    "I think the use cycle-consistency loss in an auxiliary latent space is quite clever .",
    "NOVELTY"
  ],
  [
    "My main concerns are",
    "NOVELTY"
  ],
  [
    "clarity as well as the novelty of the theory : The theorems of this paper are built heavily on existing results in",
    "NOVELTY"
  ],
  [
    "and the additional arguments appear to me as incremental .",
    "NOVELTY"
  ],
  [
    "The idea is nice .",
    "NOVELTY"
  ],
  [
    "idea of using a geometric mean of matrices , by my knowledge , is quit new",
    "NOVELTY"
  ],
  [
    "the setting may be a bit narrow with the squared loss only",
    "NOVELTY"
  ],
  [
    "I believe this abstract would make a reasonably interesting contribution however",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "-Simple but novel self-supervised task for learning text representations",
    "NOVELTY"
  ],
  [
    "but this seems to be more of an incremental twist on previous work rather than a fundamental advance",
    "NOVELTY"
  ],
  [
    "Overall this is",
    "NOVELTY"
  ],
  [
    "paper paper presenting an approximate EM technique for dictionary learning in a Bernoulli-Gaussian setting .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm and analysis follow multiple ideas from previous work .",
    "NOVELTY"
  ],
  [
    "I have found the ideas proposed in the paper very insightful and interesting .",
    "NOVELTY"
  ],
  [
    "To summarise , the contribution seems to me novel and significant",
    "NOVELTY"
  ],
  [
    "The technical novelty of the method is n't great",
    "NOVELTY"
  ],
  [
    "and the approach looks quite promising",
    "NOVELTY"
  ],
  [
    "Overall , I find the approach quite interesting and promising .",
    "NOVELTY"
  ],
  [
    "This paper has a marginal amount of originality -- it leans heavily on the Ghosh and Ferrari/Yang papers",
    "NOVELTY"
  ],
  [
    "Whereas itself the architecture is not overly novel",
    "NOVELTY"
  ],
  [
    "No new model .",
    "NOVELTY"
  ],
  [
    "I like the suggestion of improving speed with gradient-based methods .",
    "NOVELTY"
  ],
  [
    "The paper seems novel and sensible and",
    "NOVELTY"
  ],
  [
    "This is the first paper I 've seen that uses amortized variational inference to approach this type of structured inference .",
    "NOVELTY"
  ],
  [
    "The proposed idea is very similar to the following paper : \u201c Revisiting Graph Neural Networks",
    "NOVELTY"
  ],
  [
    "The major concern of this work is the weak novelty .",
    "NOVELTY"
  ],
  [
    "While this",
    "NOVELTY"
  ],
  [
    "most GNN datasets , it is not very new by itself .",
    "NOVELTY"
  ],
  [
    "but the contribution seems incremental",
    "NOVELTY"
  ],
  [
    "the reader feels that the contribution is incremental .",
    "NOVELTY"
  ],
  [
    "Decomposing tensor operator as a layer in neural network is not new .",
    "NOVELTY"
  ],
  [
    "and",
    "NOVELTY"
  ],
  [
    "the proposed method seems to be novel Significance",
    "NOVELTY"
  ],
  [
    "The new proof provides new insights into the universal approximation property .",
    "NOVELTY"
  ],
  [
    "I think the core technical idea here is really exciting !",
    "NOVELTY"
  ],
  [
    "Finally , the novelty of the proposed contribution is questionable .",
    "NOVELTY"
  ],
  [
    "T_x0008_his paper presented a novel graph-based approach for visual question answering",
    "NOVELTY"
  ],
  [
    "The work is an advance in the context of mixed linear regression , and",
    "NOVELTY"
  ],
  [
    "It is novel and explains the model and motivations well .",
    "NOVELTY"
  ],
  [
    "but it is a novel approach that will be of interest to the field",
    "NOVELTY"
  ],
  [
    "and the approach developed here is novel to my understanding , interesting , well conducted , well described , and innovative .",
    "NOVELTY"
  ],
  [
    "This entire analysis pattern is pretty novel and I have not seen similar analyses in the literature . The discussion session is very well-written and insightful as well",
    "NOVELTY"
  ],
  [
    "But given the novelty of the result and the analysis , I think it brings in interesting new ideas and directions for future work , which makes it a nice contribution .",
    "NOVELTY"
  ],
  [
    "the formal justification of the CDP trade-off is a novel contribution quality",
    "NOVELTY"
  ],
  [
    "Overall , the formulation and analysis of CDP is a good contribution to the community .",
    "NOVELTY"
  ],
  [
    "I think the paper is interesting and should definitely appear in NIPS",
    "NOVELTY"
  ],
  [
    "The general idea being explored here is not entirely new .",
    "NOVELTY"
  ],
  [
    "I do n't see what the contribution is here",
    "NOVELTY"
  ],
  [
    "I was very excited by the ideas in section 5 , this work is the first to my knowledge to attempt at interpreting poisoning attacks .",
    "NOVELTY"
  ],
  [
    "The work presents a novel and effective solution to the difficult task of learning reusable motor skills .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    ") , in my view the contributions are not significant at this stage .",
    "NOVELTY"
  ],
  [
    "Based on my understanding , I don \u2019 t find the findings to be significantly novel or surprising .",
    "NOVELTY"
  ],
  [
    "The idea is simple and novel ; to the best of my knowledge it has not been tested before",
    "NOVELTY"
  ],
  [
    "The idea is simple and novel , which is good",
    "NOVELTY"
  ],
  [
    "the autoencoder-based init scheme (",
    "NOVELTY"
  ],
  [
    "Sperduti , 2014 ) is not new while the only technical contribution of this paper is a minor change of this scheme so that it works for the LMN",
    "NOVELTY"
  ],
  [
    "In my opinion , combining these two ( LMN and init scheme ) can hardly be considered as a solid novelty contribution .",
    "NOVELTY"
  ],
  [
    "Overall I think the novelty contribution is marginal and I suggest the authors to test their models on larger-scale real problems",
    "NOVELTY"
  ],
  [
    "The overall approach of using graph neural networks to learn a joint representation of grammars with the corresponding logical specifications , and then using reinforcement learning to learn a search policy over the grammar is quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "Even so , the method ( as far as I can tell ) is novel and appears to",
    "NOVELTY"
  ],
  [
    "and obtained novel and useful results",
    "NOVELTY"
  ],
  [
    "2 .To the best of my knowledge , this paper seems to be the first paper about DP tensor decomposition , which is quite interesting .",
    "NOVELTY"
  ],
  [
    "The used proof techniques are novel and useful .",
    "NOVELTY"
  ],
  [
    "The used proof techniques are novel and useful . A very nice contribution of the paper is that it significantly deepens the insights into pairwise FW variants",
    "NOVELTY"
  ],
  [
    "The proof techniques are novel and might be useful for the future",
    "NOVELTY"
  ],
  [
    "2 .The idea of modeling positions as a latent variable is interesting and might generalize to other tasks beyond NAT",
    "NOVELTY"
  ],
  [
    "While the idea of using a representation inspired by cognitive maps is interesting",
    "NOVELTY"
  ],
  [
    ", the paper does not offer much technical novelty .",
    "NOVELTY"
  ],
  [
    "the proposed method is reasonable and novel",
    "NOVELTY"
  ],
  [
    "Combining neural nets with CRFs is not a new idea",
    "NOVELTY"
  ],
  [
    "Originality The authors propose a novel method for OOD that shows promising results and introduce a novel benchmark problem to the literature . Significance The idea to build test statistics on likelihood-ratios for OOD detection is interesting and opens room for developing novel techniques in future papers .",
    "NOVELTY"
  ],
  [
    "yet another algorithm-for-group-fairness-in-binary-classification paper",
    "NOVELTY"
  ],
  [
    "The authors provided a novel framework to analyze Adam-type algorithms by using standard FTRL framework .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "the proposed DCC is very similar to RCC-DR (",
    "NOVELTY"
  ],
  [
    "The paper proposes to use residual learning as an auxiliary to compensate for the sub-optimal expressiveness of the source policies , which is novel and interesting .",
    "NOVELTY"
  ],
  [
    "a reasonable amount of novelty",
    "NOVELTY"
  ],
  [
    "The mathematical formulation of the metric consists of simple sums and averages , which in itself is not novel . However",
    "NOVELTY"
  ],
  [
    ", the authors ' choice of using such formulations to assess model performance is novel .",
    "NOVELTY"
  ],
  [
    "I think the paper makes a good methodological contribution",
    "NOVELTY"
  ],
  [
    "I like the contributions of this paper and I think the proposed algorithms are novel",
    "NOVELTY"
  ],
  [
    "On the other hand , the contributions of the paper are somewhat limited .",
    "NOVELTY"
  ],
  [
    "but does not have any methodological contribution , and there is also few insightful results about the compared methods , nor is there meaningful analysis of the problem domain of molecules either",
    "NOVELTY"
  ],
  [
    "1 .I think the proposed hypothesis lacks the novelty that ICLR audience seeks for .",
    "NOVELTY"
  ],
  [
    "which is not novel",
    "NOVELTY"
  ],
  [
    "The proposed methodology is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The idea of using visual signals to predict wind speed is indeed quite clever .",
    "NOVELTY"
  ],
  [
    "the paper neither introduces a theoretical or a methodological novelty , nor does it",
    "NOVELTY"
  ],
  [
    "Given the limited scope of the empirical validation",
    "NOVELTY"
  ],
  [
    "This is a pretty clever idea and this reviewer highly recommends explicitly mentioning it in the intro",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work to propose a meta-optimizer for population-based optimization . * The entropy term that encourages exploration seems novel , at least in the context of optimizer learning .",
    "NOVELTY"
  ],
  [
    "It presents an interesting approach",
    "NOVELTY"
  ],
  [
    "I find the whole paper interesting and match the",
    "NOVELTY"
  ],
  [
    "Though the proposed model is simple",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "think it has novelty inside .",
    "NOVELTY"
  ],
  [
    "I am not sure what are its novel contributions and why it should be published in a scientific conference",
    "NOVELTY"
  ],
  [
    "I do not think the contributions of this paper are enough to be published in ICLR",
    "NOVELTY"
  ],
  [
    "I do not think using this standard approach in a differentiable renderer can be claimed as a significant novel contribution .",
    "NOVELTY"
  ],
  [
    "but they do not provide a significant improvement over previous work on these problems in my opinion",
    "NOVELTY"
  ],
  [
    "the technical contribution in the differentiable renderer does not seem significant enough to me for a NeurIPS paper .",
    "NOVELTY"
  ],
  [
    "which I think is the major contribution of the paper",
    "NOVELTY"
  ],
  [
    "and",
    "NOVELTY"
  ],
  [
    "Things I liked about the work",
    "NOVELTY"
  ],
  [
    "Originality To the best of my knowledge , no-one has considered the non-cooperative IRL setting addressed in this paper .",
    "NOVELTY"
  ],
  [
    "but the fact that it\u00e2\u0080\u0099s just an application of the Rosenberg result reduces the originality somewhat",
    "NOVELTY"
  ],
  [
    "I am not sufficiently versed in the literature to assess whether the idea is sufficiently novel to warrant acceptance .",
    "NOVELTY"
  ],
  [
    "The relative simplicity and generality of GraphMix is appealing .",
    "NOVELTY"
  ],
  [
    "Overall , the idea is novel and it is well",
    "NOVELTY"
  ],
  [
    "There are very little changes compared to the proposal by Ganin & Lempitsky '15",
    "NOVELTY"
  ],
  [
    "paper extends the existing results in some subtle ways",
    "NOVELTY"
  ],
  [
    "there are no or little novel contributions .",
    "NOVELTY"
  ],
  [
    "I think the paper should be rejected for lacking novelty and writing quality",
    "NOVELTY"
  ],
  [
    "The actual implementation of conditioning seems quite trivial",
    "NOVELTY"
  ],
  [
    "the baselines they compared to are not very recent",
    "NOVELTY"
  ],
  [
    "I believe there is very less novelty , technical sophistication and performance improvements in this paper",
    "NOVELTY"
  ],
  [
    "In terms of novelty , the RRSVM does the bulk of the work here and it is a straightforward progression to use the most important areas as fixation points for visual attention",
    "NOVELTY"
  ],
  [
    "-Novel formulation , SOTA results",
    "NOVELTY"
  ],
  [
    "A strong paper , that brings together and",
    "NOVELTY"
  ],
  [
    "3 .The proposed loss based on KL is not really novel .",
    "NOVELTY"
  ],
  [
    "I still have concerns that the contribution of the paper is relatively incremental and the",
    "NOVELTY"
  ],
  [
    "Thus contribution is incremental and novelty is limited .",
    "NOVELTY"
  ],
  [
    "Therefore , the idea of using hash functions is not novel .",
    "NOVELTY"
  ],
  [
    "and so it 's unclear if its met the novelty bar for NIPS",
    "NOVELTY"
  ],
  [
    "but that should include further references and readjust the contribution section considering that the straight through is not novel",
    "NOVELTY"
  ],
  [
    "In addition discussing settings such as the following do not seem of broad interest/novelty `` If we have the prior knowledge that the goal from the previous task is on the path to the goal",
    "NOVELTY"
  ],
  [
    "The novelity comes through the experimental analysis .",
    "NOVELTY"
  ],
  [
    "Other than the framework , the paper does not present any new tasks/results/algorithms , so it is not clear what the contribution is .",
    "NOVELTY"
  ],
  [
    "Overall I liked the idea , and this could potentially result in improved value iteration especially when scaled up in complex domains where complex function approximators are used",
    "NOVELTY"
  ],
  [
    "The model is an interesting case of applying POMDP methods",
    "NOVELTY"
  ],
  [
    "I like the idea",
    "NOVELTY"
  ],
  [
    ", with some interesting observations",
    "NOVELTY"
  ],
  [
    "The ideas in this work are both promising and interesting",
    "NOVELTY"
  ],
  [
    "Also the experimental gains seem incremental",
    "NOVELTY"
  ],
  [
    "such generalization",
    "NOVELTY"
  ],
  [
    "The contribution of this work seems pretty incremental to me .",
    "NOVELTY"
  ],
  [
    "I do n't think the model itself is sufficient contribution for a publication at ICLR",
    "NOVELTY"
  ],
  [
    "there is not much innovation in the model architecture .",
    "NOVELTY"
  ],
  [
    "Overall , I think the proposed algorithms lack novelty due to the following reasons .",
    "NOVELTY"
  ],
  [
    "I am not sure this is a significant contribution compared to DoReFa .",
    "NOVELTY"
  ],
  [
    "In terms of empirical contribution",
    "NOVELTY"
  ],
  [
    "and the overall idea is interesting and simple in implementation .",
    "NOVELTY"
  ],
  [
    "I think some ideas are interesting",
    "NOVELTY"
  ],
  [
    "thoug perhaps not very novel",
    "NOVELTY"
  ],
  [
    "the technical novelty of the work is limited",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the proposed algorithm as well as the analysis has novel insights/contributions .",
    "NOVELTY"
  ],
  [
    "improves over previous results in several directions",
    "NOVELTY"
  ],
  [
    "no novel algorithm is proposed and",
    "NOVELTY"
  ],
  [
    "Overall I find the results and the algorithms are quite interesting although the main idea of the new algorithm is quite simple",
    "NOVELTY"
  ],
  [
    "The contribution and novelty of this paper is incremental and somehow limited",
    "NOVELTY"
  ],
  [
    "The technique contributions are not significant .",
    "NOVELTY"
  ],
  [
    "Somewhat incremental novelty relatively to Fitnet",
    "NOVELTY"
  ],
  [
    "The framework for blind regression based on the first order local Taylor expansion of a function",
    "NOVELTY"
  ],
  [
    "b .The technical contribution is not clear and if correct , if of limited novelty .",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is thus limited",
    "NOVELTY"
  ],
  [
    "The idea of applying machine learning to induce SMT strategies is very promising , with several works pursuing it .",
    "NOVELTY"
  ],
  [
    "Each of the components of this work are present in the literature for a",
    "NOVELTY"
  ],
  [
    "and as the paper puts it to the best of my knowledge , this is the first work which combined all the moving parts mentioned above and got it to work successfully with good results .",
    "NOVELTY"
  ],
  [
    "Although it is concise it seems that the idea is interesting",
    "NOVELTY"
  ],
  [
    "The presented algorithm and theoretical results are interesting",
    "NOVELTY"
  ],
  [
    "-- An interesting idea to use CRF idea to cluster the nodes on a graph for pooling purpose",
    "NOVELTY"
  ],
  [
    "Although the proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "I like the idea itself - this fits in with the self-supervision trend",
    "NOVELTY"
  ],
  [
    "However , the novelty of the proposed method compared to the TCN seems limited",
    "NOVELTY"
  ],
  [
    "but the contribution is clear",
    "NOVELTY"
  ],
  [
    "Although the idea of combining model-free and model-based approaches is definitely not new",
    "NOVELTY"
  ],
  [
    ", the proposed approach , as far as I know , is original",
    "NOVELTY"
  ],
  [
    "I do not think that the contribution introduced in this paper is so strong to attract the interest of many researchers in the field .",
    "NOVELTY"
  ],
  [
    "The Fast-SWA is a minor tweak to the regular SWA .",
    "NOVELTY"
  ],
  [
    "the results seems to be derived on the basis of Avron and Toledo and the authors ' contribution relative to that is not clear .",
    "NOVELTY"
  ],
  [
    "and as such this paper constitutes an important contribution",
    "NOVELTY"
  ],
  [
    "The latency-reduction losses are novel",
    "NOVELTY"
  ],
  [
    ", however .",
    "NOVELTY"
  ],
  [
    "This contribution to the theory of feed-forward neural networks , through the introduction of a new computational model , the computation skeleton , seems both original and promising .",
    "NOVELTY"
  ],
  [
    ", novelty of the approach is limited as the setup is quite similar to the ERL algorithm ( which is still on archive and not published",
    "NOVELTY"
  ],
  [
    "I do n't know that the concept of `` reliance on a single direction `` seems especially novel to me",
    "NOVELTY"
  ],
  [
    "It provides a fresh take",
    "NOVELTY"
  ],
  [
    "to me , the main contribution is conceptual as opposed to technical .",
    "NOVELTY"
  ],
  [
    "but I do n't see any novelty here",
    "NOVELTY"
  ],
  [
    "I feel that this is too little an innovation for deserving publication in ICLR2018",
    "NOVELTY"
  ],
  [
    "the model change to multi-column is incremental",
    "NOVELTY"
  ],
  [
    "This is the first paper ( to my best knowledge ) to prove such convergence result for weight normalization .",
    "NOVELTY"
  ],
  [
    "this is a good paper but the contribution might not be sufficient for acceptance for the reasons below",
    "NOVELTY"
  ],
  [
    "the overall framework is very similar to previous works and the dynamics of NNs still lives in the kernel regime",
    "NOVELTY"
  ],
  [
    "the contribution is original .",
    "NOVELTY"
  ],
  [
    "this paper",
    "NOVELTY"
  ],
  [
    "discussion",
    "NOVELTY"
  ],
  [
    "As well stated in the introduction , the compression of GANs ( in particular the generator , which is used at inference time ) is of practical interest and , to the best of my knowledge , novel .",
    "NOVELTY"
  ],
  [
    "the proposed method lacks novelty",
    "NOVELTY"
  ],
  [
    "1 The technical novelty is a bit limited in compared with those 3-order tensor factorization based methods .",
    "NOVELTY"
  ],
  [
    "The approach of using static analysis for this problem is a novel contribution .",
    "NOVELTY"
  ],
  [
    "the proposed technique interesting",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge what 's proposed in this paper is novel .",
    "NOVELTY"
  ],
  [
    "Originality The problem of incorporating memory in model-free RL is not new",
    "NOVELTY"
  ],
  [
    "This paper attempts at providing both , and thus makes for a good and original contribution to the NeurIPS community .",
    "NOVELTY"
  ],
  [
    "tackles novel , challenging , large scale problem of synthesizing views for indoor scenes",
    "NOVELTY"
  ],
  [
    "which is a nice theoretical contribution",
    "NOVELTY"
  ],
  [
    "Those extensions seem a bit incremental and are not well supported by the experimental results in the paper",
    "NOVELTY"
  ],
  [
    "Parametrizing a subset of the group of increasing function and its application to signal processing tools is novel , to my knowledge .",
    "NOVELTY"
  ],
  [
    "Learning or using an underlying group of symmetry that will be combined with a deep neural network is not novel",
    "NOVELTY"
  ],
  [
    "They present an elegant method that takes into account those three difficulties by means of a well-designed optimization problem .",
    "NOVELTY"
  ],
  [
    "regarding the planning framework it is unclear how novel the result is",
    "NOVELTY"
  ],
  [
    "the MPC procedure that the authors present in this paper is not novel",
    "NOVELTY"
  ],
  [
    "The data gathering process is also not a new idea and using the error in a dynamics model for exploration is a well-known method",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel architecture for capsule networks .",
    "NOVELTY"
  ],
  [
    ", introducing a series of valuable technical novelties .",
    "NOVELTY"
  ],
  [
    "All in all , the paper brings an original contribution and will encourage further research /",
    "NOVELTY"
  ],
  [
    "2 .The novelty and technical contributions are significant .",
    "NOVELTY"
  ],
  [
    "Though adversarial learning has been studied in deep learning , this is the first study of attacks on stochastic bandit algorithms to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "and the idea is quite novel .",
    "NOVELTY"
  ],
  [
    "Novelty is mainly incremental Minor comment",
    "NOVELTY"
  ],
  [
    "While the idea of the paper is good",
    "NOVELTY"
  ],
  [
    "The idea of using a planning mechanism on sequence-to-sequence models seems novel .",
    "NOVELTY"
  ],
  [
    "This paper proposes an architecture that is not over-complicated and contains some nice ideas .",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat limited because a related alternation architecture was proposed in",
    "NOVELTY"
  ],
  [
    "To this reviewer , the idea of self-supervision is similar to the unsupervised learning for representation learning .",
    "NOVELTY"
  ],
  [
    "a novel version of multi-class nearest neighbor",
    "NOVELTY"
  ],
  [
    "Despite the fact that the implementation is only marginally tweaked from previous work ( deep SVDD )",
    "NOVELTY"
  ],
  [
    "This paper is the first demonstration of flow-based models to discrete data . As such , the work is fairly novel .",
    "NOVELTY"
  ],
  [
    "Although the introduction of discrete flows is a significant contribution , the paper currently feels like more of a proof-of-concept",
    "NOVELTY"
  ],
  [
    "The ideas and proofs in the paper are very insightful .",
    "NOVELTY"
  ],
  [
    "All of the ideas presented are novel and original to my knowledge . Compression with flows is a new research area and I am unaware of any prior works",
    "NOVELTY"
  ],
  [
    "In sum , I think this is a solid contribution and the approach will benefit the research in other problems",
    "NOVELTY"
  ],
  [
    "The technical contribution seems marginal .",
    "NOVELTY"
  ],
  [
    "The idea of using clustering to discover goals in reinforcement learning is quite old and the",
    "NOVELTY"
  ],
  [
    "The particular instantiation of clustering interesting states used in this paper does seem to be new",
    "NOVELTY"
  ],
  [
    "and the overall novelty is still somewhat limited",
    "NOVELTY"
  ],
  [
    "The proposed algorithm named MetaGrad is novel and its regret analysis guarantees the good performance for broad classes of",
    "NOVELTY"
  ],
  [
    "Although building heavily on previous work ( Boutilier and Lu , 2016 ) , this paper makes a novel effort in proposing the BMDP framework as a concrete solution to safe RL .",
    "NOVELTY"
  ],
  [
    "This is a good contribution which removes some previously required restrictions for training spiking neuron models ( which are enumerated in the introduction",
    "NOVELTY"
  ],
  [
    "This contribution is not major",
    "NOVELTY"
  ],
  [
    "However , I feel that the technical contributions are a bit incremental , as they are a fairly straightforward combination of existing techniques ( threshold/Bernoulli quantization , and slop factor ) .",
    "NOVELTY"
  ],
  [
    "The idea of explicitly representing the neighborhood structure within a dataset is generally interesting and seems related to the concept of low-dimensional image manifold .",
    "NOVELTY"
  ],
  [
    "This work seems related to simultaneous clustering and representation learning",
    "NOVELTY"
  ],
  [
    "the paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "The idea of synaptic strength appears intriguing .",
    "NOVELTY"
  ],
  [
    "Technical contributions in the present paper are rather limited .",
    "NOVELTY"
  ],
  [
    "I really liked the idea behind the pooling operation :",
    "NOVELTY"
  ],
  [
    "but this application scenario is quite limited",
    "NOVELTY"
  ],
  [
    "Overall , I like the simple idea proposed in this paper .",
    "NOVELTY"
  ],
  [
    "Intuitive and novel ideas .",
    "NOVELTY"
  ],
  [
    "propose a dynamic computation graph by pruning the activations on the fly during the training of inference , which is an interesting and novel exploration",
    "NOVELTY"
  ],
  [
    "This paper addresses the computational burden in both memory and time from a novel angle than previous network pruning methods .",
    "NOVELTY"
  ],
  [
    "This paper present an interesting and novel approach for network pruning in both training and inference .",
    "NOVELTY"
  ],
  [
    "-The proposed technique does not seem to be original enough , and it",
    "NOVELTY"
  ],
  [
    "the paper is more like a proper verification of how tree-based learning algorithms work very well in tabular data -- which is far from the basis of the paper and does not make the paper novel enough for ICLR",
    "NOVELTY"
  ],
  [
    "newcomer",
    "NOVELTY"
  ],
  [
    "the results in this paper address a novel problem , and make technically innovative and honestly surprising insights in terms of the tractability and uniqueness of the recovery problems addressed in the paper .",
    "NOVELTY"
  ],
  [
    "I like this paper",
    "NOVELTY"
  ],
  [
    "in modeern CNNs",
    "NOVELTY"
  ],
  [
    "the simplicity of this is very attractive",
    "NOVELTY"
  ],
  [
    "I believe it has not been done before",
    "NOVELTY"
  ],
  [
    "In a sense the deep and structured extensions seem to be `` just `` imported and brought together from previous studies in sparse coding",
    "NOVELTY"
  ],
  [
    "but a bit of technical in nature and very specialized in scope",
    "NOVELTY"
  ],
  [
    "limitations , a good contribution on its own",
    "NOVELTY"
  ],
  [
    "This line of work is very recent (",
    "NOVELTY"
  ],
  [
    "While the paper contributes interesting results",
    "NOVELTY"
  ],
  [
    "it seems slightly lacking in novelty/depth .",
    "NOVELTY"
  ],
  [
    "is not novel as a contribution .",
    "NOVELTY"
  ],
  [
    "However the calculations for the attacks , while very involved and non-trivial are not novel in themselves .",
    "NOVELTY"
  ],
  [
    "there is little to no significant ML contribution .",
    "NOVELTY"
  ],
  [
    "While no one facet of the paper is particularly novel",
    "NOVELTY"
  ],
  [
    "the paper , as far as I \u2019 m aware , is the first to formally decompose the ELBO into the R vs D tradeoff , which is natural",
    "NOVELTY"
  ],
  [
    "I didn \u2019 t find the paper conceptually novel ,",
    "NOVELTY"
  ],
  [
    "provides new methods for training VAE-type models which can hopefully advance the state of the art in unsupervised representation learning",
    "NOVELTY"
  ],
  [
    "I think the paper is a new take on how to deal with adversarial examples .",
    "NOVELTY"
  ],
  [
    "despite some loose wording I think this paper makes a nice contribution",
    "NOVELTY"
  ],
  [
    "These improvements over [ 1 ] is novel and significant , allowing the training of larger provably robust networks with more versatile structures .",
    "NOVELTY"
  ],
  [
    "The idea of repurposing Farkas ' lemma from linear programming to a component in NNs is very nice .",
    "NOVELTY"
  ],
  [
    "Overall , however , the ideas presented in the paper are interesting and original , presumably applicable to multiple domains including Graph attention or Graph embedding .",
    "NOVELTY"
  ],
  [
    "The work looks original .",
    "NOVELTY"
  ],
  [
    "the type prediction problem that utilizes structural information of the code",
    "NOVELTY"
  ],
  [
    "Also the pointer mechanism used for predicting user specified types is a good strategy that advances the previous method .",
    "NOVELTY"
  ],
  [
    "it seems the construction of the task specific graph is the major contribution , where the novelty is a bit limited",
    "NOVELTY"
  ],
  [
    "This work represents a very interesting and original generalization of the work of Gr\\ `` unwald and Dawid to the case of learning with inputs",
    "NOVELTY"
  ],
  [
    "The proposed model is novel from a modelling perspective since it makes CEM part of end-to-end learnable models .",
    "NOVELTY"
  ],
  [
    "it has no algorithmic novelty since it is a straightforward application of the LML layer to the CEM problem",
    "NOVELTY"
  ],
  [
    "On the positive side , the idea of applying rate distortion to this problem is interesting and as far as I can tell novel . I rather like it and think it is a promising idea .",
    "NOVELTY"
  ],
  [
    "All in all , I think there is an interesting idea in this submission that could be shaped into good paper .",
    "NOVELTY"
  ],
  [
    "A lot of the ideas in this paper are similar to those proposed in prior work -- the network for embedding the trajectory is similar to the ones from Wang et al",
    "NOVELTY"
  ],
  [
    "2 .The paper has proposed a novel loss function call the Histogram Loss .",
    "NOVELTY"
  ],
  [
    "The idea of the method is straightforward , and the proofs are not particularly surprising , and the techniques used therein not overly innovative .",
    "NOVELTY"
  ],
  [
    "I find the results and approach of this paper nice , but",
    "NOVELTY"
  ],
  [
    "somewhat incremental ; and far from the `` novelty `` and `` strong implications `` claimed",
    "NOVELTY"
  ],
  [
    "You claim a novel approach",
    "NOVELTY"
  ],
  [
    "However , what you described here does not seem really novel",
    "NOVELTY"
  ],
  [
    "so sounds a lot more incremental than what you suggest",
    "NOVELTY"
  ],
  [
    "interesting , the new procedures and concepts are clever",
    "NOVELTY"
  ],
  [
    "My only concern",
    "NOVELTY"
  ],
  [
    "the strongest innovation ( decaying memory procedure",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "While this is an interesting addition , I think that using fast encoders is not particularly novel or the main part of the work .",
    "NOVELTY"
  ],
  [
    "The paper contains intriguing ideas about the benefits of sparse and predictive coding",
    "NOVELTY"
  ],
  [
    "and the machine learning paper example in the paper is pretty toy",
    "NOVELTY"
  ],
  [
    "I believe this paper has some interesting ideas and novel results that are of interest to the community .",
    "NOVELTY"
  ],
  [
    "The first set of experimental results in Section 2 , feels like an incremental extension of a previous publication",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel attention approach to graph neural networks which is applicable to both of node and graph classification . The proposed method gives an attention to a subgraph instead of a node by which importance can be controlled as a set of nodes . Further , the authors also introduce two types of attention in the hierarchical structure of the network called intra- and inter- level attention . Considering subgraph attention would be novel and a reasonable idea .",
    "NOVELTY"
  ],
  [
    "I find the originality low in the context of that prior work",
    "NOVELTY"
  ],
  [
    "It is a natural and intuitive application of CycleGAN to domain adaptation .",
    "NOVELTY"
  ],
  [
    "The technical contribution seems like only marginal innovative .",
    "NOVELTY"
  ],
  [
    "The proposed method is a natural application of CycleGAN to domain adaptation .",
    "NOVELTY"
  ],
  [
    "The technical contribution is only marginal .",
    "NOVELTY"
  ],
  [
    "I still think the technical contribution is only marginally innovative .",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting and provide some good insight for RCD and SGD algorithms .",
    "NOVELTY"
  ],
  [
    "The algorithm itself is primarily an application of SAGA as an inner loop",
    "NOVELTY"
  ],
  [
    "but the analysis is original and the observation that the constants can be balanced in an appropriate way is original .",
    "NOVELTY"
  ],
  [
    "In particular , to the best of my knowledge , this is the first paper considering contextual combinatorial semi-bandits with * unknown* weights .",
    "NOVELTY"
  ],
  [
    "I think that it is a nice contribution",
    "NOVELTY"
  ],
  [
    "It is not clear how original the proposed contributions are .",
    "NOVELTY"
  ],
  [
    "Therefore , the originality is limited and incremental .",
    "NOVELTY"
  ],
  [
    "I found the idea interesting",
    "NOVELTY"
  ],
  [
    "interesting idea",
    "NOVELTY"
  ],
  [
    "The techniques used to obtain transport mappings are quite interesting and seem novel , and the general approach for controlling various steps from neural network function to the target function in L2 ( P ) norm in the NTK setting is insightful and novel as far as I know .",
    "NOVELTY"
  ],
  [
    "To sum up , I think that the general idea looks very natural",
    "NOVELTY"
  ],
  [
    "Novelty is a weak factor in this paper .",
    "NOVELTY"
  ],
  [
    "Applying the NFs to MaxEnt is in itself not very novel as a framework .",
    "NOVELTY"
  ],
  [
    "It seems that this work is an incremental improvement on the existing works .",
    "NOVELTY"
  ],
  [
    "The setting is reasonably novel",
    "NOVELTY"
  ],
  [
    "This observation is novel ( although not too surprising ) to my knowledge",
    "NOVELTY"
  ],
  [
    "and the contributions are clear",
    "NOVELTY"
  ],
  [
    "My main concern is about the novelty of the paper",
    "NOVELTY"
  ],
  [
    "The fact that unbiased estimates of the gradient of the Gaussian smoothing of a function can be obtained by function evaluations on a batch is not novel",
    "NOVELTY"
  ],
  [
    "I still believe this paper makes important contributions that makes it a good fit for NIPS",
    "NOVELTY"
  ],
  [
    "The approach is new .",
    "NOVELTY"
  ],
  [
    "The proposed model is ( as far as I can tell ) genuinely novel and fulfills the exciting promise of a general-purpose , learnable physics engine",
    "NOVELTY"
  ],
  [
    "In my opinion , the main weakness of the paper is that the estimator is very classical , at least for density estimation .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems highly similar to the existing multi-objective NAS algorithms ,",
    "NOVELTY"
  ],
  [
    "However , both aspects are of limited technical novelty .",
    "NOVELTY"
  ],
  [
    "However , the analysis following from this fact ( as well as the other results ) seems novel to me .",
    "NOVELTY"
  ],
  [
    "I like this idea and think the paper merits acceptance",
    "NOVELTY"
  ],
  [
    "Jointly learning the language parsing and visual representations indirectly from paired Q/A and paired",
    "NOVELTY"
  ],
  [
    "The method proposed appears to be a fairly straightforward variant of one proposed in a previous paper",
    "NOVELTY"
  ],
  [
    "There seems to be no novel machine learning contribution ( nor is it claimed ) .",
    "NOVELTY"
  ],
  [
    "We think that the major issue in this work is that it does not provide significant contributions with respect to the state of the art . It seems that the contributions are rather incremental compared to related works , such as Levy et al .2015 and Yin",
    "NOVELTY"
  ],
  [
    "The submitted paper does not provide new significant results .",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "I do see that there is some novelty in this work but given that several key references were missing",
    "NOVELTY"
  ],
  [
    "Moreover , the amount of novelty is limited compared to what is stated in the current version .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is not clear .",
    "NOVELTY"
  ],
  [
    "The proposed defense is not very original either",
    "NOVELTY"
  ],
  [
    "mechanisms",
    "NOVELTY"
  ],
  [
    "the use of actual cheap talk is rather abstract",
    "NOVELTY"
  ],
  [
    "While the intuition is nice and interesting",
    "NOVELTY"
  ],
  [
    "Overall it is an interesting paper with an interesting idea .",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper .",
    "NOVELTY"
  ],
  [
    "I really like the Proposition 3 as this is the most important contribution of the paper .",
    "NOVELTY"
  ],
  [
    "but it was pretty abstract for a neurips paper",
    "NOVELTY"
  ],
  [
    "The application of self-attention in continuous-time event sequences is an interesting approach .",
    "NOVELTY"
  ],
  [
    "I believe the proposed time embeddings are novel and generalizable to other temporal tasks .",
    "NOVELTY"
  ],
  [
    "and developing differentiable time embeddings is the key contribution of this paper",
    "NOVELTY"
  ],
  [
    "and is the most interesting contribution of this paper",
    "NOVELTY"
  ],
  [
    "Although the proposed approach is novel",
    "NOVELTY"
  ],
  [
    "Overall , it is n't an especially large contribution",
    "NOVELTY"
  ],
  [
    "but I felt it had some interesting points",
    "NOVELTY"
  ],
  [
    "of the paper",
    "NOVELTY"
  ],
  [
    "I find the paper interesting",
    "NOVELTY"
  ],
  [
    "The problem of variable selection using decision tree is not new",
    "NOVELTY"
  ],
  [
    "I think that this paper provide a relevant contribution",
    "NOVELTY"
  ],
  [
    "However , the approach is mainly an application of existing methods and the technical novelty is low .",
    "NOVELTY"
  ],
  [
    "this paper did n't give me too much scientific insight .",
    "NOVELTY"
  ],
  [
    "This paper does not provide a coherent technical novelty .",
    "NOVELTY"
  ],
  [
    "The paper is innovative .",
    "NOVELTY"
  ],
  [
    "While the paper presents an interesting combination of two approaches for the task of answer extraction , the novelty is moderate",
    "NOVELTY"
  ],
  [
    "a simple idea - encouraging",
    "NOVELTY"
  ],
  [
    "it seems the contribution of this work is quite incremental .",
    "NOVELTY"
  ],
  [
    "has some good contributions to robust option learning",
    "NOVELTY"
  ],
  [
    "main technicalities including the assumptions , the initialization , and the main proof technique is very similar to the previous art .",
    "NOVELTY"
  ],
  [
    "is insightful and novel , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "I like the idea of using \u201c pseudo \u201d OOD data for encouraging better behaved uncertainties away from the data .",
    "NOVELTY"
  ],
  [
    "It appears that the novelty of the presented method is limited .",
    "NOVELTY"
  ],
  [
    "The approach of reverse engineering the hierarchy , and learning high-level transition matrix is very interesting and promising .",
    "NOVELTY"
  ],
  [
    "the paper falls short in the novelty , precision , and clarity",
    "NOVELTY"
  ],
  [
    "An interesting idea",
    "NOVELTY"
  ],
  [
    "This is very surprising and interesting to me",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the authors are the first to provide a complete theoretical analysis of local SGD for strongly convex functions .",
    "NOVELTY"
  ],
  [
    "The overall theory seems to be partly inspired by the perturbed iterates framework of Mania et al. , however",
    "NOVELTY"
  ],
  [
    "the application is novel and interesting",
    "NOVELTY"
  ],
  [
    "Although it seems a bit incremental since the techniques involved have been studied in IAF and MADE",
    "NOVELTY"
  ],
  [
    "The theory of robust MDPs has already been extended to the model-free reinforcement learning setting",
    "NOVELTY"
  ],
  [
    "In effect , the main contribution of this paper is not original .",
    "NOVELTY"
  ],
  [
    "The family of log-concave distributions is a powerful and general family of distributions that are often used in machine learning",
    "NOVELTY"
  ],
  [
    "I think this paper makes very nice contributions to the fundamental question of estimating the MLE distribution given a bunch of observations",
    "NOVELTY"
  ],
  [
    "Therefore , the technical novelty of the proposed method is limited .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is not very clear .",
    "NOVELTY"
  ],
  [
    "The approach is novel and relevant to ICLR .",
    "NOVELTY"
  ],
  [
    "The method is novel , interesting and practical .",
    "NOVELTY"
  ],
  [
    "and incremental",
    "NOVELTY"
  ],
  [
    "It is a solid paper with some lack of novelty and significance .",
    "NOVELTY"
  ],
  [
    "I think the ideas and approaches are good , and certainly worth publishing",
    "NOVELTY"
  ],
  [
    "My main concern is that the ideas , while interesting , are not novel ,",
    "NOVELTY"
  ],
  [
    "4 .The environments seem to be all fairly similar",
    "NOVELTY"
  ],
  [
    "While the idea of correlated sampling is obviously nothing new , this technique has not yet been applied to the medoid problem .",
    "NOVELTY"
  ],
  [
    "The paper lacks technical novelty other than the training and test data generation approach",
    "NOVELTY"
  ],
  [
    "Novelty is somewhat low for the paper as Hindsight Experience Replay already presented a very similar off-goal-correction mechanism for actor-critic methods",
    "NOVELTY"
  ],
  [
    "Time-series forecasting is however a novel application for this type of models",
    "NOVELTY"
  ],
  [
    "I found the discriminator design very interesting .",
    "NOVELTY"
  ],
  [
    "theory , algorithm",
    "NOVELTY"
  ],
  [
    "I find the proposed approach new and interesting .",
    "NOVELTY"
  ],
  [
    "I find the proposed approach new and interesting .",
    "NOVELTY"
  ],
  [
    "original , convincing , and motivated",
    "NOVELTY"
  ],
  [
    "Without knowing too much about graph matching and its related literature , the approach seems novel ,",
    "NOVELTY"
  ],
  [
    "enough as a contribution",
    "NOVELTY"
  ],
  [
    "The idea of training multiple adversaries over random subspaces is very similar to the idea of random forests which help with variance reduction",
    "NOVELTY"
  ],
  [
    "Although the proposed model is a conglomeration of pre-existing parts , the combination is original to my knowledge . The use of Open Information Extraction to transform natural language statements to logical statements , which amenable to theorem provers , is novel and also circumvents the complicated preprocessing required by previous related works .",
    "NOVELTY"
  ],
  [
    "which I believe is novel",
    "NOVELTY"
  ],
  [
    "I believe that Theorem 4.2 is a very interesting ( and not so complicated ) result which really makes for a significant and original contribution .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel adversarial attack on deep neural networks .",
    "NOVELTY"
  ],
  [
    "The proposed state representation approach does n't appear to particularly novel",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper constitutes a decent contribution to the literature .",
    "NOVELTY"
  ],
  [
    "The core idea of the paper is interesting .",
    "NOVELTY"
  ],
  [
    "I think it is a good contribution to ML community",
    "NOVELTY"
  ],
  [
    "New metric for calculating the quality of the embeddings .",
    "NOVELTY"
  ],
  [
    "and useful insights on deep neural networks with implications on the training and development of an ensemble learning method that uses the same total training budget as single network training by exploiting the characteristics of their path finding method",
    "NOVELTY"
  ],
  [
    "This paper represents an excellent submission",
    "NOVELTY"
  ],
  [
    "The proposed method while simple is novel .",
    "NOVELTY"
  ],
  [
    "and the idea of such a score as a tool for guiding neuroscientists building models of the visual system is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Although the impact that this score will have in both ML and Neuroscience fields remains uncertain , the work is sufficiently novel and interesting to be published at ICLR",
    "NOVELTY"
  ],
  [
    "This is the only , albeit important , novel observation of this paper .",
    "NOVELTY"
  ],
  [
    "Overall I found the paper interesting .",
    "NOVELTY"
  ],
  [
    "The contribution is thus minor and for me does not justify publication at ICLR",
    "NOVELTY"
  ],
  [
    "and the proposed idea are interesting",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are novel and significant . The approach of having one model able to perform well on completely different tasks and type of input is very interesting and inspiring .",
    "NOVELTY"
  ],
  [
    "The main idea of the paper is very interesting and",
    "NOVELTY"
  ],
  [
    "The specific RL technique is not necessarily novel",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", I think the idea of applying RL to continual learning is novel enough for a publication .",
    "NOVELTY"
  ],
  [
    "The adversarial learning aspect is not new .",
    "NOVELTY"
  ],
  [
    "they seem in my humble opinion like incremental improvements .",
    "NOVELTY"
  ],
  [
    "this alone does not merit acceptance as the collection of results presented in this paper seem incremental for the most part",
    "NOVELTY"
  ],
  [
    "The multitrack idea is great .",
    "NOVELTY"
  ],
  [
    "Incorporating general musical knowledge into the learned network is a good idea and non-trivial",
    "NOVELTY"
  ],
  [
    "There are no other contributions in this paper .",
    "NOVELTY"
  ],
  [
    "and the presented generative model is interesting .",
    "NOVELTY"
  ],
  [
    "For novelty and significance , I think the idea is not very fancy to me .",
    "NOVELTY"
  ],
  [
    "The idea of the section is good",
    "NOVELTY"
  ],
  [
    "the paper is interesting and novel",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of retraining and detection with previously explored kernel density is limited .",
    "NOVELTY"
  ],
  [
    "but its use as a differentiable and fully trainable component within an RL system appears new .",
    "NOVELTY"
  ],
  [
    "This paper lacks novelty and has conceptual mistakes .",
    "NOVELTY"
  ],
  [
    "While certainly this is a good contribution",
    "NOVELTY"
  ],
  [
    "and provides an original approach .",
    "NOVELTY"
  ],
  [
    "In my opinions , the contribution of this paper mainly falls into two parts",
    "NOVELTY"
  ],
  [
    "the methodology is mostly combinations of existing algorithms",
    "NOVELTY"
  ],
  [
    "I felt the contribution and novelty of this work is limited .",
    "NOVELTY"
  ],
  [
    "The method is novel , to my knowledge , and interesting .",
    "NOVELTY"
  ],
  [
    "Originality The proposed idea is novel .",
    "NOVELTY"
  ],
  [
    "The first bounds on the generalization error based on the mutual information are intuitively appealing .",
    "NOVELTY"
  ],
  [
    "so conceptually there 's limited novelty",
    "NOVELTY"
  ],
  [
    "there is little new science in this paper",
    "NOVELTY"
  ],
  [
    "although I am not fully convinced by the great novelty of the presented work",
    "NOVELTY"
  ],
  [
    "As such , the result showing that the Q-learners can not switch easily between the tasks is not novel .",
    "NOVELTY"
  ],
  [
    "It seems that the contribution of the network structure is rather incremental .",
    "NOVELTY"
  ],
  [
    "Overall this is a really interesting idea incorporating concrete visual concepts and more abstract metaconcepts in a joint space and using the learning of one to guide the other .",
    "NOVELTY"
  ],
  [
    "All in all there is something truly interesting in this work",
    "NOVELTY"
  ],
  [
    "and makes an interesting contribution",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is small .",
    "NOVELTY"
  ],
  [
    "This proposal is conceptually very similar to auto-context",
    "NOVELTY"
  ],
  [
    "The model is interesting , novel",
    "NOVELTY"
  ],
  [
    "This is a very interesting algorithmic contribution .",
    "NOVELTY"
  ],
  [
    "The paper does not have any theoretical contribution , but it is unnecessary for this kind of contribution .",
    "NOVELTY"
  ],
  [
    "The current paper addresses this gap by a very simple ( yet clever )",
    "NOVELTY"
  ],
  [
    "The use of an LCP solver to infer mass from interactions is clever .",
    "NOVELTY"
  ],
  [
    "paper proposed a novel approach for robust continual learning model from the adversarial attack",
    "NOVELTY"
  ],
  [
    "The proposed approach is a novel application and combination of GAN-style generative models , knowledge distillation and model Compression .",
    "NOVELTY"
  ],
  [
    "This paper seems to provide a sensible solution to a novel problem .",
    "NOVELTY"
  ],
  [
    "This paper introduces a new method to model sequences of events",
    "NOVELTY"
  ],
  [
    "However , I feel its contribution to the literature is relatively incremental , because of the following two points",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "b ) proposes a new , interesting idea and",
    "NOVELTY"
  ],
  [
    "shows that the choice to parameterize structure via the use of auxillary random variables improves the quality of results on some",
    "NOVELTY"
  ],
  [
    "The geometric aspects of overlapping clustering models have been studied previously",
    "NOVELTY"
  ],
  [
    ", but the approach followed by the authors is very original and theoretically justified .",
    "NOVELTY"
  ],
  [
    "The concept of applying sparsity on \\gamma to prune channels is an interesting one , compared to the usual approaches of sparsity on weights .",
    "NOVELTY"
  ],
  [
    "Overall , the channel pruning with sparse \\gammas is an interesting concept",
    "NOVELTY"
  ],
  [
    "and has significantly innovative results",
    "NOVELTY"
  ],
  [
    "I have very little knowledge of this field , but the main idea idea seemed quite novel and insightful .",
    "NOVELTY"
  ],
  [
    "and the formulation is novel as far as I 'm aware .",
    "NOVELTY"
  ],
  [
    "and to the best of my knowledge it is the first ( or at least best ) applications of GANs to QuickDraw",
    "NOVELTY"
  ],
  [
    "I am slightly concerned about the novelty of the new approach",
    "NOVELTY"
  ],
  [
    "but in my opinion the theoretical contribution of the work is rather tangential to the empirical analysis and results presented in the paper",
    "NOVELTY"
  ],
  [
    "The idea on which the paper is based - that the limit of the entropic regularisation over Birkhoff polytope is on the vertices = permutation matrices - , and the link with optimal transport , is very interesting .",
    "NOVELTY"
  ],
  [
    "The paper presents a simple idea that directly uses the nature of JPEG compression",
    "NOVELTY"
  ],
  [
    "While the problem formulation is novel",
    "NOVELTY"
  ],
  [
    "The lower bound is also novel .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge these works use SGD albeit in the context of maximization",
    "NOVELTY"
  ],
  [
    "To my knowledge it is novel , and significant",
    "NOVELTY"
  ],
  [
    "idea is quite interesting and timely",
    "NOVELTY"
  ],
  [
    "Generalization to unseen combination of objects and attributes is interesting",
    "NOVELTY"
  ],
  [
    "The ideas of using instructions for navigation or using attention for combining visual and textual information have been around for a while . So there is not much novelty in the proposed method either .",
    "NOVELTY"
  ],
  [
    "The novelty and motivation behind this approach is limited .",
    "NOVELTY"
  ],
  [
    "Although all the included ideas are not fully novel",
    "NOVELTY"
  ],
  [
    ", the manuscript shows a relevant originality , paving the way for what can be a major breakthrough in deep learning theory and practice in the next few years .",
    "NOVELTY"
  ],
  [
    "=================================== Before Rebuttal =================================== The authors present a novel algorithm with both theoretical analysis and empirical results",
    "NOVELTY"
  ],
  [
    "The overall novelty of the proposed methods is limited .",
    "NOVELTY"
  ],
  [
    "So in this way , the novelty is only marginal .",
    "NOVELTY"
  ],
  [
    "In general , I think it is an interesting and novel paper . The idea of framing structure estimation as a learning problem is especially interesting and may inspire further research on related",
    "NOVELTY"
  ],
  [
    "Even though using the attention mechanism is new for this domain",
    "NOVELTY"
  ],
  [
    "All in all , the methodological novelty of the paper is small",
    "NOVELTY"
  ],
  [
    "This is not the first work to apply deep reinforcement learning for dynamic pricing problem as claimed by the authors . 2 .Limited technical contribution .",
    "NOVELTY"
  ],
  [
    "This is not the first work to apply deep reinforcement learning for dynamic pricing problem as claimed author .",
    "NOVELTY"
  ],
  [
    "2 .The technical contribution is very limited by just applying existing algorithms .",
    "NOVELTY"
  ],
  [
    "I 'm not very familiar but experimental tasks looked new to me . Moreover , the proposed approach is a novel combination of previous works .",
    "NOVELTY"
  ],
  [
    "all of this is novel work )",
    "NOVELTY"
  ],
  [
    "A beautiful new theoretical umbrella that ties f-divergences and Wasserstein divergences together .",
    "NOVELTY"
  ],
  [
    "As far as I know the paper seems original .",
    "NOVELTY"
  ],
  [
    "I am really fond of the convex geometric approach to topic modeling , it is such an original and potentially promising approach .",
    "NOVELTY"
  ],
  [
    "the paper is so original that I do n't think it should be rejected just because of this",
    "NOVELTY"
  ],
  [
    "the application of the doubly robust approach to instrumental variable regression is not totally new",
    "NOVELTY"
  ],
  [
    "but not groundbreaking",
    "NOVELTY"
  ],
  [
    "Theorem 2.5 of course makes a novel contribution , because the compactness assumption",
    "NOVELTY"
  ],
  [
    "is not required , however conceptually it is not that novel",
    "NOVELTY"
  ],
  [
    "I believe the primary claim of this paper is neither surprising nor novel .",
    "NOVELTY"
  ],
  [
    "The focus on dynamic regret is new , and the reduction from LQ controllable form to unconstrained convex",
    "NOVELTY"
  ],
  [
    "== Applying functional transforms as pooling is not a new idea .",
    "NOVELTY"
  ],
  [
    "This paper improves upon prior work in a number of ways .",
    "NOVELTY"
  ],
  [
    "and contains a substantial and novel result , making fundamental progress on the question of robust hypothesis testing .",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea of incentivizing exploration without changing the reward function as is done in multiple prior works .",
    "NOVELTY"
  ],
  [
    "I think this is a really neat idea , and as far as I 'm aware it is novel .",
    "NOVELTY"
  ],
  [
    "Nice , novel method",
    "NOVELTY"
  ],
  [
    "the underlying idea is a nice one ,",
    "NOVELTY"
  ],
  [
    "While the idea itself is rather intriguing and seems promising",
    "NOVELTY"
  ],
  [
    "but it sports little methodological innovation",
    "NOVELTY"
  ],
  [
    "I have concerns about the novelty and significance of the result .",
    "NOVELTY"
  ],
  [
    "The proposed model outperforms existing models pushing",
    "NOVELTY"
  ],
  [
    "The generalization of variational formulation from finite space to the space of probability measures seems new",
    "NOVELTY"
  ],
  [
    "As a result , the proposed methods seems to be a new way to derive the Wasserstein gradient flow ( or Fokker-Planck equation ) , which",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed idea seems relatively limited .",
    "NOVELTY"
  ],
  [
    "But overall , the flavor of the idea is not significantly different from GDUAP , despite the significant performance boost",
    "NOVELTY"
  ],
  [
    "unsupervised video-to-video translation is not a new task as clarified in the paper",
    "NOVELTY"
  ],
  [
    "The technical novelty of the paper is limited for ICLR .",
    "NOVELTY"
  ],
  [
    "the technical innovation of this paper is limited",
    "NOVELTY"
  ],
  [
    "It seems to me the construction of the local minima is very similar to [ 1 ] , since the main idea is to consider the linear region by activating all the neurons",
    "NOVELTY"
  ],
  [
    "The idea of jointly learning the quantization width and the adaptive quantization is interesting",
    "NOVELTY"
  ],
  [
    "2 .The paper designs a novel group feature embedding module with two group CNNs and bilinear pooling .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is simple , interesting",
    "NOVELTY"
  ],
  [
    "are clear",
    "NOVELTY"
  ],
  [
    "Regarding contributions , it seems to be a bit incremental since the paper doesn\u00e2\u0080\u0099t really build upon the ideas but mostly combines them in a nice way .",
    "NOVELTY"
  ],
  [
    "It is a nice idea which makes",
    "NOVELTY"
  ],
  [
    "The tasks proposed in the problem seem interesting .",
    "NOVELTY"
  ],
  [
    "I find the proposition of combining DRL and SRL with Bayesian regularization original and promising .",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge , the trust region radius is changing during the iteration for basic trust region algorithm .",
    "NOVELTY"
  ],
  [
    "intriguing",
    "NOVELTY"
  ],
  [
    "In general , I liked the idea",
    "NOVELTY"
  ],
  [
    "but to my knowledge the ideas presented are novel .",
    "NOVELTY"
  ],
  [
    "I would argue that putting them together into an algorithm which achieves competitive performance is a novel contribution in its own right",
    "NOVELTY"
  ],
  [
    "The paper looks novel and interesting .",
    "NOVELTY"
  ],
  [
    "The idea of using precision-and-recall curve for evaluating generative model is novel .",
    "NOVELTY"
  ],
  [
    "The derivation of a simple approach to compute the PRD curve is also quite interesting",
    "NOVELTY"
  ],
  [
    "but novelty is limited .",
    "NOVELTY"
  ],
  [
    "It seems that there are two different aspects that are unique in this work",
    "NOVELTY"
  ],
  [
    "The dynamic chunking is a",
    "NOVELTY"
  ],
  [
    "the notion of density estimation with respect to adversarial losses is a novel notion introduced recently , and this paper makes significant progress towards understanding this problem .",
    "NOVELTY"
  ],
  [
    "the connection between implicit density estimation and explicit density estimation , made in this paper ( Theorem 9 ) , is novel .",
    "NOVELTY"
  ],
  [
    "I think the overall contribution of the paper is pretty good .",
    "NOVELTY"
  ],
  [
    "Overall this is a nice paper that balance a subjective and an objective view of Bayesian inference via a mixture of Dirichlet processes",
    "NOVELTY"
  ],
  [
    "Overall the paper has a nice idea to use the gain from having elements in OPT added to the solution at some point to counteract removing elements randomly and achieving the same approximation as before",
    "NOVELTY"
  ],
  [
    "I 'm not actually convinced there 's much that 's methodologically new here .",
    "NOVELTY"
  ],
  [
    "the rest of the paper is somewhat incremental/engineering piece which depends somehow on previous works",
    "NOVELTY"
  ],
  [
    ". I fail to see much novel scientific contribution to the area of research ( apart from the dataset ) and I \u2019 m not sure whether there are enough scientific technical advancements .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed method is somewhat limited in my opinion .",
    "NOVELTY"
  ],
  [
    "Solving a simpler version using CNN I do not consider original unless there is a compelling pay-off",
    "NOVELTY"
  ],
  [
    ", as there is already plenty done on learning multi-modal representations",
    "NOVELTY"
  ],
  [
    "Using a differentiable architecture search for pruning a network is new to me and it makes sense .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper seems clear",
    "NOVELTY"
  ],
  [
    "The proposed scheme is quite interesting , which solves the ( non ) convex optimization in a new perspective , and somewhat provides new insight to the adaptive momentum methods .",
    "NOVELTY"
  ],
  [
    "The idea of learning factorized representations is intuitive and appealing .",
    "NOVELTY"
  ],
  [
    "and makes a few new and interesting observations",
    "NOVELTY"
  ],
  [
    "too simplistic",
    "NOVELTY"
  ],
  [
    "I like the idea of learning tree representations of text which are useful for a downstream task .",
    "NOVELTY"
  ],
  [
    "To my knowledge this is original component .",
    "NOVELTY"
  ],
  [
    "This contribution , however , presents a learning machine that is very hand-tailored to the two chosen tasks .",
    "NOVELTY"
  ],
  [
    "The fairness aspect of the proposed method is fairly standard and not very novel ( going back to 2015 ) .",
    "NOVELTY"
  ],
  [
    "The robustness aspect is an interesting addition and seems novel",
    "NOVELTY"
  ],
  [
    "Although the ensemble idea is new , the idea of selective self-training is not novel in self-training or co-training of SSL as in the following survey .",
    "NOVELTY"
  ],
  [
    "the technical contribution of this paper is moderate",
    "NOVELTY"
  ],
  [
    "I believe the idea of introducing a strongly convex prior to control the tail distribution of exponential mechanism is an interesting idea . Also the analysis to control the tail behavior of exponential mechanism ( in order to obtain a bound on the privacy parameter \\delta ) , seems novel in my opinion .",
    "NOVELTY"
  ],
  [
    "but the novelty is limited",
    "NOVELTY"
  ],
  [
    "even though they",
    "NOVELTY"
  ],
  [
    "are certainly novel and interesting",
    "NOVELTY"
  ],
  [
    "The paper presents interesting ideas on how to construct provably robust decision stumps , which was previously unknown in the literature .",
    "NOVELTY"
  ],
  [
    "The novelty is clear .",
    "NOVELTY"
  ],
  [
    "It lacks novelty : the proposed framework just simply combines the two existing techniques as mentioned above",
    "NOVELTY"
  ],
  [
    "Novelty .Applying Bayesian treatment to embedding methods for uncertainty modelling and hyperparameter tuning is not new",
    "NOVELTY"
  ],
  [
    "If the contribution made by this paper is novel and substantial",
    "NOVELTY"
  ],
  [
    "Although the application is new to me , I think the model is similar to [ 1 ] , [ 2 ] , etc .",
    "NOVELTY"
  ],
  [
    "Overall I found the paper interesting .",
    "NOVELTY"
  ],
  [
    "An interesting new idea",
    "NOVELTY"
  ],
  [
    "An",
    "NOVELTY"
  ],
  [
    "The work is therefore * marginally* novel , but it is one of the first to propose neural methods for compressing video .",
    "NOVELTY"
  ],
  [
    "The suggestion for future work of using RL and generating novel instructions is intriguing .",
    "NOVELTY"
  ],
  [
    "While the approach is interesting",
    "NOVELTY"
  ],
  [
    "I believe that the contributions of this paper are week in analyzing individual layers across-layer since there are many extensive studies are conducted on information bottleneck methods with mutual information",
    "NOVELTY"
  ],
  [
    "The differentiable pooling idea proposed in this paper is a nice contribution",
    "NOVELTY"
  ],
  [
    "liked this paper",
    "NOVELTY"
  ],
  [
    "and the ideas presented are interesting",
    "NOVELTY"
  ],
  [
    "but in my opinion not novel enough or thoroughly demonstrated to justify acceptance",
    "NOVELTY"
  ],
  [
    "Overall , this paper has no contributions on theory .",
    "NOVELTY"
  ],
  [
    "The paper tackles a novel and challenging problem for the long-horizon tasks .",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "but it seems to be a creative combination of existing ideas to perform variational continual learning in parallel .",
    "NOVELTY"
  ],
  [
    "The idea of integrating RL agents with semantic knowledge is interesting .",
    "NOVELTY"
  ],
  [
    "The theoretical results seem to be different from prior work .",
    "NOVELTY"
  ],
  [
    "The framework that is introduced is interesting and novel and combines deep learning for perception with abductive logical reasoning to provide weakly-labelled training data for the deep-learning perception component .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is two-fold .",
    "NOVELTY"
  ],
  [
    "Its proof technique seems to have some novelty",
    "NOVELTY"
  ],
  [
    "The empirical results are extremely mixed , and no specific novel method consistently outperforms existing methods",
    "NOVELTY"
  ],
  [
    "Learning disentangled representations is a promising research direction that fits well into ICLR .",
    "NOVELTY"
  ],
  [
    "The qualitative analysis of filler embeddings is indeed interesting and promising .",
    "NOVELTY"
  ],
  [
    "I found that the paper pursues interesting and promising ideas",
    "NOVELTY"
  ],
  [
    "advances the state of the art",
    "NOVELTY"
  ],
  [
    "2 .The performance gain is not so significant compared to other simpler baselines , so the net contribution of the line-graph extension is unclear considering the above",
    "NOVELTY"
  ],
  [
    "this is a nice and timely study that presents an effective framework for clinical outcome prediction .",
    "NOVELTY"
  ],
  [
    "The work builds off of previous work in a simple , but non-trivial way .",
    "NOVELTY"
  ],
  [
    "The simplicity of the idea is appealing .",
    "NOVELTY"
  ],
  [
    "The ideas in the paper appear to be of moderate significance : the models to which the methods are applicable are somewhat limited",
    "NOVELTY"
  ],
  [
    "introduced .",
    "NOVELTY"
  ],
  [
    "new approach called the 'Causal InfoGAN ' which I find to be a very minimalistic extension to the existing InfoGAN approach of Chen et.al .",
    "NOVELTY"
  ],
  [
    "the extent to which it advances RL research is unclear to me",
    "NOVELTY"
  ],
  [
    "Therefore , I think the technical novelty of the work is limited .",
    "NOVELTY"
  ],
  [
    "as a whole * all claims backed up with thorough large scale experiments",
    "NOVELTY"
  ],
  [
    "experimental exploration of disentangling and fairness at this scale seems novel to me",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is incremental due to the following reasons",
    "NOVELTY"
  ],
  [
    "The paper presents a novel and potentially impactful way of learning uncertainty over model parameters . The derivation of novel activation functions for which first and second moments are computable in closed forms ( for distributions in the exponential family ) appears to be the main ( novel ) contribution , as this is what allows forward propagation of exponential distributions in the network , and learning of their parameters via backprop .",
    "NOVELTY"
  ],
  [
    "The contribution of this work is very incremental .",
    "NOVELTY"
  ],
  [
    "While the novelty is limited",
    "NOVELTY"
  ],
  [
    "Studying label propagation in the meta-learning setting is interesting and novel .",
    "NOVELTY"
  ],
  [
    "promise to contribute a novel dataset to use for ML benchmarking on this type of problem .",
    "NOVELTY"
  ],
  [
    "The general concept of exaggerating a feature that represented a class seems novel and exciting .",
    "NOVELTY"
  ],
  [
    "`` Formalization in terms of divergence minimization is not new",
    "NOVELTY"
  ],
  [
    "The overall method seems novel and interesting",
    "NOVELTY"
  ],
  [
    "The only novelty is the weight-sharing mechanism between two GANs .",
    "NOVELTY"
  ],
  [
    "and the appendix of this draft does not contribute in this direction",
    "NOVELTY"
  ],
  [
    "where the empirical work slightly suffers",
    "NOVELTY"
  ],
  [
    "In my opinion , this paper is an excellent contribution to the RL literature .",
    "NOVELTY"
  ],
  [
    "The task is not new . The proposed approach is in line with some of the prior art , but the specific approach is new .",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are relevant and significant",
    "NOVELTY"
  ],
  [
    "the key novelty of the work is the use of the formalism of graphical models for structured learning and inference .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the work is technically",
    "NOVELTY"
  ],
  [
    "Novelty Just extending and making Chen et al. , 2018b 's distilling method to be differentiable has limited novelty .",
    "NOVELTY"
  ],
  [
    "However , the paper is original",
    "NOVELTY"
  ],
  [
    "The work is moderately original",
    "NOVELTY"
  ],
  [
    "the proposed technique is creative and likely to be of interest to the NIPS community .",
    "NOVELTY"
  ],
  [
    "The method is quite interesting and should be interesting to many people .",
    "NOVELTY"
  ],
  [
    "algorithm is somehow incremental compared with SPORF .",
    "NOVELTY"
  ],
  [
    "The paper definitely provides a very interesting and unique research direction .",
    "NOVELTY"
  ],
  [
    "the goal is closely related and the high-level approach to relate the original problem to another is the same",
    "NOVELTY"
  ],
  [
    "I found the paper interesting and enjoy reading it .",
    "NOVELTY"
  ],
  [
    "Using dictionary embeddings a la Hill et al .None of these ideas are new before but I haven",
    "NOVELTY"
  ],
  [
    "This is a nice idea that is new to me and seemed appropriate for the problem .",
    "NOVELTY"
  ],
  [
    "but somewhat",
    "NOVELTY"
  ],
  [
    "of Chaos initialization",
    "NOVELTY"
  ],
  [
    "The approach is somewhat novel , although it is still quite similar to the conventional GAIL approach .",
    "NOVELTY"
  ],
  [
    "The alternating parameterization is interesting but has been done before in ( e.g . )",
    "NOVELTY"
  ],
  [
    "I think the paper doesn \u2019 t bring much novelty",
    "NOVELTY"
  ],
  [
    "The modifications are not blindingly novel",
    "NOVELTY"
  ],
  [
    "This is also not dissimilar to ideas used in 'Bayesian Representation Learning With Oracle Constraints ' Karaletsos et al 2016 where similar contextual features c are learned to disentangle representations over observations and implicit supervision",
    "NOVELTY"
  ],
  [
    "Interpretation of FedAvg as a meta-learning algorithm is interesting .",
    "NOVELTY"
  ],
  [
    "Very limited methodological contribution .",
    "NOVELTY"
  ],
  [
    "It is a novel combination of existing techniques .",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", combining these approaches to build a general-purpose differentiable convex optimization method is original and a valuable innovation . The ASA formalism , an extension of DCP which represents parameters via affine mappings , is novel and helpful for efficiency reasons .",
    "NOVELTY"
  ],
  [
    "The neural architectures one can build with convex optimization hidden layers are powerful and promising .",
    "NOVELTY"
  ],
  [
    "I do not think this is a breakthrough paper , but it has a novel point as it addresses the theory of HTL in the non-parametric setting because it studies the Bayes risk rates rather than generalization bounds as was done previously",
    "NOVELTY"
  ],
  [
    "This makes this paper a good contribution to the literature on HTL .",
    "NOVELTY"
  ],
  [
    "modest , despite the simplicity of the algorithm",
    "NOVELTY"
  ],
  [
    "I feel that the novelty of the paper ( the approximate posterior q ( z|X ) is a product of experts of the posteriors for each modality \\prod_i q",
    "NOVELTY"
  ],
  [
    "is rather small",
    "NOVELTY"
  ],
  [
    "and presents an interesting approach for large model training .",
    "NOVELTY"
  ],
  [
    "The technical contribution seems to be incremental .",
    "NOVELTY"
  ],
  [
    "The metrics proposed in this paper are intuitive and interesting .",
    "NOVELTY"
  ],
  [
    "the use of core-sets is not novel in machine learning , but unfortunately not yet sufficiently explored in deep learning",
    "NOVELTY"
  ],
  [
    "None of the presented ideas are entirely novel . The model rather combines many existing ideas successfully",
    "NOVELTY"
  ],
  [
    "The joint variational Bayes approach seems to be the most interesting aspect of the paper .",
    "NOVELTY"
  ],
  [
    "Although learning-in-the-loop optimization is not new in itself",
    "NOVELTY"
  ],
  [
    ", the way the authors use it is interesting .",
    "NOVELTY"
  ],
  [
    "I believe that the results could represent a significant contribution",
    "NOVELTY"
  ],
  [
    "Evaluation The idea is certainly interesting and novel , as it allows to bridge two distinct worlds ( VAE and GANs ) .",
    "NOVELTY"
  ],
  [
    "I like the idea of Universal Successor Features , it seems a",
    "NOVELTY"
  ],
  [
    "bit incremental",
    "NOVELTY"
  ],
  [
    "The presented bound and method to compute it is , to the best of knowledge , novel and significantly extends the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "Overall the contribution of this paper is marginally incremental",
    "NOVELTY"
  ],
  [
    "2 .Using relative positional encoding is not a new idea",
    "NOVELTY"
  ],
  [
    "3 .Reusing previous level/segment computation with gradient fixed is also not a big innovation .",
    "NOVELTY"
  ],
  [
    "I feel that the idea is interesting",
    "NOVELTY"
  ],
  [
    "the contribution is interesting",
    "NOVELTY"
  ],
  [
    "My biggest concern is that the technical contribution is too modest .",
    "NOVELTY"
  ],
  [
    "The modification suggested by the authors is novel and useful .",
    "NOVELTY"
  ],
  [
    "I 'm still not convinced about this article novelty",
    "NOVELTY"
  ],
  [
    "I really like the overall idea but it seems that this kind of contribution is better suited for short paper",
    "NOVELTY"
  ],
  [
    "This is a good insight for understanding adversarial examples",
    "NOVELTY"
  ],
  [
    "presents several contributions that can be extended and ported to other work",
    "NOVELTY"
  ],
  [
    "The idea is extremely intriguing and very promising",
    "NOVELTY"
  ],
  [
    "This contribution is not bad for an",
    "NOVELTY"
  ],
  [
    "empirical paper",
    "NOVELTY"
  ],
  [
    "The theoretical results are new and insightful ,",
    "NOVELTY"
  ],
  [
    "The use of Langevin diffusion for latent transitions is a good idea in my opinion",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the use of CTF in density estimation as described in \\S 4 is new , and should be of interest to the community",
    "NOVELTY"
  ],
  [
    "Overall I think the theory is properly described and has a couple of interesting formulations , in spite of being",
    "NOVELTY"
  ],
  [
    "not particularly novel",
    "NOVELTY"
  ],
  [
    "This paper while presenting interesting ideas",
    "NOVELTY"
  ],
  [
    "The technical novelty is a bit limited",
    "NOVELTY"
  ],
  [
    "I think it presents enough novelties to be accepted in the conference",
    "NOVELTY"
  ],
  [
    "The novelty of the code2seq model is somewhat limited compared to the model presented in code2vec ( Alon et al .2018a ) paper .",
    "NOVELTY"
  ],
  [
    "but it doesn \u2019 t appear to be a big conceptual advance in the model architecture",
    "NOVELTY"
  ],
  [
    "while the idea being simple , I am not quite confident about the novelty .",
    "NOVELTY"
  ],
  [
    "The work is original and significant from an applications point of view .",
    "NOVELTY"
  ],
  [
    "explores this idea",
    "NOVELTY"
  ],
  [
    "There is no novelty on the modeling side of this paper . The pre-training methods are also not novel .",
    "NOVELTY"
  ],
  [
    "This means there is no novelty in the pre-training method or the extreme summarization method",
    "NOVELTY"
  ],
  [
    "The notion of fairlets I find interesting and appealing .",
    "NOVELTY"
  ],
  [
    "The algorithm proposed here is very similar to the algorithm proposed in [",
    "NOVELTY"
  ],
  [
    "I do n't see this paper as making any new algorithmic or theoretical contributions .",
    "NOVELTY"
  ],
  [
    "since the primary contribution of this paper seems to be empirical , I do n't think the current experiments on two domains are enough",
    "NOVELTY"
  ],
  [
    "Though the idea is good",
    "NOVELTY"
  ],
  [
    "I found the contribution to be too incremental for the paper to be accepted",
    "NOVELTY"
  ],
  [
    "The methodology is incremental .",
    "NOVELTY"
  ],
  [
    "It is not very novel",
    "NOVELTY"
  ],
  [
    "As far as novelty is concerned",
    "NOVELTY"
  ],
  [
    "the loss/regularization does n't seem to be novel and should have been compared against pure max-margin methods as well .",
    "NOVELTY"
  ],
  [
    "I find the paper interesting .",
    "NOVELTY"
  ],
  [
    "Their approach is extremely far away",
    "NOVELTY"
  ],
  [
    "from the state of the art",
    "NOVELTY"
  ],
  [
    "quite limited novelty",
    "NOVELTY"
  ],
  [
    "The methods are either not very novel or not",
    "NOVELTY"
  ],
  [
    "4 .Using Wasserstein barycenter to measure sentence similarity seems to be novel",
    "NOVELTY"
  ],
  [
    "Using Wasserstein to detect hypernym seems to also be novel",
    "NOVELTY"
  ],
  [
    "derivation of an alternative objective and use of a deep networks .",
    "NOVELTY"
  ],
  [
    "Thus , the novelty of this work is thin to me .",
    "NOVELTY"
  ],
  [
    "New SOTA for single softmax model on LM benchmarks .",
    "NOVELTY"
  ],
  [
    "This is probably a good idea",
    "NOVELTY"
  ],
  [
    "but it does not sound all that creative to me",
    "NOVELTY"
  ],
  [
    "this",
    "NOVELTY"
  ],
  [
    "The overall framework is quite novel .",
    "NOVELTY"
  ],
  [
    "there are also quite a few novel designs within the network .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems to be a straightforward modification of the randomized SVD algorithm , so that the contribution of this paper would be incremental .",
    "NOVELTY"
  ],
  [
    "I find the paper simple and interesting",
    "NOVELTY"
  ],
  [
    "the methodological approach does not seem to be very novel .",
    "NOVELTY"
  ],
  [
    "Proposes a \u201c group-wise model diversity \u201d loss term which is novel , to my knowledge . The use of foreground segmentation masks to improve image classification is also novel .",
    "NOVELTY"
  ],
  [
    "The ideas presented in this paper are novel and show some promise",
    "NOVELTY"
  ],
  [
    "other contributions ( some of which are advertised strongly in the abstract ) are incremental or implicit in earlier work",
    "NOVELTY"
  ],
  [
    "From this point of view , the novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "The two generator approach is nothing new .",
    "NOVELTY"
  ],
  [
    "I would consider it a very minor contribution as it is mainly a recapitulation of known results as both the robust Bellman operator and the entropy-regularized one are known to be contractions",
    "NOVELTY"
  ],
  [
    "I still think the contribution is minor and the method will not scale",
    "NOVELTY"
  ],
  [
    "The idea seems quite novel",
    "NOVELTY"
  ],
  [
    "It is an interesting design that combines the backward process with a forward process",
    "NOVELTY"
  ],
  [
    "4 .The novelty of the main contribution of the paper is arguable .",
    "NOVELTY"
  ],
  [
    "To my knowledge the proposed analysis about two time-scale TDC under diminishing step-size and constant step-size is novel .",
    "NOVELTY"
  ],
  [
    "provides good insight into the problem",
    "NOVELTY"
  ],
  [
    "but the application of this approach to this problem is novel and interesting",
    "NOVELTY"
  ],
  [
    "The mathematical derivation in this work is novel and interesting",
    "NOVELTY"
  ],
  [
    "The derivation in this manuscript is new , and I like the way of obtaining the proposed optimization procedure .",
    "NOVELTY"
  ],
  [
    "Very nice contribution as compared to classical incremental research in the MEG functional connectivity field .",
    "NOVELTY"
  ],
  [
    "The proposed approach is a promising new direction in the area of set prediction",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the method of predicting a set with the use of an encoder and iterative optimization is a fairly novel idea .",
    "NOVELTY"
  ],
  [
    "This work provides a unique approach to the problem of set prediction for autoencoding as well",
    "NOVELTY"
  ],
  [
    "The proposed method is seemingly novel .",
    "NOVELTY"
  ],
  [
    "The contribution is interesting .",
    "NOVELTY"
  ],
  [
    "The theoretical connections connection between GNNs and first-order logic strike me as interesting .",
    "NOVELTY"
  ],
  [
    "Decision To the best of my knowledge , this is the first work that proved the size-free generalization bound for multi-layer CNNs .",
    "NOVELTY"
  ],
  [
    "Although the presented approach of generating samples from a simulator ( in this case a SMC ) and fitting a neural network parametrized model to the generated samples is n't terribly novel",
    "NOVELTY"
  ],
  [
    ", the application to procedural models is interesting",
    "NOVELTY"
  ],
  [
    "However , the novelty beyond that work seems to be quite minimal for a NeurIPS paper .",
    "NOVELTY"
  ],
  [
    "This is an original and interesting contribution to knowledge , because it opens further research on a new class of valid graph",
    "NOVELTY"
  ],
  [
    "The contribution is not only significant",
    "NOVELTY"
  ],
  [
    "The paper shows improvements over previous papers for two tasks related to common-sense knowledge .",
    "NOVELTY"
  ],
  [
    "The suggested model outperforms others on two",
    "NOVELTY"
  ],
  [
    "The suggested models are novel in themselves .",
    "NOVELTY"
  ],
  [
    "The idea of decoupling motion and content is interesting ,",
    "NOVELTY"
  ],
  [
    "However , the novelty is relatively incremental given previous cited work on multi-stream networks , and",
    "NOVELTY"
  ],
  [
    "Overall this is a well-executed work with an interesting though not extremely novel idea .",
    "NOVELTY"
  ],
  [
    "It is an interesting idea of using partition in the learning of rank",
    "NOVELTY"
  ],
  [
    "The topic is not novel ,",
    "NOVELTY"
  ],
  [
    "but the work is a reasonable advance on previous work",
    "NOVELTY"
  ],
  [
    ", to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "I think the originality is good enough for accept .",
    "NOVELTY"
  ],
  [
    "This is not new in optimization community .",
    "NOVELTY"
  ],
  [
    "I think the main contribution is that this is the first paper for analyzing PIAG by Lyapunov function .",
    "NOVELTY"
  ],
  [
    "This dramatically hurt the contribution of the paper .",
    "NOVELTY"
  ],
  [
    "technically sound .",
    "NOVELTY"
  ],
  [
    "This is an interesting approach of assigning contribution weights to each source sample .",
    "NOVELTY"
  ],
  [
    "and is sort of similar to Frustratingly easy domain adaptation",
    "NOVELTY"
  ],
  [
    ", ACL-07",
    "NOVELTY"
  ],
  [
    "My main concern about this paper is the novelty given its similarity to the previous methods .",
    "NOVELTY"
  ],
  [
    "It is not the first such analysis , but maybe it is novel on the assumptions used in the analysis",
    "NOVELTY"
  ],
  [
    "Although a direct extension , the approach is novel and well-motivated .",
    "NOVELTY"
  ],
  [
    "the paper seems completely original .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    ", interesting new idea",
    "NOVELTY"
  ],
  [
    ", modest technical contribution",
    "NOVELTY"
  ],
  [
    "ORIGINALITY The method is ( to my knowledge ) novel . SIGNIFICANCE I think this paper is a significant contribution .",
    "NOVELTY"
  ],
  [
    "The technical contribution is perhaps somewhat modest , as the paper fairly straightforwardly includes non-negativity in a vae setting , but",
    "NOVELTY"
  ],
  [
    "I think this is a good idea",
    "NOVELTY"
  ],
  [
    "the paper appears to be a",
    "NOVELTY"
  ],
  [
    "and the impact or novelty is rather small",
    "NOVELTY"
  ],
  [
    "The meta-learning approach appears to be a novel contribution .",
    "NOVELTY"
  ],
  [
    "proposes to get around this problem by adapting different `` parameters `` for different time steps in recurrent networks and different",
    "NOVELTY"
  ],
  [
    "The regularizer is a clever adaption of EWC and IS into the context of GAN training .",
    "NOVELTY"
  ],
  [
    "The formulation of online memory and controlled forgetting are clever , giving rise to the adaption of EWC and IS as a practical regularizer to overcome the problem of catastrophic forgetting in GANs",
    "NOVELTY"
  ],
  [
    "It is a very good contribution .",
    "NOVELTY"
  ],
  [
    "Weaknesses The paper 's contribution is very incremental .",
    "NOVELTY"
  ],
  [
    "The originality of the approach is limited because it is a relatively straightforward combination of existing techniques for weight and activation pruning",
    "NOVELTY"
  ],
  [
    "My biggest concern with the paper is novelty , which is rather low .",
    "NOVELTY"
  ],
  [
    "I am not sure to see the exact novelty of the proposed , it seems to be very classic : soft attention over feature maps and frames is not new",
    "NOVELTY"
  ],
  [
    "This paper introduces spherical operation for convolution , which is novel in the literature as far as I know .",
    "NOVELTY"
  ],
  [
    "I do not believe this is the first attempt in translating an environment represention to a different one",
    "NOVELTY"
  ],
  [
    "The task is new and the novelty of the contribution is clear .",
    "NOVELTY"
  ],
  [
    "My main concerns are",
    "NOVELTY"
  ],
  [
    "this could be considered only a slight incremental progress on the topic over the work of Gaillard et al . [ 2014 ]",
    "NOVELTY"
  ],
  [
    "I was hoping to find such an example in the empirical application however this section does not make the necessary connections with the theoretical development",
    "NOVELTY"
  ],
  [
    "There is a sufficient degree of novelty in the new cell structure",
    "NOVELTY"
  ],
  [
    "The authors also propose two novel pre-training settings which also show improvement over the baseline BM-25",
    "NOVELTY"
  ],
  [
    "The presented methods are new , and represent a clear deviation from earlier work in this",
    "NOVELTY"
  ],
  [
    "area",
    "NOVELTY"
  ],
  [
    "The dialanine system seems to be of rather modest size compared to the systems typically studied with MD .",
    "NOVELTY"
  ],
  [
    "minor technical contribution - insufficient",
    "NOVELTY"
  ],
  [
    "The actual technical contribution seems like a small modification of WGAN .",
    "NOVELTY"
  ],
  [
    "My main concern is about the quantification of the degree of contribution of this work",
    "NOVELTY"
  ],
  [
    "There are some nice ideas in the paper and",
    "NOVELTY"
  ],
  [
    "this is not a new problem",
    "NOVELTY"
  ],
  [
    "Learning a more general policy is not new ( as also discussed in the paper ) , but using the learned structure to further guide the exploration of the policy is novel and interesting .",
    "NOVELTY"
  ],
  [
    "the novelty of the algorithm is limited",
    "NOVELTY"
  ],
  [
    "and the proposed model is novel and effective",
    "NOVELTY"
  ],
  [
    "The mutual information maximization approach is appropriate ,",
    "NOVELTY"
  ],
  [
    "but hardly novel .",
    "NOVELTY"
  ],
  [
    "The paper proposes a nice idea of sparsification of skip connections in DenseNets .",
    "NOVELTY"
  ],
  [
    "The paper presents an elegant and simple idea in",
    "NOVELTY"
  ],
  [
    "However , to the best of my knowledge , combining these techniques to scale energy-based models to modern deep network architectures is a novel contribution .",
    "NOVELTY"
  ],
  [
    "The result showing that GD is ineffective when one wishes to approximate a not so smooth function using an infinitely differentiable kernel is novel and insightful .",
    "NOVELTY"
  ],
  [
    ", and I think it could be quite a good contribution to the conference .",
    "NOVELTY"
  ],
  [
    "The originality of the paper is to study the MIPS problem under a computational budget .",
    "NOVELTY"
  ],
  [
    "The proposed method seems also quite original ,",
    "NOVELTY"
  ],
  [
    "I think the originality level of the paper is high . The issue of informative priors in these complex models seems wide open and the authors provide an interesting approach both conceptually and computationally",
    "NOVELTY"
  ],
  [
    "However given the depth of the experiments in the proposed paper I think it would be a worthy contribution to",
    "NOVELTY"
  ],
  [
    "The GTW problem dealt with in this paper has not been well studied in the literature .",
    "NOVELTY"
  ],
  [
    "The use of max flow-based methods for DTW is not novel",
    "NOVELTY"
  ],
  [
    ", but the authors build on it significantly to yield exact solutions to the proposed GTW problem , which is a novel contribution .",
    "NOVELTY"
  ],
  [
    "While it seems a promising work in terms of novelty and speeding up 3D classifications",
    "NOVELTY"
  ],
  [
    "The results are original to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "To the best of my understanding , such distributions are simply distributions with a density function .",
    "NOVELTY"
  ],
  [
    "as the final results are somewhat incremental",
    "NOVELTY"
  ],
  [
    "I do n't think the paper contains sufficiently novel elements to",
    "NOVELTY"
  ],
  [
    "be accepted as a conference track paper at ICLR",
    "NOVELTY"
  ],
  [
    "the proposed method is fundamentally a combination of prior work : dropout and `` shake-shake `` regularization",
    "NOVELTY"
  ],
  [
    "This finding is innovative .",
    "NOVELTY"
  ],
  [
    "the current contribution is rather limited in terms of methodology and shallow in terms of experimental evaluation .",
    "NOVELTY"
  ],
  [
    "The only methodological novelty of proposed contribution is the idea of encoding the multi objective reward as a logical function",
    "NOVELTY"
  ],
  [
    "The theoretical analysis is insightful and motivated .",
    "NOVELTY"
  ],
  [
    "The proposed model , however , is almost identical to that of Weston et al .2012 .As the authors have clarified in the answers to the questions",
    "NOVELTY"
  ],
  [
    "the proposed `` residual-based training strategy `` and `` long temporal fusion `` are kind of trivial or lackluster",
    "NOVELTY"
  ],
  [
    "seem fairly toyish to me",
    "NOVELTY"
  ],
  [
    "however I think the idea is nice and should be published",
    "NOVELTY"
  ],
  [
    "Although the paper shows interesting and novel theoretical results",
    "NOVELTY"
  ],
  [
    "and this article contributes a very interesting idea",
    "NOVELTY"
  ],
  [
    "I think the novelty and experimental results are significant",
    "NOVELTY"
  ],
  [
    "On the positive side , I felt that this paper was creative , and contributes some interesting technical insights",
    "NOVELTY"
  ],
  [
    "and the use KL ( pq ) plus SMC certainly seems novel and much more general than what this paper would suggest",
    "NOVELTY"
  ],
  [
    "the contributions are not clear enough .",
    "NOVELTY"
  ],
  [
    "method itself",
    "NOVELTY"
  ],
  [
    "The idea of using prototypes for continual learning is interesting",
    "NOVELTY"
  ],
  [
    "Originality The paper is original . Up to my knowledge , this is the first generalization of EP to work with t-exponential families .",
    "NOVELTY"
  ],
  [
    "The DRO framework and the variants are the main contributions in terms of methodology in this paper",
    "NOVELTY"
  ],
  [
    "I do not see this paper to be that significant of a contribution . The main idea in the paper seems like a rather direct application of the DRO modeling framework",
    "NOVELTY"
  ],
  [
    "and creatively joins together two otherwise distinct areas of machine learning research to make a modest but novel contribution to the field",
    "NOVELTY"
  ],
  [
    "and the proposed algorithm is reasonable and novel .",
    "NOVELTY"
  ],
  [
    "The paper is novel and",
    "NOVELTY"
  ],
  [
    "the algorithm is interesting",
    "NOVELTY"
  ],
  [
    "Although the contribution of introducing a new relaxed formulation of the normalized cut is interesting",
    "NOVELTY"
  ],
  [
    "The idea of using best polynomial approximation to estimate additive properties is not new",
    "NOVELTY"
  ],
  [
    "there are two major issues of this work : ( i ) limited novelty",
    "NOVELTY"
  ],
  [
    "this paper has limited novelty , incremental contributions , and",
    "NOVELTY"
  ],
  [
    "The idea is quite interesting despite its simplicity .",
    "NOVELTY"
  ],
  [
    "They derive GPs from approximations of Hessians , which I think is pretty original .",
    "NOVELTY"
  ],
  [
    "I think this is an interesting paper establishing the theoretical connection",
    "NOVELTY"
  ],
  [
    "This paper develops new novel",
    "NOVELTY"
  ],
  [
    "Originality* The approach is novel and an interesting way to combine structured information in the sentence and the image .",
    "NOVELTY"
  ],
  [
    "the proposed objective function is intuitively appealing",
    "NOVELTY"
  ],
  [
    "This paper proposes an interesting and novel method for paraphrase generation .",
    "NOVELTY"
  ],
  [
    "I don \u2019 t think the proposed idea is very innovative .",
    "NOVELTY"
  ],
  [
    "this work unfortunately offers few insights to vision practitioners , let alone general practitioners",
    "NOVELTY"
  ],
  [
    "I think this paper advances the state of the art sufficiently that I am compelled to recommend acceptance",
    "NOVELTY"
  ],
  [
    "but overall it is a nice contribution that closes a gap in theory",
    "NOVELTY"
  ],
  [
    "I think this paper is a nice theoretical contribution that settles some open questions on the complexity of SVRG .",
    "NOVELTY"
  ],
  [
    "The paper contains some interesting and clever ideas",
    "NOVELTY"
  ],
  [
    "the techniques are nontrivial and there are some clever ideas in the proofs .",
    "NOVELTY"
  ],
  [
    "Idea is simple and makes sense intuitively",
    "NOVELTY"
  ],
  [
    "In terms of new contributions , the paper seems not that strong .",
    "NOVELTY"
  ],
  [
    "but the results are interestingly new ,",
    "NOVELTY"
  ],
  [
    "The proposed amortized MAP inference is novel and different from the previous SR methods .",
    "NOVELTY"
  ],
  [
    "The idea is novel and the author explore many methods .",
    "NOVELTY"
  ],
  [
    "This gives a new interpretation of existing approaches .",
    "NOVELTY"
  ],
  [
    "I think that the paper makes some interesting contributions to the theory of GANs .",
    "NOVELTY"
  ],
  [
    "This work introduces a novel featurization of graphs , with focused application in chemistry .",
    "NOVELTY"
  ],
  [
    "The field of graph neural networks is large and growing",
    "NOVELTY"
  ],
  [
    "and the idea is somehow novel .",
    "NOVELTY"
  ],
  [
    "However , I am concerned with the lack of novelty in the paper ( whose main contribution is the embedding propagation framework ) as the idea to describe graph embeddings via a message passing/propagation framework has been proposed previously .",
    "NOVELTY"
  ],
  [
    "An interesting novel aspect of the paper is that it considers multiple labels/embeddings for nodes as this is not commonly done in",
    "NOVELTY"
  ],
  [
    "However , since the general ideas are well known and a closely related framework has recently been introduced , the novel contributions seem limited .",
    "NOVELTY"
  ],
  [
    "and contains a fascinating new form of regret bound that improves on worst-case analysis",
    "NOVELTY"
  ],
  [
    "They demonstrate a deep comprehension of the BOCPD model of Adams , and its extension for the meta-learning approach is original to me .",
    "NOVELTY"
  ],
  [
    "An advantage of this approach is that it explicitly avoids working in the original observation space and plans indirectly over a learned representation .",
    "NOVELTY"
  ],
  [
    "VPN is a contribution in this new line of research .",
    "NOVELTY"
  ],
  [
    "introduces a , to my knowledge , completely new framework for embedding Hamiltonian dynamics in a generative model .",
    "NOVELTY"
  ],
  [
    "The paper makes an interesting contribution",
    "NOVELTY"
  ],
  [
    "that is distinct from other approaches",
    "NOVELTY"
  ],
  [
    "The general idea is not new ,",
    "NOVELTY"
  ],
  [
    "The novelty is significant .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed method is very limited .",
    "NOVELTY"
  ],
  [
    "The novelty , clarity , and originality of this paper are quite great .",
    "NOVELTY"
  ],
  [
    "But the paper lacks enough novelty",
    "NOVELTY"
  ],
  [
    "The idea of the paper is very interesting and I have checked the proof is correct",
    "NOVELTY"
  ],
  [
    "There idea of leveraging duality has been applied in other contexts",
    "NOVELTY"
  ],
  [
    "The idea in the paper is original and is well explained .",
    "NOVELTY"
  ],
  [
    "Linking Entropy-SGD to PAC-Bayes learning and making use of differential privacy to improve generalization is quite interesting",
    "NOVELTY"
  ],
  [
    "However , I 'm not sure if the ideas and techniques used to solve the problem are novel enough .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel and interesting model for the task of question answering on SQuAD dataset and shows that the model outperforms existing models .",
    "NOVELTY"
  ],
  [
    "I like the paper and the idea",
    "NOVELTY"
  ],
  [
    "Overall seems like a novel and interesting way to do SGD on the edge",
    "NOVELTY"
  ],
  [
    "While the contribution is incremental",
    "NOVELTY"
  ],
  [
    "and offer very interesting additional insights into connectivity across time scales",
    "NOVELTY"
  ],
  [
    "The idea of augmenting in the feature space is new and intuitive .",
    "NOVELTY"
  ],
  [
    "bringing together works and insights related to efficient",
    "NOVELTY"
  ],
  [
    "from my point of view , the study is far from being thorough and does not lead to or bring new insights or ideas .",
    "NOVELTY"
  ],
  [
    "Finally , I 'm not sure the novelty is strong enough since the margin definition comes from",
    "NOVELTY"
  ],
  [
    "Originality I think this submission is very original as it aims at combining the physical process or rendering a scene via ray-casting with learning scene representation via deep-learning .",
    "NOVELTY"
  ],
  [
    "it does not seem to be a massive leap forward in terms of novelty .",
    "NOVELTY"
  ],
  [
    "As far as originality is concerned , the improvement in the regret bounds is new",
    "NOVELTY"
  ],
  [
    ", but they may seem incremental , especially because there are known to be suboptimal ( putting algorithmic issues aside ) .",
    "NOVELTY"
  ],
  [
    "Although the QP relaxation of ReLU neuron is not new and has been used in Raghunathan et al.",
    "NOVELTY"
  ],
  [
    "The concept of `` bi-direction verification `` is not new",
    "NOVELTY"
  ],
  [
    "and the concept of `` bi-directional verification `` is also not entirely new",
    "NOVELTY"
  ],
  [
    "This coupling between \u00cf\u0086 and P could lead to a very interesting discussion and perhaps new insight",
    "NOVELTY"
  ],
  [
    "Overall it is a good contribution",
    "NOVELTY"
  ],
  [
    "The method is interesting",
    "NOVELTY"
  ],
  [
    "Perhaps the contribution is a bit incremental and the degree of novelty is not very high .",
    "NOVELTY"
  ],
  [
    "This paper appears quite similar to the recent work `` Active Bias `` [ 1 ] . The motivation for the technique and setting appear very similar , while the details of the techniques are different .",
    "NOVELTY"
  ],
  [
    "2 .The optimization treatment is not novel .",
    "NOVELTY"
  ],
  [
    "The idea , which combines those of previous work ( wav2vec and BERT ) synergetically , is intuitive",
    "NOVELTY"
  ],
  [
    "but the overall approach of characterizing the different phases of the dynamics seems fairly original for this setting and is a nontrivial contribution",
    "NOVELTY"
  ],
  [
    "These factors make the paper seem like a weak accept even though the contribution is in a very limited setting",
    "NOVELTY"
  ],
  [
    "The paper emphasis that the zeroth-order algorithm is a novel contribution .",
    "NOVELTY"
  ],
  [
    "-The use of on-policy fitted value baseline within Q-function parameterization during on-policy fitting is nice .",
    "NOVELTY"
  ],
  [
    "The tree-structured LSTM model is an existing work but applying it to generate adversarial text is new .",
    "NOVELTY"
  ],
  [
    "Novel local predictive coding based architecture/formulation that improves previous predictive coding based methods Competitive performance in relation to the state-of-the-art recognition",
    "NOVELTY"
  ],
  [
    "The use of predictive coding for layers to converge to optimal features to improve the recognition task is attractive .",
    "NOVELTY"
  ],
  [
    "The proposed solution lacks novelty .",
    "NOVELTY"
  ],
  [
    "Novelty is in the way of dealing with multiple heads",
    "NOVELTY"
  ],
  [
    "this would be a limited contribution",
    "NOVELTY"
  ],
  [
    "and the method seems novel",
    "NOVELTY"
  ],
  [
    "Originality The idea of using DSL + ranking for architecture search seems novel . - Significance Automated architecture search is a promising way to design new networks .",
    "NOVELTY"
  ],
  [
    "the architecture is interesting and intuitive",
    "NOVELTY"
  ],
  [
    "the algorithmic idea of combining the stochastic variance-reduced gradient and primal-dual reformulation is not brand new [ 1",
    "NOVELTY"
  ],
  [
    "and the material is very interesting and novel",
    "NOVELTY"
  ],
  [
    "The approach is intriguing and the inspiration from fly visual cortex is very interesting .",
    "NOVELTY"
  ],
  [
    "But the theme of the paper overlaps with the previous work [ 8",
    "NOVELTY"
  ],
  [
    "This paper has two major drawbacks in its originality segment",
    "NOVELTY"
  ],
  [
    "the field of NN-pruning is quite busy with many related papers populating the field and 2",
    "NOVELTY"
  ],
  [
    "The paper is technically interesting",
    "NOVELTY"
  ],
  [
    "Nash Averaging approach suggested for evaluating in the presence of cycles is interesting",
    "NOVELTY"
  ],
  [
    "I am still concerned with the novelty",
    "NOVELTY"
  ],
  [
    "which weaken the novelty of this paper",
    "NOVELTY"
  ],
  [
    "The proposed method is interesting",
    "NOVELTY"
  ],
  [
    "My main concern with this work is the incremental contribution with respect to the work by Han et al . ( 2018",
    "NOVELTY"
  ],
  [
    "Conclusion This paper advances an interesting idea for few-shot classification and gets competitive results",
    "NOVELTY"
  ],
  [
    "I 'm worried about the incremental contribution on top of the work by Han et al..",
    "NOVELTY"
  ],
  [
    "I find it difficult to point my finger to novel conceptual or theoretical insights in this paper .",
    "NOVELTY"
  ],
  [
    "applying these established tools is already challenging",
    "NOVELTY"
  ],
  [
    "Overall , the proposal is novel .",
    "NOVELTY"
  ],
  [
    "Novel approach Cons",
    "NOVELTY"
  ],
  [
    "The proposed method is a bit incremental but seems to be novel .",
    "NOVELTY"
  ],
  [
    "The method proposed by the authors is new and show very",
    "NOVELTY"
  ],
  [
    "We had one reviewer disagree on the basis that this is an incremental theoretical result",
    "NOVELTY"
  ],
  [
    "from",
    "NOVELTY"
  ],
  [
    "however the theoretical result of this paper is a new one that expands on just one of the empirical observations made in [ 27",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- Before Rebuttal The authors present a novel proof regarding the Hamming distance of random bit string inputs with different binary classifications to random neural networks .",
    "NOVELTY"
  ],
  [
    "The mathematical set up of Gaussian process approximation for their proof is by the author\u00e2\u0080\u0099s admission not novel , coming from [ 41 ]",
    "NOVELTY"
  ],
  [
    "unfortunately , the model contribution currently is too modest .",
    "NOVELTY"
  ],
  [
    "While the idea of leveraging both semantic and structural information for the purpose of dimensionality reduction seems to be new and interesting",
    "NOVELTY"
  ],
  [
    "the derivation of the gradient computations is interesting by itself .",
    "NOVELTY"
  ],
  [
    "Finally , the main idea of skipping the intervals without measurements is not very novel given the existing literature on neural point processes .",
    "NOVELTY"
  ],
  [
    "it is not enough contribution for a full conference paper .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work that utilizes KL property and respective analysis for ADAM-like methods .",
    "NOVELTY"
  ],
  [
    "It is not new",
    "NOVELTY"
  ],
  [
    "Convergence characterization for KL functions with ( sort of ) adaptive step size is new also to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "the idea of using neural networks for screening pairwise and high-order feature interactions is novel , significant , and interesting .",
    "NOVELTY"
  ],
  [
    "and differential topology",
    "NOVELTY"
  ],
  [
    "Section 3 provides a nice",
    "NOVELTY"
  ],
  [
    "This proposed model is lack of novelty",
    "NOVELTY"
  ],
  [
    ", and the proposed strategy is original and to the point .",
    "NOVELTY"
  ],
  [
    "While I don \u2019 t think the paper presents much novelty in ideas or scientific insight",
    "NOVELTY"
  ],
  [
    "The proposed method is very similar to earlier work and barely novel .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is an original result .",
    "NOVELTY"
  ],
  [
    "Overall the paper is interesting , the algorithm seems novel and the regret lower and upper bounds match in several cases of interest",
    "NOVELTY"
  ],
  [
    "I like the idea of asynchronous regularization/compression",
    "NOVELTY"
  ],
  [
    "The presented technique is interesting .",
    "NOVELTY"
  ],
  [
    "The proposed methodology is not novel , it rehashes existing adversarial techniques instead of other probabilistic models used in earlier works .",
    "NOVELTY"
  ],
  [
    "However from the technical point of view , this work is somewhat incremental since prior work has done link prediction using GCN",
    "NOVELTY"
  ],
  [
    ". The idea of performing hyperlink prediction in the dual hypergraph is not new , either",
    "NOVELTY"
  ],
  [
    "In my opinion the novelty of the proposed method w.r.t .the one in [ 17 ] is quite limited",
    "NOVELTY"
  ],
  [
    "although I still think that the novelty of the proposed method w.r.t the state of the art is a bit limited and should not be emphasized too much in the text",
    "NOVELTY"
  ],
  [
    "Using RL to automatically derive ( N ) AFs is a nice change of pace from the hand-crafted heuristics that dominate BO . I like the ideas at play here and hope that you will convince me to amend my score",
    "NOVELTY"
  ],
  [
    "One of the main issues of this paper is the lack of novelty . The framework is incremented from the previous domain adaptation method such as TrAdaboost or BDA",
    "NOVELTY"
  ],
  [
    "I don \u2019 t think the results shown in the paper is that surprising or novel .",
    "NOVELTY"
  ],
  [
    "The method is novel and non-obvious .",
    "NOVELTY"
  ],
  [
    "However the generalization presented appears to be distinct from this form of generalization",
    "NOVELTY"
  ],
  [
    "A novel framework that captures long-range context information and can be trained end-to-end .",
    "NOVELTY"
  ],
  [
    "The approach seems incremental and very similar to existing work such as Papernot et .",
    "NOVELTY"
  ],
  [
    "The algorithm is quite similar to the one by Jin et al",
    "NOVELTY"
  ],
  [
    "but the PAC bound is new",
    "NOVELTY"
  ],
  [
    "The proposed method is an incremental modification to the work of Krause et al .2015 .More specifically",
    "NOVELTY"
  ],
  [
    "Overall , I think that the work is too incremental ( algorithmically , it is only one `` for `` loop ) .",
    "NOVELTY"
  ],
  [
    "and the contribution is poor . Indeed the lower bound ( Theorem 3.1 ) is not novel",
    "NOVELTY"
  ],
  [
    "Theorems 3.2 and 3.3 are not novel either .",
    "NOVELTY"
  ],
  [
    "1 .I think the model is just ARD prior over discriminative GMM which is not that novel .",
    "NOVELTY"
  ],
  [
    "Overall , I think the contribution of the paper is a bit incremental .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "As I understand it there are two novel components in this paper .",
    "NOVELTY"
  ],
  [
    "I find the paper interesting",
    "NOVELTY"
  ],
  [
    "Overall , the exploration in the paper seems novel and could be useful to the",
    "NOVELTY"
  ],
  [
    "In this sense , the contribution of the current paper is not very clear .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , using projected 3D bounding box corners as an intermediate representation is a novel idea .",
    "NOVELTY"
  ],
  [
    "As far as I know , this is a novel contribution",
    "NOVELTY"
  ],
  [
    "I think this paper adds an original and valuable angle to the existing literature on data poisoning attacks .",
    "NOVELTY"
  ],
  [
    "Novelty ) The idea of using several negative examples is not new .",
    "NOVELTY"
  ],
  [
    "To my knowledge this approach , while intuitive , has not been explored in detail before .",
    "NOVELTY"
  ],
  [
    "Derivative-free optimization is not a novel domain",
    "NOVELTY"
  ],
  [
    "but its ideas are not particularly novel .",
    "NOVELTY"
  ],
  [
    "I might under-valued the theoretical contribution .",
    "NOVELTY"
  ],
  [
    "While the proposed system achieves its goal of de-identified videos , its novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "The paper provides a novel solution to depth estimation from a single image which significantly improves the estimation quality over the state of the art . In particular , the usage of planarity and semantic edges in this context is novel and is expected to have a significant impact on 3D geometry estimation in indoor scenes and other human-engineered places that have abundant planar surfaces as well as 3D editing applications for the same .",
    "NOVELTY"
  ],
  [
    "The approach taken here is extremely interesting both technically and from a neuronal data analysis perspective .",
    "NOVELTY"
  ],
  [
    "The binary segmentation-based feature descriptors seem novel and useful .",
    "NOVELTY"
  ],
  [
    "It 's a nice paper introducing a novel method for agglomerating super-voxels regions .",
    "NOVELTY"
  ],
  [
    "The two other contributions are unclear",
    "NOVELTY"
  ],
  [
    "This distribution could be insightful and serve as a rule of thumb for understanding the effect of T",
    "NOVELTY"
  ],
  [
    "Overall this is a strong contribution to the IM literature .",
    "NOVELTY"
  ],
  [
    ", the technical innovation is very limited .",
    "NOVELTY"
  ],
  [
    "the research direction of adversarial text generation studied in this paper is interesting and promising .",
    "NOVELTY"
  ],
  [
    "I think this is an interesting idea",
    "NOVELTY"
  ],
  [
    "The idea of using object mask seems to be very similar to using attention , which",
    "NOVELTY"
  ],
  [
    ", the author argues this work is novel due to it does not fall under supervised learning",
    "NOVELTY"
  ],
  [
    "While the framing of the problem is perhaps novel in the space of PDE",
    "NOVELTY"
  ],
  [
    "and the paper needs some level of novel breakthrough in an algorithmic sense .",
    "NOVELTY"
  ],
  [
    "the proposed architecture seems intuitive and well-designed",
    "NOVELTY"
  ],
  [
    "contribution",
    "NOVELTY"
  ],
  [
    "However , the novelty of the paper is limited and",
    "NOVELTY"
  ],
  [
    "I think this paper introduces an interesting and important new GAN framework .",
    "NOVELTY"
  ],
  [
    "with an innovative idea to forecast the mature performance .",
    "NOVELTY"
  ],
  [
    "I think overall this is",
    "NOVELTY"
  ],
  [
    "The instantiation however seems quite different from existing theorem provers and applied to an area typically not considered by the core ATP community .",
    "NOVELTY"
  ],
  [
    "the state-action space is appealing",
    "NOVELTY"
  ],
  [
    "In term of novelty , the proposed method seems quite incremental .",
    "NOVELTY"
  ],
  [
    "I think the idea is interesting",
    "NOVELTY"
  ],
  [
    "I still think the contribution is incremental .",
    "NOVELTY"
  ],
  [
    "There seems to be little novelty in this work .",
    "NOVELTY"
  ],
  [
    "Novelty The model presented is a non-trivial generalisation of existing methods",
    "NOVELTY"
  ],
  [
    "and the theoretical results provide useful insight",
    "NOVELTY"
  ],
  [
    "Significance I think this is a good contribution to the link prediction literature , providing a nice way to balance model complexity with expressivity .",
    "NOVELTY"
  ],
  [
    "The idea of combining reactive-style approaches with explicit planning techniques is an interesting one , and makes sense intuitively",
    "NOVELTY"
  ],
  [
    "While the individual parts are not novel",
    "NOVELTY"
  ],
  [
    "The approach is overall novel and shows how to combine three existing ideas ( PackNet , Piggyback , and ProgressiveNet )",
    "NOVELTY"
  ],
  [
    "This paper has some interesting ideas in it",
    "NOVELTY"
  ],
  [
    "The adaptation of clustering of eigen vlaues and the strategy used are novel .",
    "NOVELTY"
  ],
  [
    "-The approach seems to be relatively novel",
    "NOVELTY"
  ],
  [
    "Weaknesses of the paper",
    "NOVELTY"
  ],
  [
    "Both the reparameterization of the clipping function and the weight normalization before quantization approaches seem not novel to me",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting idea that accounts both for the inference time and the bell-shaped distribution of weights in NNs .",
    "NOVELTY"
  ],
  [
    "The structure of the neural network in itself is not particularly original .",
    "NOVELTY"
  ],
  [
    "The proposed model is quite interesting .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is original work and in my opinion also important as the search space in the NAS field is much more complicated than",
    "NOVELTY"
  ],
  [
    "`` The idea considered here is cute .",
    "NOVELTY"
  ],
  [
    "The idea behind the paper is not novel .",
    "NOVELTY"
  ],
  [
    "but the improvements appear modest",
    "NOVELTY"
  ],
  [
    "although this paper is relatively incremental and has underwhelming experiments",
    "NOVELTY"
  ],
  [
    "The proposed regularization formulation of kernel Bayes rule is novel as far as I know , while it is based on the existing regression formulation of the conditional kernel mean .",
    "NOVELTY"
  ],
  [
    "and this is a good contribution to the",
    "NOVELTY"
  ],
  [
    "I still think that the technical novelty on the proposed methods is not strong for NIPS .",
    "NOVELTY"
  ],
  [
    "The use of the Wasserstein distance between graph signals for computing graph distances appears novel , and the work contains many interesting ideas that would be valuable for a researcher attending the conference and working on a",
    "NOVELTY"
  ],
  [
    "Sandwiched learned Bloom filters are a new contribution that extends the new research area of learned index structures .",
    "NOVELTY"
  ],
  [
    "My other concern is that the novelty seems to be marginal :",
    "NOVELTY"
  ],
  [
    "Although the paper presents a novel approach and",
    "NOVELTY"
  ],
  [
    "The only drawback of the paper is that this does not advance representation learning per se though a nice application of current models .",
    "NOVELTY"
  ],
  [
    "The focus of the paper , i.e. , to develop improved models by combining TPPs and representation learning , is a promising approach to this task",
    "NOVELTY"
  ],
  [
    "However , none of these contributions on its own are particularly novel .",
    "NOVELTY"
  ],
  [
    "the main novelty seems to lie in the stacked architecture and the particular combination of modules ( which is of limited novelty",
    "NOVELTY"
  ],
  [
    "As far as I know , the insight about the relationship between the memory cell and gradient descent updates is novel here .",
    "NOVELTY"
  ],
  [
    "While it describes very interesting work",
    "NOVELTY"
  ],
  [
    "In addition to the main contribution , this work improves an existing numerical integrator necessary for the ATMC sampler",
    "NOVELTY"
  ],
  [
    "Given the existing body of literature , I found the technical novelty of this paper rather weak .",
    "NOVELTY"
  ],
  [
    "Overall , this appears to be a board-line paper with weak novelty .",
    "NOVELTY"
  ],
  [
    "by the authors .",
    "NOVELTY"
  ],
  [
    "The paper does not introduce strong technical novelties -- mostly",
    "NOVELTY"
  ],
  [
    "and provides an interesting aspect for variance reduction methods",
    "NOVELTY"
  ],
  [
    "but the evaluation and technical novelty is weak .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is interesting from multiple perspectives",
    "NOVELTY"
  ],
  [
    "Overall I think the paper has many interesting ideas even though the presentation could be further improved",
    "NOVELTY"
  ],
  [
    "Although the idea of making numerical rules differentiable is interesting",
    "NOVELTY"
  ],
  [
    "makes the paper somewhat incremental",
    "NOVELTY"
  ],
  [
    "The idea of double descent is not new ,",
    "NOVELTY"
  ],
  [
    "but aside from analyzing its behavior under different assumptions does not pose many new ideas",
    "NOVELTY"
  ],
  [
    "The idea to represent task graphs are quite interesting .",
    "NOVELTY"
  ],
  [
    "This is an interesting combination of existing methods .",
    "NOVELTY"
  ],
  [
    "One thing I am not sure about is the contribution other than the ByAgenda batching algorithm",
    "NOVELTY"
  ],
  [
    "I suspect the contribution of this paper is a little thin if it is all about a ByAgenda batching algorithm .",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "So , I do n't really see much of a technical novelty in the paper .",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    "While the algorithms themselves are not new ( in stylistic sense",
    "NOVELTY"
  ],
  [
    "while the paper seems to advance the state-of-art in learning theory",
    "NOVELTY"
  ],
  [
    "I very much like the proposed formulation for tackling navigation",
    "NOVELTY"
  ],
  [
    "2 .In my view , the proposed formulation advances current models in the following ways",
    "NOVELTY"
  ],
  [
    "Thus , I believe the paper falls short in terms of technical contributions .",
    "NOVELTY"
  ],
  [
    "I believe the paper does n't have enough technical contribution of its own , and",
    "NOVELTY"
  ],
  [
    "the paper bring the idea of \u00e2\u0080\u009cadversarial variational Bayes\u00e2\u0080\u009d to deep Gaussian processes , which is both novel",
    "NOVELTY"
  ],
  [
    "The idea of \u00e2\u0080\u009cadversarial variational Bayes\u00e2\u0080\u009d or \u00e2\u0080\u009cimplicit posterior\u00e2\u0080\u009d is a promising direction to go and the work in this paper demonstrates a significant step",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper makes the following contributions",
    "NOVELTY"
  ],
  [
    "The paper introduces the novel idea of \u00e2\u0080\u009cimplicit posterior variational inference\u00e2\u0080\u009d to DGP",
    "NOVELTY"
  ],
  [
    "In contrast , Sect 4 is pretty novel and important for the method to work in DGP , while is quite short .",
    "NOVELTY"
  ],
  [
    "Overall , this is a well written paper that proposes and solves a novel problem .",
    "NOVELTY"
  ],
  [
    "While there is not much novelty in this part of the paper",
    "NOVELTY"
  ],
  [
    "While not",
    "NOVELTY"
  ],
  [
    "The proposed method as well as analysis techniques are some kind of mixture of existing papers .",
    "NOVELTY"
  ],
  [
    "the innovation level of this paper is not high .",
    "NOVELTY"
  ],
  [
    "The idea of using the formal notion of information in attribution maps is novel , as is the bbox metric .",
    "NOVELTY"
  ],
  [
    "introduces an appealing unsupervised",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is the extension of existing work on modeling misinformation propagation in social media to multiple cascades run simultaneously",
    "NOVELTY"
  ],
  [
    "The model of cascade priority is interesting",
    "NOVELTY"
  ],
  [
    "paper claims to propose a novel method in SSL that learns the graph instead of using a fixed graph",
    "NOVELTY"
  ],
  [
    "The overall approach is interesting",
    "NOVELTY"
  ],
  [
    "The general idea of improving the robustness of a classifier to by feeding adversarial examples to it is not a new idea .",
    "NOVELTY"
  ],
  [
    "The contribution is however a bit incremental in my opinion .",
    "NOVELTY"
  ],
  [
    "Learning features and then use a classifier such as a softmax or SVM is not new and were actually widely used 10 years ago",
    "NOVELTY"
  ],
  [
    "However , freezing the layers and continue to train the last layer is of a minor novelty .",
    "NOVELTY"
  ],
  [
    "Overall , the post-local SGD proposed by the paper seems to be a promising technique for large-scale distributed training .",
    "NOVELTY"
  ],
  [
    "the proposed model itself looks very similar to what can be found across econometric literature",
    "NOVELTY"
  ],
  [
    "it lacks novelty",
    "NOVELTY"
  ],
  [
    "1 .The paper introduces the idea of some existing hand-crafted features into the deep learning framework",
    "NOVELTY"
  ],
  [
    "4 .Though the idea to mimic normal user behaviors is interesting , and seems novel in existing literature",
    "NOVELTY"
  ],
  [
    "overall , I feel that the main contribution of this paper is not very impressive .",
    "NOVELTY"
  ],
  [
    "I still think that the ideas are interesting",
    "NOVELTY"
  ],
  [
    "and I found this aspect of the",
    "NOVELTY"
  ],
  [
    "be thought provoking with respect to how such methods are examined from a qualitative perspective",
    "NOVELTY"
  ],
  [
    "the main concern I have with this paper is novelty . It is in my opinion a somewhat trivial extension of the previous work of Prioritized experience replay in literature ;",
    "NOVELTY"
  ],
  [
    "The approach in the paper is a clever application of the method developed in [ 14 ] .",
    "NOVELTY"
  ],
  [
    "The novelty is not good enough for a NeurIPS paper in the following sense .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , IS is only used for off-policy learning .",
    "NOVELTY"
  ],
  [
    "However , the paper is limited in technical novelty and practical significance .",
    "NOVELTY"
  ],
  [
    "to the SGD optimization algorithm",
    "NOVELTY"
  ],
  [
    "So , although not very original , no one has done this",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is a novel combination of existing techniques in probabilistic numerics and the existing deterministic algorithm .",
    "NOVELTY"
  ],
  [
    "There do not seem to be significant broader novel contributions besides the proposed algorithm .",
    "NOVELTY"
  ],
  [
    "The logit-based detectors proposed in the paper are simple variants of existing methods .",
    "NOVELTY"
  ],
  [
    "it is hard to say that technical contributions are very significant .",
    "NOVELTY"
  ],
  [
    "I absolutely love this direction of research .",
    "NOVELTY"
  ],
  [
    "The idea of leveraging the initial state for augmenting the reward function is clever",
    "NOVELTY"
  ],
  [
    "The paper makes a nice conceptual step of embedding proximal optimization algorithms in a deep neural network framework as an RNN . This conceptual move is new as far as I know .",
    "NOVELTY"
  ],
  [
    "The work is a bit incremental and builds upon previous ideas from hierarchical attention literature to apply for interleaved text generation .",
    "NOVELTY"
  ],
  [
    "and the direct approach is really attractive .",
    "NOVELTY"
  ],
  [
    "I like the approach",
    "NOVELTY"
  ],
  [
    "but I am uncertain about the level of novelty .",
    "NOVELTY"
  ],
  [
    "I feel that the paper could be accepted but it certainly feels as if it needs more computational results as otherwise the original contribution would be too incremental for ICLR standards",
    "NOVELTY"
  ],
  [
    "The proposed approach involving masking out the phrase and marginalizing over possible surrounding word-concepts is novel and offers an interesting perspective on how to approach context independent scoring of phrases --",
    "NOVELTY"
  ],
  [
    "learnt language model",
    "NOVELTY"
  ],
  [
    "The proposed phrase attribution scoring mechanism is motivated from a novel perspective",
    "NOVELTY"
  ],
  [
    "As far as I know this work is original .",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "The contribution is not really clear",
    "NOVELTY"
  ],
  [
    "the idea of non expansive network is interesting and important +",
    "NOVELTY"
  ],
  [
    "The robustness verification methods presented in the paper is new and interesting .",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting approach that seems to outperform existing methods",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "The model outperforms existing approaches given the same visual and linguistic inputs",
    "NOVELTY"
  ],
  [
    "and the authors make a very nice contribution in this paper",
    "NOVELTY"
  ],
  [
    "The idea of making use of EM to estimate the mass matrix in these types of algorithms is very interesting",
    "NOVELTY"
  ],
  [
    "Although the idea seems to be straightforward and innovating",
    "NOVELTY"
  ],
  [
    "This is a good paper with nice ideas",
    "NOVELTY"
  ],
  [
    "and the authors present a natural and intuitively appealing enhancement to sampling techniques on these models",
    "NOVELTY"
  ],
  [
    "it seems the results are heavily based on previous results",
    "NOVELTY"
  ],
  [
    "but still I think the current paper has clear contributions",
    "NOVELTY"
  ],
  [
    "Encoding of the ReLU as a quadratic constraint as done in ( 2 ) is not novel ,",
    "NOVELTY"
  ],
  [
    "The Lagrangian relaxation that is then done is to the best of my knowledge different than any one introduced before .",
    "NOVELTY"
  ],
  [
    "it seems to be a novel result .",
    "NOVELTY"
  ],
  [
    "while the paper is interesting",
    "NOVELTY"
  ],
  [
    "it is not clear whether the results reported here are novel to the ML/DP community ,",
    "NOVELTY"
  ],
  [
    "The experiments on LeNet is relatively toy .",
    "NOVELTY"
  ],
  [
    "but lack of novelty and details",
    "NOVELTY"
  ],
  [
    "The technique novelty of the proposed paper is also limited",
    "NOVELTY"
  ],
  [
    "The only difference is VCBS adds relaxed parameters , which seems no technique novelty .",
    "NOVELTY"
  ],
  [
    "Although the improved analysis provides new insight",
    "NOVELTY"
  ],
  [
    "The other technical contribution on improved trajectory length is also nice but again I feel that it is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "Although the idea in the improved analysis is nice",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but I fail to see any significant contribution in this work .",
    "NOVELTY"
  ],
  [
    "Strength The paper provides us with a new insight into network quantization .",
    "NOVELTY"
  ],
  [
    "Thus , the novelty of algorithm is somewhat weak .",
    "NOVELTY"
  ],
  [
    "This is a nice contribution .",
    "NOVELTY"
  ],
  [
    "My only concern is that this view on acceleration is not new as several papers",
    "NOVELTY"
  ],
  [
    "The paper gives a new insight over why residual networks work in practice .",
    "NOVELTY"
  ],
  [
    "It follows several prior research to analyze the theoretical part , but",
    "NOVELTY"
  ],
  [
    "the understanding is new",
    "NOVELTY"
  ],
  [
    "While not ground breaking",
    "NOVELTY"
  ],
  [
    "The scope of the contribution seems limited to Poisson hidden variables",
    "NOVELTY"
  ],
  [
    "It is not clear which of the operations on PGFs are novel ( if any ) .",
    "NOVELTY"
  ],
  [
    "I found the idea of this paper interesting but I found it very hard to",
    "NOVELTY"
  ],
  [
    "The methods are novel",
    "NOVELTY"
  ],
  [
    "The idea of training M policies in parallel is somewhat related to",
    "NOVELTY"
  ],
  [
    "Also interesting is the novel training technique and the component approximations , which add intuition and motivation .",
    "NOVELTY"
  ],
  [
    "Overall , these ideas are new and interesting and will go on to inspire lots of future work .",
    "NOVELTY"
  ],
  [
    "The paper builds on several known ideas",
    "NOVELTY"
  ],
  [
    ", but the application to learning time series embeddings appears novel ( and",
    "NOVELTY"
  ],
  [
    "effective ) .",
    "NOVELTY"
  ],
  [
    "The proposed technique , though fairly straightforward and making use of established techniques , appears novel and",
    "NOVELTY"
  ],
  [
    "direction .",
    "NOVELTY"
  ],
  [
    "My overall opinion about this paper is : an interesting attempt and idea , yet without a clear contribution .",
    "NOVELTY"
  ],
  [
    "the contribution is unclear .",
    "NOVELTY"
  ],
  [
    ", and I quite like the idea",
    "NOVELTY"
  ],
  [
    "My main problem with this submission is that it is hard",
    "NOVELTY"
  ],
  [
    "to pin down what precisely the novelty is",
    "NOVELTY"
  ],
  [
    "this is a nice 'unifying review \u2019 type paper that - for me - lacks a novel insight",
    "NOVELTY"
  ],
  [
    "I was left a bit disappointed by the lack of novel insight , or a singular key new idea which you often expect in conference presentations",
    "NOVELTY"
  ],
  [
    "and I found that work very insightful .",
    "NOVELTY"
  ],
  [
    "And the paper does not contribute novelty to representation learning",
    "NOVELTY"
  ],
  [
    "The use of an automata is a nice idea .",
    "NOVELTY"
  ],
  [
    "So I think the novelty is good .",
    "NOVELTY"
  ],
  [
    "the novelty of this paper seems very limited",
    "NOVELTY"
  ],
  [
    "2 .The proposed inference example weighing method seems very similar to Batch Renormalization .",
    "NOVELTY"
  ],
  [
    "Using deep learning methods for video compression is still underexplored and poses an interesting research direction compared to current ( handcrafted ) methods",
    "NOVELTY"
  ],
  [
    ", and contains sufficient contribution for NIPS",
    "NOVELTY"
  ],
  [
    "I like the idea of using a very minimal attention mechanism .",
    "NOVELTY"
  ],
  [
    "The idea to use a GAN for model compression is something that many must have considered",
    "NOVELTY"
  ],
  [
    "ii .The novelty of the proposed architecture and training approach is low .",
    "NOVELTY"
  ],
  [
    "The proposed calibration using rejection class and temperature scaling is not new .",
    "NOVELTY"
  ],
  [
    "2 .The novel idea of applying reinforcement learning to DAG search sounds intriguing .",
    "NOVELTY"
  ],
  [
    "To the best of the author \u2019 s knowledge , such idea has never been considered by previous work in causal graphical models .",
    "NOVELTY"
  ],
  [
    "The novel aspect of the method is the introduction of edge features into the computation of the convolutional activation .",
    "NOVELTY"
  ],
  [
    "The paper is moderately original .",
    "NOVELTY"
  ],
  [
    "This paper is interesting and well organized . The idea of plotting loss surface in input space seems to be a natural extension of the loss surface w.r.t to weight change .",
    "NOVELTY"
  ],
  [
    "An interesting RL formulation for query reformulation Cons",
    "NOVELTY"
  ],
  [
    "I found the analysis to be insightful and well-conducted .",
    "NOVELTY"
  ],
  [
    "although more formalization would help sometimes Originality The paper presents an analysis for unsupervised learning of mapping between 2 domains that is totally new as far as I know .",
    "NOVELTY"
  ],
  [
    "-A new cross domain mapping is proposed",
    "NOVELTY"
  ],
  [
    "Although randomized prior functions are not new",
    "NOVELTY"
  ],
  [
    ", this paper presents new arguments regarding the logical inconsistencies of some competing methods , and results on the success of randomized prior functions for exploration in RL .",
    "NOVELTY"
  ],
  [
    "The idea is simple , and although it has been used in other contexts , its application in this area is novel .",
    "NOVELTY"
  ],
  [
    "basic ideas in this paper a not new",
    "NOVELTY"
  ],
  [
    "The paper is moderately original \u00e2\u0080\u0094 the idea of splitting diversity into lexical and syntactic is interesting .",
    "NOVELTY"
  ],
  [
    "The idea of splitting diversity into these two factors is both novel and interesting .",
    "NOVELTY"
  ],
  [
    "This is a very interesting manuscript .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the approach of first learning communication between two agents and then grounding this communication in human language is novel .",
    "NOVELTY"
  ],
  [
    "The dense re-feeding technique seems to be novel with incremental ( but meaningful ) benefits .",
    "NOVELTY"
  ],
  [
    "The paper provides novel observations in terms of deep network regularization .",
    "NOVELTY"
  ],
  [
    "The novel view that the timing is critical for regularizing the deep learning networks could have significant impact on the research field",
    "NOVELTY"
  ],
  [
    "I find this reduction fairly novel and ties DP to a large body of work on polynomial estimation .",
    "NOVELTY"
  ],
  [
    "and the \\log n factor is particularly interesting",
    "NOVELTY"
  ],
  [
    "Although I find the contribution novel and am convinced of its utility in practical applications",
    "NOVELTY"
  ],
  [
    "The draft provided a fresh view on deep convolutional neural networks ( CNN",
    "NOVELTY"
  ],
  [
    "This paper does n't give any new contributions and has no potential values .",
    "NOVELTY"
  ],
  [
    "the paper is lack of novelty and",
    "NOVELTY"
  ],
  [
    "and this paper brings some good intuitions in light of modern convolutional neural nets .",
    "NOVELTY"
  ],
  [
    "The setting considered in this paper is new and relevant . The algorithm is also new and solves the problem .",
    "NOVELTY"
  ],
  [
    "The paper may be borderline in terms of contributions for a conference like NeurIPS",
    "NOVELTY"
  ],
  [
    "An excellent contribution",
    "NOVELTY"
  ],
  [
    "The concept though is far from new",
    "NOVELTY"
  ],
  [
    "The process is interesting and incorporates plenty of useful experience",
    "NOVELTY"
  ],
  [
    "although in the current context is insufficient as stand-alone contribution",
    "NOVELTY"
  ],
  [
    "Online Min-cost matching does not have a primal-dual analysis ( to the best of my knowledge ) .",
    "NOVELTY"
  ],
  [
    "this paper is mathematically interesting",
    "NOVELTY"
  ],
  [
    "I feel this work novel and interesting in general .",
    "NOVELTY"
  ],
  [
    "Propose a novel technique applicable for prototypical networks .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is intuitive and interesting .",
    "NOVELTY"
  ],
  [
    "The use of the True Class Probability ( TCP ) is novel in the area of uncertainty estimation for the task of detecting misclassifications .",
    "NOVELTY"
  ],
  [
    "While the use of the TCP as a target is novel",
    "NOVELTY"
  ],
  [
    "confidence score estimation is not , thus the work has limited novelty .",
    "NOVELTY"
  ],
  [
    "Limited originality",
    "NOVELTY"
  ],
  [
    "I still feel that the method lacks a certain degree of novelty and the gains and not as great relative to baseline models .",
    "NOVELTY"
  ],
  [
    "The method introduced in this work seem novel in the context of other literature that train forward models .",
    "NOVELTY"
  ],
  [
    "the framing of the problem and the method the authors use seems novel Significance",
    "NOVELTY"
  ],
  [
    "I like the perspective of this paper",
    "NOVELTY"
  ],
  [
    "It looks to me there are two major novelties here",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is novel ,",
    "NOVELTY"
  ],
  [
    "Implementation of the idea seems non-trivial",
    "NOVELTY"
  ],
  [
    ", and to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "this reviewer would argue the paper is a bit incremental",
    "NOVELTY"
  ],
  [
    "a combination of two models without a clear motivation from a molecular design perspective",
    "NOVELTY"
  ],
  [
    "While a good general approach , it is not new",
    "NOVELTY"
  ],
  [
    "While this type of analysis is not completely novel",
    "NOVELTY"
  ],
  [
    ", the observations made are new and very interesting .",
    "NOVELTY"
  ],
  [
    "The work is very incremental over Luo et al ( 2018 ) `` End-to-end Active Object Tracking and Its Real-world Deployment via Reinforcement Learning `` ,",
    "NOVELTY"
  ],
  [
    "the insight gained is fairly superficial",
    "NOVELTY"
  ],
  [
    "as far as I am aware , the paper is novel .",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper novelty is not significant enough . Although useful , the suggested techniques are based on existing methods .",
    "NOVELTY"
  ],
  [
    "But although useful , the suggested methods are not novel enough .",
    "NOVELTY"
  ],
  [
    "Using meta learning to address the problem of imbalanced data distribution is an interesting idea",
    "NOVELTY"
  ],
  [
    "Overall , I believe the authors presents an insightful and interesting idea",
    "NOVELTY"
  ],
  [
    "it appears that the setup discussed in this paper is closely related to instrumental variables regression , and that the authors have essentially re-derived",
    "NOVELTY"
  ],
  [
    "The approach presented here ( based on solving a min-max optimization problem ) appears to be novel , and potentially interesting , in the context of the existing literature .",
    "NOVELTY"
  ],
  [
    "While the community has made promising progress , to my best knowledge , this paper is the first work considering attacking MOT techniques",
    "NOVELTY"
  ],
  [
    "I am not completely convinced that there is enough technical novelty .",
    "NOVELTY"
  ],
  [
    "-- -- -- Original review -- -- -- The paper presents a novel flow based on invertible convolutions .",
    "NOVELTY"
  ],
  [
    "note that using point-wise nonlinearities does not seem novel itself .",
    "NOVELTY"
  ],
  [
    "Only possibly the interpretation of them as regularizing the latent representation seems novel .",
    "NOVELTY"
  ],
  [
    "In my opinion , the technical innovation is sufficiently novel for publication .",
    "NOVELTY"
  ],
  [
    "The paper does not",
    "NOVELTY"
  ],
  [
    "introduce any new algorithm",
    "NOVELTY"
  ],
  [
    "great source of insight and intuition about robust optimization and deep learning .",
    "NOVELTY"
  ],
  [
    "method interesting",
    "NOVELTY"
  ],
  [
    "I think that the technical contribution is a bit thin for a ML conference and this paper may be a better fit for",
    "NOVELTY"
  ],
  [
    "I really liked the idea of sharing the middle layer and the inducing variables u_ { f , d } across the multiple sequences .",
    "NOVELTY"
  ],
  [
    "However , I see the main contribution of the paper in the novel theoretically-guided approach .",
    "NOVELTY"
  ],
  [
    "In sum , this is a very interesting paper that has novel contribution to the practical side of neural networks and new insights on the theoretical side .",
    "NOVELTY"
  ],
  [
    "Overall , the problem studied in this paper is interesting and novel ,",
    "NOVELTY"
  ],
  [
    "the proposed method",
    "NOVELTY"
  ],
  [
    "makes",
    "NOVELTY"
  ],
  [
    "but is not very novel .",
    "NOVELTY"
  ],
  [
    "While I acknowledge",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    "Although it is not very novel",
    "NOVELTY"
  ],
  [
    "yet it is interesting",
    "NOVELTY"
  ],
  [
    "The technical novelty however is limited .",
    "NOVELTY"
  ],
  [
    "The idea of introducing sparseness in estimation is a popular technique in many problems , so the methodology itself is not new .",
    "NOVELTY"
  ],
  [
    "There is very little novelty in this work over that presented in Abubakar Abid et .",
    "NOVELTY"
  ],
  [
    "The only incremental contribution in this work is the specific mask types and mask-specific losses .",
    "NOVELTY"
  ],
  [
    "Interesting approach to extend the framework in [ 1 ] to",
    "NOVELTY"
  ],
  [
    "for the network bandwidth limited use case Cons",
    "NOVELTY"
  ],
  [
    "Hardly any technical novelty because the core ideas are already presented as well as applied to the same task in",
    "NOVELTY"
  ],
  [
    "The contribution is sufficiently original and significant enough to warant acceptance .",
    "NOVELTY"
  ],
  [
    "Although this paper provides a new view point of RNN architectures and relates RNNs with ODEs",
    "NOVELTY"
  ],
  [
    "it fails to provide useful insight using this view point .",
    "NOVELTY"
  ],
  [
    "Generally , this work is novel .",
    "NOVELTY"
  ],
  [
    "I like the general approach the authors are taken . The model architecture the authors have put together ( including Core+Readout+Shifter+Modulator ) seems to be novel and reasonable .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is the first UDA approach for semantic segmentation that combines pseudo-labeling with feature alignment .",
    "NOVELTY"
  ],
  [
    "As the authors claim -- -the paper presents `` an early attempt towards this goal",
    "NOVELTY"
  ],
  [
    "The contribution of the paper itself is not sufficient",
    "NOVELTY"
  ],
  [
    "The idea of using behavior embedding is new in PO .",
    "NOVELTY"
  ],
  [
    "While the overall approach is simple it is also quite intuitiv",
    "NOVELTY"
  ],
  [
    "The algorithm has some little tricks in it that make it a useful contribution .",
    "NOVELTY"
  ],
  [
    "I think in general this paper lacks novelty and it should n't be surprising that activations from all layers should be more representative than one single layer representation",
    "NOVELTY"
  ],
  [
    "The studied problem is very interesting and novel .",
    "NOVELTY"
  ],
  [
    "I still think that the contribution of the present paper stands on its own .",
    "NOVELTY"
  ],
  [
    "I am concerned about the originality of the work and significance of the study",
    "NOVELTY"
  ],
  [
    "I think this is an incremental contribution to existing work with detailed experiments .",
    "NOVELTY"
  ],
  [
    "Given all of these issues and the fact that the main result is incremental and holds under a very limited setting",
    "NOVELTY"
  ],
  [
    "It does so not just by analysing online algorithms but primarily through graph partitioning , which seems novel for the problem of cooperating agents",
    "NOVELTY"
  ],
  [
    "The method is novel and the proposed implementation details constitute a significant technical contribution",
    "NOVELTY"
  ],
  [
    "and presents an innovative idea",
    "NOVELTY"
  ],
  [
    "The work might be seen as incremental",
    "NOVELTY"
  ],
  [
    "I 'm not sure whether the framework is novel .",
    "NOVELTY"
  ],
  [
    "of the proposed defense and the novel reconstructive attack method",
    "NOVELTY"
  ],
  [
    "I am concerned by the novelty of the proposed approach , which seems very similar to InfoBot",
    "NOVELTY"
  ],
  [
    "authors contribute",
    "NOVELTY"
  ],
  [
    "A novel algorithm and its asymptotic communication complexity",
    "NOVELTY"
  ],
  [
    "The algorithm , while having differences , is quite reminiscent of Elastic Averaging SGD ( EASGD ) [ 1 ] .",
    "NOVELTY"
  ],
  [
    "and as far as I know the main idea is original",
    "NOVELTY"
  ],
  [
    "In general , the novelty of this part is incremental .",
    "NOVELTY"
  ],
  [
    "The idea of reusing the samples from previous iterations for approximating the loss is interesting and worth exploring .",
    "NOVELTY"
  ],
  [
    "While I believe the authors have a promising idea",
    "NOVELTY"
  ],
  [
    "This paper presents an interesting approach to approximately implementing backpropagation that relies on a mixture of dendritic compartments and specific circuitry motifs .",
    "NOVELTY"
  ],
  [
    "although there exist good algorithms available the idea of using GANs to address the problem is new to me and makes good sense .",
    "NOVELTY"
  ],
  [
    "The general idea of this paper is interesting .",
    "NOVELTY"
  ],
  [
    "Compared with the previous work on single-turn reading comprehension , the idea in this paper differs primarily in that it alternates between the context integration and the question flow in parallel",
    "NOVELTY"
  ],
  [
    "this work is by far the first that achieves nontrivial improvement over CoQA and QuAC",
    "NOVELTY"
  ],
  [
    "I think the paper is promising",
    "NOVELTY"
  ],
  [
    "The combination of SGHMC and deep Gaussian processes is novel .",
    "NOVELTY"
  ],
  [
    "the proposed variant of the MCEM is also original .",
    "NOVELTY"
  ],
  [
    "The results presented in this paper seem to be state-of-the-art , and innovation on quantization , which has not attracted a lot of attention in the context of neural network-based image compression is a welcome contribution",
    "NOVELTY"
  ],
  [
    ", and includes several significant and novel contributions",
    "NOVELTY"
  ],
  [
    "Although the novelty is high",
    "NOVELTY"
  ],
  [
    "The main ideas are new to me and",
    "NOVELTY"
  ],
  [
    "The idea of optimizing the direction while ignoring the magnitude is interesting",
    "NOVELTY"
  ],
  [
    "The techniques for proving the lower bound",
    "NOVELTY"
  ],
  [
    "This original problem has been proposed in the prior work",
    "NOVELTY"
  ],
  [
    "However , the novelty is limited .",
    "NOVELTY"
  ],
  [
    "However , this is of minor technical novelty",
    "NOVELTY"
  ],
  [
    "the novelty in dropping intermediate frames for speedup is marginal .",
    "NOVELTY"
  ],
  [
    "this effect has been previously explored in detail in other works like schedule sampling",
    "NOVELTY"
  ],
  [
    "Overall , the paper presents some interesting experimental observations .",
    "NOVELTY"
  ],
  [
    "the technical novelty and contribution of the proposed architecture and training scheme is not clear .",
    "NOVELTY"
  ],
  [
    "I am , however , still lukewarm on this submission for its limited technical innovation and over-simplified experimental",
    "NOVELTY"
  ],
  [
    "Conditioned on the problem setup being novel",
    "NOVELTY"
  ],
  [
    "related work clarified , I think this is a solid contribution .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel compact parameterization of convolution filters .",
    "NOVELTY"
  ],
  [
    "I did not find enough of novelty , clarity or at",
    "NOVELTY"
  ],
  [
    "the paper to recommend acceptance",
    "NOVELTY"
  ],
  [
    "then to me this is a rather minor novelty and to justify it 's importance authors should run a control experiment with the exact same architecture as in DNC",
    "NOVELTY"
  ],
  [
    "I am just not too sure whether the technical aspect is novel enough to support an oral at nips",
    "NOVELTY"
  ],
  [
    "The idea seems interesting and make sense for me",
    "NOVELTY"
  ],
  [
    "The methods seem promising , and the degree of localist representation is striking .",
    "NOVELTY"
  ],
  [
    "I like the proposed approach , in this paper .",
    "NOVELTY"
  ],
  [
    "The authors proposed an interesting depth separation argument based on fractal distributions .",
    "NOVELTY"
  ],
  [
    "Finally , it seems like the novelty/contribution of this work is very small .",
    "NOVELTY"
  ],
  [
    "so this paper represents an important contribution",
    "NOVELTY"
  ],
  [
    "Overall , I was impressed by this submission .",
    "NOVELTY"
  ],
  [
    "the D-net idea is straightforward",
    "NOVELTY"
  ],
  [
    "but ( as far as I can tell ) somewhat novel ,",
    "NOVELTY"
  ],
  [
    "This work is very interesting and new to the energy efficiency community and non-intrusive load monitoring .",
    "NOVELTY"
  ],
  [
    "The data is also new to the community .",
    "NOVELTY"
  ],
  [
    "Somewhat incremental technical novelty : combination of two previously published methods ( Qiu et al .2018",
    "NOVELTY"
  ],
  [
    "the bounds in Theorems 1 and 2 are not novel and highly unlikely to be tight .",
    "NOVELTY"
  ],
  [
    "and the ideas are novel .",
    "NOVELTY"
  ],
  [
    "As far as I know , this is the first paper to apply gradient-based ( i.e .MAML-style ) meta-learning to this specific problem .",
    "NOVELTY"
  ],
  [
    "It seems to me that humans are capable of segmenting novel objects",
    "NOVELTY"
  ],
  [
    ", but less novel",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed technique is fair and the originality alike .",
    "NOVELTY"
  ],
  [
    "Although it is claimed that the paper improved existing results by either considering nonlinear models or identify more precise implication regularization , the contribution is a bit minor",
    "NOVELTY"
  ],
  [
    "the arguments are insightful",
    "NOVELTY"
  ],
  [
    "The randomization technique in this paper is not standard",
    "NOVELTY"
  ],
  [
    "I agree with the other two reviewers that the work is somewhat incremental",
    "NOVELTY"
  ],
  [
    "I think overall that this paper is a good contribution and I recommend acceptance",
    "NOVELTY"
  ],
  [
    "8/10 to my knowledge the proposed regularizer is novel",
    "NOVELTY"
  ],
  [
    "The algorithm seems to be similar to previous meta-learning approaches , but differs by introducing a lifetime value function .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm does not seem like a major innovation over cited previous work .",
    "NOVELTY"
  ],
  [
    "There is however a lack of technical novelty or insight in the models themselves .",
    "NOVELTY"
  ],
  [
    "Though directly optimizing the rate-distortion tradeoff is not an entirely novel enterprise",
    "NOVELTY"
  ],
  [
    "The methodological novelty is clear",
    "NOVELTY"
  ],
  [
    "the idea of dynamic channel pruning is not novel .",
    "NOVELTY"
  ],
  [
    "The idea of dynamic channel pruning is not novel . In my opinion , this paper is only an extension to Network Slimming ( Liu et al. , 2017 ) .",
    "NOVELTY"
  ],
  [
    "The idea is innovative",
    "NOVELTY"
  ],
  [
    "( the ICC concept itself is not new , but the algorithmic ideas appear to be",
    "NOVELTY"
  ],
  [
    "Novelty and Clarity The theoretical results are interesting and provide new insights into the topic .",
    "NOVELTY"
  ],
  [
    "The new model is interesting and captures some of the new challenges in machine learning .",
    "NOVELTY"
  ],
  [
    "The new observations of shuffle set property and co-kernel matrix are interesting techniques for spectral learning .",
    "NOVELTY"
  ],
  [
    "Overall this is an interesting new result on spectral learning and contains some new techniques specially designed for mixture of Markov chains .",
    "NOVELTY"
  ],
  [
    "Overall the model is novel and the",
    "NOVELTY"
  ],
  [
    "It provides interesting observations",
    "NOVELTY"
  ],
  [
    "3 .Without further explanations and analyses about the experimental results , the contribution of the paper seems limited .",
    "NOVELTY"
  ],
  [
    "4 .This paper proposed an improved version of the AEC algorithm .",
    "NOVELTY"
  ],
  [
    "This paper has some interesting insights and a few ideas of how to validate an evaluation method .",
    "NOVELTY"
  ],
  [
    "The paper unifies adversarial 0/1 loss minimization and empirical risk minimization via a novel loss function",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , apart from the Lee Lin and Wahba SVM , this is the first multiclass kernel machine enjoying both Fisher consistency and universal consistency .",
    "NOVELTY"
  ],
  [
    "The algorithmic contribution is not earth-shattering or novel .",
    "NOVELTY"
  ],
  [
    "The paper offers significant novelty and extends the state of the art in the area .",
    "NOVELTY"
  ],
  [
    "The idea of adding binomial RVs - which are the discrete counter parts of Gaussians - seems natural and intuitive , at least wit hind sight .",
    "NOVELTY"
  ],
  [
    "somewhat incremental relative to Shah and Barber ( Neurips 2018 ) , results are only marginally positive",
    "NOVELTY"
  ],
  [
    "Although it \u2019 s not highly original",
    "NOVELTY"
  ],
  [
    "I think the idea looks interesting",
    "NOVELTY"
  ],
  [
    "although the novelty is a bit incremental , as it basically combined the two well-known models ( VAE and Glow ) .",
    "NOVELTY"
  ],
  [
    "The idea presented in the paper is however interesting and timely and deserves to be shared with the wider generative models community",
    "NOVELTY"
  ],
  [
    "Conceptually , the proposed approach seems like a straight-forward application/extension of existing methods",
    "NOVELTY"
  ],
  [
    "The ideas and contributions of this paper are very nice and I hope to see more such speedups in other applications since ALS is such a general workhorse",
    "NOVELTY"
  ],
  [
    "Sampling proportionally to the leverage scores is not terribly new",
    "NOVELTY"
  ],
  [
    "but I think this paper innovates well on the application side to meet the NIPS bar",
    "NOVELTY"
  ],
  [
    "We do not see a real technical innovation",
    "NOVELTY"
  ],
  [
    ", but the combination of the said methods is interesting in itself .",
    "NOVELTY"
  ],
  [
    "we do not see a clear technical breakthrough that would be reused by other authors .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and",
    "NOVELTY"
  ],
  [
    "the paper as it stands may not be as useful as its novelty",
    "NOVELTY"
  ],
  [
    "I also do n't see too much novelty in this approach",
    "NOVELTY"
  ],
  [
    "The idea of using imitation learning to make approximate decisions is not new .",
    "NOVELTY"
  ],
  [
    "The idea of introducing stochasticity by convolutional filters into the conditional generative models seems to be novel and the reviewer thinks it could be of interest for the community .",
    "NOVELTY"
  ],
  [
    "not really novel ( CycleGAN for timeseries ) nor DTW as reconstruction error",
    "NOVELTY"
  ],
  [
    "The novelty is not very high as the main architecture is from CycleGAN and the proposed similarity measures for the reconstruction error are not really novel .",
    "NOVELTY"
  ],
  [
    "Your paper merges this into the retirement problem in an interesting way .",
    "NOVELTY"
  ],
  [
    "I find the idea to use the multi-head attention very interesting",
    "NOVELTY"
  ],
  [
    "To my best knowledge , it is original .",
    "NOVELTY"
  ],
  [
    "Conceptual novelty seems to be limited .",
    "NOVELTY"
  ],
  [
    "My main concern is that while this paper does a good job under the topic of SVRG , the overall contribution may not be big .",
    "NOVELTY"
  ],
  [
    "this seems like good work .",
    "NOVELTY"
  ],
  [
    "systems can give rise to optimal algorithms for convex optimization \u00e2\u0080",
    "NOVELTY"
  ],
  [
    "The contribution seems to be rather incremental ( evaluating existing methods on 2 dataset",
    "NOVELTY"
  ],
  [
    "some related work might be missing",
    "NOVELTY"
  ],
  [
    "The work is original enough",
    "NOVELTY"
  ],
  [
    "-The idea seems to be original enough , simple and easy to implement .",
    "NOVELTY"
  ],
  [
    "However , I think the idea is interesting",
    "NOVELTY"
  ],
  [
    "The proposed form for the HTQF is interesting and appears to be a novel contribution worthy of a presentation at NIPS .",
    "NOVELTY"
  ],
  [
    "Originality -- -- -- -- -- -- The present work is a novel unifying view of multiple calibration errors ( ECE , MCE , MMCE ) .",
    "NOVELTY"
  ],
  [
    "The technical novelty of this paper is very limited .",
    "NOVELTY"
  ],
  [
    "But the novelty is very limited",
    "NOVELTY"
  ],
  [
    "-- I liked the posterior sharpening idea .",
    "NOVELTY"
  ],
  [
    "Some results seem to be novel ,",
    "NOVELTY"
  ],
  [
    "but similar ideas and analysis have been proposed/done before .",
    "NOVELTY"
  ],
  [
    "and the algorithm and the analysis provided in the paper form an interesting contribution in this respect .",
    "NOVELTY"
  ],
  [
    "presents a simple intuitive extension to the original GEM paper that is much more computationally efficient and is thus more suited and feasible for real lifelong learning applications",
    "NOVELTY"
  ],
  [
    "The paper can be viewed as somewhat incremental but the increment is probably crucial for any real-world practical application",
    "NOVELTY"
  ],
  [
    "Rationale for my evaluation : The method is somewhat incremental",
    "NOVELTY"
  ],
  [
    "but I see the contribution as too minor to constitute a paper at the conference track of a leading international conference such as ICLR .",
    "NOVELTY"
  ],
  [
    "This paper is interesting",
    "NOVELTY"
  ],
  [
    "I only give a `` marginal acceptance `` for the following reasons",
    "NOVELTY"
  ],
  [
    "One key insight of this paper is not new .",
    "NOVELTY"
  ],
  [
    "The perspective of connecting Nesterov 's method and ODE is not new , but to the best of my knowledge , this is the first work where Nesterov 's method can be derived directly from the given ODE . The proposed approach is interesting but I find the contribution a bit weak .",
    "NOVELTY"
  ],
  [
    "but the convergence analysis in the paper is not new ,",
    "NOVELTY"
  ],
  [
    "The inexact version is not new neither",
    "NOVELTY"
  ],
  [
    "I find the approach interesting",
    "NOVELTY"
  ],
  [
    "The overall technical contribution is fairly small and are ideas that are regularly implemented when optimizing systems .",
    "NOVELTY"
  ],
  [
    "given that the novelty in the project is relatively limited",
    "NOVELTY"
  ],
  [
    "The novelty of the project is relatively limited . The proposed and implemented environments have been studied before",
    "NOVELTY"
  ],
  [
    "The present paper 's new `` D-Conv `` operator appears new",
    "NOVELTY"
  ],
  [
    "the contributions are not enough for this veneue",
    "NOVELTY"
  ],
  [
    "The first message of the paper is trivial and can not be considered as a novel contribution",
    "NOVELTY"
  ],
  [
    "Even considering this assumption to be correct , the contribution is minimal to the field and benefits of averaging saliency maps have been known since the SmoothGrad paper .",
    "NOVELTY"
  ],
  [
    "method , apart from being very similar to what is already there in the literature",
    "NOVELTY"
  ],
  [
    "Even assuming the correctness of this assumption , the contribution over what already exists in the literature is not enough for this venue .",
    "NOVELTY"
  ],
  [
    "From what I can tell the paper is novel but I am not very familiar with work on diagnosis systems",
    "NOVELTY"
  ],
  [
    "It is not necessarily groundbreaking but a fine contribution that is sufficient for NIPS presentation .",
    "NOVELTY"
  ],
  [
    "This paper combines the work of two previous algorithms",
    "NOVELTY"
  ],
  [
    "but I find the extensions somewhat incremental compared to existing work",
    "NOVELTY"
  ],
  [
    "Though the idea of a tradeoff between objectives in signal restoration is not novel",
    "NOVELTY"
  ],
  [
    ", the work is a novel contribution and extension to the theory around this important area of research .",
    "NOVELTY"
  ],
  [
    "The paper strikes me as an",
    "NOVELTY"
  ],
  [
    "extremely significant followup",
    "NOVELTY"
  ],
  [
    "to a recent paper",
    "NOVELTY"
  ],
  [
    "these are minor contributions and not enough to cover up the major flaws that I discussed above .",
    "NOVELTY"
  ],
  [
    "Overall , the proposed approach is heuristic , and the novelty is very limited .",
    "NOVELTY"
  ],
  [
    "The proposed method is a novel combination of existing methods .",
    "NOVELTY"
  ],
  [
    "This makes the paper not novel enough .",
    "NOVELTY"
  ],
  [
    "My main concern is the novelty of the model .",
    "NOVELTY"
  ],
  [
    "However , the contribution of the paper seems incremental , since it barely combine several existing ideas without introducing new modules to solve their problems .",
    "NOVELTY"
  ],
  [
    "My major concern on this paper is the significance , as the contribution of the paper seems to be very limited .",
    "NOVELTY"
  ],
  [
    "Applying them to feature attribution/saliency map does not seem to have much technical contribution .",
    "NOVELTY"
  ],
  [
    "However , this contribution also seems to be minor .",
    "NOVELTY"
  ],
  [
    "the proposed method in this paper is original .",
    "NOVELTY"
  ],
  [
    "While the idea is simple",
    "NOVELTY"
  ],
  [
    "I think the idea is interesting . Incorporating modulated derivative and Laplacian operators into physical simulators is novel and well justified .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well-written and the ideas are novel .",
    "NOVELTY"
  ],
  [
    "The idea is novel to the best of my knowledge and the improvement over DQN",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting idea",
    "NOVELTY"
  ],
  [
    "results in this paper are interesting in general",
    "NOVELTY"
  ],
  [
    "it seems that a few references are broken To my knowledge the idea of making amount of transfer between tasks dependent on the particular sample at hand is new",
    "NOVELTY"
  ],
  [
    "This approach makes sense to me , and is new in a way",
    "NOVELTY"
  ],
  [
    "but it doesn \u2019 t appear to be very revolutionary or significant to me .",
    "NOVELTY"
  ],
  [
    "Again , I feel that this modification not particularly revolutionary .",
    "NOVELTY"
  ],
  [
    "The method for computing the rate-distortion curves of deep generative models is interesting and the rate-prior distortion curve is promising as a performance measure .",
    "NOVELTY"
  ],
  [
    "the main technical contribution of this work is the estimated AIS rate-prior distortion curve and it is based on a straight-forward application of AIS",
    "NOVELTY"
  ],
  [
    "Although the findings in the experiments are interesting and insightful",
    "NOVELTY"
  ],
  [
    "My main issue with the paper is that these two topics are actually not new and are well covered by the existing RL formalisms .",
    "NOVELTY"
  ],
  [
    "I found this a nice new insight and the strongest part of the paper .",
    "NOVELTY"
  ],
  [
    "This paper considers generative modeling in the online continual learning setting for the first time .",
    "NOVELTY"
  ],
  [
    "The weaknesses of this work include that it is a not-too-distant variation of prior work",
    "NOVELTY"
  ],
  [
    "Introducing the tree structure is a neat way of extending the existing rSLDS model to multiscale scenarios .",
    "NOVELTY"
  ],
  [
    "The idea of `` controlling what you can `` is an intuitive and appealing approach to thinking about these kinds of environments .",
    "NOVELTY"
  ],
  [
    "No single component in this method is orignal",
    "NOVELTY"
  ],
  [
    "but agree with the other reviewers that the novelty of the work in this paper likely does n't meet the bar for acceptance given that the most significant contributions of this paper are around combining good ideas from other papers without much additional novelty",
    "NOVELTY"
  ],
  [
    "Here the text is written such as to indicate that this is a novel contribution of the present paper",
    "NOVELTY"
  ],
  [
    "1- Overall , the result is fairly novel , and provides interesting insight into the behavior of stochastic algorithms in this non-convex problem .",
    "NOVELTY"
  ],
  [
    "the originality is limited .",
    "NOVELTY"
  ],
  [
    "t think modeling the temporal dependencies of the latent variables with a convolutional network is a significant contribution to the conditional flow-based methods",
    "NOVELTY"
  ],
  [
    "Though the overall novelty is still not fully convincing",
    "NOVELTY"
  ],
  [
    "While the idea appears to be quite novel for meta-learning",
    "NOVELTY"
  ],
  [
    "The introduction of using distributional signature to derive attention scores seems interesting and a novel contribution .",
    "NOVELTY"
  ],
  [
    "The idea of dividing the hidden states into two parts is interesting as it helps the model to control the effect of unsupervised loss on main supervised task .",
    "NOVELTY"
  ],
  [
    "Although the scientific contribution may be low in the paper",
    "NOVELTY"
  ],
  [
    "It is also nice to see some interesting approaches towards objective evaluation .",
    "NOVELTY"
  ],
  [
    "This is a nice piece of work",
    "NOVELTY"
  ],
  [
    "2 .To the best of my knowledge , this work is the first verification method that can scale up to more than 10K hidden units within a reasonable computation time .",
    "NOVELTY"
  ],
  [
    "The main contribution of the paper is a state evolution theory under certain assumptions",
    "NOVELTY"
  ],
  [
    "that this paper presents a very creative and interesting exploration that makes both theoretical and empirical contributions",
    "NOVELTY"
  ],
  [
    "Yet , to the best of our knowledge , the literature on deep neural networks does not propose any method for the quantitative evaluation of the uncertainty estimates .",
    "NOVELTY"
  ],
  [
    "Given these existing literatures , the contribution of this paper should be considered more properly .",
    "NOVELTY"
  ],
  [
    "that presents a new angle on why the current CNN architectures",
    "NOVELTY"
  ],
  [
    "The experimental setting proposed in this paper is interesting .",
    "NOVELTY"
  ],
  [
    "the proposed model is trivial .",
    "NOVELTY"
  ],
  [
    "Thus , the novelty of this paper is incremental .",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting transfer learning framework where either the source or the target domain can not observe the data in the other domain .",
    "NOVELTY"
  ],
  [
    "The main issue of this paper is the novelty is incremental .",
    "NOVELTY"
  ],
  [
    "Because the idea is not new , and formulating HPG from PG is so straightforward",
    "NOVELTY"
  ],
  [
    ", the work seems incremental .",
    "NOVELTY"
  ],
  [
    "makes an interesting observation",
    "NOVELTY"
  ],
  [
    "This paper seems very similar to the work of Contrado \u2019 s RADIN algorithm which similarly evaluates sequential datapoints with a recurrent neural network by adaptively \u201c purchasing \u201d the most valuable features for the current datapoint under evaluation according to a budget .",
    "NOVELTY"
  ],
  [
    "I like the idea of having a synthetic dataset where all the parameters are controllable .",
    "NOVELTY"
  ],
  [
    "The novelty and the neatness of the problem definition is striking and this will motivate new research in this application .",
    "NOVELTY"
  ],
  [
    "Although I am not an expert in Graphical models , the paper seems like a novel extension of the distance dependent CRP referenced in the paper .",
    "NOVELTY"
  ],
  [
    "The authors are proposing a novel approach to experimental design for investigating animal behaviour and learning . While this is obviously a positive in terms of novelty",
    "NOVELTY"
  ],
  [
    "The idea of learning group structure is not new .",
    "NOVELTY"
  ],
  [
    "Another issue with the paper is that it heavily builds on the existing work by Rothe et al.",
    "NOVELTY"
  ],
  [
    "Analysis of the communication",
    "NOVELTY"
  ],
  [
    "Even though this issue has been occasionally mentioned before , I think this highly original work that focuses on this otherwise not sufficiently discussed problem .",
    "NOVELTY"
  ],
  [
    "-- SDR characterisation of the convolutional filters is interesting -- The authors show that filters with different characteristics are responsible for different aspects of image modelling Cons",
    "NOVELTY"
  ],
  [
    "To my knowledge , the idea is novel and has not yet been explored in the RL literature",
    "NOVELTY"
  ],
  [
    "This is a new solution to an old problem .",
    "NOVELTY"
  ],
  [
    "I enjoyed this paper overall , and I think the idea is a good one .",
    "NOVELTY"
  ],
  [
    "The techniques are interesting .",
    "NOVELTY"
  ],
  [
    "One thing that was not clear to me was which part was technically the most interesting/novel contribution of this paper given [ 9 ] ( and possibly other papers ) .",
    "NOVELTY"
  ],
  [
    "This is a nice innovation for sequence-to-sequence modeling .",
    "NOVELTY"
  ],
  [
    "The technical contribution required to make it work is non-trivial",
    "NOVELTY"
  ],
  [
    "I find the concrete contribution of the paper a bit thin to the point that I am hesitant to recommend this paper for acceptance",
    "NOVELTY"
  ],
  [
    "the modulation mentioned in the paper does not seem particularly novel .",
    "NOVELTY"
  ],
  [
    "the exact architecture of the model is probably unique , but the idea of modulating a state with a goal is not and has been seen in other work such as [ 2 ] and [ 3 ] among others .",
    "NOVELTY"
  ],
  [
    "The ideas are generally of high quality",
    "NOVELTY"
  ],
  [
    "The paper is original to my knowledge , and a valuable extension to the interesting",
    "NOVELTY"
  ],
  [
    "it is hard to observe the contribution of DDL in terms of the performance",
    "NOVELTY"
  ],
  [
    "The above facts reduce the novelty of the approach",
    "NOVELTY"
  ],
  [
    "but I think it is a nice idea which can facilitate the optimization",
    "NOVELTY"
  ],
  [
    "and mature",
    "NOVELTY"
  ],
  [
    "The text makes it sound like the idea of using 3d convolutions in a convLSTM is novel .",
    "NOVELTY"
  ],
  [
    "and the idea sounds interesting",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "The idea introduced is simple and flexible to be used for any CNN architecture",
    "NOVELTY"
  ],
  [
    "Novelty is extremely limited",
    "NOVELTY"
  ],
  [
    "I feel that the idea of learning an imitation classifier is somehow novel and intuitive ,",
    "NOVELTY"
  ],
  [
    "Although there is not much novelty in combining the two",
    "NOVELTY"
  ],
  [
    "This is a very succinct paper and I think that it serves as a nice theoretical contribution .",
    "NOVELTY"
  ],
  [
    "The reduction from oblivious to adversarial adversaries seems new",
    "NOVELTY"
  ],
  [
    "as well",
    "NOVELTY"
  ],
  [
    "I 'm not aware of a comparable work , so the novelty here seems good",
    "NOVELTY"
  ],
  [
    "but this seems like a very limited investment",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "and the proposed approach seems novel and elegant to me .",
    "NOVELTY"
  ],
  [
    "I think it is an interesting idea",
    "NOVELTY"
  ],
  [
    "The idea is an interesting one",
    "NOVELTY"
  ],
  [
    "This idea is elegant .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper is an interesting contribution to the community .",
    "NOVELTY"
  ],
  [
    "It tells the community something new .",
    "NOVELTY"
  ],
  [
    "This work provides a novel way to use both labeled and unlabeled data at training time .",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper provides a novel methodology that adds value over previous methods .",
    "NOVELTY"
  ],
  [
    "My major concern is that it isn \u2019 t new in general .",
    "NOVELTY"
  ],
  [
    "The analysis of the minimax objective is novel and the proof technique introduces several interesting ideas .",
    "NOVELTY"
  ],
  [
    "Nevertheless , I do think there are some interesting ideas theoretically and algorithmically .",
    "NOVELTY"
  ],
  [
    "the main contributions are clear . I believe that the idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "In general i find the paper interesting , with nice ideas and I believe that will be appreciated from researchers that are interested on smooth games and their connections to machine learning applications",
    "NOVELTY"
  ],
  [
    "receptive fields of a neuron had already been used by other works before which the authors cite",
    "NOVELTY"
  ],
  [
    "that in my opinion , is a simple and interesting idea",
    "NOVELTY"
  ],
  [
    "I like the idea of using Bayesian inference to obtain estimated ground truth for deciding how to set the payments",
    "NOVELTY"
  ],
  [
    "the contributions are very different",
    "NOVELTY"
  ],
  [
    "In general I think this paper is a strong contribution",
    "NOVELTY"
  ],
  [
    "The work gives a technique with novel provable guarantees .",
    "NOVELTY"
  ],
  [
    "The overall idea presented in the paper is quite nice :",
    "NOVELTY"
  ],
  [
    "Novel method to generate adversarial examples .",
    "NOVELTY"
  ],
  [
    "The idea of using the magnitude of the gradient as an exploration signal is not new",
    "NOVELTY"
  ],
  [
    "The overall technical contribution is incremental and may not have enough novelty to be published in ICLR .",
    "NOVELTY"
  ],
  [
    "Although the paper contains interesting ideas and empirical results",
    "NOVELTY"
  ],
  [
    "The results are original ,",
    "NOVELTY"
  ],
  [
    "but not particularly surprising or timely .",
    "NOVELTY"
  ],
  [
    "the novel concentration bound could be of interest on its own",
    "NOVELTY"
  ],
  [
    "There is nothing new with the intrinsically motivated selection of goals here",
    "NOVELTY"
  ],
  [
    "Novel as far as I could tell .",
    "NOVELTY"
  ],
  [
    "This seems to be very novel and of great theoretical interest",
    "NOVELTY"
  ],
  [
    "Beside this result , the rest of the paper is incremental , as the link between convergence rate and the projection of the desired outputs on the information space was already made in Jacot 2018 NB",
    "NOVELTY"
  ],
  [
    "the contributions are weak and unclear .",
    "NOVELTY"
  ],
  [
    "However , the resulting model is quite like a combination of the existing advances and the",
    "NOVELTY"
  ],
  [
    "Overall , I believe the contributions listed above are valuable , novel and worth publishing .",
    "NOVELTY"
  ],
  [
    "Each way that the proposed framework generalizes previous work is , in my opinion , relatively incremental .",
    "NOVELTY"
  ],
  [
    "The dynamic database setting",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is new .",
    "NOVELTY"
  ],
  [
    "This paper improves the previous rate for log-concave sampling and provides new ideas for designing new sampling algorithms .",
    "NOVELTY"
  ],
  [
    "the introduced method to visualize attention effects of the joint representation is interesting and seems effective",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel two stage scheme for semantic segmentation . In the first stage , a sub-network predicts the initial rough segmentation results which are the seed of the second stage . In the second stage , another sub-network estimates the similarities between the pixels based on their multi-level features . Finally , cascaded random walk is performed to update the results . The evaluations on Pascal VOC 2012 and Pascal Context validate the effectiveness of the proposed method combined with Deeplab v2 . The novelty of the proposed method is sufficient",
    "NOVELTY"
  ],
  [
    "Compared to existing networks that incorporate crf and random walk , the proposed method seems still unique",
    "NOVELTY"
  ],
  [
    "The findings seem conceptually similar to the older sparse coding ideas from the visual cortex",
    "NOVELTY"
  ],
  [
    "Problem setting , proposed algorithms and obtained their regret upper bounds look new .",
    "NOVELTY"
  ],
  [
    "The sampling framework seems novel .",
    "NOVELTY"
  ],
  [
    "and has a significant amount of novelty both in terms of",
    "NOVELTY"
  ],
  [
    "The setup of the paper is is interesting",
    "NOVELTY"
  ],
  [
    "While the ideas in this paper are innovative and exciting",
    "NOVELTY"
  ],
  [
    "My main concern on this work is its novelty seems to be limited .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and different from established approaches to segmentation .",
    "NOVELTY"
  ],
  [
    "The idea of the paper to analyze an idealized execution of the EM algorithm , by using the true Q function , instead of the one obtained by sample average is quite novel .",
    "NOVELTY"
  ],
  [
    "The idea is very original and I found the paper very creative .",
    "NOVELTY"
  ],
  [
    "The combination of a hedging algorithm with BO is not new .",
    "NOVELTY"
  ],
  [
    "Their idea for incorporating invariance in Gaussian processes in original and novel .",
    "NOVELTY"
  ],
  [
    "it is a good submission with significant contributions to the field",
    "NOVELTY"
  ],
  [
    "I believe the contribution may not be sufficient for a publication at ICLR",
    "NOVELTY"
  ],
  [
    "This is an interesting extension to standard attention mechanism which can be used in other applications as well .",
    "NOVELTY"
  ],
  [
    "The paper has novel models for neural language modeling and some interesting messages .",
    "NOVELTY"
  ],
  [
    "The discussion on the Hoyer measure is inspiring",
    "NOVELTY"
  ],
  [
    "`` The paper fails to demonstrate convincingly that universality",
    "NOVELTY"
  ],
  [
    "I like this general unifying framework and the insight it provides .",
    "NOVELTY"
  ],
  [
    "The theoretical analysis is not brand new .",
    "NOVELTY"
  ],
  [
    "I really like the idea of this paper - it is definitely novel and worth pursuing",
    "NOVELTY"
  ],
  [
    "Although the ideas of 1",
    "NOVELTY"
  ],
  [
    "explaining ResNets using ODE/PDE and 3 ) adding noise to architectures [ 1,2 ] , ares not new",
    "NOVELTY"
  ],
  [
    "to my knowledge this is the first paper that connects PDE-based theory with adversarial robustness",
    "NOVELTY"
  ],
  [
    "The algorithm itself does not seem too novel , as using ensemble and adding noise are separated presented by some other papers .",
    "NOVELTY"
  ],
  [
    "The paper offers an interesting , original notion of envy-free fairness that is well-studied in other disciplines such as sociology , psychology and economics , and applying it to machine learning .",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u009dConstruct tilings from a set of isometries that is not a group.\u00e2\u0080\u009d This is an interesting idea",
    "NOVELTY"
  ],
  [
    "Moreover the contribution -- adding soft labeling to TapNet -- seems modest .",
    "NOVELTY"
  ],
  [
    "The proposed cost function is novel in its design",
    "NOVELTY"
  ],
  [
    "Giving all layers of the decoder access to corresponding layers in the encoder does not seem novel , at least in the way it is phrased at various points throughout the paper",
    "NOVELTY"
  ],
  [
    "it seemed like an incremental change to Transformers",
    "NOVELTY"
  ],
  [
    "I am worried about the novelty of this paper .",
    "NOVELTY"
  ],
  [
    "it is interesting and includes the original result",
    "NOVELTY"
  ],
  [
    "there is nothing groundbreaking in this study . As acknowledged by the authors , the results are not all that novel in light of recent work that has already shown that one could conduct adversarial attacks by corrupting a single pixel as well as work that has shown that CNNs do not generalize to noise degradations they have not seen",
    "NOVELTY"
  ],
  [
    "Moreover , to the best of my knowledge , it is the first time that I see a large-scale empirical evaluation of uncertainty calibration methods",
    "NOVELTY"
  ],
  [
    "to Bayesian deep learning methods",
    "NOVELTY"
  ],
  [
    "I believe it is a totally novel analysis .",
    "NOVELTY"
  ],
  [
    "Weakness The proposed method , including the architecture and training strategy , is relatively simple and very closely related to existing approach .",
    "NOVELTY"
  ],
  [
    ", I find the self-distillation algorithm very interesting and it 's nice that it can achieve zero l_2 loss w.r.t the correct labels",
    "NOVELTY"
  ],
  [
    "In particular , the concept of AIR is nothing new and its connection to NTK top eigenspace has already been written in previous work",
    "NOVELTY"
  ],
  [
    "The key problem being solved is novel and interesting to me . It seems to be the first work trying to deal with totally unpaired \u00e2\u0080\u0098multi-modal\u00e2\u0080\u0099 data without any other constraints to my best of knowledge",
    "NOVELTY"
  ],
  [
    "The paper makes a certain contribution to existing Laplace approximations for the task in terms of accuracy and scalability .",
    "NOVELTY"
  ],
  [
    "However , it is incremental and the novelty is a bit low , compared to many recent closely related works",
    "NOVELTY"
  ],
  [
    "The proposed algorithms are novel .",
    "NOVELTY"
  ],
  [
    "This alone seems like an excellent contribution and a step towards faster linear algebra primitives via the modern optimization toolbox .",
    "NOVELTY"
  ],
  [
    "proposed idea of using probabilistic generative models for lossy image compression is very interesting",
    "NOVELTY"
  ],
  [
    "The two similarity scores are not too novel",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "however the contribution is very marginal .",
    "NOVELTY"
  ],
  [
    "1 .The originality of this paper is not much .",
    "NOVELTY"
  ],
  [
    "Both of the ideas are not very original .",
    "NOVELTY"
  ],
  [
    ", the paper presents a very interesting ideas",
    "NOVELTY"
  ],
  [
    "already uses this concept which makes it unclear what this paper adds",
    "NOVELTY"
  ],
  [
    "the method combines existing approaches together with a novel unsupervised loss .",
    "NOVELTY"
  ],
  [
    "While memory augmented RNNs and RNNs with attention mechanisms are not new , some of these architectures had not yet been applied to language modeling .",
    "NOVELTY"
  ],
  [
    "I \u2019 m not sure about the novelty of the proposed n-gram RNN because I recall seeing similar architectures before but I understand that novelty was not the point of that architecture as it mainly serves as a proof of the lack of ability of the more complicated architectures to do better",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel formulation of the problem of finding hidden units that are crucial in making a neural network come up with a certain output .",
    "NOVELTY"
  ],
  [
    "Quality The idea explored in the paper is interesting",
    "NOVELTY"
  ],
  [
    "Originality This approach to finding important hidden units is novel .",
    "NOVELTY"
  ],
  [
    "Novel neural network architectures used with counterfactual generator and counterfactual discriminator are interesting and these can be extended to other tasks",
    "NOVELTY"
  ],
  [
    "Is there sufficient novelty in what they propose",
    "NOVELTY"
  ],
  [
    "this paper falls under incremental improvement as it improves GANITE framework to solve dose-response estimation . As authors use GAN for counterfactual estimation which is not novel ( GANITE ) and estimating dose-response estimation is not novel (",
    "NOVELTY"
  ],
  [
    "In my opinion , there is little original contribution in this paper .",
    "NOVELTY"
  ],
  [
    "Given that there is ( in my opinion ) no new methodology in the paper , I would n't consider this paper a significant contribution .",
    "NOVELTY"
  ],
  [
    "No original contribution .",
    "NOVELTY"
  ],
  [
    "The work is original .",
    "NOVELTY"
  ],
  [
    "The idea of dual-module is interesting and wise .",
    "NOVELTY"
  ],
  [
    "I would say the technical novelty is incremental since the extension is straightforward and similar to previous work .",
    "NOVELTY"
  ],
  [
    "the proposed recovery algorithms are all classical ones , and it is unclear how novel the analysis is",
    "NOVELTY"
  ],
  [
    "The paper is rather incremental , however , still interesting .",
    "NOVELTY"
  ],
  [
    "The applications to Multilingual machine translation and fairness applications are to the best of the knowledge of the reviewer new in this context and are interesting .",
    "NOVELTY"
  ],
  [
    "Overall the authors make a nice contribution . The insight of defining rho to be the stationary distribution of the Markov chain P^pi and connecting this to eq ( 1 ) is interesting . Also the definition of the reward function on p.7 in terms of the distance between phi",
    "NOVELTY"
  ],
  [
    "t+1 } ) and phi ( z_g ) looks original .",
    "NOVELTY"
  ],
  [
    "combination of functions with both bounded submodularity ratio and additive noise",
    "NOVELTY"
  ],
  [
    "This work shows a new data generation method , part-level identity shuf\u00ef\u00ac\u0082ing technique .",
    "NOVELTY"
  ],
  [
    "learning disentangled representation is not a new method in person reID field .",
    "NOVELTY"
  ],
  [
    "The main contribution of this paper , disentangled representation , is similar to previous works .",
    "NOVELTY"
  ],
  [
    "somewhat artificial",
    "NOVELTY"
  ],
  [
    "and this paper discusses a new way to",
    "NOVELTY"
  ],
  [
    "To my knowledge the proposed word-level discriminator and channel-wise attention are novel .",
    "NOVELTY"
  ],
  [
    "On the whole , I am very impressed with this work .",
    "NOVELTY"
  ],
  [
    "Very good .",
    "NOVELTY"
  ],
  [
    "Interesting use of constructed triplets",
    "NOVELTY"
  ],
  [
    "2 .The theory addresses two widely recognized problems as if they 're novel",
    "NOVELTY"
  ],
  [
    "This work is interesting as it is the first streaming algorithm for robust submodular maximization .",
    "NOVELTY"
  ],
  [
    "this work is very enlightening",
    "NOVELTY"
  ],
  [
    "To the best of our knowledge , this is the first paper that showed the effectiveness of deep structures in citation network datasets",
    "NOVELTY"
  ],
  [
    "I would like to judge the contribution of this paper is sufficiently significant to accept",
    "NOVELTY"
  ],
  [
    "The approach is novel to my knowledge , the paper",
    "NOVELTY"
  ],
  [
    "I find the paper very inspiring",
    "NOVELTY"
  ],
  [
    "is not really novel but it does n't seem other papers have done this before so it 's nice to know it works well",
    "NOVELTY"
  ],
  [
    "Prior work has already done that",
    "NOVELTY"
  ],
  [
    "However the result is not particularly surprising or insightful ,",
    "NOVELTY"
  ],
  [
    "The paper has several novel contributions on tabular data representation learning and generative modeling .",
    "NOVELTY"
  ],
  [
    "The model itself is also not particularly novel and the work currently misses some",
    "NOVELTY"
  ],
  [
    "I find the overall contribution incremental given the work of Mathias et al . ( 2018 ) .",
    "NOVELTY"
  ],
  [
    "Overall , I find the idea of stability training interesting .",
    "NOVELTY"
  ],
  [
    "while I think the paper contains interesting ideas",
    "NOVELTY"
  ],
  [
    "I find the current evaluation lacking",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is new",
    "NOVELTY"
  ],
  [
    "Pros 1 .It is new to apply quadrature rules to improve kernel approximation .",
    "NOVELTY"
  ],
  [
    "it is basically an improvement of the bounds in C. De Sa et al 's work , and thus not very novel in my opinion .",
    "NOVELTY"
  ],
  [
    "the results are not surprising and from my point of view , the overall novelty of this paper is a bit marginal for top-tier conference like ICLR .",
    "NOVELTY"
  ],
  [
    "Overall I think the idea is interesting .",
    "NOVELTY"
  ],
  [
    "I think this paper makes a valuable contribution to the theoretical literature on DDMs",
    "NOVELTY"
  ],
  [
    "The idea of cycle consistency is not novel since it has been already shown to be effective in addressing data with multiple modalities in the supervised setting",
    "NOVELTY"
  ],
  [
    "this work is the first trial to use this idea to solve the unpaired data clustering problem",
    "NOVELTY"
  ],
  [
    "our community could benefit from such a novel task which will bring forth\u00c2 various innovative work",
    "NOVELTY"
  ],
  [
    "Due to this , the scientific contribution to the corresponding community is highly limited to providing empirical results on the CTR task .",
    "NOVELTY"
  ],
  [
    "This work fairly lacks its originality since the proposing method heavily relies on the two previous works , self-attention and top-k restriction",
    "NOVELTY"
  ],
  [
    "however , their application seems to be monotonic without a novel idea of task-specific adaptation .",
    "NOVELTY"
  ],
  [
    "The novelty is minimal and the problem is of interest only",
    "NOVELTY"
  ],
  [
    "and so using this idea in itself is not real contribution",
    "NOVELTY"
  ],
  [
    "then using imitation learning in this setting is really not novel",
    "NOVELTY"
  ],
  [
    "So it 's impossible to know whether there is any new insight here Experimental Evaluation",
    "NOVELTY"
  ],
  [
    "Very minor contribution , a manuscript that is lacking important details and does not relate it 's technical section to existing work",
    "NOVELTY"
  ],
  [
    "I am not sure if this is novel ,",
    "NOVELTY"
  ],
  [
    "In general the novelty of this paper seems low",
    "NOVELTY"
  ],
  [
    "This is the first worst-case analysis for RLSVI and even though it might not yield novel insights beyond the analysis itself , is an important technical contribution . The proof relies to large parts on existing strategies",
    "NOVELTY"
  ],
  [
    "but contains novel technical insights such as lemma 5",
    "NOVELTY"
  ],
  [
    "The HiBO",
    "NOVELTY"
  ],
  [
    "The proposed MUL framework is novel and interesting to my knowledge .",
    "NOVELTY"
  ],
  [
    "To my knowledge , however , the explicit formulation of MUL is novel",
    "NOVELTY"
  ],
  [
    "and its novelty is significant",
    "NOVELTY"
  ],
  [
    "and the proposed method is novel for unsupervised domain adaptation .",
    "NOVELTY"
  ],
  [
    "importantly , limited technical contribution",
    "NOVELTY"
  ],
  [
    "I 'm not quite as convinced this makes a great contribution to",
    "NOVELTY"
  ],
  [
    "I think it likely advances a new and interesting theory that could inspire further empirical research",
    "NOVELTY"
  ],
  [
    "so has both novelty and merit for perception sciences .",
    "NOVELTY"
  ],
  [
    "Originality The authors provide an accessible , yet innovative framework to link conformity and theory of mind processes in collective decision making quite elegantly .",
    "NOVELTY"
  ],
  [
    "Overall , the ideas presented in the paper are intriguing",
    "NOVELTY"
  ],
  [
    "The structural coherence property established in the paper is new as far as I can see and I can see that it could be a useful contribution to the literature .",
    "NOVELTY"
  ],
  [
    "The proof techniques , mainly the Mendelson small ball property with some convex analysis are appropriate",
    "NOVELTY"
  ],
  [
    "but not novel",
    "NOVELTY"
  ],
  [
    "This is a good idea",
    "NOVELTY"
  ],
  [
    "The proposed approach is a simple combination of existing approaches",
    "NOVELTY"
  ],
  [
    "The analyses are novel and",
    "NOVELTY"
  ],
  [
    "My main concern is that I find the contribution of this paper a bit weak for NIPS .",
    "NOVELTY"
  ],
  [
    "I find this to limit the contributions of this submission",
    "NOVELTY"
  ],
  [
    "However , the proposed method does not seem to be of great originality , essentially defining a network that directly outputs 3D points and pose .",
    "NOVELTY"
  ],
  [
    "but currently the paper fails to convince me of the novelty of the",
    "NOVELTY"
  ],
  [
    "Pros and Cons To the best of my knowledge , the result is novel",
    "NOVELTY"
  ],
  [
    "2 .As per my knowledge , this is the first work which replaces non-linear functions in reversible normalizing flow model with GNN model .",
    "NOVELTY"
  ],
  [
    "several defences are based on a similar principle and the contributions of this paper are unclear .",
    "NOVELTY"
  ],
  [
    "As potential criticism , the technical contributions of the paper are scarce .",
    "NOVELTY"
  ],
  [
    "given that fairness is a pretty novel topic in the machine learning ( ML ) community , I believe that simple ideas/approaches as the one presented in the paper are of general interest and minimize the gap between theoretical and practical aspects",
    "NOVELTY"
  ],
  [
    "The paper is an empirical paper and is presenting a quantitive study of role of texture which others have already presented like Gatys et al .2017 .The paper itself has no novel contributions .",
    "NOVELTY"
  ],
  [
    "I find that the paper contributions are incremental and do not offer sufficient experimental results .",
    "NOVELTY"
  ],
  [
    "I have concerns about the novelty of the paper",
    "NOVELTY"
  ],
  [
    "The idea appears to be somewhat novel considering that majority of existing methods consider randomize inputs or the model itself",
    "NOVELTY"
  ],
  [
    "The proposed network and the methods are interesting ,",
    "NOVELTY"
  ],
  [
    "with",
    "NOVELTY"
  ],
  [
    "I agree with other reviewers that the work is interesting and novel",
    "NOVELTY"
  ],
  [
    "I think that the paper presents a neat idea -- feedback connections are too often ignored in computational models of the nervous system",
    "NOVELTY"
  ],
  [
    "While this is interesting , I do not see any conceptual novelty .",
    "NOVELTY"
  ],
  [
    "and the field of study is a promising approach to RL .",
    "NOVELTY"
  ],
  [
    "The formulation of AdaGain is very reminiscent of the SGA algorithm in Kushner & Yin ( 2003 ) , and more generally gradient descent optimization of the learning rate is not new .",
    "NOVELTY"
  ],
  [
    ", very interesting approach and ideas Conceptually simple",
    "NOVELTY"
  ],
  [
    "Although the innovation is relatively incremental",
    "NOVELTY"
  ],
  [
    "representations",
    "NOVELTY"
  ],
  [
    "The technical contribution is thorough",
    "NOVELTY"
  ],
  [
    "To me , the results of the paper seems incremental -- the authors apply an existing representation method to graphs",
    "NOVELTY"
  ],
  [
    "The ideas are not original , since people already use constant minibatch for practical problem .",
    "NOVELTY"
  ],
  [
    "novel method for adaptively using either the MC method for policy evaluation or the temporal difference method",
    "NOVELTY"
  ],
  [
    "the method is , to my knowledge , original and from the numerical experiments seems to achieve the target the authors set for it",
    "NOVELTY"
  ],
  [
    "I like the idea of using confidence intervals on the MC estimate to figure out whether or not the TD estimate is reliable . To my knowledge , this is original and makes a lot of sense .",
    "NOVELTY"
  ],
  [
    "The paper is a solid contribution",
    "NOVELTY"
  ],
  [
    "In this sense , the main idea of this work is incrementally novel .",
    "NOVELTY"
  ],
  [
    "Given the moderate novelty",
    "NOVELTY"
  ],
  [
    "a standalone reason to accept this paper",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "the reviewer feels that this paper starts with an interesting idea",
    "NOVELTY"
  ],
  [
    "but the developments on the theoretical side is a bit thin .",
    "NOVELTY"
  ],
  [
    "an interesting model which is quite intriguing in its simplicity .",
    "NOVELTY"
  ],
  [
    "is incremental",
    "NOVELTY"
  ],
  [
    "Overall I think that the paper makes an interesting contribution . I find very interesting the idea of performing inference on the set of unobserved components in the latent space .",
    "NOVELTY"
  ],
  [
    "Overall , the approach is not very innovative",
    "NOVELTY"
  ],
  [
    "While the paper makes some novel theoretical contributions",
    "NOVELTY"
  ],
  [
    "The idea of combining non-parametric density estimators with GANs is interesting and underexplored .",
    "NOVELTY"
  ],
  [
    "The visualizations are interesting and provide some general intuition",
    "NOVELTY"
  ],
  [
    "but they do n't yield any clear novel insights that could be used in practice .",
    "NOVELTY"
  ],
  [
    "This is high novelty work , and",
    "NOVELTY"
  ],
  [
    "and the approach taken is interesting",
    "NOVELTY"
  ],
  [
    "This work shows significant improvements over the state of the art in few-shot classification which is an important contribution",
    "NOVELTY"
  ],
  [
    "The simple inductive bias presented in the paper for disentangling local and global information is very interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the paper has a novel idea which is well motivated",
    "NOVELTY"
  ],
  [
    "The most severe issue is lacking novelty . It is a straightforward combination of existing work , therefore , the contribution of this work is rare .",
    "NOVELTY"
  ],
  [
    "Therefore , from this perspective , this study is incremental rather than innovative . However",
    "NOVELTY"
  ],
  [
    ", the core idea of the proposed method , that is , combining the word representation , sub-graph state , incoming and outgoing representations seems to be novel .",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea of utilizing sub-graphs for simplicity and saving the computational cost to encode a structural ( grammatical or semantic ) information .",
    "NOVELTY"
  ],
  [
    "I 'm not sure if it brings anything drastically new to survival analysis",
    "NOVELTY"
  ],
  [
    "The way to decompose a risk into latent causes seems especially interesting contribution",
    "NOVELTY"
  ],
  [
    "This seems an interesting contribution for competing risks analysis and the author seem to acknowledge the main concerns of the reviewers in their response",
    "NOVELTY"
  ],
  [
    "Overall , the paper provides limited technical novelty .",
    "NOVELTY"
  ],
  [
    "2 .BlockDrop seems to introduce a general framework of policy network to prune neural networks",
    "NOVELTY"
  ],
  [
    "Overall , I liked the ideas presented in the paper .",
    "NOVELTY"
  ],
  [
    "The contribution is a fresh perspective on approximating value functions ,",
    "NOVELTY"
  ],
  [
    "The technical contribution is interesting but given that this field of flows in probability space is still not very well spread in the ML community",
    "NOVELTY"
  ],
  [
    "and I do not feel the paper offers new insights which the ICLR community in general would benefit from .",
    "NOVELTY"
  ],
  [
    "but the mathematical relationships investigated in the paper are illuminating",
    "NOVELTY"
  ],
  [
    "Overall , the contribution is modest at best .",
    "NOVELTY"
  ],
  [
    "The idea of using the reversal Markov chain and related results ( although simple ) are novel , as far as I know",
    "NOVELTY"
  ],
  [
    "Overall this papers contains novel ideas",
    "NOVELTY"
  ],
  [
    "While there are some similar approaches ( as described in the related work ) , the proposed variant appears novel ,",
    "NOVELTY"
  ],
  [
    "this appears to be a reasonable , if somewhat incremental , contribution to the recommendation community",
    "NOVELTY"
  ],
  [
    "The paper includes several theoretical results , and introduces a novel 'clipping ' trick used to prove the bounds .",
    "NOVELTY"
  ],
  [
    "I like how this paper formalizes failure in representation learning as information loss in z",
    "NOVELTY"
  ],
  [
    "-- -although the formulation is not particularly novel",
    "NOVELTY"
  ],
  [
    "timely , and interesting",
    "NOVELTY"
  ],
  [
    "The method , using GANs to map low confidence examples to high confidence examples of the same class is highly original and shows promise as an effective method .",
    "NOVELTY"
  ],
  [
    "containing innovative elements",
    "NOVELTY"
  ],
  [
    "I like the idea of designing more sophisticated ways to encourage more exploration over the samples that the model is not good at .",
    "NOVELTY"
  ],
  [
    "The general idea of connecting network parameters such as depth , width , and sparsity to classical function spaces is interesting and could lead to novel insights into how and why these networks work and under what settings .",
    "NOVELTY"
  ],
  [
    "paper with a novel ( afaik ) model achieving",
    "NOVELTY"
  ],
  [
    "The parsing model is intriguing .",
    "NOVELTY"
  ],
  [
    "the work as a whole is not very original . The method proposed of using a sparsity schedule to perform pruning is simple and effective , but is a rather incremental contribution .",
    "NOVELTY"
  ],
  [
    "The paper makes a nice contribution ,",
    "NOVELTY"
  ],
  [
    "though it is not particularly significant or surprising .",
    "NOVELTY"
  ],
  [
    "Methodological contributions are minor .",
    "NOVELTY"
  ],
  [
    "the extension of using GNN is indeed natural and straightforward compared with ( Brock et al .2018 ) .Towards that end , the contribution and novelty of the paper is largely marginal and not impressive .",
    "NOVELTY"
  ],
  [
    "The problem formulation is new and interesting",
    "NOVELTY"
  ],
  [
    "The core observation of extreme learning rates and the proposal of clipping the updates is not novel",
    "NOVELTY"
  ],
  [
    "the model is a mix of many components",
    "NOVELTY"
  ],
  [
    "While not the first model to try to handle modeling data with missing features , it is still a fairly original and elegant formulation .",
    "NOVELTY"
  ],
  [
    "The novelty of this submission seems a little limited .",
    "NOVELTY"
  ],
  [
    "The model brings no novelty , or to put it bluntly , it is rather simplistic .",
    "NOVELTY"
  ],
  [
    "In contrast to the thin experiments and ( lack of ) technical novelty",
    "NOVELTY"
  ],
  [
    "are overdrawn and uninteresting",
    "NOVELTY"
  ],
  [
    "I agree with the other reviewers that the theorems in this paper are interesting .",
    "NOVELTY"
  ],
  [
    "etc can be represented in the framework is distracting and makes it seem less novel than it is",
    "NOVELTY"
  ],
  [
    "an interesting idea of co-training gbdts with nns",
    "NOVELTY"
  ],
  [
    "The idea is not new ,",
    "NOVELTY"
  ],
  [
    "but discarding backprop and using target propagation , that allows gbdts to do what they are best for - e.g .build trees to simulate gradients - is neat and witty .",
    "NOVELTY"
  ],
  [
    "The idea of showing low rank structure which makes it possible to use second-order information without approximations is interesting .",
    "NOVELTY"
  ],
  [
    "I do like the idea of the paper",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the paper is the first to introduce an *exact* coreset/sketch construction for linear regression problems ( i.e .there is no loss in quality by using the coreset/sketch instead of the original input data ) .",
    "NOVELTY"
  ],
  [
    "this contribution is insufficient to be considered as a technical contribution .",
    "NOVELTY"
  ],
  [
    "Even though the idea is interesting",
    "NOVELTY"
  ],
  [
    "While simple , the method is to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "To conclude , the suggested approach is not novel",
    "NOVELTY"
  ],
  [
    "the approach is novel .",
    "NOVELTY"
  ],
  [
    "There seem to be two main contributions in the paper .",
    "NOVELTY"
  ],
  [
    "Both approaches seem to be interesting .",
    "NOVELTY"
  ],
  [
    "While limited novelty is found in the methodology/engineering - novelty being mainly related to the affine transfer mechanism",
    "NOVELTY"
  ],
  [
    "I am not sure what is the novelty compared to",
    "NOVELTY"
  ],
  [
    "I have concerns about the novelty of this method",
    "NOVELTY"
  ],
  [
    "This is not the first paper to",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , it presents novel counter examples and theoretical results , these results being obtained using conductance type techniques .",
    "NOVELTY"
  ],
  [
    ", this is overall an interesting contribution .",
    "NOVELTY"
  ],
  [
    "I assume this work is novel",
    "NOVELTY"
  ],
  [
    "I found no original contributions on this part from the authors",
    "NOVELTY"
  ],
  [
    "I agree that the paper seems intuitive and it",
    "NOVELTY"
  ],
  [
    "makes incremental contributions",
    "NOVELTY"
  ],
  [
    "rather",
    "NOVELTY"
  ],
  [
    "However , it seems that it is indeed novel and given rather",
    "NOVELTY"
  ],
  [
    "While the main advantage of the contribution",
    "NOVELTY"
  ],
  [
    "The idea is very novel .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the final performance is state-of-the-art on all the important benchmarks .",
    "NOVELTY"
  ],
  [
    "-- and I find them interesting",
    "NOVELTY"
  ],
  [
    "Overall I was impressed by the volume of contributions presented throughout the paper and also I very muched like the light shed on important classes of models that turn out to be not as black box as they could seem",
    "NOVELTY"
  ],
  [
    "Section 5 is a strong and original bit , it seems .",
    "NOVELTY"
  ],
  [
    "I find both of these innovations novel .",
    "NOVELTY"
  ],
  [
    "Natural , novel extension to gradient-based meta-learning",
    "NOVELTY"
  ],
  [
    "The latter technique has been used in other RL papers before",
    "NOVELTY"
  ],
  [
    "but to my knowledge has not been applied to this specific problem",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "I found this to be an interesting approach to hierarchical multitask learning , augmenting a previous approach with several steps leading to increased autonomy , an essential agent for any learning agent . Both the intuition behind the construction and the application to test problem reveal novel insight .",
    "NOVELTY"
  ],
  [
    "While",
    "NOVELTY"
  ],
  [
    "the novelty is not especially high",
    "NOVELTY"
  ],
  [
    "There 's a nice application of powerful existing models , combined and tailored to the current work .",
    "NOVELTY"
  ],
  [
    "introduces some nice tricks",
    "NOVELTY"
  ],
  [
    "The `` analogical decoder `` idea is really nice .",
    "NOVELTY"
  ],
  [
    "I really liked the idea of using an oracle that gives the position as upper bound .",
    "NOVELTY"
  ],
  [
    "I am afraid that the novelty and insight of this work is not good enough for acceptance .",
    "NOVELTY"
  ],
  [
    "1 The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "trace minimization is already well explored and this paper provides little insight .",
    "NOVELTY"
  ],
  [
    "The exact mechanism through which this paper operates is novel",
    "NOVELTY"
  ],
  [
    "== Originality == The main contribution of the paper is a novel idea ( to my knowledge ) . Speficially , the self-validation module proposed to combine and update location and class labels is very interesting , and is more original than the typical combination of different task-specific architectures to get a new result .",
    "NOVELTY"
  ],
  [
    "I found the idea of traversing a parse tree of a formula top-down and converting it to a vector very interesting .",
    "NOVELTY"
  ],
  [
    "I am not convinced that this theory is yet",
    "NOVELTY"
  ],
  [
    "or is superior to some other data-dependent analysis",
    "NOVELTY"
  ],
  [
    "It 's quite a nice idea to bring this finding from human decision-making to machine learning .",
    "NOVELTY"
  ],
  [
    "Overall , I really like the high-level idea",
    "NOVELTY"
  ],
  [
    "Nice introduction to Fourier analysis providing non-trivial insights of ReLU networks .",
    "NOVELTY"
  ],
  [
    "an interesting algorithm and direction",
    "NOVELTY"
  ],
  [
    "of NN in tabular data learning .",
    "NOVELTY"
  ],
  [
    "The technical contribution is incremental .",
    "NOVELTY"
  ],
  [
    "I found the formulation quite similar with dlADMM ( Wang et al . ( 2019 ) ) , the contribution is incremental",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , the idea is novel .",
    "NOVELTY"
  ],
  [
    "this paper shows good ideas",
    "NOVELTY"
  ],
  [
    "The idea in this paper is quite original . The three principles used to formulate the loss function provide some new insights .",
    "NOVELTY"
  ],
  [
    "Overall , I think the idea in this paper is interesting .",
    "NOVELTY"
  ],
  [
    "The contributions are not significant .",
    "NOVELTY"
  ],
  [
    "but the contributions of this paper compared to TLSTM are not significant enough for acceptance , and",
    "NOVELTY"
  ],
  [
    "I think there are a lot of novel and interesting ideas in this paper though they have not been fully explored",
    "NOVELTY"
  ],
  [
    "The use of the absolute value transfer function is new to me",
    "NOVELTY"
  ],
  [
    "Although the proposed method is not significantly novel , nor very sophisticated",
    "NOVELTY"
  ],
  [
    "the paper is contributing to the domain by expliciting an idea that have not been very much exploited so far",
    "NOVELTY"
  ],
  [
    "and the result is new",
    "NOVELTY"
  ],
  [
    "The problem is interesting and novel",
    "NOVELTY"
  ],
  [
    "this paper are very strong --",
    "NOVELTY"
  ],
  [
    "The theoretical results on single and multitask learning in classification networks are novel",
    "NOVELTY"
  ],
  [
    "as in previous literature the focus was mainly on regression networks",
    "NOVELTY"
  ],
  [
    "The key analysis are although inspired by [ 16 ] but tackling the cross entropy",
    "NOVELTY"
  ],
  [
    "loss function in this setting is original .",
    "NOVELTY"
  ],
  [
    "so in this sense , the framework proposed by the authors is different and original .",
    "NOVELTY"
  ],
  [
    "I found this paper quite interesting and I think the contribution is quite original and appealing to the community .",
    "NOVELTY"
  ],
  [
    "There are potentially interesting ideas in this paper .",
    "NOVELTY"
  ],
  [
    "The method is simple but novel .",
    "NOVELTY"
  ],
  [
    "PROS AND CONS Interesting idea for learning quickly from small numbers of samples of expert state trajectories .",
    "NOVELTY"
  ],
  [
    "I do n't think the model presented here is very novel",
    "NOVELTY"
  ],
  [
    "the algorithm appears non-trivial and innovative",
    "NOVELTY"
  ],
  [
    "Overall this seems like the first approach of using Bayesian learning in order to reach mixed Nash equilibrium in RL .",
    "NOVELTY"
  ],
  [
    "As this work does not introduce new theory or a dramatic new concept",
    "NOVELTY"
  ],
  [
    "a novel method",
    "NOVELTY"
  ],
  [
    "I have several concerns about whether this contribution is significant enough : Random smoothing has been studied extensively recently and the proof technique in this paper is not so different from previous papers",
    "NOVELTY"
  ],
  [
    "the paper seems to be a bit incremental .",
    "NOVELTY"
  ],
  [
    "Although there are interesting components in this paper , I do agree that the paper is incremental given that many random smoothing methods have been proposed recently for L2 , L_infty norms .",
    "NOVELTY"
  ],
  [
    "This is a new take on the classical field of BOED and conceptionally interesting .",
    "NOVELTY"
  ],
  [
    "The idea of the alternating minimization algorithm is not new .",
    "NOVELTY"
  ],
  [
    "in terms of both the writing and technical novelty",
    "NOVELTY"
  ],
  [
    "I would n't say this paper proposed a groundbreaking innovation",
    "NOVELTY"
  ],
  [
    "this paper presented a very natural extension to something practitioners were already very familiar with : taking an average of word vectors for a sentence and measure by cosine similarity .",
    "NOVELTY"
  ],
  [
    "Both max pooling and Jaccard distance are not something new",
    "NOVELTY"
  ],
  [
    "It seems that the overall idea is very similar to Kim\u00e2\u0080\u0099s paper that using very deep fully convolutional layers and residual learning for image restoration . Overall , there is some advancement made by the paper , but may be not significantly enough for a NIPS paper .",
    "NOVELTY"
  ],
  [
    "While it provides some contribution in denoising , the strategy of mixed training set has already used in Kim\u00e2\u0080\u0099s paper for different levels of super-resolution",
    "NOVELTY"
  ],
  [
    "it seems that all the ideas of this paper",
    "NOVELTY"
  ],
  [
    "are original",
    "NOVELTY"
  ],
  [
    "but actually very similar to Kim\u00e2\u0080\u0099s work",
    "NOVELTY"
  ],
  [
    "nor are they particularly novel , the paper represents a concise contribution of effective optimization strategies , broadly applicable to the emergent communication literature",
    "NOVELTY"
  ],
  [
    "Perhaps its greatest shortcoming is simply whether it meets the NeurIPS bar in terms of its novelty/technicality",
    "NOVELTY"
  ],
  [
    "and the idea of RAVE is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "but admittedly practically powerful and theoretically interesting",
    "NOVELTY"
  ],
  [
    "the paper does not make a very novel contribution",
    "NOVELTY"
  ],
  [
    "there was no theoretical contribution .",
    "NOVELTY"
  ],
  [
    "Using an architecture to learn how to split the input , find solutions , then merge these is novel .",
    "NOVELTY"
  ],
  [
    "I think the method is interesting",
    "NOVELTY"
  ],
  [
    "While",
    "NOVELTY"
  ],
  [
    "simple and the approach is not new",
    "NOVELTY"
  ],
  [
    "However , based on the previous results in Mei et al. , 2016 and Zhong et al. , 2017 , this work is incremental",
    "NOVELTY"
  ],
  [
    "and the proposed idea is novel and builds on a sound theoretical framework of Koopman operator theory .",
    "NOVELTY"
  ],
  [
    "insightful",
    "NOVELTY"
  ],
  [
    "Novel approach to regression",
    "NOVELTY"
  ],
  [
    "the paper proposes an extension of GPS , which to my knowledge is novel .",
    "NOVELTY"
  ],
  [
    "The paper proposes what seems to be a good idea",
    "NOVELTY"
  ],
  [
    "The model is not entirely new .",
    "NOVELTY"
  ],
  [
    "paper introduces a novel combination over evolutionary ( population-based training ) and value-based reinforcement learning .",
    "NOVELTY"
  ],
  [
    "and the is certainly original",
    "NOVELTY"
  ],
  [
    "the current paper contains incremental and marginal new findings versus the existing literature",
    "NOVELTY"
  ],
  [
    "In its current form the paper does not contain sufficient contributions for acceptance .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work that uses ML for wind speed prediction from flags .",
    "NOVELTY"
  ],
  [
    "From an applications perspective , this is therefore certainly a novel contribution",
    "NOVELTY"
  ],
  [
    "it provides a novel method for predicting wind speeds using commonly-available `` instrumentation . `` Second",
    "NOVELTY"
  ],
  [
    "and I do believe the dataset is one of the biggest contributions of this paper",
    "NOVELTY"
  ],
  [
    "While the paper proposes an interesting idea I have many reservations about the paper and applicability of the idea in practice prompting my score which I outline below",
    "NOVELTY"
  ],
  [
    "basic idea is neat CON",
    "NOVELTY"
  ],
  [
    "The use of XOR gates to improve quantization seems novel .",
    "NOVELTY"
  ],
  [
    "and I still think the contribution is kind of marginal ( especially given [ 1 ] )",
    "NOVELTY"
  ],
  [
    "However , the contribution of this paper is limited .",
    "NOVELTY"
  ],
  [
    "The idea of learning embeddings while learning a clustering is not novel and doing this using a deep NN is not novel either . But",
    "NOVELTY"
  ],
  [
    "incorporating an AE component is novel .",
    "NOVELTY"
  ],
  [
    "The paper has proposed a novel framework to design parameter-free algorithms .",
    "NOVELTY"
  ],
  [
    "2 .Novel objectives for a multi-agent training setup Cons",
    "NOVELTY"
  ],
  [
    "This work seems to be a solid addition to the Riemannian optimization repertoire . Both the analysis and the experiments show merits of the algorithm . The analysis is new",
    "NOVELTY"
  ],
  [
    "but considering previous work , it is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The current contribution of this paper is limited , however it could be improved in a number of ways .",
    "NOVELTY"
  ],
  [
    "the technical part is rather incremental .",
    "NOVELTY"
  ],
  [
    "The fact that additional conceptors can be trained does not appear new for the approach described here .",
    "NOVELTY"
  ],
  [
    "pretty novel",
    "NOVELTY"
  ],
  [
    "While the idea of forming such equivalence sets is very interesting",
    "NOVELTY"
  ],
  [
    "I 'm not sure anything very novel is being proposed",
    "NOVELTY"
  ],
  [
    ", and the proposed method is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel , and does a good job of handling a type of information that previous methods couldn \u2019 t .",
    "NOVELTY"
  ],
  [
    "this is a well-written paper that proposes an interesting , well-motivated , and novel method with",
    "NOVELTY"
  ],
  [
    "It seems that there is no new founding in this paper .",
    "NOVELTY"
  ],
  [
    "Building graph with RL value functions is very novel and provides a new way to model the environment and do the planning .",
    "NOVELTY"
  ],
  [
    "Combining RL and planning has already been discussed in PRM-RL~",
    "NOVELTY"
  ],
  [
    "And data programming can be an interesting approach here",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , drawing conclusions on the behavior of the agents based on these metrics is a novel approach and a good contribution .",
    "NOVELTY"
  ],
  [
    "On the reinforcement learning aspect , they propose a novel approach to describe multi-agent behaviors and use novel metrics that help both the description work and the design of new experiments .",
    "NOVELTY"
  ],
  [
    "Overall , from the perspective of deep learning , I think the paper is novel and provides some insights into different approaches to the problem .",
    "NOVELTY"
  ],
  [
    "The paper presents some novel contributions .",
    "NOVELTY"
  ],
  [
    "The paper seems to be a clever idea for speeding up minibatching methods",
    "NOVELTY"
  ],
  [
    "The work is inspiring",
    "NOVELTY"
  ],
  [
    "and having seen also the other reviews I think the paper makes a good contribution",
    "NOVELTY"
  ],
  [
    "The proof techniques are not really groundbreaking",
    "NOVELTY"
  ],
  [
    "In general I like the idea of looking further into the effect of adding network structure on the original information bottleneck",
    "NOVELTY"
  ],
  [
    "D^2 ) , which is novel",
    "NOVELTY"
  ],
  [
    "The method is interesting and elegant",
    "NOVELTY"
  ],
  [
    "it looks a bit incremental .",
    "NOVELTY"
  ],
  [
    "-W3 .The overall novelty of theory is limited .",
    "NOVELTY"
  ],
  [
    "the degree of novelty of the current theory seems fairly low given that prior work",
    "NOVELTY"
  ],
  [
    "I am still not quite convinced that the current theoretical analysis is particularly novel given the results in",
    "NOVELTY"
  ],
  [
    "The main novelties of this paper are : estimation of nonparametric probability density functions for emissions , and the fact they",
    "NOVELTY"
  ],
  [
    "linear algebra algorithm ( eg SVD",
    "NOVELTY"
  ],
  [
    "using continuous linear algebra ( quas- and continuos matrices ) .To the best of my knowledge , what I could see is that the paper seems to be the outcome of a very good job from the author ( s",
    "NOVELTY"
  ],
  [
    "As a non-expert",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "I do n't have enough background to tell if this is much of a leap from related work that has already proposed learning certain parameters of quantizers",
    "NOVELTY"
  ],
  [
    "and explores an interesting idea -- -aggregating mini-batch statistics across iterations .",
    "NOVELTY"
  ],
  [
    "Overall , while the proposed approach is novel , its performance is comparable to prior approaches , with the disadvantage of an additional computational/memory footprint",
    "NOVELTY"
  ],
  [
    "-- so are not terribly new",
    "NOVELTY"
  ],
  [
    "The proposed scheme of solving diffeomorphic registration by discretizing a variational solution similar to [ 1 ] is a novel contribution , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Scope of contributions",
    "NOVELTY"
  ],
  [
    "this work contains some novelty but lacks rigorous analysis of its proposed method",
    "NOVELTY"
  ],
  [
    "Originality This paper is fairly original as it formalises the problem of sensorimotor prediction and evaluation .",
    "NOVELTY"
  ],
  [
    "What reported in this paper seems to be interesting",
    "NOVELTY"
  ],
  [
    "The main issue is the lack of novelty .",
    "NOVELTY"
  ],
  [
    "Using CNNs to handle variable length time series is hardly novel .",
    "NOVELTY"
  ],
  [
    "Comments The algorithm is a nice application of non-negative matrix factorization ( NMF ) .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is original to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "This is a novel weakly-supervised clustering method rarely seen .",
    "NOVELTY"
  ],
  [
    "This paper presents some experiments on adversarial learning",
    "NOVELTY"
  ],
  [
    "is fixed and black-box with interesting",
    "NOVELTY"
  ],
  [
    "Augmenting the prior of VAE is not a novel contribution but I see the novelty applied to caption generation task",
    "NOVELTY"
  ],
  [
    "The unified view presented I believe is interesting",
    "NOVELTY"
  ],
  [
    "I do not find enough novelty .",
    "NOVELTY"
  ],
  [
    "This paper is original ,",
    "NOVELTY"
  ],
  [
    "The technique is incremental , and the technical contribution to multi-armed bandit research is small .",
    "NOVELTY"
  ],
  [
    "The technical novelty of the paper is incremental .",
    "NOVELTY"
  ],
  [
    "The new technical contribution to the multi-armed bandit research is likely to be small , since there are already a number of solutions achieving optimal or new optimal regret bounds",
    "NOVELTY"
  ],
  [
    "The impact to the community might be incremental .",
    "NOVELTY"
  ],
  [
    "The use of Bayesian active learning to generate the training set feels like an elegant idea .",
    "NOVELTY"
  ],
  [
    "I agree that overparameterization improves recovery is a new finding .",
    "NOVELTY"
  ],
  [
    "The idea of testing the \u00e2\u0080\u009caffinity\u00e2\u0080\u009d of pairs of data points using tangent cone is new as far as I know . The true positive rate control in Section 4 is new and useful .",
    "NOVELTY"
  ],
  [
    "I feel that this paper contains enough interesting new insights that should merit an accept to NIPS",
    "NOVELTY"
  ],
  [
    "The pipelined method is interesting .",
    "NOVELTY"
  ],
  [
    "4 .I like the key idea",
    "NOVELTY"
  ],
  [
    "I think the idea of the proposed algorithm is interesting",
    "NOVELTY"
  ],
  [
    "and the literature is complete and relevant",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "I found the methodology fairly straightforward",
    "NOVELTY"
  ],
  [
    "and not having a particular component as contribution",
    "NOVELTY"
  ],
  [
    "The method and applications of the paper are thus original , in my opinion .",
    "NOVELTY"
  ],
  [
    "To summarize , I like the idea of the paper and I think the result can be illuminating and worth some more follow-up work to understand the RL training in general",
    "NOVELTY"
  ],
  [
    "The setting is novel and deserves research in-depth , and the idea is easy to understand .",
    "NOVELTY"
  ],
  [
    "The proposed method is interesting and can be applied in many other estimators with similar properties as Eq",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well written and the proposed method advances the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "albeit somewhat unexciting",
    "NOVELTY"
  ],
  [
    "the method of choice ( free-energy based Q-function approximation ) seems a bit exotic",
    "NOVELTY"
  ],
  [
    "The upper bound and the algorithm to efficiently compute it is novel .",
    "NOVELTY"
  ],
  [
    "the paper is not particularly novel",
    "NOVELTY"
  ],
  [
    "As a result , the technical novelty in this paper is somewhat limited .",
    "NOVELTY"
  ],
  [
    "The authors nicely present the generalized formulation toward CGNL by unifying the two previous works of bilinear pooling and non-local module .",
    "NOVELTY"
  ],
  [
    "I find the idea of separating content and view interesting and I like the GMV and CGMV architectures .",
    "NOVELTY"
  ],
  [
    "I really enjoyed the paper",
    "NOVELTY"
  ],
  [
    "it actually was a pioneering study on the use of low resolution weights during inference while allowing for auxiliary variables during learning",
    "NOVELTY"
  ],
  [
    "The idea seems reasonable and novel",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting",
    "NOVELTY"
  ],
  [
    "their wavenet implementation is probably not as good as the original one",
    "NOVELTY"
  ],
  [
    "I think this paper will be a valuable contribution",
    "NOVELTY"
  ],
  [
    ", and the connection to spectral graph theory is a very interesting non-obvious one , which gives the work novelty and originality .",
    "NOVELTY"
  ],
  [
    "1.b .The idea and analysis of re-tuning batch normalization statistics to match 1-4-3 data is novel . 1.c .The idea of doing distributed training with FP16 reduce-scatter and HFP8 allgather is novel and is supported by an",
    "NOVELTY"
  ],
  [
    "Using stacked attention for zero-shot learning seems to be a new idea",
    "NOVELTY"
  ],
  [
    "is not a ground-breaking work as adding attention mechanism to different visual tasks becomes quite common these days",
    "NOVELTY"
  ],
  [
    "I think the self-adversarial attack observation is",
    "NOVELTY"
  ],
  [
    "but not very convinced that the proposed defense techniques are novel enough for the submission . Note self-adversarial attack is not a new observation",
    "NOVELTY"
  ],
  [
    "Novelty is not enough as most of the proposed solution or observations are already published .",
    "NOVELTY"
  ],
  [
    "These results are more or less new",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are original and relevant to the real-world applications of such systems .",
    "NOVELTY"
  ],
  [
    "Architecture seems to be novel .",
    "NOVELTY"
  ],
  [
    "Architecture is original .",
    "NOVELTY"
  ],
  [
    "The noise-scaling approach is ( to my knowledge ) novel , good and in my view the most valuable part of the paper .",
    "NOVELTY"
  ],
  [
    "I like the paper , I like the algorithm and I think it is a valuable contribution",
    "NOVELTY"
  ],
  [
    "and builds on tools from discrete-time dynamical systems",
    "NOVELTY"
  ],
  [
    "The paper has several interesting ( and to the best of my knowledge original ) components",
    "NOVELTY"
  ],
  [
    "In light of this , I would rate the novelty of the basic goal of this paper as relatively low ,",
    "NOVELTY"
  ],
  [
    "though the specific proposal is novel to me and seems reasonable",
    "NOVELTY"
  ],
  [
    "Clearly , this has not been done before .",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting .",
    "NOVELTY"
  ],
  [
    "but I believe the last of your contributions have already been achieved in other work",
    "NOVELTY"
  ],
  [
    "It is a simple and intuitive idea",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the algorithm presented is original .",
    "NOVELTY"
  ],
  [
    "I think this is a good contribution",
    "NOVELTY"
  ],
  [
    "The idea of using polynomial transformation is not new",
    "NOVELTY"
  ],
  [
    "and I like the idea of incorporating additional structure into the learning process through the expected blockwise structure .",
    "NOVELTY"
  ],
  [
    "I do not understand real advantage of this method over previous methods",
    "NOVELTY"
  ],
  [
    "-- Some of the ideas presented are standard or well-known properties to most ML practitioners",
    "NOVELTY"
  ],
  [
    "the paper needs to address the concerns first so as to not confuse that community -- The Bayesian RNN models being discussed are not novel either and their properties have been discussed in the corresponding papers",
    "NOVELTY"
  ],
  [
    "I think this is a very nice and original contribution trying to bridge properties of simple models of neural networks",
    "NOVELTY"
  ],
  [
    "While the idea of using synthetic data ( which can be easily procedurally generated ) to do this reverse-engineer training is very clever",
    "NOVELTY"
  ],
  [
    "the limited novelty",
    "NOVELTY"
  ],
  [
    "The proposed approach is a useful addition to existing literature .",
    "NOVELTY"
  ],
  [
    "proposed approach helps finding better policy while guarantee the better discounted return over the baseline policy",
    "NOVELTY"
  ],
  [
    "This is the solid work addressing the limitation of existing work and propose a better approach .",
    "NOVELTY"
  ],
  [
    "The proposed idea is novel and",
    "NOVELTY"
  ],
  [
    "An interesting model for maliciously injecting data into learning",
    "NOVELTY"
  ],
  [
    "This model appears to be new",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "I do not see much technical novelty in this paper .",
    "NOVELTY"
  ],
  [
    "The paper is , to my knowledge , original",
    "NOVELTY"
  ],
  [
    "the formalization in Definition 2 is quite interesting , and leads to interesting gradient estimators which , unlike in typical variance reduction methods , are constructed in a different way depending on the query point .",
    "NOVELTY"
  ],
  [
    "The framework is very incremental . It is novel but limited .",
    "NOVELTY"
  ],
  [
    "Overall , the scientific contribution appears to be slim .",
    "NOVELTY"
  ],
  [
    "The idea of starting from a small , sparse network and expanding it is not novel .",
    "NOVELTY"
  ],
  [
    "unified min-max optimization to learn the behavior model and the reward function + interesting idea of using generative adversarial networks to simulate user rewards .",
    "NOVELTY"
  ],
  [
    "I find the pros of the paper that it : offers an interesting extension to earlier analyses of mixture models in ssl",
    "NOVELTY"
  ],
  [
    "I enjoyed reading this paper , it is clear , interesting and proposes an original network architecture ( PredNet ) for video frame prediction that has produced promising results on both synthetic and natural images",
    "NOVELTY"
  ],
  [
    "I think the randomized version is novel although pinball loss has been used before .",
    "NOVELTY"
  ],
  [
    "Although the pinball loss is strongly motivated",
    "NOVELTY"
  ],
  [
    "by prior work , randomized version of that simultaneously optimizing for all quantiles is novel and seems to have very competitive empirical performance on a variety of tasks . The OC approach is very novel for the filtering task .",
    "NOVELTY"
  ],
  [
    "The methodological novelty is also very interesting .",
    "NOVELTY"
  ],
  [
    "The work is novel",
    "NOVELTY"
  ],
  [
    "Overall , this paper presents a method that is not particularly novel to a new application domain ( medical reports ) that",
    "NOVELTY"
  ],
  [
    "it is a well-done application paper but perhaps a little lacking novelty-wise for NIPS",
    "NOVELTY"
  ],
  [
    "An interesting way to represent time-dependent potentials with a network for regularizing generative models Cons",
    "NOVELTY"
  ],
  [
    "Not much theoretical novelties in the paper , nor a good analysis on the source of errors of the model",
    "NOVELTY"
  ],
  [
    "but I really liked the fresh ideas and the concrete perspectives they give for MABs both on the applicative and theoretic grounds",
    "NOVELTY"
  ],
  [
    "This is the first paper that gives an algorithm with a rigorous guarantee for this",
    "NOVELTY"
  ],
  [
    "There is little contribution on the methodology side from the paper .",
    "NOVELTY"
  ],
  [
    "I think that the idea of estimating the gradient of the MI instead of directly calculating it is an exciting research direction",
    "NOVELTY"
  ],
  [
    "Interesting new model for representation learning based on an estimation of the MI gradients ' .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "with interesting ( and potentially useful ) insights",
    "NOVELTY"
  ],
  [
    "because there is little novelty to the model 's core components",
    "NOVELTY"
  ],
  [
    "Despite the RRN 's lack of novelty",
    "NOVELTY"
  ],
  [
    "Wildcard denoising : Sampling a 'wildcard ' word does seem to be a novel regularization technique that others may find useful .",
    "NOVELTY"
  ],
  [
    "the development itself is not novel enough to significantly increase the paper 's score .",
    "NOVELTY"
  ],
  [
    ".This is not significantly new enough to warrant an increase from 'sub-standard ' .",
    "NOVELTY"
  ],
  [
    "The theoretical novelty is limited .",
    "NOVELTY"
  ],
  [
    ", and the idea involving the Laplacian of the similarity graph is interesting .",
    "NOVELTY"
  ],
  [
    "The paper sets up a powerful generalization of existing regrets and present algorithms that are efficient , which I believe provides enough novelty .",
    "NOVELTY"
  ],
  [
    "However I am a bit concerned about its contribution in terms of theoretical results",
    "NOVELTY"
  ],
  [
    "Originality The paper is original .",
    "NOVELTY"
  ],
  [
    "I do n't believe that the contributions of the paper meet the standards of ICLR",
    "NOVELTY"
  ],
  [
    "the paper does not say anything new about how to solve the problem",
    "NOVELTY"
  ],
  [
    "The ideas of introducing a meta-mapping and treating it similarly or the same as a learning a task itself are novel to me .",
    "NOVELTY"
  ],
  [
    "Novel combination of MRFs and formal grammars for images Cons",
    "NOVELTY"
  ],
  [
    "This is a small but nice contribution .",
    "NOVELTY"
  ],
  [
    "The paper makes notable novel contributions by introducing the PGLD together with novel stochastic processes .",
    "NOVELTY"
  ],
  [
    "The idea is natural and intuitive .",
    "NOVELTY"
  ],
  [
    "I\u00e2\u0080\u0099m not sure how novel the idea is ,",
    "NOVELTY"
  ],
  [
    "I wonder if the end result is a bit too incremental in the absence of some attempt to explore this source of ( lack of ) robustness",
    "NOVELTY"
  ],
  [
    "This paper looks like a collection of several standard algorithms to solve a problem .",
    "NOVELTY"
  ],
  [
    "seems the paper fails to explain what is it 's original contribution .",
    "NOVELTY"
  ],
  [
    "Many of the technical details are original",
    "NOVELTY"
  ],
  [
    "However after some re-organisation of the document I think this will makes a solid contribution",
    "NOVELTY"
  ],
  [
    "The open-world related tasks have been defined in many previous works",
    "NOVELTY"
  ],
  [
    "Unfortunately , this paper is lack of novelty .",
    "NOVELTY"
  ],
  [
    "this model is just a direct combination of the recent powerful algorithms such as DOC and other simple traditional models . I do not really see enough novelty here .",
    "NOVELTY"
  ],
  [
    "Although this idea is interesting",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting .",
    "NOVELTY"
  ],
  [
    "The combination of two existing techniques seems not novel enough .",
    "NOVELTY"
  ],
  [
    "some of the results and the bounds themselves are well-known and can thus not be considered novel .",
    "NOVELTY"
  ],
  [
    "+The limb scoring network is pretty interesting .",
    "NOVELTY"
  ],
  [
    "I think providing a graphical illustration on the trajectories taken by this scheme vs plain gradient descent can be very insightful and maybe provide some intuition why the idea works",
    "NOVELTY"
  ],
  [
    "Although the idea seems incremental , the experimental results do seem solid .",
    "NOVELTY"
  ],
  [
    "The idea seems incremental 2",
    "NOVELTY"
  ],
  [
    "I think this paper is an interesting idea",
    "NOVELTY"
  ],
  [
    "Overall , it 's a novel way of looking at the problem and is a pretty good start in the direction of deepnets learning parameters for other networks which I have not seen before .",
    "NOVELTY"
  ],
  [
    "The technical contributions are not significant enough , since it is in the existing SSD detection framework and the network design are mainly based on experience .",
    "NOVELTY"
  ],
  [
    "The efficient implementation of SSD on iOS can not be regarded as a contribution since it simply based on the CoreML library",
    "NOVELTY"
  ],
  [
    "The new dataset introduced in this paper might be an interesting addition to the existing ones",
    "NOVELTY"
  ],
  [
    "So there is no particular novelty in the combination of local metrics .",
    "NOVELTY"
  ],
  [
    "Comments -I like the proposed framework because it embeds a large set of possible way of combining metrics",
    "NOVELTY"
  ],
  [
    "The idea of using different functions for combining metrics could have been used in other papers , for me the real novelty is to provide a sufficiently general framework for combining these metrics .",
    "NOVELTY"
  ],
  [
    "The methods used in this paper are similar to previous works on neural architecture search ( NAS ) , but",
    "NOVELTY"
  ],
  [
    "This simple combination makes the novelty of this paper unclear",
    "NOVELTY"
  ],
  [
    "I believe that the paper is novel and significant to a fair degree",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "although the novelty is limited",
    "NOVELTY"
  ],
  [
    "The idea to extend the use of VAE-GANs to the video prediction setting is a pretty natural one",
    "NOVELTY"
  ],
  [
    "and not especially novel",
    "NOVELTY"
  ],
  [
    "extension of VAE-GANs to video prediction setting",
    "NOVELTY"
  ],
  [
    "Limited novelty - Limited analysis of model/architecture design choices",
    "NOVELTY"
  ],
  [
    "The contribution",
    "NOVELTY"
  ],
  [
    "However , the novelty of the work is limited",
    "NOVELTY"
  ],
  [
    "So since the model proposed in this article is not a major contribution and shares many common ideas with existing hierarchical reinforcement learning methods ,",
    "NOVELTY"
  ],
  [
    "Original problem",
    "NOVELTY"
  ],
  [
    "outline of paper is good - novel metric Cons",
    "NOVELTY"
  ],
  [
    "This is not a novel approach",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper is incremental , as it combines two previously published methods .",
    "NOVELTY"
  ],
  [
    "I liked the article which presented clear ideas and focus on a new side of stochastic descent algorithm .",
    "NOVELTY"
  ],
  [
    "The results are innovative , and yet intuitively explained .",
    "NOVELTY"
  ],
  [
    "The lifting technique is novel .",
    "NOVELTY"
  ],
  [
    "It seems new and interesting to propose a nonlinear spectral method which optimally trains a particular class of feedforward neural networks .",
    "NOVELTY"
  ],
  [
    "The method proposed in the paper is not very novel",
    "NOVELTY"
  ],
  [
    "I 'm not aware of any work that address the asymmetric padding issue this way and I think this solution is quite novel .",
    "NOVELTY"
  ],
  [
    ", but I believe this analysis is novel .",
    "NOVELTY"
  ],
  [
    "my primary concern is that the model seems somewhat lacking in novelty .",
    "NOVELTY"
  ],
  [
    "*Originality* The originality is limited for what regards Section 3",
    "NOVELTY"
  ],
  [
    "the idea of taking into account the data manifold is not brand new since already proposed in",
    "NOVELTY"
  ],
  [
    "but the technical contribution is rather incremental .",
    "NOVELTY"
  ],
  [
    "the idea of having a fixed voxel-net decoder is interesting",
    "NOVELTY"
  ],
  [
    "The idea of combining active vision with object classification is interesting .",
    "NOVELTY"
  ],
  [
    "The paper provides decent technical contributions with some novel ideas about multi-doc summary learning models without a ( supervised ) paired data set .",
    "NOVELTY"
  ],
  [
    "with a strong motivation and novel theoretical and algorithmic insights",
    "NOVELTY"
  ],
  [
    "Overall , this is an incremental paper .",
    "NOVELTY"
  ],
  [
    "Aggregating weights of different layers has been an idea explored before",
    "NOVELTY"
  ],
  [
    "The paper also does not propose any new training methods based on the insights uncovered and it is not clear how significant the connection uncovered is with the information presented in the current draft",
    "NOVELTY"
  ],
  [
    "In it \u2019 s current form I unfortunately don \u2019 t think the contributions of the paper are significant enough for acceptance .",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting application of GNNs to the space of reinforcement learning and clearly",
    "NOVELTY"
  ],
  [
    "transfer learning",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the paper presents an original result",
    "NOVELTY"
  ],
  [
    "This paper appears to be a first attempt to the multitask approach for WFAs .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems interesting however",
    "NOVELTY"
  ],
  [
    "While the technical novelty is clear",
    "NOVELTY"
  ],
  [
    "My major concern is that the technical novelty is somehow limited in terms of the two closely related works of Transformer and stochastic shared embedding ( SSE ) .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution of this work is very motivated by the prior work on performing submodular maximization in parallel , which is also noted by the authors",
    "NOVELTY"
  ],
  [
    "I consider the plot of the coreset archetypes on a toy experiment insightful and it might be a relevant addition to the appendix .",
    "NOVELTY"
  ],
  [
    "In my opinion the biggest strength of the paper is the novelty of the proposed method",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , this paper constitutes the first approach using GANs for the KG alignment task .",
    "NOVELTY"
  ],
  [
    "The theoretical contributions are strong : the authors not only introduce a proper energy formulation of ReLU RBMs , but also a novel sampling mechanism and an improvement on AIS for estimating their partition function .",
    "NOVELTY"
  ],
  [
    "this will further limit the appeal of the paper",
    "NOVELTY"
  ],
  [
    "Compared to general methods like Rao et al [ 42 ] , this work seems too",
    "NOVELTY"
  ],
  [
    "The use of this theory in rating estimation is somewhat novel",
    "NOVELTY"
  ],
  [
    "The contribution is marginal ,",
    "NOVELTY"
  ],
  [
    "is not new",
    "NOVELTY"
  ],
  [
    "Given this major weakness and with limited novelty",
    "NOVELTY"
  ],
  [
    "On the overall I think this paper presents an interesting idea of IR for off-policy learning .",
    "NOVELTY"
  ],
  [
    "Both two models/ideas are actually trivial and in line with the current trend of combining different architectures",
    "NOVELTY"
  ],
  [
    "ideas are quite trivial",
    "NOVELTY"
  ],
  [
    "This paper introduces the stochastic kinetic model into social dynamics which is novel . I like the idea .",
    "NOVELTY"
  ],
  [
    "The ideas are not new",
    "NOVELTY"
  ],
  [
    "The model itself is an incremental work ,",
    "NOVELTY"
  ],
  [
    "but the application is novel",
    "NOVELTY"
  ],
  [
    "The idea of learning the quantization instead of using pre-defined human-made algorithm is nice and very much in the spirit of modern machine learning .",
    "NOVELTY"
  ],
  [
    "The paper is very incremental .",
    "NOVELTY"
  ],
  [
    "All in all , the novelty in this paper is not very clear to me .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel FE scheme and discusses it",
    "NOVELTY"
  ],
  [
    "The idea is indeed interesting and AFAIK",
    "NOVELTY"
  ],
  [
    "I am convinced that the proposed model is better than BicycleGAN , and the approach is somehow novel",
    "NOVELTY"
  ],
  [
    "the novelty of the method is limited .",
    "NOVELTY"
  ],
  [
    "The paper lacks originality",
    "NOVELTY"
  ],
  [
    "however the results are interesting .",
    "NOVELTY"
  ],
  [
    "However , the novelty of the approach is limited from a machine learning standpoint .",
    "NOVELTY"
  ],
  [
    "The paper is fairly novel .",
    "NOVELTY"
  ],
  [
    "The improvements over a generically-trained generation model are very small .",
    "NOVELTY"
  ],
  [
    "The automation of parallelism across the different dimensions in each of the layers appears somewhat new .",
    "NOVELTY"
  ],
  [
    "automatically exploring this to find the most efficient approach is new",
    "NOVELTY"
  ],
  [
    "existing work",
    "NOVELTY"
  ],
  [
    "but I think these are minor",
    "NOVELTY"
  ],
  [
    "However , the proposed approach is not very original and applies to small graphs only as it requires a memory of order n^2 .",
    "NOVELTY"
  ],
  [
    "significant .",
    "NOVELTY"
  ],
  [
    "This work is original , to the best of my knowledge , in automatically grading an agents capability in a Goal directed MDP .",
    "NOVELTY"
  ],
  [
    "This work is interesting and innovative since this is the first one to incorporate the deep learning model into automatic theorem proving and the results also outperforms the conventional approach .",
    "NOVELTY"
  ],
  [
    "and",
    "NOVELTY"
  ],
  [
    "There is little novelty -- the method is arguably too simple to be called a",
    "NOVELTY"
  ],
  [
    "Overall , there \u2019 s not much novelty here",
    "NOVELTY"
  ],
  [
    "Although memory augmented neural networks and reinforcement learning are both well-known , the proposed method combined them in a novel way .",
    "NOVELTY"
  ],
  [
    "My main concern is the novelty of the work if we look at it from an ensemble learning perspective .",
    "NOVELTY"
  ],
  [
    "I found the paper original and interesting .",
    "NOVELTY"
  ],
  [
    "this is not quite a breakthrough but rather an expansion of previous ideas",
    "NOVELTY"
  ],
  [
    "The proposed architecture is novel and appropriate for these type of problems and could lead to better prediction of strategic interaction .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge there is no real time style transfer method that can adjust certain style parameters after it has been trained .",
    "NOVELTY"
  ],
  [
    "The general idea of third person imitation learning is nice , clear and ( at least to my understanding ) also novel",
    "NOVELTY"
  ],
  [
    "I fail to see why the situation for the GAN based approach is any different than that of any other existing IRL algorithm .",
    "NOVELTY"
  ],
  [
    "I think that the paper has several substantial contributions .",
    "NOVELTY"
  ],
  [
    ", and it provides a novel theoretical contribution ( originality ) that seems technically correct ( high quality",
    "NOVELTY"
  ],
  [
    "paper proposes a novel zeroth-order algorithm for high-dimensional optimization",
    "NOVELTY"
  ],
  [
    "The positive aspects of the paper are",
    "NOVELTY"
  ],
  [
    "This is a nice paper that establishes convergence of actor-critic algorithm in the special case of LQR .",
    "NOVELTY"
  ],
  [
    "I do think that the bilevel optimization perspective , while interesting , does not really contribute much to the exposition of either the algorithm , or the analysis .",
    "NOVELTY"
  ],
  [
    "The idea seems to be inspired by recent work ( Hu et al",
    "NOVELTY"
  ],
  [
    "and properties of Bernoulli-Poisson link function",
    "NOVELTY"
  ],
  [
    "The proposed model , although inspired by various recent works , makes some interesting improvements .",
    "NOVELTY"
  ],
  [
    "Although the subject of the task is not quite close to my area and the topic of programming language edit is relatively new to me",
    "NOVELTY"
  ],
  [
    "Overall speaking , the qualitative result in the paper has already been discovered in many previous work , although the quantitative results seem to be new .",
    "NOVELTY"
  ],
  [
    "This paper is original .",
    "NOVELTY"
  ],
  [
    "the influence of the new model component seems marginal",
    "NOVELTY"
  ],
  [
    "1 .The idea of using the concept of age is not new .",
    "NOVELTY"
  ],
  [
    "The paper presents an incremental contribution with respect to previous methods for VQA that only exploit an image attention mechanism guided by question data .",
    "NOVELTY"
  ],
  [
    "There is limited technical novelty .",
    "NOVELTY"
  ],
  [
    "the techniques are quite similar to",
    "NOVELTY"
  ],
  [
    "It is a good idea to combine asynchronous parallel updates with greedy coordinate selection and this combination is novel .",
    "NOVELTY"
  ],
  [
    "and for me this work did n't really give any new insights that make it stand out among them",
    "NOVELTY"
  ],
  [
    "The model between document and topic is very similar to previous pure topic models",
    "NOVELTY"
  ],
  [
    "The reviewer feels this alone is not enough contribution .",
    "NOVELTY"
  ],
  [
    "but intuitive pre-training tasks for this scenario",
    "NOVELTY"
  ],
  [
    "The main method is based on published `` slimmable networks , `` such that the novelty is limited",
    "NOVELTY"
  ],
  [
    "but as concurrent work this does not diminish the originality of the paper here",
    "NOVELTY"
  ],
  [
    "although I agree with the other reviewers that it is a bit incremental",
    "NOVELTY"
  ],
  [
    "The novelty of this work seems to be incremental .",
    "NOVELTY"
  ],
  [
    "2 .It is a nice idea , exploiting tree structure in the ground metric , and yields an",
    "NOVELTY"
  ],
  [
    "The idea of taking measurements in two stages in compressed sensing ( to recover the support , then approximate the signal values on this support ) is not new . However",
    "NOVELTY"
  ],
  [
    ", the idea of recovering a superset of the support rather than the exact support appears to be novel . - The connections to Group Testing are interesting and appear to be novel as far as I know .",
    "NOVELTY"
  ],
  [
    "Even if the idea of taking compressed sensing measurements in two stages is not new",
    "NOVELTY"
  ],
  [
    "Originality While others have pointed out limitations before , this paper considers relational networks for the first time .",
    "NOVELTY"
  ],
  [
    "no new architectures are presented to address these limitations .",
    "NOVELTY"
  ],
  [
    "No new theory development .",
    "NOVELTY"
  ],
  [
    "Overall , the proposal 2 component embedding approach is interesting .",
    "NOVELTY"
  ],
  [
    "This work proposes a simple method that is original compared existing GANs .",
    "NOVELTY"
  ],
  [
    "the methodological contribution is minor",
    "NOVELTY"
  ],
  [
    "If we look at the actual contributions of the paper in terms of engineering , I do not think the reported improvements are that impressive .",
    "NOVELTY"
  ],
  [
    "The study seems to be adding",
    "NOVELTY"
  ],
  [
    "This paper is insightful , and interesting .",
    "NOVELTY"
  ],
  [
    "I think the paper is a nice contribution to the theoretical analysis of LSTM word embeddings .",
    "NOVELTY"
  ],
  [
    "Also I am not sure that Proposition 1 is novel enough to warrant a proof here",
    "NOVELTY"
  ],
  [
    "To be honest , the theoretical contribution of the paper is limited .",
    "NOVELTY"
  ],
  [
    "From this perspective , the paper seems like an application of existing tools (",
    "NOVELTY"
  ],
  [
    "The proposed method is very similar to two prior works cited by the authors",
    "NOVELTY"
  ],
  [
    "than the two very similar prior works",
    "NOVELTY"
  ],
  [
    "The proposed stochastic pooling is novel and demonstrated that empirically useful .",
    "NOVELTY"
  ],
  [
    "Originality The idea is quite very simple",
    "NOVELTY"
  ],
  [
    "This appears a novel aspect ( at least to my knowledge ) that is not featured in the current stochastic and adversarial MAB literature .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is novel in the sense that it actively detects if there is any change in the arms ' distribution",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is incremental in the context of prior Adversarial Debasing ( AD ) approach using essentially same GAN for group fairness and prior work presenting ideas of utilizing clean validation data to defend against data poisoning .",
    "NOVELTY"
  ],
  [
    "It is very interesting the combination of the idea of using cross-reconstruction of 3D flow and adversarial training for view classification from the encodings .",
    "NOVELTY"
  ],
  [
    "The proposed architecture seems novel",
    "NOVELTY"
  ],
  [
    "I think this concept is not novel anymore and the expectations should be raised to real applications",
    "NOVELTY"
  ],
  [
    "The simplicity of the training process that is fully based on pixel labeling makes this work interesting",
    "NOVELTY"
  ],
  [
    "I think the authors are on something here and the idea is great",
    "NOVELTY"
  ],
  [
    "The proposed idea seems new .",
    "NOVELTY"
  ],
  [
    "However , the reviewer finds the main contribution rather incremental in its nature .",
    "NOVELTY"
  ],
  [
    "A new GAIL formulation for saving on interaction data .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and goes in the interesting direction of learning watermarks using adversarial training techniques .",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting approach to understanding relations among entities .",
    "NOVELTY"
  ],
  [
    ", the model proposed here is novel and effective at handling relations and shows promise for higher-level reasoning tasks .",
    "NOVELTY"
  ],
  [
    "The way of learning the regularization is also nice .",
    "NOVELTY"
  ],
  [
    "the paper seems a bit pre-mature .",
    "NOVELTY"
  ],
  [
    "This part looks like an extension to Ian \u2019 s work with Inception-V3 model",
    "NOVELTY"
  ],
  [
    "If that is the case , the technical contribution looks marginal although its implication is interesting .",
    "NOVELTY"
  ],
  [
    "the paper seems to make a technical contribution as well",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of this paper is novel , and results are",
    "NOVELTY"
  ],
  [
    "The idea of using a CNN feature map and LSTM embedding to solve spatial reasoning tasks is not new .",
    "NOVELTY"
  ],
  [
    "The proposed approach is a classic one already presented elsewhere",
    "NOVELTY"
  ],
  [
    "The combination of those ideas is novel and enjoyable .",
    "NOVELTY"
  ],
  [
    "My overall assessment of the paper is that it is extremely weak , both in terms of the novelty of method proposed , its",
    "NOVELTY"
  ],
  [
    "It is an interesting paper and as far as I know , the first paper to apply deep learning models to retinal data .",
    "NOVELTY"
  ],
  [
    "The derived bound",
    "NOVELTY"
  ],
  [
    "The proposed architectural idea is not particularly original",
    "NOVELTY"
  ],
  [
    "Using gradients as importance measure was already done in previous work",
    "NOVELTY"
  ],
  [
    "Though taking the average of gradients over several input instances is new",
    "NOVELTY"
  ],
  [
    "while the criterion seems new it is also related to criteria used in the segmentation literature",
    "NOVELTY"
  ],
  [
    "the idea that compressibility and attractiveness are related is not new and is also present in 43",
    "NOVELTY"
  ],
  [
    "think they enrich the paper",
    "NOVELTY"
  ],
  [
    "I lean towards rejecting this paper because I do not find the methodological contribution to be significant enough to be published at ICLR , given that the main contribution is applying current techniques to a novel toy domain",
    "NOVELTY"
  ],
  [
    "Therefore , the contribution of the method is questionable .",
    "NOVELTY"
  ],
  [
    "The scientific contribution of this statement is therefore questionable .",
    "NOVELTY"
  ],
  [
    "Thus , the problem setting provides some novelty .",
    "NOVELTY"
  ],
  [
    "From the perspective of the method , this paper incorporates the memory bank to the RNN , which is not new in the machine learning research area , but heuristic enough for the transfer learning community .",
    "NOVELTY"
  ],
  [
    "which is interesting and heuristic to the domain adaptation research community",
    "NOVELTY"
  ],
  [
    "It provides some of the first rigorous analysis of feedback alignment since the original paper came out",
    "NOVELTY"
  ],
  [
    "this paper presents a seemingly promising architecture capable of learning and using variables",
    "NOVELTY"
  ],
  [
    "the improvements were modest over competitor methods and raise concerns about the impact of the methods moving forward .",
    "NOVELTY"
  ],
  [
    "The method is original",
    "NOVELTY"
  ],
  [
    "although not completely distinct from previous works",
    "NOVELTY"
  ],
  [
    "Although the obtained PAC-Bayesian bound is not novel",
    "NOVELTY"
  ],
  [
    "the new proof technique can enrich the comprehension both PAC-Bayes and Rademacher generalization theories and foster the emergence of new ideas .",
    "NOVELTY"
  ],
  [
    "I like the paper a lot",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting approach to change point detection .",
    "NOVELTY"
  ],
  [
    "The idea is very interesting .",
    "NOVELTY"
  ],
  [
    "The paper proposed a novel sample-efficient pretraining task",
    "NOVELTY"
  ],
  [
    "All these observations are interesting .",
    "NOVELTY"
  ],
  [
    "the idea is new",
    "NOVELTY"
  ],
  [
    "The idea of using hard attention for interpretability is novel to the field .",
    "NOVELTY"
  ],
  [
    "the saccader cell is also a simple yet novel design",
    "NOVELTY"
  ],
  [
    "The proposed modifications are quite incremental .",
    "NOVELTY"
  ],
  [
    "The paper analyses latent-variable modeling from a rate-distortion point-of-view in a novel and interesting fashion , highlighting important fundamental connections . In particular , the paper presents a novel theorem ( inspired by how the rate-distortion function is computed ) that gives a lower bound on the negative log likelihood . This lower bound allows to quantify by how much a latent-variable model could be improved by either modifying the prior or the likelihood function . The latter is important , since the paper shows a duality between improving one while keeping the other fixed and vice versa . Finally , the paper derives a practical implementation/approximation ( founded on solid theoretical analysis ) of quantifying the improvement potential of a latent-variable model . These , so called \u201c glossy statistics \u201d are quantitatively analyzed in a set of experiments with different variational autoencoder architectures ( various likelihood models and priors ) on a number of datasets . The main contribution of this paper is to provide novel proofs and theoretical analysis that connect latent-variable modeling with rate-distortion on a very fundamental level .",
    "NOVELTY"
  ],
  [
    "but I also believe that this is not the main contribution of the paper , which is rather laying the mathematical groundwork for future work",
    "NOVELTY"
  ],
  [
    "The idea is closely related to sparse Bayesian learning but the variational approximation is achieved via the local reparametrization trick of Kingma 2015",
    "NOVELTY"
  ],
  [
    "the idea is interesting and simple and",
    "NOVELTY"
  ],
  [
    "So conceptually , the paper is novel .",
    "NOVELTY"
  ],
  [
    "Such bounds are intuitive and novel .",
    "NOVELTY"
  ],
  [
    "I believe the results of the paper are novel and elegant .",
    "NOVELTY"
  ],
  [
    "The paper has mediocre novelty given other similar papers recently .",
    "NOVELTY"
  ],
  [
    "The problem which the authors study and the proposed method are both quite novel .",
    "NOVELTY"
  ],
  [
    "The idea of using coarse statistical signatures to calculate attention is an interesting one .",
    "NOVELTY"
  ],
  [
    "and the proposed method is interesting in my opinion .",
    "NOVELTY"
  ],
  [
    "The idea to decompose the synthesis task into two sub-tasks of first learning a set of individual traces for each example , and then learning a program consistent with a satisfiable subset of traces is quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "poster Though the idea of this paper is rather simple",
    "NOVELTY"
  ],
  [
    "This work does n't seem that original from an algorithmic point of view since Reed & De Freitas ( 2015 ) and Cai et",
    "NOVELTY"
  ],
  [
    "However the application to program repair is novel ( as far as I know ) .",
    "NOVELTY"
  ],
  [
    "This work is novel and quite impressive .",
    "NOVELTY"
  ],
  [
    "I think that this is a nice complementary idea to the PGDS which add some extra sparsity into the mix",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "this is a nice paper with",
    "NOVELTY"
  ],
  [
    "The reviewers seem to",
    "NOVELTY"
  ],
  [
    "paper makes a useful contribution and should be accepted",
    "NOVELTY"
  ],
  [
    "the connection to optimal control via continuous depth idea is fascinating .",
    "NOVELTY"
  ],
  [
    "however , the presented algorithm is not novel , the implementation and experiments might not be as relevant",
    "NOVELTY"
  ],
  [
    ", the idea and the algorithms are novel and original .",
    "NOVELTY"
  ],
  [
    "their contribution to identifying separating sets of features is original and interesting",
    "NOVELTY"
  ],
  [
    "I do agree that , from the optimization perspective , this paper suffers from somewhat limited novelty .",
    "NOVELTY"
  ],
  [
    "I found this new method very interesting .",
    "NOVELTY"
  ],
  [
    "contribution and should be accepted to ICLR",
    "NOVELTY"
  ],
  [
    "the contribution is okay but",
    "NOVELTY"
  ],
  [
    "However , the major weakness of the paper is the lack of novelty of the core idea .",
    "NOVELTY"
  ],
  [
    "lack of novelty and",
    "NOVELTY"
  ],
  [
    "The idea is somewhat novel , in terms of meta-learning based low-shot detection framework .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel algorithm and analysis for solving mixed regression problem .",
    "NOVELTY"
  ],
  [
    "More importantly , the algorithm is novel and wth good theoretical",
    "NOVELTY"
  ],
  [
    "Using batch normalization on existing binarization/ternarization techniques is a bit of an incremental contribution .",
    "NOVELTY"
  ],
  [
    "I like the general idea of the paper ( as stated above ) along with its objectives but I have several concerns",
    "NOVELTY"
  ],
  [
    "Since the paper proposes just to encode history with a RNN , the proposed solution lacks of originality , and the contribution of the paper in term of model is quite low .",
    "NOVELTY"
  ],
  [
    "Low contribution in term of model",
    "NOVELTY"
  ],
  [
    "The idea of a more expressive variational distribution seems good ,",
    "NOVELTY"
  ],
  [
    "although it is not novel .",
    "NOVELTY"
  ],
  [
    "3 .There is not much novelty in the methodology . The proposed meta algorithm is basically a direct extension of existing methods",
    "NOVELTY"
  ],
  [
    "an interesting",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is not sufficient since it is an incremental work on batch normalization ( BN ) .",
    "NOVELTY"
  ],
  [
    "In general , the paper presents an interesting idea .",
    "NOVELTY"
  ],
  [
    "I am not sure I understand the novelty of this work on the modeling side .",
    "NOVELTY"
  ],
  [
    "overall I liked this paper",
    "NOVELTY"
  ],
  [
    "that some of the ideas within",
    "NOVELTY"
  ],
  [
    "it",
    "NOVELTY"
  ],
  [
    "The main issues with the paper is that its contributions are not new .",
    "NOVELTY"
  ],
  [
    "The authors explain that they use a novel loss function that is better than an RL based function used by Zhong et al.",
    "NOVELTY"
  ],
  [
    "this is something that has been done already in the context of pointer networks and other work like See et al .2017 for summarization and Jia et al.",
    "NOVELTY"
  ],
  [
    "The novelty is relatively limited ,",
    "NOVELTY"
  ],
  [
    "Although this work is incremental",
    "NOVELTY"
  ],
  [
    "It has enough originality to warrant publication at NIPS .",
    "NOVELTY"
  ],
  [
    "this paper provides a novel combination of the two",
    "NOVELTY"
  ],
  [
    "Marginally original , the paper is a combination of two previous ideas , although the specific combination is novel .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and appealing .",
    "NOVELTY"
  ],
  [
    "It appears that I did not understand well the novelty of some points of the paper .",
    "NOVELTY"
  ],
  [
    "The paper is interesting and imaginative .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed method is incremental over Dinan et al . ( 2018 ) .",
    "NOVELTY"
  ],
  [
    "Knowledge distillation for video classification is no longer a novel idea unfortunately",
    "NOVELTY"
  ],
  [
    "I felt the paper is a nice extension of the Vyas 2016 paper .",
    "NOVELTY"
  ],
  [
    "Though I found this paper interesting and novel",
    "NOVELTY"
  ],
  [
    "but it does not seem like a very large delta on the work of [ 9 ]",
    "NOVELTY"
  ],
  [
    "From this view point , the contribution of this work seems limited .",
    "NOVELTY"
  ],
  [
    "this paper does an interesting and original analysis which can help us understand better the polytopes composing the input space",
    "NOVELTY"
  ],
  [
    "Novel and efficient approach of redesigning the classifier as a post-processing step after the representation training Cons",
    "NOVELTY"
  ],
  [
    "This work seems to be a follow-up work from Convergent Learning [ 1 ] and SVCCA [ 2 ]",
    "NOVELTY"
  ],
  [
    "Novel method .",
    "NOVELTY"
  ],
  [
    "The proposed method itself is extremely simple and is similar to numerous training strategies that have previously been advocated in the literature . As a result the contribution would be incremental at best and could be significant with sufficiently strong empirical results supporting this particular variant .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the regret lower bound ( Thm 6 ) and the upper bound ( Thm 11 ) are new .",
    "NOVELTY"
  ],
  [
    "I like the idea of using deep learning for physical equations .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the work is original .",
    "NOVELTY"
  ],
  [
    "I find this to be very surprising and exciting .",
    "NOVELTY"
  ],
  [
    "Originality Very original and creative paper .",
    "NOVELTY"
  ],
  [
    "6 .2 .I very much like the idea of `` translating `` an SNN into an ANN .",
    "NOVELTY"
  ],
  [
    "The approach to match the features of another unrelated image is interesting and it goes beyond producing adversarials for classification",
    "NOVELTY"
  ],
  [
    "interesting and original",
    "NOVELTY"
  ],
  [
    "but I find the contribution rather limited in scope",
    "NOVELTY"
  ],
  [
    "This is a good contribution .",
    "NOVELTY"
  ],
  [
    "The introduction of gossip algorithms to Deep-RL is original .",
    "NOVELTY"
  ],
  [
    "I think this paper is a nice bridge from traditional program analysis and machine learning .",
    "NOVELTY"
  ],
  [
    "The paper have little novelty .",
    "NOVELTY"
  ],
  [
    "my opinion is that the theoretical aspects of the paper seems to be incremental .",
    "NOVELTY"
  ],
  [
    "However , apart from DRO-TopK-PN , the proposed algorithms appear to be minor modifications of existing algorithms .",
    "NOVELTY"
  ],
  [
    "2 .The proposed algorithms seem to be similar to those of Fan et al . ( 2017 ) and Namkoong and Duchi ( 2017 ) .",
    "NOVELTY"
  ],
  [
    "Novel architecture that makes sense Numerically and visually outperforms baselines Paper",
    "NOVELTY"
  ],
  [
    "I think the idea of extracting factors from the teacher network and teaching the student network to mimic these factors and training both for factor mimicking and task accuracy at the same time are nice ideas .",
    "NOVELTY"
  ],
  [
    "\u2014\u2014\u2014 The paper presents an novel formulation for extracting hierarchical template representations that has not been discussed in that form .",
    "NOVELTY"
  ],
  [
    "The ideas are similar to previous work in intrinsic motivation",
    "NOVELTY"
  ],
  [
    "Overall it 's a decent , simple technique , perhaps slightly incremental on previous state of the art .",
    "NOVELTY"
  ],
  [
    "Novelty is restricted",
    "NOVELTY"
  ],
  [
    "it is hard to tell that the use of attention is not novel .",
    "NOVELTY"
  ],
  [
    "Lack of novelty",
    "NOVELTY"
  ],
  [
    "I like the overall idea of using a tree-structured neural network which internally performs planning as an abstraction of Q-function , which makes implementation simpler compared to VPN .",
    "NOVELTY"
  ],
  [
    "The application to actor-critic setting ( ATreeC ) is novel ,",
    "NOVELTY"
  ],
  [
    "though the underlying idea was proposed by",
    "NOVELTY"
  ],
  [
    "n-step Q-learning with reward prediction loss ) are same as those of VPN",
    "NOVELTY"
  ],
  [
    "The application to actor-critic setting ( ATreeC ) is novel",
    "NOVELTY"
  ],
  [
    "While poorly designed search spaces is maybe a problem that many people in the community are aware of , this is , to the best of my knowledge , the first paper that systematically shows that for several commonly used search spaces there is not much to be optimized .",
    "NOVELTY"
  ],
  [
    "I do think that the paper makes an important contribution which hopefully helps future work to over come these flaws .",
    "NOVELTY"
  ],
  [
    "with a clean , novel result",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and interesting to allow update to be corrected even when the update is delayed .",
    "NOVELTY"
  ],
  [
    "and that the algorithms and theoretical results presented in this paper are significant and novel .",
    "NOVELTY"
  ],
  [
    "The paper 's technical novelty is limited to this simple loop extension and generator sharing .",
    "NOVELTY"
  ],
  [
    "I find this lack of any technical novelty a negative factor",
    "NOVELTY"
  ],
  [
    "The co-training framework is not so novel for me , which combined the Wasserstein loss and general GAN loss .",
    "NOVELTY"
  ],
  [
    "Originality The idea of improving the fairness of predictions via disentangling looks novel to me .",
    "NOVELTY"
  ],
  [
    "it is a little bit straight-forward derived from the original binarization scheme",
    "NOVELTY"
  ],
  [
    "The approach presented in this paper is interesting",
    "NOVELTY"
  ],
  [
    "the above , the contribution over the SOTA ( selectivenet ) is marginal .",
    "NOVELTY"
  ],
  [
    "Separating the inducing points for mean and covariance is a novel concept based on the RKHS representation of Gaussian processes",
    "NOVELTY"
  ],
  [
    "hence , lacks sufficient contribution .",
    "NOVELTY"
  ],
  [
    "However , the theoretical novelty is quite limited .",
    "NOVELTY"
  ],
  [
    "This paper has presented several novel ideas for reading comprehension (",
    "NOVELTY"
  ],
  [
    "but I \u2019 m not sure if they \u2019 re significantly novel for publication in its current state .",
    "NOVELTY"
  ],
  [
    "the contribution is clearly descibed",
    "NOVELTY"
  ],
  [
    "It is novel to apply constrained beam search [ 19 ] in the training process .",
    "NOVELTY"
  ],
  [
    "is a novel neural network specialized for relational reasoning",
    "NOVELTY"
  ],
  [
    "Overall , I think this problem is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is not significant due to the following reasons",
    "NOVELTY"
  ],
  [
    "The main message ( i.e .the concept of the deep generative classifier can be useful for detecting out-of-distribution samples ) is not really new because it has been explored before",
    "NOVELTY"
  ],
  [
    "are significant .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting",
    "NOVELTY"
  ],
  [
    "I do not feel it is innovative enough .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , predicting neural responses at this scale ( several thousand simultaneous recordings ) to natural movies in awake mice , while taking into account confounding animal state variables , is a relatively new task with no successful models .",
    "NOVELTY"
  ],
  [
    "The approach towards certifying robustness of neural networks is novel and very different from existing approaches .",
    "NOVELTY"
  ],
  [
    "Novel , timely , and of broad interest .",
    "NOVELTY"
  ],
  [
    "ORIGINALITY To my knowledge the proposed method is novel .",
    "NOVELTY"
  ],
  [
    "The paper also , to the best of my knowledge , is the first to use flow-based methods for lossless compression , concurrent with",
    "NOVELTY"
  ],
  [
    "This paper is among the first papers on two emerging lines of research",
    "NOVELTY"
  ],
  [
    "The authors use H-divergence idea to provide bounds for regression problems- which is new",
    "NOVELTY"
  ],
  [
    "these do not provide a significant technical extension to the results in",
    "NOVELTY"
  ],
  [
    "I do not feel the quality , originality , and significance of the work to be high enough to merit acceptance",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work that models normalizing flows in the sequential setting in this way",
    "NOVELTY"
  ],
  [
    "Overall I found the paper interesting",
    "NOVELTY"
  ],
  [
    "I believe the idea is nice",
    "NOVELTY"
  ],
  [
    "My main concern is about the contribution of the paper .",
    "NOVELTY"
  ],
  [
    "However , there is no novelty in the \u00e2\u0080\u009cannotation model\u00e2\u0080\u009d ( relation between the ground clustering and the annotations ) .",
    "NOVELTY"
  ],
  [
    "This model is not novel",
    "NOVELTY"
  ],
  [
    "Overall I feel positive about the proposed method",
    "NOVELTY"
  ],
  [
    "and using the spectral relaxation of K-means for deep clustering is novel and original",
    "NOVELTY"
  ],
  [
    "limited novelty",
    "NOVELTY"
  ],
  [
    "I believe that the idea of stochastic Bellman operators is interesting",
    "NOVELTY"
  ],
  [
    "( though a bit incremental , due to the presence of [ 5,12 ] ) in the context of gap-action increasing Bellman operator",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "are quite basic and test a straightforward implication of the suggested approach .",
    "NOVELTY"
  ],
  [
    "The novelty seems to be too limited .",
    "NOVELTY"
  ],
  [
    "The paper is very interesting , but the novelty is low compared to the referenced work .",
    "NOVELTY"
  ],
  [
    "I found this paper interesting",
    "NOVELTY"
  ],
  [
    "The end-to-end framework is also quite",
    "NOVELTY"
  ],
  [
    "I consider the work as a good conference contribution .",
    "NOVELTY"
  ],
  [
    "As far as I am aware , the framework proposed in this paper is original .",
    "NOVELTY"
  ],
  [
    "The theorems appear to be",
    "NOVELTY"
  ],
  [
    "novel and the tools used to establish these results are drawn on from other works",
    "NOVELTY"
  ],
  [
    "The main contribution is experiments comparing various existing distillation methods to different parts of the model",
    "NOVELTY"
  ],
  [
    "prediction layer ) , so is not particularly novel in contributing new techniques for distillation .",
    "NOVELTY"
  ],
  [
    "Novelty .The idea of simulating the effect of iterative attacks using two distinct steps is novel and appealing to me .",
    "NOVELTY"
  ],
  [
    "The idea presented in the paper is interesting",
    "NOVELTY"
  ],
  [
    "and makes some good contributions",
    "NOVELTY"
  ],
  [
    "The approach the authors take is interesting and different from what has done before",
    "NOVELTY"
  ],
  [
    "The novelty is in combining pre-existing ideas .",
    "NOVELTY"
  ],
  [
    ".Therefore the originality is in some sense reduced",
    "NOVELTY"
  ],
  [
    "The main idea in this paper is interesting",
    "NOVELTY"
  ],
  [
    "The overall idea is not novel .",
    "NOVELTY"
  ],
  [
    "The contributions seem to be in the computational neuroscience of navigation",
    "NOVELTY"
  ],
  [
    "3- Paper has a good technical contribution",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "There is not very much technical novelty in this part .",
    "NOVELTY"
  ],
  [
    "is novel in the sense that it extends the recent previous works on model-free learning of MFGs to continuous state-action state spaces",
    "NOVELTY"
  ],
  [
    "The proposal of constructing meta-learning based on unsupervised learning seems to be original .",
    "NOVELTY"
  ],
  [
    "An interesting approach to meta-learning is presented .",
    "NOVELTY"
  ],
  [
    "The idea of using heads ( or branches ) in deep networks is not entirely novel",
    "NOVELTY"
  ],
  [
    "The work is rather incremental :",
    "NOVELTY"
  ],
  [
    "The variance reduction technique used in this article is very similar to the de-bias technique used in Javanmard and Montanari ( 2015 ) and Lee et a",
    "NOVELTY"
  ],
  [
    "( 2015 ) , so the theoretical contribution is kind of limited .",
    "NOVELTY"
  ],
  [
    "The authors provide a novel , interesting , and simple algorithm capable of training with limited memory .",
    "NOVELTY"
  ],
  [
    "My major concern of this paper is the lack of novelty .",
    "NOVELTY"
  ],
  [
    "The paper presents new insights into element-wise multiplication operation which has been previously used in VQA literature",
    "NOVELTY"
  ],
  [
    "2 .The paper presents a new model for the task of VQA that beats the current state-of-art by 0.42",
    "NOVELTY"
  ],
  [
    "the theoretical contribution that with the added the delta the algortihm converges , seems quite trivial",
    "NOVELTY"
  ],
  [
    "This result is also insightful .",
    "NOVELTY"
  ],
  [
    "mainly because of the insights and rigor that it brings to the capsule networks idea",
    "NOVELTY"
  ],
  [
    "contribution to existing machine learning approaches to automated programming that is achieved by training on a large corpus of Android apps",
    "NOVELTY"
  ],
  [
    "and a nice break from more traditional approaches of learning abstract syntax trees",
    "NOVELTY"
  ],
  [
    "the novelty of the approach in the paper comes under question",
    "NOVELTY"
  ],
  [
    "The paper adds novelty in addressing finite precision arithmetic and general activation functions relative to previous verification approaches .",
    "NOVELTY"
  ],
  [
    "I do n't find the proposed system different from the framework of artificial neural network .",
    "NOVELTY"
  ],
  [
    "Given all the prior works that smooth GAN training , the idea that integrates image quality assessment metrics with GANs sounds interesting .",
    "NOVELTY"
  ],
  [
    "This paper presents a novel way to do unsupervised pretraining in a deep convolutional network setting (",
    "NOVELTY"
  ],
  [
    "All in all , this is an interesting piece of",
    "NOVELTY"
  ],
  [
    "Originality The idea of knockoff filters is not new , but",
    "NOVELTY"
  ],
  [
    "the DL architecture required to exploit this idea , as proposed in this paper , is new and shown to be critical .",
    "NOVELTY"
  ],
  [
    "I think that the idea is interesting",
    "NOVELTY"
  ],
  [
    "the authors proposed the expected gradients algorithm which is a nice extension of the integrated gradients algorithm",
    "NOVELTY"
  ],
  [
    "The scenario presented is in fact very common in many fields",
    "NOVELTY"
  ],
  [
    "and mapping these alternatives to a common semantic class is not new .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the explanation of universal perturbations in terms of positive curvature is novel .",
    "NOVELTY"
  ],
  [
    "Considering the problems below , I don \u2019 t see any reliable contribution in this paper .",
    "NOVELTY"
  ],
  [
    "The ideas in this paper are very interesting",
    "NOVELTY"
  ],
  [
    "The paper does not have a significant novel contribution , but rather extends GANs ( improved-GAN mostly ) with a manifold regularization , which has been explored in many other works Kumar et al",
    "NOVELTY"
  ],
  [
    "The local SGD itself is not new and has been already proposed",
    "NOVELTY"
  ],
  [
    "Some of the ideas are interesting",
    "NOVELTY"
  ],
  [
    "the novelty is low , this very type of decomposition is already widely studied",
    "NOVELTY"
  ],
  [
    "Applying SVD to the matricized weights of deep neural networks is not new .",
    "NOVELTY"
  ],
  [
    "Of course simultaneously learning projections in two directions , ala auto-encoders , is not new .",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting .",
    "NOVELTY"
  ],
  [
    "The method introduced in this paper is intuitive",
    "NOVELTY"
  ],
  [
    "The loss reweighting and oscillating schemes appear to be just heuristics",
    "NOVELTY"
  ],
  [
    "Both the problem and the proposed approach I would deem fairly original .",
    "NOVELTY"
  ],
  [
    "The idea has already been discussed out in the literature and the novelty of the work seems to be twofold",
    "NOVELTY"
  ],
  [
    "1- The contribution of this work given existing work ( more specifically the famous Chang et al work seems not to be enough for a venue like ICLR .If I want to list the contributions",
    "NOVELTY"
  ],
  [
    "This , although useful , does not introduce a novel technical contribution .",
    "NOVELTY"
  ],
  [
    "method with a collection of multiple novel contributions that are interesting and practical .",
    "NOVELTY"
  ],
  [
    "Teacher/student co-searching via learning two sets of architectures in one supernet seems novel , simple , and effective .",
    "NOVELTY"
  ],
  [
    "The zoomed convolution operator seems like a novel efficient alternative to ( expensive ) dilated convolutions .",
    "NOVELTY"
  ],
  [
    "there are several very interesting empirical findings in this paper",
    "NOVELTY"
  ],
  [
    "This paper contributes some interesting ideas to a recent topic of interest in the community --",
    "NOVELTY"
  ],
  [
    "While I find the paper to contain interesting ideas",
    "NOVELTY"
  ],
  [
    "The idea of interpreting the `` human-likeness `` of program behaviors is interesting , and could help substantially with augmenting the traditionally small clean datasets in program synthesis .",
    "NOVELTY"
  ],
  [
    "Concerns -The learning rate schedule on the CIFAR experiments is unconventional .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited . Modeling longer dialog history ( beyond the current turn ) is not new",
    "NOVELTY"
  ],
  [
    "contains very original ideas , and",
    "NOVELTY"
  ],
  [
    "very interesting result of mapping `` solution `` of unregularised logistic regression",
    "NOVELTY"
  ],
  [
    "In that regard , the idea is not brand new",
    "NOVELTY"
  ],
  [
    "But the technical innovation is fairly modest .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of this work is pretty incremental , and I think it is not quite at the standards for ICLR at this time .",
    "NOVELTY"
  ],
  [
    "Originality* The observation that referring expressions are compositional and that neural networks for VQA should incorporate compositional priors is not novel",
    "NOVELTY"
  ],
  [
    "The paper is a purely empirical study that does not introduce any novel machine learning or evaluation techniques .",
    "NOVELTY"
  ],
  [
    "The novelty is low : the paper is a straightforward application of the variational dropout paper",
    "NOVELTY"
  ],
  [
    "The G-MF and G-BP ( with variants ) algorithms are interesting and provide a better bound on the partition function that the",
    "NOVELTY"
  ],
  [
    "Originality The model is very similar to Mathieu et al , although using image pairs rather than category labels directly . The idea of weakly-supervised disentangling has also been explored in many other papers",
    "NOVELTY"
  ],
  [
    "Yang et al .The description of reference ambiguity seems new and potentially valuable",
    "NOVELTY"
  ],
  [
    "and this paper makes a modest advance in terms of the model and potentially in terms of the theory .",
    "NOVELTY"
  ],
  [
    "The idea of quantization and the analysis of quantized SGD is not new .",
    "NOVELTY"
  ],
  [
    "The authors provide a novel dimension independent bound which does seem novel .",
    "NOVELTY"
  ],
  [
    "This result to my knowledge is new ,",
    "NOVELTY"
  ],
  [
    "The 2.1-2.2 on extension of the connection between regularized solution and maximum margin solution to general homogeneous models and to non-asymptotic regimes -- this is in my opinion key contribution of the paper and an important result",
    "NOVELTY"
  ],
  [
    "I think the ideas proposed in this paper are interesting .",
    "NOVELTY"
  ],
  [
    "I see the the work as a nice extension/improvement of the I2A ( Weber et .al .2017 ) and the ATreeC/TreeQN work ( Fraquhar et .al .2017",
    "NOVELTY"
  ],
  [
    "To my knowledge this is novel",
    "NOVELTY"
  ],
  [
    "The paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "This idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the paper presents a novel idea , which is well motivated and",
    "NOVELTY"
  ],
  [
    "I like the underlying idea of this paper , that of applying max margin learning to potential games .",
    "NOVELTY"
  ],
  [
    "The proposed approach seems incremental and lacks novelty .",
    "NOVELTY"
  ],
  [
    "This approach has been used before for active learning with neural networks ensembles",
    "NOVELTY"
  ],
  [
    "1995 .The used model , PETS , is also not novel and the proposed methodology for having first an unsupervised learning phase and then a new specific learning task is also not very innovative .",
    "NOVELTY"
  ],
  [
    "Given the lack of a rigorous evaluation framework and the lack of novelty of the proposed methods , I believe the significance of the contribution is very low .",
    "NOVELTY"
  ],
  [
    "I believe the paper is quite insightful ,",
    "NOVELTY"
  ],
  [
    "I find the result of this paper rather incremental .",
    "NOVELTY"
  ],
  [
    "This sort of an RNN-based auto-encoder + hypernetwork combination is novel and interesting .",
    "NOVELTY"
  ],
  [
    "While I found the idea appealing",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "However the paper mostly provides a framework that relies on existing work .",
    "NOVELTY"
  ],
  [
    "This is fine , but not of great novelty .",
    "NOVELTY"
  ],
  [
    "However , novelty of the approach is limited , and I am",
    "NOVELTY"
  ],
  [
    "From an architectural point of view , the contribution is minimal .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is fairly low",
    "NOVELTY"
  ],
  [
    "The ideas used in this paper are not entirely new .",
    "NOVELTY"
  ],
  [
    "Learning both weights and label predictions in SSL seems to be novel",
    "NOVELTY"
  ],
  [
    "The perspective of norm constraint is different from the traditional approximation theory and may serve as a good contribution to the community .",
    "NOVELTY"
  ],
  [
    "There is not a huge algorithm novelty for the methods proposed in this paper",
    "NOVELTY"
  ],
  [
    "As far as I know , the work is based on an original idea and problem formulation .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed tree positional encodings are novel .",
    "NOVELTY"
  ],
  [
    "However this general formulation is not novel to this paper",
    "NOVELTY"
  ],
  [
    "However , novelty is limited",
    "NOVELTY"
  ],
  [
    "Many claims and observations appear trivial and well-known",
    "NOVELTY"
  ],
  [
    "Overall , I like the main idea of the paper .",
    "NOVELTY"
  ],
  [
    "the crashed cars dataset is interesting",
    "NOVELTY"
  ],
  [
    "Strengths The idea of thinking about sketches in terms of Bayesian nonparametric is interesting to me . The combination of an infinite-dimensional process with suitable independence structure ( the underlying Poisson random measure ) is promising and has the potential to give analytic posterior ( which is key for their use in these problems )",
    "NOVELTY"
  ],
  [
    "this presents a relatively simplistic way of deriving representations of saliency and combining these with inputs for training that builds robustness against white and black box attacks",
    "NOVELTY"
  ],
  [
    "I think that the paper makes some interesting contributions and",
    "NOVELTY"
  ],
  [
    "I am not convinced that there is enough novelty and substance on this",
    "NOVELTY"
  ],
  [
    "Although the basic components of the architecture are pre-existing",
    "NOVELTY"
  ],
  [
    "Overall , the introduced method is novel and the results it allows generating are interesting .",
    "NOVELTY"
  ],
  [
    "The main originality is contained in two particular aspects",
    "NOVELTY"
  ],
  [
    "the idea contained in the paper is not a very big contribution to the field but still remains interesting",
    "NOVELTY"
  ],
  [
    "My main concern with this submission is its novelty .",
    "NOVELTY"
  ],
  [
    "However , at the moment , I do not see much novelty in this paper comparing to previous work .",
    "NOVELTY"
  ],
  [
    "The paper was improved significantly but still lacks novelty .",
    "NOVELTY"
  ],
  [
    "At the heart of the technique lies the stacking of GANS and the authors claim to be proposing a novel model here",
    "NOVELTY"
  ],
  [
    "the differences to another very similar work to that of the authors",
    "NOVELTY"
  ],
  [
    "the authors also do not offer any novel technical insights compared to that paper and actually fall short in positioning their paper in the broader context of approximate inference for generative models . Given these failings , this paper has very little novelty and does not perform accurate attribution of credit to the community .",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting and novel - I 've not previously seen the idea of predicting different picewise constant projections instead of directly predicting the desired output",
    "NOVELTY"
  ],
  [
    "While the method is interesting",
    "NOVELTY"
  ],
  [
    "To my understanding , the contribution is of a primarily theoretical interest .",
    "NOVELTY"
  ],
  [
    "with a grounded theoretical frameworks and based on an interesting novel idea . Although no ingredient of the pipeline could be considered really novel , the overall solution can be deemed original because of the proposed smart combination of the components .",
    "NOVELTY"
  ],
  [
    "Overall , this paper could provide a novel insight into the role of modeling morphology as latent variables .",
    "NOVELTY"
  ],
  [
    "The overall idea is interesting and has many potentials .",
    "NOVELTY"
  ],
  [
    "It offers a new model ( Theseus ) and an elegant application Jaakkola and Haussler\u00e2\u0080\u0099s Fisher Kernel idea",
    "NOVELTY"
  ],
  [
    "The idea sounds interesting .",
    "NOVELTY"
  ],
  [
    "I am concerned , though , that the paper does n't make a substantial novel contribution to representation learning .",
    "NOVELTY"
  ],
  [
    "not much of a contribution",
    "NOVELTY"
  ],
  [
    "The convergence theorem does n't seem to be much of a contribution in my opinion , either to the optimization or the deep learning community .",
    "NOVELTY"
  ],
  [
    "I want to acknowledge that while the motivation and contributions are in my opinion",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "While the idea of thinking about such a taxonomy is novel ,",
    "NOVELTY"
  ],
  [
    "Novel attempt at understanding prototypes .",
    "NOVELTY"
  ],
  [
    "Nevertheless , the paper proposes new original ideas that are contribute to this line of work and that admit further extension .",
    "NOVELTY"
  ],
  [
    "but my major concern is about the novelty of this work , given the fact that the structure of the proposed stochastic layers is quite similar to VIBNet",
    "NOVELTY"
  ],
  [
    "the method would be a moderate extension from related paper [ 20 ] . The methodological novelty might be limited .",
    "NOVELTY"
  ],
  [
    "I liked the idea of learning multiple distance metrics to utilize multiple different types of similarities in the data .",
    "NOVELTY"
  ],
  [
    "in fact these are not really new discoveries",
    "NOVELTY"
  ],
  [
    "their influences are rather insignificant `` seem a bit careless to me",
    "NOVELTY"
  ],
  [
    "I am not sure how novel is this approach .",
    "NOVELTY"
  ],
  [
    "The paper presents novel results by utilizing the ideas from the field of communication-efficient distributed optimization .",
    "NOVELTY"
  ],
  [
    "As far as I know this paper is original .",
    "NOVELTY"
  ],
  [
    "So I do n't find a big methodological novelty .",
    "NOVELTY"
  ],
  [
    "The approach is novel and the gain in complexity is significant .",
    "NOVELTY"
  ],
  [
    "The experiments are rather toy",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "Given that the experimental results are also not particularly novel",
    "NOVELTY"
  ],
  [
    "Nevertheless , this approach is very similar to TorusE [ 1 ] , since the element-wise rotation on the complex plane is somehow related to transformation on high-dimensional Torus .",
    "NOVELTY"
  ],
  [
    "I found this paper lacking in terms of contributions .",
    "NOVELTY"
  ],
  [
    "Both dilated convolutions and the fusion module are not novel .",
    "NOVELTY"
  ],
  [
    "I think that this paper should be rejected on the basis of insufficient contributions",
    "NOVELTY"
  ],
  [
    "This is an interesting paper that addresses shortcomings of existing approaches",
    "NOVELTY"
  ],
  [
    "This paper presents a nice idea",
    "NOVELTY"
  ],
  [
    "the ideas seem intriguing",
    "NOVELTY"
  ],
  [
    "on the computational and practical side , I think that there is a truly new contribution for the special topic of norms crafting .",
    "NOVELTY"
  ],
  [
    "The view of approximating the predictive distribution over simplex",
    "NOVELTY"
  ],
  [
    "As far as I know , the method is novel .",
    "NOVELTY"
  ],
  [
    "This work is builds on a wide body of work on learned priors",
    "NOVELTY"
  ],
  [
    "This approach seems novel as far as I 'm aware",
    "NOVELTY"
  ],
  [
    "8/10 A decent geodesic MCMC algorithm is provided ,",
    "NOVELTY"
  ],
  [
    "not novel in itself , but",
    "NOVELTY"
  ],
  [
    "first time applied to the problem considered .",
    "NOVELTY"
  ],
  [
    "of my knowledge",
    "NOVELTY"
  ],
  [
    "The theorem 2.1 is a significant contribution",
    "NOVELTY"
  ],
  [
    "The theoretical contribution mentioned in the appendix does not really seem to be a contribution",
    "NOVELTY"
  ],
  [
    "Overall , I like the premise of this paper and agree that with the potential benefits of the dataset generated .",
    "NOVELTY"
  ],
  [
    "While this paper is as far as I can tell novel in how it does what it does",
    "NOVELTY"
  ],
  [
    "I think this is a novel idea and I have not seen this before .",
    "NOVELTY"
  ],
  [
    "I think the idea of this paper is clear",
    "NOVELTY"
  ],
  [
    "general , I find many of the observations in this paper interesting",
    "NOVELTY"
  ],
  [
    "promising",
    "NOVELTY"
  ],
  [
    "As such , this work has limited novelty but provides good empirical contributions",
    "NOVELTY"
  ],
  [
    "Overall this is a good contribution but for an empirical paper this could be strengthened by considering more domains or tasks and demonstrating the ability of this method to work across the board",
    "NOVELTY"
  ],
  [
    "Novel algorithm and addition of rich java like language in subfield of 'conditional program generation ' proposed",
    "NOVELTY"
  ],
  [
    "The authors present a very intriguing novel approach that in a clear and coherent way . The approach is thoroughly explained for a large audience . The task itself is interesting and novel . The large evaluation section that discusses many different properties is a further indication that this approach is not only novel but also very promising",
    "NOVELTY"
  ],
  [
    "the contribution is very simple and the individual pieces do not seem to be significant contributions .",
    "NOVELTY"
  ],
  [
    "Overall this is an interesting paper but its contribution is very broad rather than having a specific deeper contribution .",
    "NOVELTY"
  ],
  [
    "as the method is n't very novel",
    "NOVELTY"
  ],
  [
    "Method is not very novel",
    "NOVELTY"
  ],
  [
    "Decision The paper",
    "NOVELTY"
  ],
  [
    "however , the impact of the paper might be limited by its limited technical novelty and lack of comparisons to strong baselines .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited as it is a somewhat straightforward extension of prior work .",
    "NOVELTY"
  ],
  [
    "While the findings of this paper are interesting",
    "NOVELTY"
  ],
  [
    "the contributions are clear",
    "NOVELTY"
  ],
  [
    "The authors responded to my concern and I think this submission is a good contribution",
    "NOVELTY"
  ],
  [
    "The ability to learn interpretable meta-models with gradient descent is a good contribution .",
    "NOVELTY"
  ],
  [
    "but it",
    "NOVELTY"
  ],
  [
    "While the main constituent ideas of this paper are not entirely novel , I think the specific combination of tools has not been explored previously .",
    "NOVELTY"
  ],
  [
    "Overall , the novelty of this paper is fairly low and there is still substantial room for improvement in some of the analysis .",
    "NOVELTY"
  ],
  [
    "Novelty The authors did a fine job of completing the picture of statistical minimax rates for total variation classes .",
    "NOVELTY"
  ],
  [
    "it does not offer new algorithmic insights nor fundamentally new proof techniques .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is not clear . Neither L1 no logdet",
    "NOVELTY"
  ],
  [
    "are novel regularizers",
    "NOVELTY"
  ],
  [
    "The key concern is that most of the proposed method is built upon Benzing et al",
    "NOVELTY"
  ],
  [
    "and the original contribution seems limited . While the paper introduces a few optimizations further , this seems to be incremental than originally novel .",
    "NOVELTY"
  ],
  [
    "is empirical and with limited technical novelty",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems original .",
    "NOVELTY"
  ],
  [
    "I believe the algorithm introduced in this paper , if it is presented well , can be an interesting addition to the literature of Deep RL , e.g. , in terms of improving the rate of convergence",
    "NOVELTY"
  ],
  [
    "Pseudo PML is a natural extension of PML and I find the general framework of Algorithm 1 elegant and",
    "NOVELTY"
  ],
  [
    "The idea of the paper is good",
    "NOVELTY"
  ],
  [
    "but the novelty is limited .",
    "NOVELTY"
  ],
  [
    "the idea of using inference for option discovery has already been presented in Daniel2016",
    "NOVELTY"
  ],
  [
    "The assumptions and the overall proof ideas is similar to a previous work [",
    "NOVELTY"
  ],
  [
    "However , extending the analysis to residual networks is non-trivial and novel , as far as I know .",
    "NOVELTY"
  ],
  [
    "how the paper overcomes certain limitations in previously introduced methods of interest to the field .",
    "NOVELTY"
  ],
  [
    "This seems to be a promising approach compared to previous methods which rely on specialized architectures ( coupling blocks , etc . )",
    "NOVELTY"
  ],
  [
    "is original in its use of deep reinforcement learning and graph neural networks to learn novel search control heuristics for SAT solving",
    "NOVELTY"
  ],
  [
    "While the techniques used are not novel themselves , the application domain is .",
    "NOVELTY"
  ],
  [
    "While their mathematical justification is interesting in relation to previous work , it\u00e2\u0080\u0099s not particularly novel or interesting in and of itself .",
    "NOVELTY"
  ],
  [
    "but to my knowledge no one has done this analysis before",
    "NOVELTY"
  ],
  [
    "The use of gaussian process to model the time dependency along with pseudo point from RNN is original ,",
    "NOVELTY"
  ],
  [
    "but not",
    "NOVELTY"
  ],
  [
    "The novelty of this",
    "NOVELTY"
  ],
  [
    "paper seems reasonably high",
    "NOVELTY"
  ],
  [
    "Your cascading DQN idea seems like a good one",
    "NOVELTY"
  ],
  [
    "The results",
    "NOVELTY"
  ],
  [
    "of this paper unifies and",
    "NOVELTY"
  ],
  [
    "generalizes previous works on this topic",
    "NOVELTY"
  ],
  [
    "The main issue is that I am not sure if the level of novelty is sufficient for ICLR . The contributions of the paper consist of a new loss term and a modification of the other loss term in OE [ 1 ] .",
    "NOVELTY"
  ],
  [
    "Attacking it with trained deep neural nets is a nice idea that should be of interest to the NIPS",
    "NOVELTY"
  ],
  [
    "The scope and novelty of this contribution is not huge since",
    "NOVELTY"
  ],
  [
    "but I do not think this is significantly novel .",
    "NOVELTY"
  ],
  [
    "The CartoonSet dataset and the new task , which is called semantic style transfer between two domains , are nice contributions of this paper .",
    "NOVELTY"
  ],
  [
    "In terms of technical contributions , it is not significant to have the X-shaped GAN or the straightforward semantic consistency loss",
    "NOVELTY"
  ],
  [
    "My biggest concern about this work is the lack of novelty .",
    "NOVELTY"
  ],
  [
    "I still think that the paper lacks novelty , however .",
    "NOVELTY"
  ],
  [
    "the technical novelty together with the fine empirical evaluation are just good enough for ICLR",
    "NOVELTY"
  ],
  [
    "The method lacks algorithmic novelty",
    "NOVELTY"
  ],
  [
    "severely lacks algorithmic novelty",
    "NOVELTY"
  ],
  [
    "My main concern with this work is novelty .",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper does not present substantially new ideas to merit publication",
    "NOVELTY"
  ],
  [
    "This is an original research work especially of the robustness certification with the general activation functions , which may provide a good direction for the future research on this problem .",
    "NOVELTY"
  ],
  [
    "The paper would be a much stronger contribution",
    "NOVELTY"
  ],
  [
    "The novelty of the paper lies in the analysis",
    "NOVELTY"
  ],
  [
    "Fairly simple objective , in line with previous work on unsupervised learning methods to representation learning in RL",
    "NOVELTY"
  ],
  [
    "The methods pertaining hierarchical models are interesting",
    "NOVELTY"
  ],
  [
    "My main concern is with the novelty . The work does not seem to be very novel .",
    "NOVELTY"
  ],
  [
    "the main contribution of the paper is not clear (",
    "NOVELTY"
  ],
  [
    "It does not provide a novel reward shaping method",
    "NOVELTY"
  ],
  [
    "I am not sure what \u2019 re the contributions of",
    "NOVELTY"
  ],
  [
    "This model is a relatively simple extension of the Neural Statistician , so the novelty of the idea is not enough to counterbalance the lack of quantitative evaluation",
    "NOVELTY"
  ],
  [
    "concepts into our training of VAEs",
    "NOVELTY"
  ],
  [
    "The idea per se is not new",
    "NOVELTY"
  ],
  [
    "The introduction of sigma-algebra formulation of expressiveness is very novel and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed method is new and interesting",
    "NOVELTY"
  ],
  [
    "topic of deep learning on set functions .",
    "NOVELTY"
  ],
  [
    "The idea for applying neural network with an attention mechanism to approximate DPP probability seems to be new",
    "NOVELTY"
  ],
  [
    "but the novelty of the idea seems to be limited as it just applies existing techniques to a new scenario without a novel adaptation to it .",
    "NOVELTY"
  ],
  [
    "I believe this is a significant contribution and it should appear in NeurIPS",
    "NOVELTY"
  ],
  [
    "this paper is at the very least an interesting theoretical contribution",
    "NOVELTY"
  ],
  [
    "The paper presents some interesting ideas and results . In general , I like the idea of the algorithm .",
    "NOVELTY"
  ],
  [
    "I think this paper has some new ideas",
    "NOVELTY"
  ],
  [
    "I think this paper has some new ideas",
    "NOVELTY"
  ],
  [
    "I also like the idea of the algorithm .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is not mature enough to be accepted : there is not enough novelty , and the results lack of novelty , enough delta in performance from prior work",
    "NOVELTY"
  ],
  [
    "This work is innovative in generalizing markov decision process to multi-view scenarios .",
    "NOVELTY"
  ],
  [
    "This paper presents a novel positional embedding for transformer networks . The definition of this embedding , specifically designed to support tree-like datasets , is a novel contribution .",
    "NOVELTY"
  ],
  [
    "While introducing a novel mechanism",
    "NOVELTY"
  ],
  [
    "as it is the first to propose a helpful inductive bias for transformers to handle tree-like datasets",
    "NOVELTY"
  ],
  [
    "I believe that the idea is interesting",
    "NOVELTY"
  ],
  [
    "This paper has good idea",
    "NOVELTY"
  ],
  [
    "I agree with Reviewer 2 that the paper provide some insight from Physics and can be an interesting contribution to the community .",
    "NOVELTY"
  ],
  [
    "The algorithm is similar to other importance sampling algorithms",
    "NOVELTY"
  ],
  [
    "but I thought the way that it used SDDs and sampled variables dynamically was clever .",
    "NOVELTY"
  ],
  [
    "The idea of multitask learning for sentence representations is not new to this paper",
    "NOVELTY"
  ],
  [
    "Without claiming to know all relevant literature , I found the derived bounds insightful and interesting .",
    "NOVELTY"
  ],
  [
    "5 .Novelty with respect to OWM is rather small .",
    "NOVELTY"
  ],
  [
    "A major criticism I have with this paper is that there is little novelty here .",
    "NOVELTY"
  ],
  [
    "So although the work is solid , the lack of originality lets it down .",
    "NOVELTY"
  ],
  [
    "The originality is relative low though",
    "NOVELTY"
  ],
  [
    "Overall , I found the idea to employ FLIP for Lagrangian learning tasks novel and very interesting .",
    "NOVELTY"
  ],
  [
    "the direction this paper takes is certaily new and interesting",
    "NOVELTY"
  ],
  [
    "The work does not include original ideas .",
    "NOVELTY"
  ],
  [
    "1 The novelty is relatively limited , as the technical parts are strongly relevant to the previous works .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is incremental and not technically sound .",
    "NOVELTY"
  ],
  [
    "and the model seems interesting and , as far as I can tell , also novel .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "and could be an interesting contribution .",
    "NOVELTY"
  ],
  [
    "This is the main idea that gives them an edge over the analysis in Dekel et al'15 and which gives the improved regret rates over Flaxman et al .I found the paper very interesting",
    "NOVELTY"
  ],
  [
    "and the authors provide an improvement over the state of the art with a very simple algorithm that elegantly uses the optimistic learning framework of Rakhlin and Shridharan .",
    "NOVELTY"
  ],
  [
    "The metric proposed in this paper is based on an interesting and also innovative observation that samples in each class will concentrate in a convex cone in the embedding space",
    "NOVELTY"
  ],
  [
    "I like this observation since several existing theoretical results have similar implications although in far simpler settings",
    "NOVELTY"
  ],
  [
    "2 .The major issue is that the proposed algorithm and the contribution ( improvement of generalization ) is not novel .",
    "NOVELTY"
  ],
  [
    "the problem setup and loss for DENNs are not very representative of typical applications of neural networks",
    "NOVELTY"
  ],
  [
    "The residual binarization idea is interesting .",
    "NOVELTY"
  ],
  [
    "The proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "but my major concern is the limited theoretical contribution , given the fact that this work is mainly based on set-input neural networks introduced in Ref .",
    "NOVELTY"
  ],
  [
    "I recommend a weak reject as the technical contribution of the paper seems rather limited",
    "NOVELTY"
  ],
  [
    "The strategy adopted in the proposed pipeline , which break down the task into two step , looks interesting .",
    "NOVELTY"
  ],
  [
    "However , I do not consider this strategy completely novel , since each component of the proposed pipeline is based on existing method .",
    "NOVELTY"
  ],
  [
    "The idea of matching state distributions in the context of learning behaviors is not new .",
    "NOVELTY"
  ],
  [
    "as no new insight is provided over the original Beta-VAE paper",
    "NOVELTY"
  ],
  [
    "I think the paper has novelty but",
    "NOVELTY"
  ],
  [
    "I do not find the improvement brought by the paper very significant compared to the standard greedy methods",
    "NOVELTY"
  ],
  [
    "The main technical contribution is therefore only in changing the unidirectional architecture to bidirectional",
    "NOVELTY"
  ],
  [
    "Although technical novelty is limited ( first weakness )",
    "NOVELTY"
  ],
  [
    "I think there is novelty in the paper 's systematic experimental investigation",
    "NOVELTY"
  ],
  [
    "I think this is a decent paper with some interesting ideas",
    "NOVELTY"
  ],
  [
    "It seems that the two main contributions are related to the language .",
    "NOVELTY"
  ],
  [
    "the paper overall looks incremental , so it is a paper nice to have , but its acceptance seems to be depending on the quality of other papers",
    "NOVELTY"
  ],
  [
    "The design of distribution of the loss vectors looks nontrivial to me",
    "NOVELTY"
  ],
  [
    "3.1 Strengths This is a solid submission that extends previous work",
    "NOVELTY"
  ],
  [
    "This is one of the first steps into a general reduction framework for this kind of trade-off .",
    "NOVELTY"
  ],
  [
    "5.1 Strengths The algorithm and the theoretical results are original .",
    "NOVELTY"
  ],
  [
    "-",
    "NOVELTY"
  ],
  [
    "The paper is in a way a very clever approach by using the well studied technique of boosting and applying it in a sequential manner .",
    "NOVELTY"
  ],
  [
    "There is nothing strikingly novel in this work , using unlabeled test samples in a transductive way seem to help slightly",
    "NOVELTY"
  ],
  [
    "The paper also proposes a pretty smart idea",
    "NOVELTY"
  ],
  [
    "I like the idea for this paper quite a bit , it really got me thinking",
    "NOVELTY"
  ],
  [
    "Unfortunately , as it is , it also feels a bit spare in terms of contributions .",
    "NOVELTY"
  ],
  [
    "and very insightful",
    "NOVELTY"
  ],
  [
    "One might worry that the main result of regularizing the weighting scheme by adding a small diagonal matrix to the empirical covariance of the control variates before inversion is minor",
    "NOVELTY"
  ],
  [
    "I found this derivation very illuminating and relevant .",
    "NOVELTY"
  ],
  [
    "The authors present a nice introduction into the idea of modelling sets of topics , i.e .sets of points on a simplex , as the geometric structure of a polytope",
    "NOVELTY"
  ],
  [
    "It seems that the authors do not introduce new ideas or techniques in the analysis .",
    "NOVELTY"
  ],
  [
    "The contribution seems not novel and enough .",
    "NOVELTY"
  ],
  [
    "leads to novel regularization effect on both models",
    "NOVELTY"
  ],
  [
    "Both the idea and the experiment results are interesting .",
    "NOVELTY"
  ],
  [
    "Although it is presents incremental additions to prior work",
    "NOVELTY"
  ],
  [
    "While I find the overall idea interesting",
    "NOVELTY"
  ],
  [
    "While I find the overall idea interesting",
    "NOVELTY"
  ],
  [
    "Formulation",
    "NOVELTY"
  ],
  [
    "The idea is definitely interesting and I can see how this would benefit the practitioner",
    "NOVELTY"
  ],
  [
    "the idea of designing a model that takes local information about the function as input and outputs an update , using a hidden state to summarize history , is very appealing and could unify a lot of the current techniques using stochastic gradient , or variants thereof .",
    "NOVELTY"
  ],
  [
    "The problem is novel",
    "NOVELTY"
  ],
  [
    "so in that perspective , its novelty is incremental",
    "NOVELTY"
  ],
  [
    "I understand that the problem might be new",
    "NOVELTY"
  ],
  [
    "In sum , I think the problem looks interesting and novel",
    "NOVELTY"
  ],
  [
    "but the novelty of proposed model seems incremental ,",
    "NOVELTY"
  ],
  [
    "This paper has good novelty in using the Taylor approximation thus greatly simplifying the analysis of the behaviour of the model .",
    "NOVELTY"
  ],
  [
    "and good novelty",
    "NOVELTY"
  ],
  [
    "This is a nice idea",
    "NOVELTY"
  ],
  [
    "I find the proposed algorithmic approach interesting .",
    "NOVELTY"
  ],
  [
    "From technical point of view , the construction of stochastic correlated losses used for Theorem 1 and 2 ( zero order bounds ) and its proof seems particularly interesting ,",
    "NOVELTY"
  ],
  [
    "Overall , I do find the federated dropout idea quite interesting .",
    "NOVELTY"
  ],
  [
    "The work is novel in the way it proposes to measure memorization to the best of the reviewer \u2019 s knowledge .",
    "NOVELTY"
  ],
  [
    "the novel insights and/or the practical usefulness of the proposed method seem very limited .",
    "NOVELTY"
  ],
  [
    "The paper puts forward an interesting observation using a novel approach .",
    "NOVELTY"
  ],
  [
    "Finally , one can argue that this work is incremental",
    "NOVELTY"
  ],
  [
    "Methodology wise , there are no novel components that offer a proven advantage with respect to past methods .",
    "NOVELTY"
  ],
  [
    "Originality The idea is new as far as I can tell .",
    "NOVELTY"
  ],
  [
    "The results seem to outperform existing methods on the introduced dataset and the dataset itself is a relevant contribution .",
    "NOVELTY"
  ],
  [
    "This works lacks novelty since the main idea is just a simple concatenation of a JPEG-artifact-removal model and a super resolution model .",
    "NOVELTY"
  ],
  [
    "-Their technique of Lagrangian formulation is very similar to previous works .",
    "NOVELTY"
  ],
  [
    "The technique used is not very novel and is similar in spirit to other approaches .",
    "NOVELTY"
  ],
  [
    "m not sure how novel this particular combination is",
    "NOVELTY"
  ],
  [
    "so having both available is a great contribution",
    "NOVELTY"
  ],
  [
    "So in that sense I consider the main idea of the paper original .",
    "NOVELTY"
  ],
  [
    "The paper introduces an elegant method to train a single feed-forward style transfer network with a large number of styles",
    "NOVELTY"
  ],
  [
    "this is a good paper presenting an elegant and valuable contribution",
    "NOVELTY"
  ],
  [
    "Novelty of that paper is the new design of PPL .",
    "NOVELTY"
  ],
  [
    "but maybe ICLR paper is not the best format to present such kind of novelty",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "proposes",
    "NOVELTY"
  ],
  [
    "but have several drawbacks and conference paper format is not the best way to present such kind of novelty .",
    "NOVELTY"
  ],
  [
    "The technical novelty is quite limited",
    "NOVELTY"
  ],
  [
    "I worry that this is quite a fragile approach to this problem .",
    "NOVELTY"
  ],
  [
    "I personally find the theoretical argument behind the proposed scoring function very interesting",
    "NOVELTY"
  ],
  [
    "the contribution seems rather small to be accepted for ICLR . This is a straight application and combination of existing pieces with not much originality and without being backed up by very strong experimental results",
    "NOVELTY"
  ],
  [
    "although the proposed",
    "NOVELTY"
  ],
  [
    "method seems a direct application of Arora et al",
    "NOVELTY"
  ],
  [
    ".,2016a , I find their extension novel and quite interesting ,",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this is the first paper to study differential privacy for GANs .",
    "NOVELTY"
  ],
  [
    "This paper seems to be making an interesting insight .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , such pooling functions are novel .",
    "NOVELTY"
  ],
  [
    "The theoretical results are novel , and they provide matching upper and lower bounds on the competitive ratio , thus settling the approximability of the problem . The algorithms are very natural , and the analyses are insightful .",
    "NOVELTY"
  ],
  [
    "because the contributions of the paper seem very vague and are neither thoroughly defined nor tested .",
    "NOVELTY"
  ],
  [
    "Overall , the paper seemed original with a comprehensive set of results for a carefully set up and clearly presented model for an important problem .",
    "NOVELTY"
  ],
  [
    "1 .The main methodological contribution ( using HD vectors ) are a nice contribution .",
    "NOVELTY"
  ],
  [
    "the incremental nature of the contribution lead me to believe that this paper does not represent a sufficient advance to warrant publication .",
    "NOVELTY"
  ],
  [
    "The paper novelty is somewhat limited as it is mostly a combination of previously existing techniques .",
    "NOVELTY"
  ],
  [
    "I do not think its contributions rise to the level required for an ICLR paper",
    "NOVELTY"
  ],
  [
    "the idea of the proposed approach is interesting : using variational inference for binary weight neural networks .",
    "NOVELTY"
  ],
  [
    "The approach is novel and well motivated .",
    "NOVELTY"
  ],
  [
    "The idea of producing orthogonal gradients across tasks or examples is not new in the context of lifelong/multi-task learning .",
    "NOVELTY"
  ],
  [
    "Overall , this paper presents a novel contribution to reinforcement learning with augmented memory/world-state .",
    "NOVELTY"
  ],
  [
    "I like the idea of constructing the knowledge graph as the agent roll out .",
    "NOVELTY"
  ],
  [
    "The idea of extracting policies corresponding to individual automaton states and making them into options seems novel",
    "NOVELTY"
  ],
  [
    "The idea of leveraging feature groups in a neural network",
    "NOVELTY"
  ],
  [
    "structure",
    "NOVELTY"
  ],
  [
    "the novelty of the RESE model",
    "NOVELTY"
  ],
  [
    "Simple connections between PAC-Bayes bound and entropy SGD objective is the first novelty .",
    "NOVELTY"
  ],
  [
    "The results presented here are interesting and I particularly liked the introduction of the renormalized kernel to study the noiseless case",
    "NOVELTY"
  ],
  [
    "abundance of new ideas and novel content",
    "NOVELTY"
  ],
  [
    "The authors acknowledge that hybridizing the extrinsic CNNs and intrinsic CNNs is not new and several works are cited",
    "NOVELTY"
  ],
  [
    "The idea is very nice , well describes and quite novel in my opinion . I really liked the adoption of classical CFD approaches in learning .",
    "NOVELTY"
  ],
  [
    "Although this contribution is relatively incremental",
    "NOVELTY"
  ],
  [
    "does not really find novel architectures in a broad sense",
    "NOVELTY"
  ],
  [
    "the derivation of the bi-level optimization is interesting",
    "NOVELTY"
  ],
  [
    "and the proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "Somewhat incremental novelty compared to ( Balduzizi et al. , 2016 )",
    "NOVELTY"
  ],
  [
    "Interesting idea .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "Whilst the novelty of the two models is questionable ( they are adaptations of existing models to the task",
    "NOVELTY"
  ],
  [
    "The paper is very novel - the idea of developing a domain specific language full of building blocks to represent various curiosity modules is unique and interesting .",
    "NOVELTY"
  ],
  [
    "Using a ranking loss based on the node distance together with Gaussian embeddings is probably new",
    "NOVELTY"
  ],
  [
    "even if the novelty is not that big",
    "NOVELTY"
  ],
  [
    "Overall the paper brings some new ideas .",
    "NOVELTY"
  ],
  [
    "In terms of the compression algorithm , the idea is novel and makes a lot of sense .",
    "NOVELTY"
  ],
  [
    "TITLE Meta-learning for stochastic gradient mcmc REVIEW SUMMARY A wonderful paper with many great ideas and insights .",
    "NOVELTY"
  ],
  [
    "ORIGINALITY The idea of meta learning sg-mcmc is not something I have seen before , so to my knowledge the idea is original .",
    "NOVELTY"
  ],
  [
    "This paper develops new interesting ideas of broad interest .",
    "NOVELTY"
  ],
  [
    "The paper do not present substantial novelty compared to previous work .",
    "NOVELTY"
  ],
  [
    "3 .Novelty From a methodological point of view the paper is not novel enough .",
    "NOVELTY"
  ],
  [
    "From the application point of view , there is also little novelty given that the paper is tested on action recognition using relatively-small datasets",
    "NOVELTY"
  ],
  [
    "and there is not much novelty about the model",
    "NOVELTY"
  ],
  [
    "The model is novel and the experimental results are convincing . There is enough technical novelty in the paper to accept it .",
    "NOVELTY"
  ],
  [
    "and a novel solution",
    "NOVELTY"
  ],
  [
    "And this paper contributes in a novel way to incorporate the constraints with both soft and hard training strategies .",
    "NOVELTY"
  ],
  [
    "2 .The proposed model differs with other soft-regularization-based methods in terms of an additional distillation process",
    "NOVELTY"
  ],
  [
    "Interesting problem and novel idea .",
    "NOVELTY"
  ],
  [
    "Guiding program synthesis by intermediate execution states is novel ,",
    "NOVELTY"
  ],
  [
    "While there are many previous analyses of least-squares learning in Hilbert spaces , the finding that tail-averaging overcomes saturation is novel and interesting , providing deeper understanding of the role of averaging in SGD .",
    "NOVELTY"
  ],
  [
    "An incremental yet interesting advance in geometric CNNs .",
    "NOVELTY"
  ],
  [
    "The technical novelty seems incremental ( but interesting ) with respect to existing methods .",
    "NOVELTY"
  ],
  [
    "The proposed technique is interesting",
    "NOVELTY"
  ],
  [
    "Though the idea is interesting",
    "NOVELTY"
  ],
  [
    "apparently novel features to their approach which they outline in their paper",
    "NOVELTY"
  ],
  [
    "To my knowledge it is novel and represents a significant contribution which would be of interest to the field .",
    "NOVELTY"
  ],
  [
    "new approach to",
    "NOVELTY"
  ],
  [
    "Hellinger-distance",
    "NOVELTY"
  ],
  [
    "The ideas behind the",
    "NOVELTY"
  ],
  [
    "the novelty is limited",
    "NOVELTY"
  ],
  [
    "There is almost no novelty here .",
    "NOVELTY"
  ],
  [
    "I do not feel that there is sufficient novelty to overcome the issues already raised above . Simply adapting the VAE decoder noise factors via either a trainable noise parameter or an MoG model represents an incremental contribution as similar techniques are exceedingly common .",
    "NOVELTY"
  ],
  [
    "But on a superficial level , I do not believe these contributions are sufficient to salvage the paper",
    "NOVELTY"
  ],
  [
    "The idea of using three terms to model the latent features of a user or an item is interesting , while",
    "NOVELTY"
  ],
  [
    "the novelty",
    "NOVELTY"
  ],
  [
    "is a",
    "NOVELTY"
  ],
  [
    "bit limited",
    "NOVELTY"
  ],
  [
    "The work 's main originality is in introducing the study of CPS as a parameterized computational problem .",
    "NOVELTY"
  ],
  [
    "The techniques used to establish fixed-parameter tractability or intractability are fairly standard in the area and can not be considered new contributions in my opinion",
    "NOVELTY"
  ],
  [
    "whose results are very interesting and inspiring to me",
    "NOVELTY"
  ],
  [
    "I do not have much background in this field , but I found the ideas of DKs very interesting and novel",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , up-to-know there are no accelerated variance-reduced methods having all these advantages simultaneously .",
    "NOVELTY"
  ],
  [
    "I think the main result from the paper ( chaining bounds for mutual information , and application to learning ) is fairly novel and should find broader mathematical use .",
    "NOVELTY"
  ],
  [
    "In terms of novelty , I found the argument about convergence using diagonal Fisher being faster compared with full Fisher quite interesting , and its application for large batch training to be insightful .",
    "NOVELTY"
  ],
  [
    "I do not consider the proposed method a significant improvement over existing techniques for closing the generalization gap for large batch training",
    "NOVELTY"
  ],
  [
    "given that the technical novelty is limited and mostly the paper lives off of the clever application of previously published recurrent VAEs",
    "NOVELTY"
  ],
  [
    "Proposed idea is novel and proposes an interesting change to existing embedding-based few-shot learning techniques .",
    "NOVELTY"
  ],
  [
    "This paper introduces a novel approach to estimating the parameters of a linear dynamical system using MLE",
    "NOVELTY"
  ],
  [
    "the methodological novelty is not large",
    "NOVELTY"
  ],
  [
    "However , the methodological novelty is not large and the paper would need to do a better",
    "NOVELTY"
  ],
  [
    "The idea of matching the future , generated without modelling jump interval , is quite interesting and its interplay with the exploration",
    "NOVELTY"
  ],
  [
    "I think the learning of the abstractions using lower bounds of the mutual information is very interesting",
    "NOVELTY"
  ],
  [
    "but it does n't really advance state-of-the-art in terms of the kind of models we can build",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "The extension of forward prediction to",
    "NOVELTY"
  ],
  [
    "the ideas and the estimators are not novel .",
    "NOVELTY"
  ],
  [
    "1 ] Using Fenchel Conjugate trick to explain minmax formulation in GAN ( Eq . ( 4 ) ) is novel and quite nice .",
    "NOVELTY"
  ],
  [
    "For the stochastic setting , it seems to be novel .",
    "NOVELTY"
  ],
  [
    "I found the unification ideas of high interest",
    "NOVELTY"
  ],
  [
    "Although SGP is not the contribution of this paper",
    "NOVELTY"
  ],
  [
    "the breadth of the experiments conducted by the authors is novel and significant .",
    "NOVELTY"
  ],
  [
    "and their approach is natural and promising",
    "NOVELTY"
  ],
  [
    "On the downside , the theoretical contribution is moderate , and the empirical studies quite",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and effective .",
    "NOVELTY"
  ],
  [
    "This idea is very interesting and tries to marry phrase-based statistical machine translation with neural methods in a principled way .",
    "NOVELTY"
  ],
  [
    "I 'm not an expert on this subfield , but as far as I know the work is original .",
    "NOVELTY"
  ],
  [
    "The approach is interesting",
    "NOVELTY"
  ],
  [
    "The idea seems interesting",
    "NOVELTY"
  ],
  [
    "and would bring in new insights .",
    "NOVELTY"
  ],
  [
    "The proposed measures are natural and intuitive",
    "NOVELTY"
  ],
  [
    "I felt that Reg-Greedy is a really nice idea",
    "NOVELTY"
  ],
  [
    "but the paper did not do it justice .",
    "NOVELTY"
  ],
  [
    "The novelty in terms of the RC model of this paper is limited .",
    "NOVELTY"
  ],
  [
    "Therefore I am not convinced that the improvements are sufficiently innovative for publication at ICLR despite the promising experimental results .",
    "NOVELTY"
  ],
  [
    "The paper appears to be quite original",
    "NOVELTY"
  ],
  [
    "' contribution is clear",
    "NOVELTY"
  ],
  [
    "The idea of unfolding of sparse recovery framework to deep network is not new .",
    "NOVELTY"
  ],
  [
    "However , to my best knowledge , the proposed unfolding scheme of ADMM framework and the associated training scheme are quite novel .",
    "NOVELTY"
  ],
  [
    "the learned shrinkage operator appears similar to the standard shrinkage operator",
    "NOVELTY"
  ],
  [
    "The paper",
    "NOVELTY"
  ],
  [
    "The storage of gradients using appropriate structure is original to me and may be worth disseminating",
    "NOVELTY"
  ],
  [
    "While the experiments are in toy settings , the connection to UCB-H and the novel optimistic Q-function and it \u2019 s training formulation make the contributions of this paper significant .",
    "NOVELTY"
  ],
  [
    "This is to my knowledge novel and promising .",
    "NOVELTY"
  ],
  [
    "I like the proposed model and the fact that it is possible to learn a bijection between the latent variables and actions is cute .",
    "NOVELTY"
  ],
  [
    "Overall , I like the technical contribution of the paper .",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel and seems to be equivariant to SO ( 3 ) rotations , translations , and set permutations .",
    "NOVELTY"
  ],
  [
    "Cons .1 .The novelty of the paper seems to be the combinations of MAML and FiLM , which seems a bit limited .",
    "NOVELTY"
  ],
  [
    "and the reward prediction architecture looks like an original and sound idea .",
    "NOVELTY"
  ],
  [
    "I feel that the paper does not have a sufficient contribution . The theoretical novelty is small ;",
    "NOVELTY"
  ],
  [
    "3 .The novelty compared to ( Abiri & Ohlsson , 2019 ) is very small .",
    "NOVELTY"
  ],
  [
    "Given a graph capsule network is in place , I found the contribution of this paper ( tree capsule network ) is limited .",
    "NOVELTY"
  ],
  [
    "Overall , the paper has a novel approach of tackling model compression that is interesting",
    "NOVELTY"
  ],
  [
    "but the novelty is limited .",
    "NOVELTY"
  ],
  [
    "The main aspects mentioned in the paper , \\epsilon tuning , learning rate warmup and decaying schedule , are not something new and many of which are mentioned or used in the recent advances",
    "NOVELTY"
  ],
  [
    "The proposed method is very natural , and at a high level , introducing a set of quantile levels and providing more expressive class of estimates",
    "NOVELTY"
  ],
  [
    ", which is not new",
    "NOVELTY"
  ],
  [
    "the proposed method does not bring any improvement over the current state-of-the-art in this setup .",
    "NOVELTY"
  ],
  [
    "The key novelty is the integration of the PATE differential privacy framework from recent work",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper is interesting , well written , novel , and therefore appropriate for ICLR .",
    "NOVELTY"
  ],
  [
    "This paper presents interesting theoretical ideas and clearly separates the opportunities for adding/removing hidden units without",
    "NOVELTY"
  ],
  [
    "but if true then I believe that the analysis provided by the authors is both novel and intriguing , and could have nontrivial practical impact on those training neural networks in a distributed fashion",
    "NOVELTY"
  ],
  [
    ", this paper is presented very clearly and provides a novel and important approach for handling current issues in relevant robotics fields .",
    "NOVELTY"
  ],
  [
    "This hardly constitutes a novel contribution , and the paper should not pretend it is .",
    "NOVELTY"
  ],
  [
    "While I like the idea and the",
    "NOVELTY"
  ],
  [
    "This paper builds on existing work in an interesting and novel way .",
    "NOVELTY"
  ],
  [
    "This paper develops new theory to prove guarantees on dictionary selection , which improves on previous work from several years ago",
    "NOVELTY"
  ],
  [
    "as far as I know , the combinaison of Siamese network , nonlocal operation , co-excitation and margin-based loss in a 2 stage detector for 1-shot object detection is novel quality",
    "NOVELTY"
  ],
  [
    "the major problem of this paper is the novelty .",
    "NOVELTY"
  ],
  [
    "Maybe the only novel part is combining the MCMC with the learned generator for generating samples .",
    "NOVELTY"
  ],
  [
    "I personally like the paper as a nice combination of recently developed techniques to improve the algorithm for solving the remaining problem in statistics",
    "NOVELTY"
  ],
  [
    "The major reason is the lack of technical originality .",
    "NOVELTY"
  ],
  [
    "The construction itself would be novel while each component",
    "NOVELTY"
  ],
  [
    "have been already known",
    "NOVELTY"
  ],
  [
    "Section 2.3 , which the authors call it Main Result , is not that novel",
    "NOVELTY"
  ],
  [
    "The algorithm is new",
    "NOVELTY"
  ],
  [
    "but such algorithms for RMDPs is relatively new",
    "NOVELTY"
  ],
  [
    "Although the technique itself is not novel",
    "NOVELTY"
  ],
  [
    "This paper introduces a novel loss to train an image-to-image mapping from unpaired data",
    "NOVELTY"
  ],
  [
    "Using pairwise distances in this context is new and interesting .",
    "NOVELTY"
  ],
  [
    "I could not find any technical contribution or something sufficiently mature and interesting for presenting in ICLR .",
    "NOVELTY"
  ],
  [
    "The idea proposed in the paper , even in the specific problem context considered , are incremental .",
    "NOVELTY"
  ],
  [
    "The idea about intent embeddings for zero-shot learning is not fully original (",
    "NOVELTY"
  ],
  [
    "but I regret to say that the paper is limited in terms of its novelty .",
    "NOVELTY"
  ],
  [
    "the paper feels like a combination of two existing ideas from Anil et al .and Xiao et al .Having a broader set of experiments could have made up for the limited novelty of the paper",
    "NOVELTY"
  ],
  [
    "Analysis on the semi-random setting is new",
    "NOVELTY"
  ],
  [
    "I consider the present paper a minor extension of [ 4 ] ,",
    "NOVELTY"
  ],
  [
    "in my opinion , the overall work is rather incremental and the novelty is limited .",
    "NOVELTY"
  ],
  [
    "The idea is new and interesting",
    "NOVELTY"
  ],
  [
    "I like the idea of learning a latent structure DAG for VAEs",
    "NOVELTY"
  ],
  [
    "I maintain the original comment that the continuous-time convergence of KL under LSI is n't surprising and the discretization analysis seems novel",
    "NOVELTY"
  ],
  [
    "The first contribution of the paper , which proves a convergence bound in the KL divergence without assuming strong convexity is not surprising",
    "NOVELTY"
  ],
  [
    "Nevertheless , the discretization analysis using arguments based on the Fokker-Planck PDE for the density seems novel .",
    "NOVELTY"
  ],
  [
    "The second part of the paper , where a generalized convergence bound in the Renyi divergence is shown , is novel .",
    "NOVELTY"
  ],
  [
    "The method is new and provides a direct generalization of the Linear Distance Metric learning .",
    "NOVELTY"
  ],
  [
    "it is not very novel",
    "NOVELTY"
  ],
  [
    "Though the proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "the model presented in the paper is interesting and is a good contribution to the field .",
    "NOVELTY"
  ],
  [
    "interesting contribution",
    "NOVELTY"
  ],
  [
    "this",
    "NOVELTY"
  ],
  [
    ", the contribution is rather minor and not well presented .",
    "NOVELTY"
  ],
  [
    "However , I do n't think this work contributes anything significant to the work that has already been done in this area .",
    "NOVELTY"
  ],
  [
    "This paper",
    "NOVELTY"
  ],
  [
    "with extensive",
    "NOVELTY"
  ],
  [
    "experiments but the similarity with [ 1 ] make it an incremental contribution and",
    "NOVELTY"
  ],
  [
    "a technical issue with what is explained at Section 3.3",
    "NOVELTY"
  ],
  [
    "I really like the idea of using the Stein discrepancy for doing approximate inference . I also like the idea of having a set of particles ( samples ) that are iteratively transformed to match the target distribution .",
    "NOVELTY"
  ],
  [
    "I find this paper interesting",
    "NOVELTY"
  ],
  [
    "but it is not entirely new and this paper does not present a method for getting from sensed data to higher level concepts .",
    "NOVELTY"
  ],
  [
    "This is an interesting and very well written paper . The observation that previous methods ( such as extragradient ) fail in the stochastic setting for minimax problems is novel and important , .",
    "NOVELTY"
  ],
  [
    "The addition of the task-level semi-supervised setting is appreciated .",
    "NOVELTY"
  ],
  [
    "This result is novel and establishes that some ESR measures remain SR .",
    "NOVELTY"
  ],
  [
    "It is quite strange that the authors do not cite the paper by Metropolis or some survey on MCMC methods because there is nothing novel about this algorithm",
    "NOVELTY"
  ],
  [
    "I do not see any significant novelty in this part of the paper .",
    "NOVELTY"
  ],
  [
    "The theoretical results providing mixing bounds for these samplers in combination with ESR measures are novel and interesting .",
    "NOVELTY"
  ],
  [
    "Still the impression is that these are just minor adaptations of the previous work",
    "NOVELTY"
  ],
  [
    "The focus on determinantal point processes precludes other contributions and the utility of general ESR measures",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "Moreover , the proposed method has limited novelty as the use of full-precision skip connections has been proposed in Bi-Real",
    "NOVELTY"
  ],
  [
    "The proposed ideas seem quite insightful/useful",
    "NOVELTY"
  ],
  [
    "The removal of the base measure assumption is very interesting , making the estimator attractive and robust when specifying the parametric model itself is not easy",
    "NOVELTY"
  ],
  [
    "I think this is a thorough",
    "NOVELTY"
  ],
  [
    "paper and a useful contribution to the emergent communication literature",
    "NOVELTY"
  ],
  [
    "While the connection of scale invariant models to novel schemes of learning rates is interesting ( and novel",
    "NOVELTY"
  ],
  [
    "As the authors note , the idea of reasoning over both the design of an agent and its control policy is not new ,",
    "NOVELTY"
  ],
  [
    "but this paper introduces some new ideas and",
    "NOVELTY"
  ],
  [
    "steps forward to making GP classifiers more competitive for image classification .",
    "NOVELTY"
  ],
  [
    "While the extensions ( hierarchical model and amortization ) are not excitingly novel",
    "NOVELTY"
  ],
  [
    "Insightful understanding of the VQ-VAE as hard EM clustering",
    "NOVELTY"
  ],
  [
    "The idea of formulating the threat model as the inner maximization problem is an old one .",
    "NOVELTY"
  ],
  [
    "The idea of using invertible networks for estimating a specific forward process is not new ,",
    "NOVELTY"
  ],
  [
    "Strengths \u00e2\u0080\u0094 Interesting and novel approach .",
    "NOVELTY"
  ],
  [
    "Extension",
    "NOVELTY"
  ],
  [
    "The novelty is limited .",
    "NOVELTY"
  ],
  [
    "Authors do not seem to offer any truly new theoretical extension to `` building blocks `` of their system , which is based on known components proposed elsewhere",
    "NOVELTY"
  ],
  [
    "As such , the algorithm can be seen as a self-learning inspired extension of previous work , which executed 1 ) and 2 ) only once .",
    "NOVELTY"
  ],
  [
    "the manuscript is mainly a continuation of previous work on OT-based DA",
    "NOVELTY"
  ],
  [
    "the conceptual difference is previous work is limited",
    "NOVELTY"
  ],
  [
    "The paper presents a novel meta-learning method as well as the detailed algorithm and analysis of its convergence property .",
    "NOVELTY"
  ],
  [
    "The paper proposes a ( I believe ) novel method to obtain visual explanations .",
    "NOVELTY"
  ],
  [
    "and the proposed method is very appealing especially on large datasets",
    "NOVELTY"
  ],
  [
    "It is very much inline with the previous",
    "NOVELTY"
  ],
  [
    "The development in this submission seems quite similar to [ 15 ] , including problem formulation and solution used .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited because the model is relatively incremental .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution is somewhat incremental and the evaluation/discussion should focus more on the sense selection module .",
    "NOVELTY"
  ],
  [
    "1 .The novelty is not clear .",
    "NOVELTY"
  ],
  [
    "and model is interesting",
    "NOVELTY"
  ],
  [
    "The generation process is novel and interesting and",
    "NOVELTY"
  ],
  [
    "-The contribution of Theorem 1 is a nice addition to the literature .",
    "NOVELTY"
  ],
  [
    "I did not see much novelty here .",
    "NOVELTY"
  ],
  [
    "Novel . The idea of Minimal Variance Sampling is interesting .",
    "NOVELTY"
  ],
  [
    "The new method is interesting",
    "NOVELTY"
  ],
  [
    "This work does not seem particularly original as applying transformations to input is done in most AR estimators .",
    "NOVELTY"
  ],
  [
    "I believe this result is new .",
    "NOVELTY"
  ],
  [
    "I like the idea presented in the paper and as far as I am aware it is novel and relevant to NIPS .",
    "NOVELTY"
  ],
  [
    "2 .I like the idea very much",
    "NOVELTY"
  ],
  [
    "I believe a standardized procedure for comparing optimizers can be viewed as an original contribution .",
    "NOVELTY"
  ],
  [
    "but lacks a few important features in my opinion",
    "NOVELTY"
  ],
  [
    "and the proposed ideas are interesting",
    "NOVELTY"
  ],
  [
    "However , many parts of the ideas discussed in the paper ( Section 3.3 ) are already investigated in Wei et al. , 2016 , which limits the novel contribution of the paper .",
    "NOVELTY"
  ],
  [
    "so it is not clear to me how the approach here is really novel in comparison",
    "NOVELTY"
  ],
  [
    "Even if there is some distinction I am missing , the high level idea is clearly not that new .",
    "NOVELTY"
  ],
  [
    "Overall , the idea looks very original and promissing",
    "NOVELTY"
  ],
  [
    "It is original in this sense .",
    "NOVELTY"
  ],
  [
    "the regularizations proposed in this paper are combination of empirical losses",
    "NOVELTY"
  ],
  [
    "The techniques of the result are quite interesting , and different from the traditional approaches for analyzing gradient descent .",
    "NOVELTY"
  ],
  [
    "The paper provides a new analysis for learning ReLU unit",
    "NOVELTY"
  ],
  [
    "annealing schedule for the selection",
    "NOVELTY"
  ],
  [
    "The proposed model is novel , which can take a trajectory or a constraint as a short-term goal .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper may be incremental",
    "NOVELTY"
  ],
  [
    "although the proposed approach seems interesting",
    "NOVELTY"
  ],
  [
    "the findings of this papers are not surprising and do not contribute novel insights .",
    "NOVELTY"
  ],
  [
    "the idea is very trivial",
    "NOVELTY"
  ],
  [
    "This implementation makes the algorithm in Section 4 quite similar to existing methods",
    "NOVELTY"
  ],
  [
    "Most of the results are not novel and have been discussed previously by Yarin Gal and other authors .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is novel ,",
    "NOVELTY"
  ],
  [
    "-- -- -- The idea of TFiLM is novel , and",
    "NOVELTY"
  ],
  [
    "While this idea is interesting",
    "NOVELTY"
  ],
  [
    "outperforms existing methods in terms of coverage and compositionality",
    "NOVELTY"
  ],
  [
    "The paper is very interesting",
    "NOVELTY"
  ],
  [
    "NIPS as it introduces novel methodology ( model & algorithm ) to tackle important applications ( entity resolution ) .",
    "NOVELTY"
  ],
  [
    "it seems to me that this is a solid contribution",
    "NOVELTY"
  ],
  [
    "The technical novelty is small , as the extension of the existing NAS models to handle physical inputs and a few new operators is relatively straightforward .",
    "NOVELTY"
  ],
  [
    "application of NAS to physics based",
    "NOVELTY"
  ],
  [
    ", intuitive and novel .",
    "NOVELTY"
  ],
  [
    "While the extensions individually are incremental and not particularly exciting",
    "NOVELTY"
  ],
  [
    "On the other hand , to the best of my knowledge , this is the first paper that uses a stochastic Runge-Kutta integrator for sampling from strongly log-concave densities with explicit guarantees .",
    "NOVELTY"
  ],
  [
    "The overall contribution of the paper is clear",
    "NOVELTY"
  ],
  [
    "Writing the OT problem as a positive LP and combining the work of [ Sherman",
    "NOVELTY"
  ],
  [
    "with entropy regularized OT is novel and interesting and could lead to promising subsequent results on regularized OT",
    "NOVELTY"
  ],
  [
    "The connection seem to be novel to my knowledge but at the same time seems intuitive once reading the statement of the theorem",
    "NOVELTY"
  ],
  [
    "The use of an XOR-like dataset to study loss landscapes is interesting , making for a controlled and analyzable setting to carry out the study",
    "NOVELTY"
  ],
  [
    "The two-stage generator scheme the authors use to avoid adversarial noise patterns is quite clever",
    "NOVELTY"
  ],
  [
    "The combination of the global and local alignment is novel , nicely motivated",
    "NOVELTY"
  ],
  [
    "to explore",
    "NOVELTY"
  ],
  [
    "It is an interesting and to the best of my knowledge original work , both in terms of the theoretical framework and the obtained results .",
    "NOVELTY"
  ],
  [
    "Using a least-squares loss in combination with tensor methods is attractive because it enables ALS algorithms with closed-form updates that can be computed very fast",
    "NOVELTY"
  ],
  [
    "In terms of originality , the paper is a useful application of block kriging and Murray-Smith [ 35 ] .",
    "NOVELTY"
  ],
  [
    "Unfortunately , this paper is not a good contribution at the moment , as the work , although potentially interesting , is somewhat incremental and poorly presented .",
    "NOVELTY"
  ],
  [
    "I do not see a sufficient contribution to warrant publication in ICLR",
    "NOVELTY"
  ],
  [
    "workloads",
    "NOVELTY"
  ],
  [
    "the domain into which the",
    "NOVELTY"
  ],
  [
    "paper is venturing is relatively novel , but the proofs techniques are not extremely original ,",
    "NOVELTY"
  ],
  [
    "This is one of the first analysis for SGD on multi-layer , non-linear neural networks .",
    "NOVELTY"
  ],
  [
    "onto the quantum object creating a quantum binary neural network I have to say I liked the paper , it is indeed novel and I haven \u2019 t seen this anywhere else",
    "NOVELTY"
  ],
  [
    "I find the contribution incremental",
    "NOVELTY"
  ],
  [
    "I pretty much like the idea that exploiting other alternative neural network structure for planning besides designing network by unfolding the existing planning algorithm .",
    "NOVELTY"
  ],
  [
    "I do n't think there is a particularly deep novel insight in this paper ,",
    "NOVELTY"
  ],
  [
    "The idea is interesting .",
    "NOVELTY"
  ],
  [
    "results are very promising",
    "NOVELTY"
  ],
  [
    "I think the idea is nice",
    "NOVELTY"
  ],
  [
    "The paper presents several fresh ideas and techniques for leanring high-dimensional event sequence in the continuous time space",
    "NOVELTY"
  ],
  [
    "The ideas in the paper are not novel and neither do the authors claim that they are",
    "NOVELTY"
  ],
  [
    "I also think that the impact of the work is also somewhat limited due to the enormous success of the wavenet architecture .",
    "NOVELTY"
  ],
  [
    "Not much novelty/originality .",
    "NOVELTY"
  ],
  [
    "The algorithm is clear but it is similar to the Dynamic Filter Networks paper .",
    "NOVELTY"
  ],
  [
    "The methodologies of Kiela et al",
    "NOVELTY"
  ],
  [
    "are very similar to those proposed in this work",
    "NOVELTY"
  ],
  [
    "Because this modification is not particularly novel",
    "NOVELTY"
  ],
  [
    "The proposed method is interesting , novel and tackles a",
    "NOVELTY"
  ],
  [
    "A key technical tool underpinning the proofs is a novel way of analyzing UCB algorithms via a potential function .",
    "NOVELTY"
  ],
  [
    "the problem introduced in the paper is novel",
    "NOVELTY"
  ],
  [
    ", although there is some similarity to the `` dark pools `` problem introduced by Goncharev et al",
    "NOVELTY"
  ],
  [
    "I think the paper introduces a nice new wrinkle into the standard multi-armed bandit model and that the potential-function-based analysis of UCB is a nice innovation that will potentially find its way into other theory papers on bandits",
    "NOVELTY"
  ],
  [
    "the novelty and originality is a big concern .",
    "NOVELTY"
  ],
  [
    "The only novelty of the paper is to extend ASCG to proximal setting , which however , is quite trivial .",
    "NOVELTY"
  ],
  [
    "Overall , I do n't feel the paper has a substantial contribution .",
    "NOVELTY"
  ],
  [
    "This manuscript provides a clear step forward in low precision training , through a mixture of novel ideas and solid",
    "NOVELTY"
  ],
  [
    "includes some novel tricks like chunk-based accumulation 2",
    "NOVELTY"
  ],
  [
    "but the results in Table 4 and section 4.3 are not novel and could be removed",
    "NOVELTY"
  ],
  [
    "In my opinion , the approach taken in this work does not constitute a major methodological advancement",
    "NOVELTY"
  ],
  [
    "The idea of having a sparse prior in latent space is indeed relevant , The approximation and reparameterization of the spike variable is however functionally appealing .",
    "NOVELTY"
  ],
  [
    "the chosen architecture is not a novel one but attached to this task , it can be considered as if",
    "NOVELTY"
  ],
  [
    "The idea of using convolutional networks to encode the videos is interesting .",
    "NOVELTY"
  ],
  [
    "A novel model has been presented for learning graph representations from 2D data .",
    "NOVELTY"
  ],
  [
    "the paper presents a novel approach for learning graph representations from 2D data",
    "NOVELTY"
  ],
  [
    "4 .Overall technically the proposed approach is a bit straightforward and does not bring too much novelty .",
    "NOVELTY"
  ],
  [
    "contrast-invariance computation",
    "NOVELTY"
  ],
  [
    "This manuscript has some interesting ideas .",
    "NOVELTY"
  ],
  [
    "The joint analysis of LSE and Bayesian optimization is interesting and perhaps even insightful .",
    "NOVELTY"
  ],
  [
    "due",
    "NOVELTY"
  ],
  [
    "I believe the experiments are rather weak in comparison to the theoretical contributions",
    "NOVELTY"
  ],
  [
    "in general , I think the contribution is limited .",
    "NOVELTY"
  ],
  [
    "the personalization itself is not a novel thing",
    "NOVELTY"
  ],
  [
    "I fail to find any new contribution in this combination .",
    "NOVELTY"
  ],
  [
    "and the idea is interesting . The regularization approach is novel compared to the methods of the literature .",
    "NOVELTY"
  ],
  [
    "the loss is somewhat novel",
    "NOVELTY"
  ],
  [
    "Overall , I think that the proposed GNN architecture is an original and interesting approach for this specific application .",
    "NOVELTY"
  ],
  [
    "The use of OBs is novel and interesting .",
    "NOVELTY"
  ],
  [
    "While the use of",
    "NOVELTY"
  ],
  [
    "Open bigrams is novel",
    "NOVELTY"
  ],
  [
    "This paper had a real , clear , different idea that appeared interesting and promising .",
    "NOVELTY"
  ],
  [
    "o The basic idea of the different update time scales , done flexibly , controlled by the master forget/input gates seemed original , flexible , and good .",
    "NOVELTY"
  ],
  [
    "o Has an original , promising approach .",
    "NOVELTY"
  ],
  [
    "The paper seems very interesting .",
    "NOVELTY"
  ],
  [
    "this work is original to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The Bayes-stability is a significant contribution of this paper",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel up to my knowledge . Although the methodological innovations are not that advanced , the vectorization in the specific application considered is novel , as well as the dynamic discretization .",
    "NOVELTY"
  ],
  [
    "the novelty is moderate . The paper does n't aim for a significant technical contribution .",
    "NOVELTY"
  ],
  [
    "The application of the compression and momentum to the parameter server is fairly original .",
    "NOVELTY"
  ],
  [
    "The three ways proposed in the paper to deal with domain shift in the transductive setting is new as far as I know",
    "NOVELTY"
  ],
  [
    "I particularly enjoyed the promise of relating/unifying these ideas to Langevin dynamics .",
    "NOVELTY"
  ],
  [
    "Philosophically",
    "NOVELTY"
  ],
  [
    "I enjoyed reading the paper , the proposed reinterpretation of NLL in terms of a weighted average and its approximation based on weights that do not depend on the labels but the ( assumed known ) labels marginal is interesting",
    "NOVELTY"
  ],
  [
    "This paper is very original .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and an original application of the wavelet transform .",
    "NOVELTY"
  ],
  [
    "My impression of this manuscript is that the idea and the analysis is probably fine",
    "NOVELTY"
  ],
  [
    "but that the idea is somewhat incremental",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    ", the paper is an interesting contribution",
    "NOVELTY"
  ],
  [
    "I am unsure of the significance of the contribution , as it does not seem like that much of an improvement over the cited previous works .",
    "NOVELTY"
  ],
  [
    "Novelty The idea of using logic gates for dequantization is interesting and ( as far as I know ) novel .",
    "NOVELTY"
  ],
  [
    "The precise combination of NPs with RSSMs ( or similar ) models appears to be novel .",
    "NOVELTY"
  ],
  [
    "I do have one particular concern to do with the characterisation of the posterior dropout elbo -- -while its use for TGQNs might be apposite , the idea of sampling from the prior to prevent the posterior from overfitting is not new , especially for ELBOs",
    "NOVELTY"
  ],
  [
    "but the innovation of combining the PCA and LPP to produce the dimensionally reduced representation of the longitudinal data",
    "NOVELTY"
  ],
  [
    "significant enough",
    "NOVELTY"
  ],
  [
    "I acknowledged the novel contributions of this work .",
    "NOVELTY"
  ],
  [
    "layer norm definitely is novel and significant",
    "NOVELTY"
  ],
  [
    "Overall , I liked the idea .",
    "NOVELTY"
  ],
  [
    "Relevant topic in computer vision + Interesting",
    "NOVELTY"
  ],
  [
    "the main contribution of this paper is only the observation that RIP constant should be small to rule out spurious local minima",
    "NOVELTY"
  ],
  [
    "The paper introduces an original idea .",
    "NOVELTY"
  ],
  [
    "The idea of providing provably correct policies is very appealing for reasons that the paper",
    "NOVELTY"
  ],
  [
    "the methodological contribution of the paper is minimal",
    "NOVELTY"
  ],
  [
    "NOVELTY The problem setup is very similar to prior work on feedforward neural style transfer , but the paper is the first to my knowledge that uses a single network to apply different styles to input images",
    "NOVELTY"
  ],
  [
    "; the proposed conditional instance normalization layer is also novel",
    "NOVELTY"
  ],
  [
    "SUMMARY The problem and method are slightly incremental , but the several improvements over prior work make this paper a significant addition to the growing literature on neural style transfer .",
    "NOVELTY"
  ],
  [
    "Slightly incremental - Somewhat lacking in quantitative evaluation",
    "NOVELTY"
  ],
  [
    "prior work on this topic",
    "NOVELTY"
  ],
  [
    "The novelty here is very limited .",
    "NOVELTY"
  ],
  [
    "-- A novel two-step procedure is proposed .",
    "NOVELTY"
  ],
  [
    "Unfortunately , the sole novelty in this paper is a new justification for the STL estimator . The presentation , while thorough , is not novel or particularly clear .",
    "NOVELTY"
  ],
  [
    "2 .Modeling logical queries into regions in vector space is an interesting idea",
    "NOVELTY"
  ],
  [
    "-SLIM provides a novel integration of the previously existing SILO and DStumps methods to produce a locally interpretable model .",
    "NOVELTY"
  ],
  [
    "this paper presents a novel method for interpretability",
    "NOVELTY"
  ],
  [
    "The paper does not provide new theoretical developments or a technical contribution .",
    "NOVELTY"
  ],
  [
    "I like the idea and hope the authors improve the paper and submit to a future conference",
    "NOVELTY"
  ],
  [
    "3 .Originality The originality of this work is essentially just from proving PLTs are better than pick-one HSMs",
    "NOVELTY"
  ],
  [
    "The theorems and proofs are new for XMLC , which is important since pick-one HSMs are frequently used in practice",
    "NOVELTY"
  ],
  [
    "However , there is a very little technical contribution in terms of the method .",
    "NOVELTY"
  ],
  [
    "The authors introduce their idea together with interesting analysis",
    "NOVELTY"
  ],
  [
    "This is new compared to prior works",
    "NOVELTY"
  ],
  [
    "their method of evolution of a parameterized search space seems also new",
    "NOVELTY"
  ],
  [
    "in the context of Neural Architecture Search",
    "NOVELTY"
  ],
  [
    "The authors propose an incremental modification to the transformer network which accounts for spatial relationship between the objects . The ideas of using transformer encoder+decoder architecture , pre-training the network with cross-entropy loss and fine-tuning in self-critical setup using CIDER scores with rollout as reward are borrowed from previous literature",
    "NOVELTY"
  ],
  [
    "The paper proposes an incremental modification to the transformer networks for image captioning",
    "NOVELTY"
  ],
  [
    "is a bit technical ( with limited novelty",
    "NOVELTY"
  ],
  [
    "and the mathematical context in which this is derived is insightful and may lead to further progress in the development of Transformers capable of constructing still richer structures",
    "NOVELTY"
  ],
  [
    "enlightening , another major contribution of the paper .",
    "NOVELTY"
  ],
  [
    "but the overall novelty is limited",
    "NOVELTY"
  ],
  [
    "This paper is really interesting and with great contribution if it",
    "NOVELTY"
  ],
  [
    "to real world social networks like Twitter or Facebook",
    "NOVELTY"
  ],
  [
    "and the idea is interesting and innovative .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is mainly on the theoretical side , while",
    "NOVELTY"
  ],
  [
    "providing very nice insights",
    "NOVELTY"
  ],
  [
    "The contributions sound interesting",
    "NOVELTY"
  ],
  [
    "Visual object-centric derenderers , particle filters and expectation violation datasets have been proposed before",
    "NOVELTY"
  ],
  [
    "So I do n't consider this aspect of the paper to be new in any significant way .",
    "NOVELTY"
  ],
  [
    "While the ideas presented in this paper are natural and well founded",
    "NOVELTY"
  ],
  [
    "While the ideas presented are interesting",
    "NOVELTY"
  ],
  [
    ", I think that the proposed model is a bit incremental compared to previous work , and that the experiments are a bit weak .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed defense strategy is novel",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "I really like the idea of finding a unifying framework for analyzing the privacy-loss after post-processing",
    "NOVELTY"
  ],
  [
    "The view of post-processing ( randomly ) as a Markov process is novel ( to me at least )",
    "NOVELTY"
  ],
  [
    "Judging by the title the main contribution of this model is a novel model architecture .",
    "NOVELTY"
  ],
  [
    "I am not very sure on my review of the novelty of this method .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting",
    "NOVELTY"
  ],
  [
    "However , the proposed algorithm , SENSE-S , is incremental in the sense of aggregating two simple structures .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first paper that provides a unifying framework that yields results on a variety of network models .",
    "NOVELTY"
  ],
  [
    "-- they expose the main ideas effectively",
    "NOVELTY"
  ],
  [
    "I think that this paper makes an interesting and non-obvious contribution",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting , and ( to the best of my knowledge ) novel approach to binary classification with abstention .",
    "NOVELTY"
  ],
  [
    "Overall , I think the contribution of the paper is strong .",
    "NOVELTY"
  ],
  [
    "The GNN architecture for 2QBF ( Section 2 ) is simple , elegant , and well-motivated as a minimal extension of successful SAT solvers",
    "NOVELTY"
  ],
  [
    "but the suggested method is not novel",
    "NOVELTY"
  ],
  [
    "The proposed approach is incremental , but anyway novel .",
    "NOVELTY"
  ],
  [
    "Overall , this is a solid work with a novel method",
    "NOVELTY"
  ],
  [
    "The work looks original .",
    "NOVELTY"
  ],
  [
    "The work is novel",
    "NOVELTY"
  ],
  [
    "In my opinion , the proposed method is neither sufficiently novel nor justified properly .",
    "NOVELTY"
  ],
  [
    "The elements of the solution have been existing before , and their application to improve ensemble models seems to be the main novel innovation of the article .",
    "NOVELTY"
  ],
  [
    "Novelty of the work and its relation to the Dasgupta paper is a concern",
    "NOVELTY"
  ],
  [
    "The idea is nice in three folds .",
    "NOVELTY"
  ],
  [
    "This is definitely a novel area that requires the machine not only understand the corpus , but also the scientific figure associated with the figure .",
    "NOVELTY"
  ],
  [
    "There are no novel algorithms associated with this dataset .",
    "NOVELTY"
  ],
  [
    "This paper was interesting",
    "NOVELTY"
  ],
  [
    "4.The idea of reconstructing z is not new , which has been mentinoed in the infoGAN [ 1 ] paper .",
    "NOVELTY"
  ],
  [
    "I am still unable to fully gauge the contribution of the paper",
    "NOVELTY"
  ],
  [
    "I do n't think there 's significant novelty here : all the components are existing and combining them seems very trivial to me",
    "NOVELTY"
  ],
  [
    "I thus think the contribution of the paper is pretty not significant .",
    "NOVELTY"
  ],
  [
    "While the idea of using mask is interesting and",
    "NOVELTY"
  ],
  [
    "and brings forth some nice theory",
    "NOVELTY"
  ],
  [
    "This work actually presents compression algorithm with little connection with lottery ticket",
    "NOVELTY"
  ],
  [
    "However , it is not novel eg Aigrain'19 did essentially the same thing for classification models",
    "NOVELTY"
  ],
  [
    "In addition to lack of novelty , the",
    "NOVELTY"
  ],
  [
    "Even though there are a family of unsupervised approaches for domain alignment , this paper is the first to solve the knowledge graph alignment problem in an unsupervised/weakly supervised way .",
    "NOVELTY"
  ],
  [
    "I personally worked on similar sparse unfolding problems before so this work looks particularly novel and interesting to me .",
    "NOVELTY"
  ],
  [
    "I believe this paper presents a novel and insightful approach to creating programs from imprecise specifications .",
    "NOVELTY"
  ],
  [
    "The idea of generating audio from 2D spectrogram is original",
    "NOVELTY"
  ],
  [
    "There is reasonable novelty in the proposed method compared to the existing literature .",
    "NOVELTY"
  ],
  [
    "=== Novelty/originality === As far as I know , this line of analysis in the context of RL is novel .",
    "NOVELTY"
  ],
  [
    "I think the main contribution of this paper is the discussion on two novel learning settings",
    "NOVELTY"
  ],
  [
    "Predicting the middle point between two states for modeling the dynamics via deep neural networks is not new",
    "NOVELTY"
  ],
  [
    "I like the idea of splitting the control problem into a prediction and a correction phase , which leverages the power of deep neural networks and also incorporates our understanding of physics . The introduction of the hierarchical structure alleviates the problem of accumulating error in single-step forwarding models and significantly improves the efficiency of the proposed method .",
    "NOVELTY"
  ],
  [
    "s not clear what is new here compared",
    "NOVELTY"
  ],
  [
    "not sufficiently differentiated from other work in robust MDPs and multi-agent RL to make a strong contribution yet",
    "NOVELTY"
  ],
  [
    "This is a very interesting and timely paper , with multiple contributions .",
    "NOVELTY"
  ],
  [
    "Even though the novelty here is limited , Pre-LN placement has been used in prior work",
    "NOVELTY"
  ],
  [
    "The idea of training MoG prior , but a unimodal Gaussian posterior for each training data is nice .",
    "NOVELTY"
  ],
  [
    "While KL-averaging is not a new idea , previously",
    "NOVELTY"
  ],
  [
    "The task seems to be novel and complex .",
    "NOVELTY"
  ],
  [
    "2 .There is less novelty in terms of the models presented for evaluation since they are composed of existing models",
    "NOVELTY"
  ],
  [
    "This work is an improvements on existing methods .",
    "NOVELTY"
  ],
  [
    "The results are interesting , which provide a practically relevant extension of the prior work .",
    "NOVELTY"
  ],
  [
    "As mentioned the paper proposed two novel algorithms which both enjoy the aforementioned theoretical properties under various assumptions .",
    "NOVELTY"
  ],
  [
    "finding a stable correction seems a novel direction to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "first evidence of effectively training large RNN based language models under the constraint of differential privacy",
    "NOVELTY"
  ],
  [
    "I did not find strong algorithmic ideas in the paper .",
    "NOVELTY"
  ],
  [
    "Whereas neither of these components are new",
    "NOVELTY"
  ],
  [
    "and represents a valuable contribution",
    "NOVELTY"
  ],
  [
    "potential to be a significant contribution",
    "NOVELTY"
  ],
  [
    "while the idea sounds interesting",
    "NOVELTY"
  ],
  [
    "3 .To the best of my knowledge using such a model for task boundary detection is novel and quite interesting .",
    "NOVELTY"
  ],
  [
    "I find the basic idea of the paper quite appealing as it leverages the elegance of the deep kernel learning formulation to yield an attempt at a principled Bayesian version of continual learning and demonstrates empirical value .",
    "NOVELTY"
  ],
  [
    "Using Kronecker Factorization to approximate RTRL algorithm appears novel to me .",
    "NOVELTY"
  ],
  [
    "and the proposed method is interesting",
    "NOVELTY"
  ],
  [
    "I think the originality of this paper is minor .",
    "NOVELTY"
  ],
  [
    "The proposed method is a simple extension of GPI to the option framework , and theoretical contribution is minor .",
    "NOVELTY"
  ],
  [
    "Although this feature may be novel in the option framework , I think that this contribution is incremental since composing a new policy from existing policies have been investigated in recent studies .",
    "NOVELTY"
  ],
  [
    "The idea of dropping observations to implicitly train a world model in a model-based reinforcement learning setup is novel and original .",
    "NOVELTY"
  ],
  [
    "and the idea of training a world model implicitly through dropout is novel and original .",
    "NOVELTY"
  ],
  [
    "I like the idea of coupling the language and the conversation model .",
    "NOVELTY"
  ],
  [
    "The idea of enforcing information isolation is brilliant . Creating hidden information and allowing the two-party model to learn through self-play is a very interesting approach and",
    "NOVELTY"
  ],
  [
    "Overall I think the idea of using uncertainties for continual learning is interesting .",
    "NOVELTY"
  ],
  [
    "2 .It is relatively novel .",
    "NOVELTY"
  ],
  [
    "the observation is interesting but the novelty is arguable .",
    "NOVELTY"
  ],
  [
    "I think this paper provides plenty of insightful observations .",
    "NOVELTY"
  ],
  [
    "Although this paper is outside my expertise , I find the proposed algorithm quite interesting which boils down to a plain kernel ridge regression for structured output prediction .",
    "NOVELTY"
  ],
  [
    "the proposed method is novel and could be complementary with other methods that achieve good results on Clothing1M .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- This paper presents a novel approach for dealing with asymmetric label noise",
    "NOVELTY"
  ],
  [
    "Its novelty is incremental as variants of CRFs have been widely used and combined with CNNs previously , including for prediction of landmarks , albeit using different formulations than the one proposed .",
    "NOVELTY"
  ],
  [
    "Given Tucker et al , its contribution is somehow incremental ,",
    "NOVELTY"
  ],
  [
    "but I think it is an interesting idea to use neural networks for control variate to handle the case where f is unknown .",
    "NOVELTY"
  ],
  [
    "said , this particular use of deep learning in this context might be novel .",
    "NOVELTY"
  ],
  [
    "The use of maximum disagreement as uncertainty measure is novel for exploration .",
    "NOVELTY"
  ],
  [
    "The major drawback is the method is a collection of many existing methods and as such it is hard to draw the major technical contribution of the paper .",
    "NOVELTY"
  ],
  [
    "It is not sufficiently novel and the empirical results do not prove sufficient effectiveness of this incremental approach",
    "NOVELTY"
  ],
  [
    "Overall , the proposed method itself seems to be novel and interesting .",
    "NOVELTY"
  ],
  [
    "I believe the results in the paper are novel",
    "NOVELTY"
  ],
  [
    "the paper extends them in a novel way to handle MDSs",
    "NOVELTY"
  ],
  [
    "Novel application of GAN that is capable of generating a sequence of observations that is consistent with the dynamics of the environment .",
    "NOVELTY"
  ],
  [
    "The idea of training a GAN to generate realistic transitions that is interesting .",
    "NOVELTY"
  ],
  [
    "The idea of learning an abstract transition model using GAN is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "Moreover , these works improve over the current manuscript in a number of ways",
    "NOVELTY"
  ],
  [
    "Furthermore , this method is , to my knowledge , new .",
    "NOVELTY"
  ],
  [
    "The proposed method seems to be novel and brings many interesting ideas in Makur et al .with empirical validation .",
    "NOVELTY"
  ],
  [
    "The algorithm is based on the accelerated gradient descent from Nesterov together with a multistage approach that does not seem new neither .",
    "NOVELTY"
  ],
  [
    "While this is an interesting idea on its surface",
    "NOVELTY"
  ],
  [
    "taken individually , the contributions of the paper are mostly based on prior work , however",
    "NOVELTY"
  ],
  [
    ", their combination is conceptually interesting",
    "NOVELTY"
  ],
  [
    "-- What concerns me the most is the novelty of this work . It seems solid and effective . However , based on the current content , I can not fully appreciate its novelty . Using deep learning models to extract features from different modalities has been used before",
    "NOVELTY"
  ],
  [
    "Using LSTM for fusion is not new , either .",
    "NOVELTY"
  ],
  [
    "Using the ConvLSTM to fuse features from different focal lengths and different levels of VGG is",
    "NOVELTY"
  ],
  [
    "interesting , but not a significant innovation",
    "NOVELTY"
  ],
  [
    "While the idea proposed in the paper is interesting",
    "NOVELTY"
  ],
  [
    "I believe the proposed method is interesting , and I have not seen a similar approach before .",
    "NOVELTY"
  ],
  [
    "The idea of evolving core-sets in order to improve running time of linear solvers is new to me .",
    "NOVELTY"
  ],
  [
    "These contributions are novel",
    "NOVELTY"
  ],
  [
    "I think the idea of PG and the demonstrated benefits make the paper interesting enough to be accepted at ICLR",
    "NOVELTY"
  ],
  [
    "The technique is not novel in spirit .",
    "NOVELTY"
  ],
  [
    "This paper proposed an interesting and intuitive counting model for VQA .",
    "NOVELTY"
  ],
  [
    "This paper proposed an interesting and interpretable model for counting in",
    "NOVELTY"
  ],
  [
    "both the embedding method and the training of variational models used in this work are already well developed . Thus , this work doesn \u2019 t show too much novel contribution .",
    "NOVELTY"
  ],
  [
    "The suggested reparametrisation and its theoretical analysis are very interesting and I enjoyed reading the paper .",
    "NOVELTY"
  ],
  [
    "In general I like the idea",
    "NOVELTY"
  ],
  [
    "I generally like the proposed method , which seems useful and intuitive .",
    "NOVELTY"
  ],
  [
    "have significant concerns about the novelty of the",
    "NOVELTY"
  ],
  [
    "I am not convinced by the novelty of this paper .",
    "NOVELTY"
  ],
  [
    "While the model is , to my knowledge , indeed novel",
    "NOVELTY"
  ],
  [
    "GMMs are nice and intuitive",
    "NOVELTY"
  ],
  [
    "but not novel in any way",
    "NOVELTY"
  ],
  [
    "I think that the paper lacks novelty and that it spends far too much space on `` trivial `` properties of the model instead of addressing shortcomings",
    "NOVELTY"
  ],
  [
    "the proposed method does not solve the limitations of any previous",
    "NOVELTY"
  ],
  [
    "The quality of results might be improved but there is little novelty .",
    "NOVELTY"
  ],
  [
    "2 .The results shown in Table 3 is incremental to me .",
    "NOVELTY"
  ],
  [
    "In general all the reviewers seem to agree that the paper often lacks intuition for the proposed algorithm but the contributions look quite significant",
    "NOVELTY"
  ],
  [
    "Although the use of partial identification bounds for policy learning is not new",
    "NOVELTY"
  ],
  [
    "yet its use in online decision making is innovative",
    "NOVELTY"
  ],
  [
    "Overall I think that the idea is interesting and the work presented in this paper is very promising .",
    "NOVELTY"
  ],
  [
    "the idea of making BLEU differentiable",
    "NOVELTY"
  ],
  [
    "and this paper provides a nice idea on how to make this work .",
    "NOVELTY"
  ],
  [
    "My main concern is that the paper is limited in technical novelty and it suffers from a",
    "NOVELTY"
  ],
  [
    "the originality and the improvement w.r.t .baselines are somewhat",
    "NOVELTY"
  ],
  [
    "this paper is mainly an extension of the prior work",
    "NOVELTY"
  ],
  [
    "While the contribution seems a bit incremental and the experimental setting is a",
    "NOVELTY"
  ],
  [
    "bit unclear and limited to low-dimensional state space , the inference of task-specific subtask graphs based on past experiences and the proposal of a UCB-inspired reward shed some interesting insights on how to approach meta-hierarchical RL where long-horizon tasks and sparse rewards",
    "NOVELTY"
  ],
  [
    "The idea of adding an `` empathy `` auxiliary task to the reference-game setup is an interesting one",
    "NOVELTY"
  ],
  [
    "Unfortunately , however , the contributions of the paper are some way off what would be required for a full ICLR paper .",
    "NOVELTY"
  ],
  [
    "although I think that this paper is a nice contribution in the domain of movie conversational recommendation",
    "NOVELTY"
  ],
  [
    "and this is an interesting novel idea",
    "NOVELTY"
  ],
  [
    "The technical contribution is a very simple extension of Simonyan et al .2013 .The main novelty lies within the created dependency graph from the node importance weights",
    "NOVELTY"
  ],
  [
    "The idea of producing an interpretable dependency graph for nodes is interesting ,",
    "NOVELTY"
  ],
  [
    "The idea of applying neuron-editing to an autoencoder is pretty interesting .",
    "NOVELTY"
  ],
  [
    "-- Fourier decomposition is an important and ( to the best of my knowledge ) mostly original angle from which the authors analyze the input-output map governing neural networks .",
    "NOVELTY"
  ],
  [
    "-- The setup in the toy experiments of Sec .4 seems novel & thoughtful",
    "NOVELTY"
  ],
  [
    "and provides new insights into the representation power of neural nets .",
    "NOVELTY"
  ],
  [
    "A nice , in some sense novel , way of introducing responsibilities into the surrogate loss .",
    "NOVELTY"
  ],
  [
    "While the idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "but the constraint , which seems to be the novel part of the formulation",
    "NOVELTY"
  ],
  [
    "I also really liked the idea of using Thomson sampling instead of a closed for acquisition function in order to generate better samples while performing the integral .",
    "NOVELTY"
  ],
  [
    "This paper presents a general PIAG algorithm an inexact extension of previously proposed exact PIAG from",
    "NOVELTY"
  ],
  [
    "The Lyapunov function based proof technique has been used earlier in",
    "NOVELTY"
  ],
  [
    "the perspective of convergence in expectation , almost surely , and semi-algebraic property is a new addition",
    "NOVELTY"
  ],
  [
    "In terms of originality & novelty , while the idea to do iteration has yet to be tried in image matching , this idea has been demonstarted in various other applications",
    "NOVELTY"
  ],
  [
    "Therefore it 's not as original",
    "NOVELTY"
  ],
  [
    "One of my main concerns is whether the paper is novel/significant enough for NeurIPS .",
    "NOVELTY"
  ],
  [
    "To me , theoretical contribution of the paper seems not enough .",
    "NOVELTY"
  ],
  [
    "However , there are no novel scientific contributions . The idea of fusing standard bi-LSTM layers coupled with a dense fully-connected layer alone is not a substantial technical contribution .",
    "NOVELTY"
  ],
  [
    "The technical contributions are also not novel or strong to make the paper convincing .",
    "NOVELTY"
  ],
  [
    "the idea is very interesting , even though with heavy assumptions .",
    "NOVELTY"
  ],
  [
    "The idea itself is simple but the intuition behind it is rather interesting and ( to the best of my knowledge ) provides novel insights into the workings of artificial neural networks with relu activations .",
    "NOVELTY"
  ],
  [
    "novel algorithm FG-SGD to achieve the goal",
    "NOVELTY"
  ],
  [
    "9 The proposed FG-SGD algorithm is novel .",
    "NOVELTY"
  ],
  [
    "The idea I think is generally good",
    "NOVELTY"
  ],
  [
    "This is an important departure from the usual variational approximations used in VIB .",
    "NOVELTY"
  ],
  [
    "is that robustifying D in GAN training is not a new idea",
    "NOVELTY"
  ],
  [
    "Originality The particular setting explored in this paper is novel .",
    "NOVELTY"
  ],
  [
    "novel improvement in methodology for learning code execution",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is not clear . The idea of combining autoencoders with supervised learning has been explored before",
    "NOVELTY"
  ],
  [
    "While I do n't see this as substantial contribution to the field , I think that using the notion of geodesic distance in this context is novel .",
    "NOVELTY"
  ],
  [
    "This is a quite interesting idea on using the level-sets .",
    "NOVELTY"
  ],
  [
    "The main contribution of this paper is to suggest a new algorithm with additional theoretical convergence guarantee",
    "NOVELTY"
  ],
  [
    "Even though the paper seems to be a direct extension of a previous method ( OFO )",
    "NOVELTY"
  ],
  [
    ", the paper has original materials such as new theoretical analysis .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the work here is quite novel and adds some interesting results to our understanding of binary-state associative memory networks and their capacity . Furthermore , the connections between such higher-order networks and different forms of feedforward net also seemed interesting and novel .",
    "NOVELTY"
  ],
  [
    "The idea of LCN is very interesting",
    "NOVELTY"
  ],
  [
    "I really like the idea of the authors",
    "NOVELTY"
  ],
  [
    "The paper is generally a good addition to the TTS literature",
    "NOVELTY"
  ],
  [
    "The main contribution of this work is a novel probabilistic model based on prior scientific knowledge that contains both continuous and discrete latent states which is very commendable .",
    "NOVELTY"
  ],
  [
    "So , it does not have new mathematical theorems or many new ideas .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first paper that attempts to analyze learned word embeddings in the context of numerical common sense .",
    "NOVELTY"
  ],
  [
    "Overall , the demixing-GAN structure is relatively novel .",
    "NOVELTY"
  ],
  [
    "But it is not novel .",
    "NOVELTY"
  ],
  [
    "I like the idea behind the algorithm .",
    "NOVELTY"
  ],
  [
    "In particular , the idea of coupling PAC-Bayes and stability is appealing .",
    "NOVELTY"
  ],
  [
    "the contribution is clear",
    "NOVELTY"
  ],
  [
    "The problem formulation is , to my knowledge , novel and has theoretical appeal due to its simplicity and combinatorial structure .",
    "NOVELTY"
  ],
  [
    "It contains a truly novel idea for an architecture in solving inverse problems .",
    "NOVELTY"
  ],
  [
    "but the idea of separation is quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "3 .No technical contribution .",
    "NOVELTY"
  ],
  [
    "Still , I feel the contribution of this paper is somewhat weak .",
    "NOVELTY"
  ],
  [
    "I find that this work is a very nice contribution to the literature .",
    "NOVELTY"
  ],
  [
    "and as far as I can tell , the experiment conducted is a novel one and may add value to the knowledge regarding the human visual system .",
    "NOVELTY"
  ],
  [
    "Although the definition of GaLU is new , the idea of combining a non-linear projection with a linear transformation is an old one .",
    "NOVELTY"
  ],
  [
    "To the best of our knowledge , it does n't introduce new insight on the understanding of non-convex optimization .",
    "NOVELTY"
  ],
  [
    "and timely",
    "NOVELTY"
  ],
  [
    "this is an interesting idea",
    "NOVELTY"
  ],
  [
    "At the same time I think the paper does not have a significant amount of machine learning novelty in it .",
    "NOVELTY"
  ],
  [
    "most of the techniques are already used with convolutional networks",
    "NOVELTY"
  ],
  [
    ", which makes it a significant contribution",
    "NOVELTY"
  ],
  [
    "The paper presents a novel perspective on counterfactual regret minimization ( CFR ) in sequential problems which leads to new proof if the CFR theorem for sequence form plans and allows generalization of the result to correlated plans . As a result , it presents first CFR-based algorithm for computing EFCE . I consider the contribution in the paper to be novel .",
    "NOVELTY"
  ],
  [
    "While I agree this paper presents interesting empirical observations",
    "NOVELTY"
  ],
  [
    "but I enjoyed reading the submission and found the results interesting .",
    "NOVELTY"
  ],
  [
    "So far , the contribution appears to me rather limited for ICLR .",
    "NOVELTY"
  ],
  [
    "I like the idea ,",
    "NOVELTY"
  ],
  [
    "the main algorithms are very similar to some existing methods",
    "NOVELTY"
  ],
  [
    "as the main contribution is not particularly novel",
    "NOVELTY"
  ],
  [
    "the idea of learning a Dirichlet prior is very similar to that proposed in",
    "NOVELTY"
  ],
  [
    "The main contribution in this work seems to be the application to an existing black-box model",
    "NOVELTY"
  ],
  [
    "Although this paper contains interesting idea and results",
    "NOVELTY"
  ],
  [
    "-- From the point of view of graph neural networks , the novelty of the proposed techniques is marginal -- The performance of the proposed method are only better than existing methods on some of the targets",
    "NOVELTY"
  ],
  [
    "From the view of graph neural networks , the proposed technique is not that new since edge embedding has already been studied in existing literature .",
    "NOVELTY"
  ],
  [
    "The idea of learning this type of general encoding with NN is interesting and , as far as I know , novel .",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting , novel approach to learning bases/dictionaries for probe functions , and",
    "NOVELTY"
  ],
  [
    "I find this perspective very refreshing and original , in particular in light of the connection with online learning",
    "NOVELTY"
  ],
  [
    "and this is the main and worthy contribution of this paper , in my opinion",
    "NOVELTY"
  ],
  [
    "The paper improves upon the analysis from Lecuyer et al and develops a training method for producing certifiably robust randomized classifiers that is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "novelty in architecture design is trivial",
    "NOVELTY"
  ],
  [
    "the way of using unlabeled images is not new",
    "NOVELTY"
  ],
  [
    "1 .Architecture is not novel .",
    "NOVELTY"
  ],
  [
    "2 .Using an auxiliary branch to measure confidence and try to get more labeled data is not new .",
    "NOVELTY"
  ],
  [
    "I am not an expert of this subject , but it seems to me that looking at deep linear networks in an infinite-dimensional setting , instead of the usual finite-dimensional one , is a good idea .",
    "NOVELTY"
  ],
  [
    "Using methods from optimal control to study this problem is original , and apparently efficient .",
    "NOVELTY"
  ],
  [
    "it seems to me that it is not really what the article presents as a surprise",
    "NOVELTY"
  ],
  [
    "These inference problems are inspired by some well studied graph constructions and seem to be new",
    "NOVELTY"
  ],
  [
    "I do not think the techniques are of sufficient novelty to warrant publication .",
    "NOVELTY"
  ],
  [
    "I do not think that there are any new ideas here which merit special attention .",
    "NOVELTY"
  ],
  [
    "this problem setup may be a bit foreign and a clear example might be useful",
    "NOVELTY"
  ],
  [
    "The proposed approach is quite appealing",
    "NOVELTY"
  ],
  [
    "but likely can not be applied",
    "NOVELTY"
  ],
  [
    "This paper makes an interesting contribution .",
    "NOVELTY"
  ],
  [
    "The consistency ( parametric and structural/sparsistency ) analysis is new and improves in certain ( small ) aspects over previous work .",
    "NOVELTY"
  ],
  [
    "I think the first part of the paper has very good original contributions with",
    "NOVELTY"
  ],
  [
    "2 .I am unable to appreciate the novelty of the acceleration for RGD since",
    "NOVELTY"
  ],
  [
    "with some originality and quality",
    "NOVELTY"
  ],
  [
    "This is a solid paper that advances the methodology of training latent variable models with complex latent distributions .",
    "NOVELTY"
  ],
  [
    "I found these technical contributions to be a bit small .",
    "NOVELTY"
  ],
  [
    "The paper is interesting but largely empirical",
    "NOVELTY"
  ],
  [
    "The contribution of the present paper is more than that anyway",
    "NOVELTY"
  ],
  [
    "The contributions claimed are",
    "NOVELTY"
  ],
  [
    "Novel technique to impose inequality constraints on neural network activations .",
    "NOVELTY"
  ],
  [
    "and not presented as a novel contribution",
    "NOVELTY"
  ],
  [
    "STRENGTH The most prominent contribution is the paper is probably among the first to construct a pipeline to fully reconstruct both a physical simulation and graphics reconstruction for physics scene understanding",
    "NOVELTY"
  ],
  [
    "although I find the contributed results slightly overstated",
    "NOVELTY"
  ],
  [
    "The submission contains little contribution with regard to the exiting work .",
    "NOVELTY"
  ],
  [
    "I like the underlying idea behind the method",
    "NOVELTY"
  ],
  [
    "Overall it 's not clear what this paper adds to existing body of work",
    "NOVELTY"
  ],
  [
    "Although the method is developed based on some existing concepts in the literature , the use of mixture of autoencoders for deep clustering is novel .",
    "NOVELTY"
  ],
  [
    "The idea does n't strike me as particular innovative , feeling like a natural extension of the prior work listed .",
    "NOVELTY"
  ],
  [
    "The idea is extremely simple and I like it conceptually .",
    "NOVELTY"
  ],
  [
    "While I like the idea",
    "NOVELTY"
  ],
  [
    "I feel that the approach is not particularly novel , requires significant access to privileged information , and is not sufficiently situated in the literature .",
    "NOVELTY"
  ],
  [
    "The approach of using privileged information ( image pairs that are the same place with different appearance ) to train representations to be similar [ 3,4 ] is a very straightforward and not particularly novel auxiliary loss ,",
    "NOVELTY"
  ],
  [
    "novel approach to achieve these important goals by allowing a trusted",
    "NOVELTY"
  ],
  [
    "The reconstruction formulation of the problem is interesting and relevant for the task *",
    "NOVELTY"
  ],
  [
    "Limited novelty",
    "NOVELTY"
  ],
  [
    "From the technical point of view this is limited novelty , but still an interesting improvement of the model",
    "NOVELTY"
  ],
  [
    "The paper has nice insights on better initialization",
    "NOVELTY"
  ],
  [
    "paper with useful insights .",
    "NOVELTY"
  ],
  [
    "The idea of using the empirical distribution before is very interesting",
    "NOVELTY"
  ],
  [
    "The idea is very intuitive , and the implementation is kind of an incremental combination of ( Rebuffi et al. , 2018 ) building models for multi-tasks and ( Oreshkin et al. , 2018 ) tailoring based on task embeddings .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is mostly theoretical",
    "NOVELTY"
  ],
  [
    "I think the paper presents some interesting and novel ideas .",
    "NOVELTY"
  ],
  [
    "but in my opinion the theory makes the paper interesting in itself",
    "NOVELTY"
  ],
  [
    "While the idea of bringing together rules , prototypes , and NNs is definitely novel",
    "NOVELTY"
  ],
  [
    "The idea sounds promising .",
    "NOVELTY"
  ],
  [
    "The key concept , of re-framing the classification task as being random , represents a novel intuition and they immediately pull fruitful analysis from it .",
    "NOVELTY"
  ],
  [
    "Despite",
    "NOVELTY"
  ],
  [
    "the originality of the work",
    "NOVELTY"
  ],
  [
    "The proposed Laplacian-pooling ideas could be interesting",
    "NOVELTY"
  ],
  [
    "Overall , I thought the method was interesting and novel",
    "NOVELTY"
  ],
  [
    "grounded",
    "NOVELTY"
  ],
  [
    "Overall I feel that the contribution may be quite weak",
    "NOVELTY"
  ],
  [
    ".The paper is very interesting",
    "NOVELTY"
  ],
  [
    "The authors present a convincing case for the originality of their",
    "NOVELTY"
  ],
  [
    "I am not comfortable enough within the literature in the PES-estimation field to reliable assess the degree of originality of the approach",
    "NOVELTY"
  ],
  [
    "contribution Specific comments",
    "NOVELTY"
  ],
  [
    "The idea is also not original .",
    "NOVELTY"
  ],
  [
    "This looks like a good theoretical contribution and an interesting direction in the theory of deep learning to me",
    "NOVELTY"
  ],
  [
    "The development of parallelizing stochastic optimization algorithms in this paper is quite interesting .",
    "NOVELTY"
  ],
  [
    "the idea sounds natural",
    "NOVELTY"
  ],
  [
    "New view on combining loss functions and regularizers via inf-convolutions .",
    "NOVELTY"
  ],
  [
    "I believe the use of spherical radial quadrature is really novel .",
    "NOVELTY"
  ],
  [
    "this is very nice , as it provides a unifying framework for existing approaches to random feature maps",
    "NOVELTY"
  ],
  [
    "I like the overall approach of estimating the local Riemannian metric for achieving near isometric embedding of manifold data .",
    "NOVELTY"
  ],
  [
    "this paper has interesting idea",
    "NOVELTY"
  ],
  [
    "a way that suggests that the techniques ( rather than mostly the perspective",
    "NOVELTY"
  ],
  [
    "and as an extension to BGAN , the paper is a very nice idea",
    "NOVELTY"
  ],
  [
    "Given the extensive literature on combining discrete and continuous latent variables in VAEs , the novelty factor of the proposed model is quite weak .",
    "NOVELTY"
  ],
  [
    "The ideas presented are interesting",
    "NOVELTY"
  ],
  [
    "and in agreement with R1 I still do not see technical novelty in the paper .",
    "NOVELTY"
  ],
  [
    "I think this paper will make a great contribution",
    "NOVELTY"
  ],
  [
    ".Thus , while I like the application , I am not sure if there is any novel contributions being made in the paper . Overall",
    "NOVELTY"
  ],
  [
    "however I am not sure about the novelty of contributions made in the paper .",
    "NOVELTY"
  ],
  [
    "Paper tackles the task-order sensitivity challenge in continual learning and introduces an effective order-robust approach .",
    "NOVELTY"
  ],
  [
    "However the improvement over Borodin 's et al method is relatively small",
    "NOVELTY"
  ],
  [
    "The paper provides a novel contribution in a largely explored field .",
    "NOVELTY"
  ],
  [
    "The introduced approach is interesting",
    "NOVELTY"
  ],
  [
    "While it is a rather simple idea which could be summarised much earlier in the single equation",
    "NOVELTY"
  ],
  [
    "I really like the thoroughness and the clarity of the exposure of the idea .",
    "NOVELTY"
  ],
  [
    "The paper presents a very nice idea introducing knowledge distillation to object class detection in images .",
    "NOVELTY"
  ],
  [
    "5 .The paper provides analysis and insights into the different aspects and novelties introduced in this work .",
    "NOVELTY"
  ],
  [
    "Novelty .The idea of knowledge distilation is not new and has been explored before in the literature .",
    "NOVELTY"
  ],
  [
    ".Therefore conceptual novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "2 .In my opinion , the idea is elegant .",
    "NOVELTY"
  ],
  [
    "I think this is a nice idea and the metric does merge the stability and low variance of mean score with the aspirations of best score",
    "NOVELTY"
  ],
  [
    "The connection between leverage scores and density using the proposed regularized Christoffel functions is interesting .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution is limited .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "Yet , I do n't think its contribution is significant , considering the work of Krause et al .2015 which uses rank-1 update to triangular Cholesky factor",
    "NOVELTY"
  ],
  [
    "This is a nice paper that expands on a bayesian model of teaching introduced in a 2014 cognitive psychology paper .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper should be rejected as it suffers from not high enough level of novelty in proposed method .",
    "NOVELTY"
  ],
  [
    "which is not enough",
    "NOVELTY"
  ],
  [
    "The overall scientific contribution to the field of Machine Learning is minor .",
    "NOVELTY"
  ],
  [
    "The detector-based performance measure is a nice idea .",
    "NOVELTY"
  ],
  [
    "The idea is rather incremental compared to FractalNet .",
    "NOVELTY"
  ],
  [
    "Nevertheless this work presents a novel method towards code generation .",
    "NOVELTY"
  ],
  [
    "Originality The interpretation seems somewhat novel , but not very surprising , though .",
    "NOVELTY"
  ],
  [
    "The proposed methodology is -- however -- just a starting point",
    "NOVELTY"
  ],
  [
    "These two developed approaches are interesting .",
    "NOVELTY"
  ],
  [
    "However , based on existing literature",
    "NOVELTY"
  ],
  [
    ", neither of them seems to contain *significant* novelty",
    "NOVELTY"
  ],
  [
    "Neither the algorithm design nor the analysis has sufficient novelty , compared to the typical standard of a top-tier conference .",
    "NOVELTY"
  ],
  [
    "It is not very clear what the novelty of this paper is .",
    "NOVELTY"
  ],
  [
    "The main concern about the novelty is that the proposed method seems like a slight variation on label propagation in order to get nicer features and then just using whatever classifier .",
    "NOVELTY"
  ],
  [
    "The filters are not new",
    "NOVELTY"
  ],
  [
    "It is a nice application of using deep features .",
    "NOVELTY"
  ],
  [
    "Limited technical novelty .",
    "NOVELTY"
  ],
  [
    "I think the technical contribution of this paper is very limited .",
    "NOVELTY"
  ],
  [
    "Although the proposed framework is not entirely novel",
    "NOVELTY"
  ],
  [
    "the optimization process is novel for this particular application",
    "NOVELTY"
  ],
  [
    "and shown to be critical by empirical evaluations",
    "NOVELTY"
  ],
  [
    "The idea of incorporating graph diffusion into neural networks seem both interesting and novel .",
    "NOVELTY"
  ],
  [
    "but as far as I can tell does not make novel testable predictions",
    "NOVELTY"
  ],
  [
    "Although inspired by prior work , the author 's contribution is novel , original and important .",
    "NOVELTY"
  ],
  [
    "2 .The introduction of a novel metric that tries to capture the `` tunability `` of an optimizer .",
    "NOVELTY"
  ],
  [
    "which however is somewhat incremental compared to similar comparisons made in the past .",
    "NOVELTY"
  ],
  [
    "The transport mechanism is also novel and seems intuitively better than the original PointNet approach of just concatenating the heat maps to the feature maps and this is shown as they track the true keypoints better than previous approaches",
    "NOVELTY"
  ],
  [
    "* intrinsic reward using keypoints is novel as far I know and intuitive and promising",
    "NOVELTY"
  ],
  [
    "Although the idea is not very novel",
    "NOVELTY"
  ],
  [
    "the paper makes enough contributions to get accepted",
    "NOVELTY"
  ],
  [
    "Conclusion Although the novelty with existing video captioning approaches is limited",
    "NOVELTY"
  ],
  [
    "The main innovations are straight forward",
    "NOVELTY"
  ],
  [
    "These contributions appear to be incremental advances considered that similar solutions have been proposed previously for PCA [ 3 ] and PLS [ 4 ] .",
    "NOVELTY"
  ],
  [
    "The idea of nested-means clustering is interesting , which somehow shows its effectiveness",
    "NOVELTY"
  ],
  [
    "The proposed memory architecture is new .",
    "NOVELTY"
  ],
  [
    "The proposed memory architecture is new but a bit limited to 2D/3D navigation tasks .",
    "NOVELTY"
  ],
  [
    "Novelty and Significance The proposed idea is novel in general .",
    "NOVELTY"
  ],
  [
    "2 .Novelty of this work is also limited",
    "NOVELTY"
  ],
  [
    "Overall , this paper is interesting and provides several novel observations .",
    "NOVELTY"
  ],
  [
    "This work is really the first to tackle learning contextual reserve pricing with multiple strategic bidders",
    "NOVELTY"
  ],
  [
    "It is quite hard to assess the novelty on the algorithmic side at this stage",
    "NOVELTY"
  ],
  [
    "I think the proposed model could make some contributions to related research communities",
    "NOVELTY"
  ],
  [
    "The idea of learning and incorporating `` adjustable loss weights `` is interesting",
    "NOVELTY"
  ],
  [
    "and I 'm not sure about the method 's novelty .",
    "NOVELTY"
  ],
  [
    "Overall I found this paper to be an original , high-quality contribution that should admit further extensions and combinations .",
    "NOVELTY"
  ],
  [
    "The paper presents a",
    "NOVELTY"
  ],
  [
    "intuitive approach to few-shot learning .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- OVERALL JUDGMENT The paper presents a clever use of VAEs for generating entity pairs conditioning on relations .",
    "NOVELTY"
  ],
  [
    "The downside of this paper is that it is weak on novelty and it is heavily based on \u00e2\u0080\u009cA .",
    "NOVELTY"
  ],
  [
    "The characterization of the distributed deep learning in the form of pipeline optimization seems to be a novel contribution , and the convergence results , particularly incorporated with randomized smoothing",
    "NOVELTY"
  ],
  [
    "While the manuscript is an interesting read from the theoretical perspective",
    "NOVELTY"
  ],
  [
    "The technique proposed in the paper to update an approximate solution to certain optimization problems for streaming data is inspired from previous work on homotopy continuation , but",
    "NOVELTY"
  ],
  [
    "is an interesting and new contribution . Combined with its use for efficiently constructing conformal sets , the contribution is novel .",
    "NOVELTY"
  ],
  [
    ", which is novel as far as I know",
    "NOVELTY"
  ],
  [
    "Therefore it seems to me that the contribution of this paper is limited in terms of technical contribution .",
    "NOVELTY"
  ],
  [
    "This paper provides a lot of novel insights in low-precision training",
    "NOVELTY"
  ],
  [
    "The paper was a good contribution to domain adaptation . It provided a new way of looking at the problem by using the cluster assumption .",
    "NOVELTY"
  ],
  [
    "I like the idea and the overall direction",
    "NOVELTY"
  ],
  [
    "I think that this paper contains interesting ideas and is a solid contribution to human-in-the-loop ML research .",
    "NOVELTY"
  ],
  [
    "and the solution , as far as I can tell , seems nontrivial",
    "NOVELTY"
  ],
  [
    "This conversion of ratio problems to a series of constrained optimization problems is a standard textbook problem , and therefore not new",
    "NOVELTY"
  ],
  [
    "The idea tested in section 4.2 seems not novel since previous works have already used recurrence to mitigate problems faced using one-step training",
    "NOVELTY"
  ],
  [
    "Overall I think the work is interesting",
    "NOVELTY"
  ],
  [
    "and although it is generalizable to other tasks and systems , it does not have sufficient novelty in its algorithm and approach",
    "NOVELTY"
  ],
  [
    "find the paper novel and interesting . To my knowledge the algorithm is original and it adds to the existing tollbox of IB based approaches .",
    "NOVELTY"
  ],
  [
    "an interesting technique",
    "NOVELTY"
  ],
  [
    "If the novelty is in applying to continual learning and new datasets , it is not clear that this is sufficient .",
    "NOVELTY"
  ],
  [
    "The approach taken in the paper based on parse trees and recursive neural networks seems interesting and promising .",
    "NOVELTY"
  ],
  [
    "The novelty is not enough . All the techniques involved in the paper are not new but from existing literature . The idea is not new .",
    "NOVELTY"
  ],
  [
    "the results are very",
    "NOVELTY"
  ],
  [
    "My major concern is about the novelty of this paper .",
    "NOVELTY"
  ],
  [
    "`` AAAI .2017 .The author combines this two ideas together , which is incremental in terms of novelty .",
    "NOVELTY"
  ],
  [
    "But its novelties and merits seem limited and rather incremental .",
    "NOVELTY"
  ],
  [
    "Originality The main contribution of the paper is similar to multiplicative gating .",
    "NOVELTY"
  ],
  [
    "The added stochasticity and the model ensembling interpretation is probably novel .",
    "NOVELTY"
  ],
  [
    "Significance This paper makes incremental improvements and would be of moderate interest to the machine learning community .",
    "NOVELTY"
  ],
  [
    "This is a nice contribution for describing a way to",
    "NOVELTY"
  ],
  [
    "I like the idea of using dynamical systems theory to attempt to explain what is going on",
    "NOVELTY"
  ],
  [
    "3 .The key contribution of the paper that the authors could highlight better is that they do not add new hyper-parameters",
    "NOVELTY"
  ],
  [
    "Paper claims that this reformulation allows better analysis and , in particular , gives an insight to use initial state noise to regularize hidden states and fight exploding gradients problem",
    "NOVELTY"
  ],
  [
    "While the idea is intriguing",
    "NOVELTY"
  ],
  [
    "I reiterate that the idea of approximating the posterior distribution over neural network weights with a posterior distribution over a lower dimensional representation of weights is interesting .",
    "NOVELTY"
  ],
  [
    "which I beleive is quite limited",
    "NOVELTY"
  ],
  [
    "The manuscript has a flavour of a review paper with some incremental extensions",
    "NOVELTY"
  ],
  [
    "The methodology contained in this paper is incremental .",
    "NOVELTY"
  ],
  [
    "I found the paper well motivated and original",
    "NOVELTY"
  ],
  [
    "2 .The analyses about the adversarial experiment and regularizing effect are insightful .",
    "NOVELTY"
  ],
  [
    "The originality of the proposed method , to some extent , is limited . 2 .The empirical observation about the superiority of high-level features is not new , since several existing studies have found it and took advantage of it",
    "NOVELTY"
  ],
  [
    "the significance and novelty of the method itself seems limited",
    "NOVELTY"
  ],
  [
    "the experiments do not provide much insight into the architecture itself .",
    "NOVELTY"
  ],
  [
    "the architecture of f_l and c_l do not seem particularly novel .",
    "NOVELTY"
  ],
  [
    "Proposes an interesting way to incorporate the rotation operations into the gated architectures .",
    "NOVELTY"
  ],
  [
    "The idea and the premise of this paper is interesting .",
    "NOVELTY"
  ],
  [
    "the paper proposes an interesting idea",
    "NOVELTY"
  ],
  [
    "It initially looks incremental with little twist in the use of such short rollouts in policy learning ,",
    "NOVELTY"
  ],
  [
    "To my knowledge the method is original",
    "NOVELTY"
  ],
  [
    "The theoretical analyses on vulnerability and dimensionality is novel and provide some insights .",
    "NOVELTY"
  ],
  [
    "and using evolutionary strategy as a tool for meta-learning with RL tasks opens new directions",
    "NOVELTY"
  ],
  [
    "The paper has interesting elements and the results are original .",
    "NOVELTY"
  ],
  [
    "The method is novel ,",
    "NOVELTY"
  ],
  [
    "This work includes original ideas and empirical findings .",
    "NOVELTY"
  ],
  [
    "The formulation is straightforward , so while I recognize it as a contribution , it is not a particularly large one .",
    "NOVELTY"
  ],
  [
    "Idea to move compression to frequency domain is a nice addition to this field",
    "NOVELTY"
  ],
  [
    "and the",
    "NOVELTY"
  ],
  [
    "loss contribution metric appears novel to me . The paper is therefore original from that aspect .",
    "NOVELTY"
  ],
  [
    "I do think that the idea explored in this paper is an interesting one and I encourage the authors to continue working in that direction .",
    "NOVELTY"
  ],
  [
    "Up to my knowledge the ArcCos kernel in connection to the ReLU neural networks interpretation in eq ( 5 ) is new and an interesting result .",
    "NOVELTY"
  ],
  [
    "but this eq ( 5 ) looks novel and interesting to me",
    "NOVELTY"
  ],
  [
    "has been discussed in previous work",
    "NOVELTY"
  ],
  [
    "I would recommend not claiming any novel contribution on the topic",
    "NOVELTY"
  ],
  [
    "While this result is novel",
    "NOVELTY"
  ],
  [
    "Overall , this paper is well-written , very novel and introduces a very practical way to adaptively regularize a neural network .",
    "NOVELTY"
  ],
  [
    "I think originality of this idea is above average .",
    "NOVELTY"
  ],
  [
    "I think this paper is theoretically very strong and the analysis is concrete with novelties .",
    "NOVELTY"
  ],
  [
    "the algorithm derivations are interesting and novel",
    "NOVELTY"
  ],
  [
    "the approach to training deep neural networks with the",
    "NOVELTY"
  ],
  [
    "I am not an expert in this particular area , so I \u2019 m not confident about the novelty .",
    "NOVELTY"
  ],
  [
    "In a nutshell , this paper presents a novel framework to solve an interesting problem motivated by real world time series",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the result is novel .",
    "NOVELTY"
  ],
  [
    "//cran.r-project.org/web/packages/bootSVD/bootSVD.pdf The novelty of the present approach is therefore unclear given prior works on bootstrapping SVD/PCA",
    "NOVELTY"
  ],
  [
    "the crux of the approach that is presented is very interesting",
    "NOVELTY"
  ],
  [
    "The algorithm is different from STORN and VRNN but does not provide any novel improvements upon them .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this is indeed a novel idea and indeed an important one .",
    "NOVELTY"
  ],
  [
    "1 .The idea for this",
    "NOVELTY"
  ],
  [
    "2 .I \u2019 m not convinced about the novelty of this paper .",
    "NOVELTY"
  ],
  [
    "the proposed idea",
    "NOVELTY"
  ],
  [
    "The proposed approach seems to be of interest and to produce interesting results",
    "NOVELTY"
  ],
  [
    ", interesting idea of combining various sources of information in a Bayesian framework for seq2seq models Handling something in an online manner typically makes things more difficult",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge I do n't see anything immediately wrong with this and it seems novel .",
    "NOVELTY"
  ],
  [
    "The proposed method is new",
    "NOVELTY"
  ],
  [
    "The idea is not entirely new .",
    "NOVELTY"
  ],
  [
    "This is nice theoretical work that establishes a relationship between the architecture of a fully connected ReLU network ( namely , depth and width of its layers ) , and the early behavior of the gradient descent training .",
    "NOVELTY"
  ],
  [
    "the ideas presented in this paper are interesting",
    "NOVELTY"
  ],
  [
    "the proposed model is novel and clever",
    "NOVELTY"
  ],
  [
    "The work is also sufficiently novel , and has some clever tricks",
    "NOVELTY"
  ],
  [
    "The idea of learning the difference between two distributions is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "Similar ideas have been explored in prior work such as",
    "NOVELTY"
  ],
  [
    "but are not doing exactly what the authors try to do",
    "NOVELTY"
  ],
  [
    "The proposed model is quite straightforward in its formulation , and since the paper is not addressing the importance of , or any challenges with the problem they are trying to solve , the contribution of this work appears minor",
    "NOVELTY"
  ],
  [
    "In sum , the idea seems nice and interesting but the model",
    "NOVELTY"
  ],
  [
    "The idea of using an autoregressive teacher model to improve a non-autoregressive translation model has been used in Gu et al.",
    "NOVELTY"
  ],
  [
    "I find the paper interesting and enjoyable",
    "NOVELTY"
  ],
  [
    "The idea is not very novel since several previous work have tried the mixture of flow such as the mentioned RAD and Deep Mixture",
    "NOVELTY"
  ],
  [
    "I think though the paper makes contribution on exploring better flow models but the novelty is relatively weak",
    "NOVELTY"
  ],
  [
    "The proposed model is technically novel in the sense that it explores the conditional modeling with the recent pixel ( R/C ) NN framework . The extension of pixel-CNN to auto-encoders is interesting .",
    "NOVELTY"
  ],
  [
    "The approximation theory shown in this paper ( Theorem 1 ) is closely related to well-known results on kernel interpolation .",
    "NOVELTY"
  ],
  [
    "This paper is a pure technical report with no novel contribution",
    "NOVELTY"
  ],
  [
    "The idea of employing object detection CNNs for OCR is not novel either",
    "NOVELTY"
  ],
  [
    "Beside the absence of novelty , the paper also suffers from several other serious flaws",
    "NOVELTY"
  ],
  [
    "All this makes the proposed method an incremental extension of existing solutions .",
    "NOVELTY"
  ],
  [
    "The paper adds a novel and interesting angle to the question of why neural networks apparently need to be heavily over-parameterized for training",
    "NOVELTY"
  ],
  [
    "The key contribution of this paper is not clear .",
    "NOVELTY"
  ],
  [
    "The originality is limited .",
    "NOVELTY"
  ],
  [
    "I am not sure I have learnt anything new from the paper",
    "NOVELTY"
  ],
  [
    "al methodology to prove convergence relying on the carre du champ is by now very standard and the proofs of the paper are only minor adaptations",
    "NOVELTY"
  ],
  [
    "All told the proposed method is quite incremental , as mixture GANs/multi-generators have been done before .",
    "NOVELTY"
  ],
  [
    "The problem and the setting it studies is very natural .",
    "NOVELTY"
  ],
  [
    "The reason is that the proof of this algorithm is too similar to the original approach of Blum et al .So",
    "NOVELTY"
  ],
  [
    "their proof approach appears to be incremental over Blum et al approach .",
    "NOVELTY"
  ],
  [
    "and also mention that it was discussed by Blum et al .2 .I think the novel and interesting part of this paper is indeed the algorithm in Section 3",
    "NOVELTY"
  ],
  [
    "The idea of constructing continuous surrogate functions and using them for differentiating through solvers with piecewise-constant output spaces is thought-provoking and I can see it inspiring many new directions of work .",
    "NOVELTY"
  ],
  [
    "I think this is a well written , well structured piece of research that presents some new contributions building on earlier work in the area",
    "NOVELTY"
  ],
  [
    "I believe this paper shows a promising approach for the face-related applications (",
    "NOVELTY"
  ],
  [
    "that I have not seen elsewhere so far .",
    "NOVELTY"
  ],
  [
    "The approach is somewhat novel .",
    "NOVELTY"
  ],
  [
    "me that SA-FPN is really novel",
    "NOVELTY"
  ],
  [
    "Given that the idea proposed by this paper is novel and interesting",
    "NOVELTY"
  ],
  [
    "This in an elegant choice , somewhat resembling the DiffPool method since it 's also end-to-end trainable",
    "NOVELTY"
  ],
  [
    "The paper draws on a wide range of ideas , and proposes novel perspectives on how these ideas might apply in RL . In particular , the concept of reachability , reversability and dissipation are explored , with respect to properties of the underlying MDP that can be exploited . I found many of the ideas thought-provoking .",
    "NOVELTY"
  ],
  [
    "While this submission has",
    "NOVELTY"
  ],
  [
    "I think the paper is fairly original . I have not seen many applications of Fourier transforms or complex analysis in RL , so the idea of the paper is very novel and fairly exciting .",
    "NOVELTY"
  ],
  [
    "I like the paper for its originality . The idea of using characteristic value function is new and unique to me . The paper follows up nicely on the idea of proposing natural extensions",
    "NOVELTY"
  ],
  [
    "functions",
    "NOVELTY"
  ],
  [
    "iteration",
    "NOVELTY"
  ],
  [
    "However , I do believe novel ideas like this are good for conference discussions .",
    "NOVELTY"
  ],
  [
    "I find the manifold mixup idea to be closely related to several lines of work for generalization abilities in machine learning",
    "NOVELTY"
  ],
  [
    "I am not clear on the novelty of this formulation , as it appears to have been proposed in a similar form in previous works",
    "NOVELTY"
  ],
  [
    "the paper may lack technical novelty in some respect",
    "NOVELTY"
  ],
  [
    "3 .Fig 5 shows some interesting insight",
    "NOVELTY"
  ],
  [
    "I think this paper is a novel work",
    "NOVELTY"
  ],
  [
    "the dimensionality reduction problem and propose a solution to it with analytical performance guarantees",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "The proposed framework is quite similar to DSN , which limits this work 's novelty .",
    "NOVELTY"
  ],
  [
    "this paper proposes to use BLEU and a corpus of multiple references in an interesting ( potentially novel ) way .",
    "NOVELTY"
  ],
  [
    "surface",
    "NOVELTY"
  ],
  [
    "I really like the discourse and found it to be filled with interesting insights throughout ranging from the connection between routing networks and neural architecture search to the heuristic for selecting k",
    "NOVELTY"
  ],
  [
    "I think there are some really good idea in this paper and vote for acceptance on that basis",
    "NOVELTY"
  ],
  [
    "While in the sparse regime treating the generality of the noise is interesting and as far as I know original",
    "NOVELTY"
  ],
  [
    "The algorithm seems related to a spectral algorithms designed for sparse graphs",
    "NOVELTY"
  ],
  [
    "I like the idea in this paper as I think combining probabilistic models and neural networks is an interesting avenue of research .",
    "NOVELTY"
  ],
  [
    "I think the idea is really intriguing and I like the work",
    "NOVELTY"
  ],
  [
    "The approach , to me , seems novel in fitting MRFs .",
    "NOVELTY"
  ],
  [
    "It is not new to use Jacobian regularizer for improving the robustness learning .",
    "NOVELTY"
  ],
  [
    "the paper 's contribution/novelty may be limited because Jacobian regularization has been earlier thoroughly discussed in",
    "NOVELTY"
  ],
  [
    "[ 19",
    "NOVELTY"
  ],
  [
    "the paper does not provide a potent novelty .",
    "NOVELTY"
  ],
  [
    "while SMOE is indeed novel",
    "NOVELTY"
  ],
  [
    "this paper presents a nice way of generating saliency maps from activations inside a network .",
    "NOVELTY"
  ],
  [
    "The technical delta from monotonic models ( existing ) to monotonic and convex/concave seems rather small ,",
    "NOVELTY"
  ],
  [
    "so the contribution of this work lies in the theoretical bounds",
    "NOVELTY"
  ],
  [
    "I believe this paper provides some interesting theoretical results for an approach that is widely-used in practice",
    "NOVELTY"
  ],
  [
    "the contributions of this work are only the theoretical bounds ; the node sampling algorithms have been proposed in existing work",
    "NOVELTY"
  ],
  [
    "The originality of this work is not significant ,",
    "NOVELTY"
  ],
  [
    "I find the paper very interesting and I like the idea of taking into account the statistical problem behind the ERM problem .",
    "NOVELTY"
  ],
  [
    "I am a bit concerned about the novelty of the paper",
    "NOVELTY"
  ],
  [
    "I find the idea interesting",
    "NOVELTY"
  ],
  [
    "but the contribution seems to be limited",
    "NOVELTY"
  ],
  [
    "As far as I am aware , the idea of learning connections in a channel-wise level is novel , as is the method to do this efficiently ( instead of accounting for all possible channel - channel connections in the network ) .",
    "NOVELTY"
  ],
  [
    "the approach in Savarese and Maire differs from the one proposed here in many ways",
    "NOVELTY"
  ],
  [
    "so I still consider this submission highly original",
    "NOVELTY"
  ],
  [
    "To the best of the reviewer 's knowledge , this adaptive approach is novel for asymptotically exact recovery in the SBMs .",
    "NOVELTY"
  ],
  [
    "Overall I believe the paper is a good contribution to the SBM literature .",
    "NOVELTY"
  ],
  [
    "but I 'm skeptical this is the first work to combine clustering and supervised prediction using an RL technique",
    "NOVELTY"
  ],
  [
    "and with the rest of the paper 's technical contribution so small",
    "NOVELTY"
  ],
  [
    "exploration bonuses , but with a slightly different take on the structure of the bonus",
    "NOVELTY"
  ],
  [
    "This is a very exciting proposal that deviates from the typical assumption that all future frames can be predicted with the same certainty",
    "NOVELTY"
  ],
  [
    "I do not work myself in video prediction , but having read in the area I believe the proposal is very novel and could make a significant shift in how prediction is currently perceived .",
    "NOVELTY"
  ],
  [
    ", and the approach is new as far as I know",
    "NOVELTY"
  ],
  [
    "While non-asymptotic behavior of TD and asymptotic behavior of TDC have been studied before , non-asymptotic analysis for TDC is new and interesting given the importance of off-policy learning and the challenge of step-size tuning in two time-scale algorithms .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- Originality -It is not a new concept that high capacity models can improve prediction tasks",
    "NOVELTY"
  ],
  [
    "but the authors apply the idea to video prediction and are the first to demonstrate that such models can perform well on this task",
    "NOVELTY"
  ],
  [
    "Significance The idea that high capacity models can perform well compared to specialized , handcrafted architectures is not novel ,",
    "NOVELTY"
  ],
  [
    "this paper is the first to apply the idea to video prediction and the first to conduct a rigorous experimental study of this type",
    "NOVELTY"
  ],
  [
    "but this",
    "NOVELTY"
  ],
  [
    "which is an interesting contribution",
    "NOVELTY"
  ],
  [
    "The idea of parameterizing Bayesian framework with neural networks is very interesting .",
    "NOVELTY"
  ],
  [
    "This is not the first theoretical paper that studies spurious optimality , and not the first one that attempts a general theory .",
    "NOVELTY"
  ],
  [
    "I think the idea of the paper is nice , and an interesting perspective on GANs",
    "NOVELTY"
  ],
  [
    "The numerical contributions are certainly significant .",
    "NOVELTY"
  ],
  [
    "Although this paper brings a new perspective , based",
    "NOVELTY"
  ],
  [
    "on optimal transport theory",
    "NOVELTY"
  ],
  [
    "as far as I can understand this paper does not establish formal new results .",
    "NOVELTY"
  ],
  [
    "Although the main contributions are clear",
    "NOVELTY"
  ],
  [
    "the work is novel and builds upon previous works in the literature .",
    "NOVELTY"
  ],
  [
    "Formulating this difficult task as a network learning problem is quite novel to me .",
    "NOVELTY"
  ],
  [
    "Thus , this work has some notable novelty and contributions .",
    "NOVELTY"
  ],
  [
    "Overall , this paper has some notable novel contributions with good presentations .",
    "NOVELTY"
  ],
  [
    "However , the focus of our paper is a novel feature representation , the formulation using a GNN framework , and the self-supervised losses .",
    "NOVELTY"
  ],
  [
    "The approach is novel",
    "NOVELTY"
  ],
  [
    "The paper proposes a new search space and a novel search method . Both contributions are original .",
    "NOVELTY"
  ],
  [
    "It presents a solid contribution , given its technical novelty , proposed",
    "NOVELTY"
  ],
  [
    "The work is fairly novel in its approach , combining a learned reward estimator with a contextual bandit algorithm for exploration/exploitation .",
    "NOVELTY"
  ],
  [
    "While the method is novel and interesting",
    "NOVELTY"
  ],
  [
    "but the approach is novel and as the authors point out",
    "NOVELTY"
  ],
  [
    "and the core ideas are compelling",
    "NOVELTY"
  ],
  [
    "One drawback to the first contribution ( EINN ) is that the Needleman-Wunsch algorithm is not , actually , widely used at all in bioinformatics .",
    "NOVELTY"
  ],
  [
    "Novel and intriguing idea Strong theoretical guarantees CONS",
    "NOVELTY"
  ],
  [
    "the adversarial framework to use a simple prior to align the hidden features seems new .",
    "NOVELTY"
  ],
  [
    "The paper is very technical",
    "NOVELTY"
  ],
  [
    "Although this is not the first paper to discuss the problem of mutli-class classification with rejection , the contribution of this",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is not significant .",
    "NOVELTY"
  ],
  [
    "The idea of learning soft dependency arcs in tandem with an NMT objective is very similar to recent notions of self-attention (",
    "NOVELTY"
  ],
  [
    "I feel that the first two ideas are particularly interesting .",
    "NOVELTY"
  ],
  [
    "This paper has some very good ideas ,",
    "NOVELTY"
  ],
  [
    "The work presented is novel but there are some notable omissions",
    "NOVELTY"
  ],
  [
    "From this perspective , there is not much novelty in this paper .",
    "NOVELTY"
  ],
  [
    "This formulation provides a novel perspectives on deep learning and offers many interesting avenues",
    "NOVELTY"
  ],
  [
    "The proposed approach combining graph neural networks with transformer-based placement network appears , at first glance , novel .",
    "NOVELTY"
  ],
  [
    "The novelty of the model is limited .",
    "NOVELTY"
  ],
  [
    "Many parts of the proof are not novel ( following from a minor modification of prior work ) .",
    "NOVELTY"
  ],
  [
    "one novel idea is `` variance auto-tuning",
    "NOVELTY"
  ],
  [
    "I like the core idea of this paper",
    "NOVELTY"
  ],
  [
    "The idea of generalising NTMs to `` universal `` TMs is interesting in itself ...",
    "NOVELTY"
  ],
  [
    "while the idea is neat",
    "NOVELTY"
  ],
  [
    ", it is not necessarily novel .",
    "NOVELTY"
  ],
  [
    "the idea is novel , the paper",
    "NOVELTY"
  ],
  [
    "The idea and approach presented in this paper is very nice .",
    "NOVELTY"
  ],
  [
    "Keeping these two groups of work in mind , I find the contribution of the proposed method limited .",
    "NOVELTY"
  ],
  [
    "This is a valuable and original use of adversarial models in the area of transparency .",
    "NOVELTY"
  ],
  [
    "Overall , the paper proposes some simple but interesting ideas ,",
    "NOVELTY"
  ],
  [
    "The paper has some nice ideas",
    "NOVELTY"
  ],
  [
    "but the contribution of the paper is not clear for me .",
    "NOVELTY"
  ],
  [
    "The VCR task is a novel task ( proposed by Zellers et al",
    "NOVELTY"
  ],
  [
    ". The proposed HGL framework for this interesting task is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The theoretical results are interesting and relatively novel .",
    "NOVELTY"
  ],
  [
    "too preliminary",
    "NOVELTY"
  ],
  [
    "Quality The paper follows recent trends in the literature",
    "NOVELTY"
  ],
  [
    ", but combines it with a novel reinforcement learning approach , sidestepping the issue of a lack of labeled examples and making it easier to adapt the method to new domains .",
    "NOVELTY"
  ],
  [
    "Originality Finding a smoothing of the reward function that actually works is a novel and interesting contribution that has n't been provided before .",
    "NOVELTY"
  ],
  [
    "I like the general idea of this paper , since it has the flavor of combining deep learning with logic rules",
    "NOVELTY"
  ],
  [
    "I feel the combination of these techniques is",
    "NOVELTY"
  ],
  [
    "definitely interesting but also somehow incremental .",
    "NOVELTY"
  ],
  [
    "I think this paper makes a clear contribution",
    "NOVELTY"
  ],
  [
    "The idea of discovering 3D key-point is very nice , though",
    "NOVELTY"
  ],
  [
    "not completely novel (",
    "NOVELTY"
  ],
  [
    "I like the idea of relative pose estimation as a supervisory signal .",
    "NOVELTY"
  ],
  [
    "The idea of self-supervised 3D keypoint localization is not entirely novel and have been addressed in the literature .",
    "NOVELTY"
  ],
  [
    "I think it is a good paper with sufficient novel contributions to be accepted to NIPS .",
    "NOVELTY"
  ],
  [
    "However , the idea is very related to Yeh et al . \u2019 s work which has already published but not mentioned at all .",
    "NOVELTY"
  ],
  [
    "The use of Gaussian mixture as a specific model for causal discovery from data with group-wise causal mechanisms seems novel and interesting .",
    "NOVELTY"
  ],
  [
    "This idea is interesting , even if it is not a real surprise",
    "NOVELTY"
  ],
  [
    "the idea of detaching feature transformation from convolution is interesting",
    "NOVELTY"
  ],
  [
    "the discussion about interpretability is interesting , and very trendy",
    "NOVELTY"
  ],
  [
    "Generally , the ideas in this paper are interesting , even not surprising .",
    "NOVELTY"
  ],
  [
    "Overall , I think this is a nice contribution .",
    "NOVELTY"
  ],
  [
    "The paper 's technical contribution seems limited .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution is limited and the technique proposed is just a small modification of existing gradient based algorithms .",
    "NOVELTY"
  ],
  [
    "While the paper has a variety of contributions",
    "NOVELTY"
  ],
  [
    "because neither the results nor the techniques are particularly surprising in the context of previous works",
    "NOVELTY"
  ],
  [
    "and I think this paper makes a certain contribution in this sense",
    "NOVELTY"
  ],
  [
    "The method is very similar to some of the existing works in the literature .",
    "NOVELTY"
  ],
  [
    "The proposed method is very similar to certain methods in the literature Detail comments",
    "NOVELTY"
  ],
  [
    "Its novelty is limited .",
    "NOVELTY"
  ],
  [
    "I like the basic idea adopted in the paper to extend Vedantam et",
    "NOVELTY"
  ],
  [
    "The backward value function idea is a nice novel way of addressing the cumulative cost constraint problem .",
    "NOVELTY"
  ],
  [
    "in my opinion , the main idea is the sharing of convolutional weights , and this is not new .",
    "NOVELTY"
  ],
  [
    "version",
    "NOVELTY"
  ],
  [
    "I find the idea interesting .",
    "NOVELTY"
  ],
  [
    "The proposed ideas are novel and seem useful .",
    "NOVELTY"
  ],
  [
    "the proposed method for learning from ordinal point relations has a minor novelty",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper is in my opinion the ( lack of ) novelty of the proposed approach",
    "NOVELTY"
  ],
  [
    "To represent formulas as graphs is not new .",
    "NOVELTY"
  ],
  [
    "It 's a nice idea for premise selection that performs better than the SOTA by combining existing ideas ( graph representation of formulas + graph vector representation learning ) .",
    "NOVELTY"
  ],
  [
    "Based on Eq . ( 1 ) ( the modified loss ) , the propose \\alpha auto-tuning algorithm , which is relatively novel .",
    "NOVELTY"
  ],
  [
    "Since , considering the trend of gains , the contribution of the proposing method seems to be incremental , this concern is inevitable .",
    "NOVELTY"
  ],
  [
    "To confirm the effective learning of visual concepts",
    "NOVELTY"
  ],
  [
    "and semantic parsing of sentences , they insightfully exploit the nature of the CLEVR dataset for visual reasoning diagnosis .",
    "NOVELTY"
  ],
  [
    "I also found the simplified examples quite interesting and intuitive .",
    "NOVELTY"
  ],
  [
    "I have not seen something similar",
    "NOVELTY"
  ],
  [
    "The approach with the attention on trees is original ,",
    "NOVELTY"
  ],
  [
    "but otherwise the tree-to-tree model is straightforward .",
    "NOVELTY"
  ],
  [
    "competing works .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is quite interesting , comparing to the existing metric learning based methods and optimization based methods .",
    "NOVELTY"
  ],
  [
    "However , there is not much novelty in this paper .",
    "NOVELTY"
  ],
  [
    "The authors do not propose any new model architectures .",
    "NOVELTY"
  ],
  [
    "I find this paper lacking in novelty .",
    "NOVELTY"
  ],
  [
    "1 .The idea is interesting",
    "NOVELTY"
  ],
  [
    "While the generalization of GANs to the broader class of f-divergences is interesting from a theoretical point of view",
    "NOVELTY"
  ],
  [
    "I believe this is a significantly novel contribution .",
    "NOVELTY"
  ],
  [
    "Unfortunately , the \u00e2\u0080\u009csingle step gradient method\u00e2\u0080\u009d proposed in the paper is not as novel as the authors claim .",
    "NOVELTY"
  ],
  [
    "This is a very original contribution which studies commonly used reductions for multi-label classification .",
    "NOVELTY"
  ],
  [
    "containing somehow",
    "NOVELTY"
  ],
  [
    "but the attention mechanism used is not new",
    "NOVELTY"
  ],
  [
    "The fact that it is applied between a sequence decoder and graph node embeddings makes the paper interesting but maybe not novel",
    "NOVELTY"
  ],
  [
    ".Incorporating these elements in the present analysis seems nontrivial",
    "NOVELTY"
  ],
  [
    "My primary concern is that the work appears incremental when compared to the baselines HRL and HRL with Stop .",
    "NOVELTY"
  ],
  [
    "Strengths \u00e2\u0080\u0093 The paper presents a novel and well-motivated approach that is crisply explained",
    "NOVELTY"
  ],
  [
    "One limitation of the proposed",
    "NOVELTY"
  ],
  [
    "from scratch",
    "NOVELTY"
  ],
  [
    "i think the idea is nice",
    "NOVELTY"
  ],
  [
    "This paper makes an interesting contribution .",
    "NOVELTY"
  ],
  [
    "but it looks incremental that the paper presents some techniques in improving Batch Normalization only .",
    "NOVELTY"
  ],
  [
    "is original and tackle a critical issue",
    "NOVELTY"
  ],
  [
    "this work is very interesting",
    "NOVELTY"
  ],
  [
    "The technical novelty is somewhat limited to a minor",
    "NOVELTY"
  ],
  [
    "This approach is a novel one in the space of domain randomization and sim2real work .",
    "NOVELTY"
  ],
  [
    "The heuristic proposed in the paper is interesting and promising in some respects",
    "NOVELTY"
  ],
  [
    "As far as I can see , this work is not particularly novel when compared with the Pilanci/Wainwright work",
    "NOVELTY"
  ],
  [
    "The proposed quantization technique is novel and leads to quantifiable trade-off between communication and convergence .",
    "NOVELTY"
  ],
  [
    "The authors provide an innovative perspective unifying modern linguistic and cognitive theory to examine how people ask questions , which has the potential to foster novel research in the active learning literature with models asking more sophisticated questions",
    "NOVELTY"
  ],
  [
    "From the perspective of a computational cognitive scientist , this paper advances the field of self-directed learning .",
    "NOVELTY"
  ],
  [
    "the ideas are interesting enough",
    "NOVELTY"
  ],
  [
    "interest",
    "NOVELTY"
  ],
  [
    "applicable and",
    "NOVELTY"
  ],
  [
    "provide novel insights",
    "NOVELTY"
  ],
  [
    "The proposed histogram loss is new and well-designed .",
    "NOVELTY"
  ],
  [
    "This is an interesting method",
    "NOVELTY"
  ],
  [
    "It is not clear to me that the work contributes any new ideas beyond those already introduced in the following paper",
    "NOVELTY"
  ],
  [
    "The idea is very similar to previous work on data-driven tight frame ( Cai et al .Applied",
    "NOVELTY"
  ],
  [
    "Although the CMF constraints used by the authors seem new , the overall novelty is still weak in my opinion .",
    "NOVELTY"
  ],
  [
    "The Audio fingerprinting models proposed in the paper are quite incremental .",
    "NOVELTY"
  ],
  [
    "Authors propose novel adversarial attack which recolors all pixels of the image in the same way using function f",
    "NOVELTY"
  ],
  [
    "The idea of using separate functions is interesting",
    "NOVELTY"
  ],
  [
    "Recasting the policy evaluation as a primal-dual optimization via the Fenchel duality technique is not new .",
    "NOVELTY"
  ],
  [
    "Given these existing work , this contribution in the paper is relatively straightforward",
    "NOVELTY"
  ],
  [
    "The method is interesting , novel",
    "NOVELTY"
  ],
  [
    "While the more general underlying principle would have been interesting to explore and a background section might have added additional clarity the paper 's novel ideas and impressive results still outline a significant contribution",
    "NOVELTY"
  ],
  [
    "The results appear to be novel ,",
    "NOVELTY"
  ],
  [
    "but not particularly original or technically deep .",
    "NOVELTY"
  ],
  [
    "This work can be characterized as a novel combination of well-known techniques .",
    "NOVELTY"
  ],
  [
    "this paper could be a great contribution on the actor critic methods",
    "NOVELTY"
  ],
  [
    "The idea of dynamic temperature scaling has been tried in other works and tasks ( e.g. ,",
    "NOVELTY"
  ],
  [
    "The paper puts forth an original framing of the problem of explaining deep neural networks .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the proposed combination of GLMs and random network models together with the MCMC Bayesian inference algorithm for inferring latent structure is novel and represents a significant contribution .",
    "NOVELTY"
  ],
  [
    "The idea of using cross-lingual or multilingual representations to seamlessly handle documents across languages is not terribly novel as it has been use in multilignual categorization or semantic similarity for some time .",
    "NOVELTY"
  ],
  [
    "however proposes",
    "NOVELTY"
  ],
  [
    "The paper gives interesting , theoretical results",
    "NOVELTY"
  ],
  [
    "This work introduces a novel approach for learning good features .",
    "NOVELTY"
  ],
  [
    "as a contribution .",
    "NOVELTY"
  ],
  [
    "the main idea of implementing two independent agents/networks to implement a reward signal that rewards deviation is interesting .",
    "NOVELTY"
  ],
  [
    "proposed approach is quite interesting and is , at my knowledge , innovative",
    "NOVELTY"
  ],
  [
    "A main weakness of this work is its technical novelty with respect to spatial transformer networks ( STN ) and also the missing comparison to the same . The proposed X-transformation seems quite similar to STN , but applied locally in a neighborhood .",
    "NOVELTY"
  ],
  [
    "In this regard , the technical novelty seems limited in this work .",
    "NOVELTY"
  ],
  [
    "insightful",
    "NOVELTY"
  ],
  [
    "but the contributions are very incremental .",
    "NOVELTY"
  ],
  [
    "but it is nonetheless a novel demonstration of the use of meta-learning for instilling machine learning models with the capacity for systematic and compositional generalization .",
    "NOVELTY"
  ],
  [
    "though none in particular seem especially novel or surprising",
    "NOVELTY"
  ],
  [
    "but what is described in the paper does not seem especially novel",
    "NOVELTY"
  ],
  [
    "Given that the novelty does not appear high",
    "NOVELTY"
  ],
  [
    "This is an interesting paper",
    "NOVELTY"
  ],
  [
    "It seems like there 's not yet a large body of work in this area",
    "NOVELTY"
  ],
  [
    ", and the submission 's solution seems novel .",
    "NOVELTY"
  ],
  [
    "The proposed model has several interesting novelties ( mainly in terms of new applications/experiments",
    "NOVELTY"
  ],
  [
    "Training the generative model with fixed ground-truth ordering was similarly performed in",
    "NOVELTY"
  ],
  [
    ") and is thus not particularly novel .",
    "NOVELTY"
  ],
  [
    "even the `` dynamic `` part of the dynamic survival analysis is not very novel",
    "NOVELTY"
  ],
  [
    "To me , the novelty is incremental .",
    "NOVELTY"
  ],
  [
    "The novelty and effectiveness of attentional generator may be limited .",
    "NOVELTY"
  ],
  [
    "Besides , the novelty of some proposed parts may be limited",
    "NOVELTY"
  ],
  [
    ") .",
    "NOVELTY"
  ],
  [
    "evaluation",
    "NOVELTY"
  ],
  [
    "This submission presents a really novel , creative , and useful way to achieve unsupervised abstractive multi-document summarization , which is quite an impressive feat .",
    "NOVELTY"
  ],
  [
    "But this should n't overshadow the bigger contributions of this paper",
    "NOVELTY"
  ],
  [
    "2 .Using a mixture of Gaussian for VAE has been used in many works before",
    "NOVELTY"
  ],
  [
    "and the novelty of the work is also limited .",
    "NOVELTY"
  ],
  [
    "Incremental == While the theoretical justification of the methods are interesting , these are not a contribution of the paper ( but of previous work by Mussmann et al . )",
    "NOVELTY"
  ],
  [
    "this idea is not new",
    "NOVELTY"
  ],
  [
    "the technical part of this paper seems to be rather straightforward",
    "NOVELTY"
  ],
  [
    "The major drawback of this paper lies in its weak technical contribution .",
    "NOVELTY"
  ],
  [
    "and this paper seemed not to provide any improvement on it",
    "NOVELTY"
  ],
  [
    "but not a significant one to NIPS which leans more to theory",
    "NOVELTY"
  ],
  [
    "another concern is that the formulation is closely similar to that in [ 30",
    "NOVELTY"
  ],
  [
    "but the technical contribution is not significant , which limits its quality especially for NIPS",
    "NOVELTY"
  ],
  [
    "but the technique has been applied to SGD before",
    "NOVELTY"
  ],
  [
    "The limitation of this paper mainly lies in the significance and proof novelty given the existing literature",
    "NOVELTY"
  ],
  [
    "Therefore the proof novelty is not significant , and the theoretical results are somehow incremental .",
    "NOVELTY"
  ],
  [
    "It 's application of known techniques , and lacks any ML novelty or sufficient ML interest .",
    "NOVELTY"
  ],
  [
    "the proposed idea is simple and intuitively appealing",
    "NOVELTY"
  ],
  [
    "There seems to be little novelty in this .",
    "NOVELTY"
  ],
  [
    "This is a simple and intuitively appealing idea",
    "NOVELTY"
  ],
  [
    "but I think the effectiveness of it here is interesting and surprising \u00e2\u0080\u0094 specially given that the variation of this problem for the second price auctions is hard to approximate",
    "NOVELTY"
  ],
  [
    "this paper could be an improvement of existing results",
    "NOVELTY"
  ],
  [
    "it is unclear if the results from Lemma 1 to Theorem 1 and 2 are both being stated as novel results",
    "NOVELTY"
  ],
  [
    "I am not sure that being the state-of-the-art for few-shot NER would be a sufficient contribution for ICLR , even if",
    "NOVELTY"
  ],
  [
    "I think the contribution is insufficient in terms of scope and convincingness of the",
    "NOVELTY"
  ],
  [
    "Although factorization ideas have been exploited in the past for other tasks I think applying it to MTL is interesting .",
    "NOVELTY"
  ],
  [
    "For the lack of novelty of the theoretical result and no suggestion of any improvement",
    "NOVELTY"
  ],
  [
    "I find the theorems interesting .",
    "NOVELTY"
  ],
  [
    "I also find the connection between the dimension of the subspace that contains the points and quality of margin obtained by cross-entropy insightful .",
    "NOVELTY"
  ],
  [
    "is a nice extension of NPI",
    "NOVELTY"
  ],
  [
    "it is a nice extension of Reed & de Freitas",
    "NOVELTY"
  ],
  [
    "it is too derivative and incremental .",
    "NOVELTY"
  ],
  [
    "The experiments are not showing anything insightful and",
    "NOVELTY"
  ],
  [
    "There is a novel model of how the brain learns relational structure .",
    "NOVELTY"
  ],
  [
    "To my knowledge , both the model and the experimental data analysis are novel .",
    "NOVELTY"
  ],
  [
    "I like how the paper addresses the weakness of the existing graph Laplacian operators ( dominance of the first eigenvector ) and proposed a new method",
    "NOVELTY"
  ],
  [
    "The paper is quite original , I am not aware of similar studies .",
    "NOVELTY"
  ],
  [
    "and the paper addresses this problem in a novel , interesting way .",
    "NOVELTY"
  ],
  [
    "I 'm not completely sure whether the whole approach is novel or not in the open set recognition domain , but both parts are not novel enough .",
    "NOVELTY"
  ],
  [
    "Despite the performance improvement , little technical novelty with regard to machine learning is introduced in the paper .",
    "NOVELTY"
  ],
  [
    "`` does `` Originality I would consider both the method ( Dirichlet mixture models with multiple elastic nets ) and the approach ( evaluation in terms of scrutinability and explainability ) quite original",
    "NOVELTY"
  ],
  [
    ".As mentioned in the comments I feel fairly strongly that this is a marginal at best contribution beyond TerpreT",
    "NOVELTY"
  ],
  [
    "It is truly inspiring .",
    "NOVELTY"
  ],
  [
    "Although the overall results are improved from the previous methods , the proposed method is lack of novelty .",
    "NOVELTY"
  ],
  [
    "This is original work of high technical quality",
    "NOVELTY"
  ],
  [
    "Originality The paper seems fairly original . The idea of leveraging known facts about linear eigenfunctions to obtain a relation between the underlying Gram matrix and the spectrum of the adjacency matrix is nice .",
    "NOVELTY"
  ],
  [
    "-- Originality and Significance -- Using a neural network for emulating the functionality of a DPP appears to be a novel contribution which has not previously appeared in the literature .",
    "NOVELTY"
  ],
  [
    "To the best of my understanding , these are all noteworthy contributions which go beyond being simply \u00e2\u0080\u0098incremental\u00e2\u0080\u0099 .",
    "NOVELTY"
  ],
  [
    "This approach is novel compared to prior results in tackling the VLN task .",
    "NOVELTY"
  ],
  [
    "Even though the two key ideas proposed in the paper has been explored in the literature in other contexts",
    "NOVELTY"
  ],
  [
    "I did not see any novel idea presented in this paper .",
    "NOVELTY"
  ],
  [
    "I did not see any novel idea proposed in this paper .",
    "NOVELTY"
  ],
  [
    "I think the first intuition is interesting",
    "NOVELTY"
  ],
  [
    "I do not see a clear novelty in the proposal .",
    "NOVELTY"
  ],
  [
    "The GP formalism with learning using Kronecker methods is not new",
    "NOVELTY"
  ],
  [
    ", but its application to estimate multivariate response functions is novel , as far as I can tell .",
    "NOVELTY"
  ],
  [
    "This work is a wise combination of recent methods to effectively address the problem of graph-based semi-supervised learning",
    "NOVELTY"
  ],
  [
    "Although the paper proposed a new interesting generative method for graph-based semi-supervised learning , it is not super novel , as it employs the other existing methods as the blocks of their method , like LSM , SBM , GCN",
    "NOVELTY"
  ],
  [
    "simple , efficient algorithm - novel convergence/recovery analysis *assuming* Gaussian-distributed data Con",
    "NOVELTY"
  ],
  [
    "The idea of converting the architecture characteristics , which is discrete in nature , to continuous variables is interesting .",
    "NOVELTY"
  ],
  [
    "I found the semi-supervised learning approach very interesting",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "and some of the proposed techniques are novel , the semi-supervised learning approach is also interesting .",
    "NOVELTY"
  ],
  [
    "The idea of using this kind of update has been around for some time .",
    "NOVELTY"
  ],
  [
    "The idea of the proof is similar to [ Kanade , Steike 2014 ] and therefore not quite ground-breaking , but notably novel .",
    "NOVELTY"
  ],
  [
    "I really like the derivation here and it seems that theoretically",
    "NOVELTY"
  ],
  [
    "The idea of utilizing back-propagated sensitivity map is not novel for weakly-supervised object localization [ 1,2 ] , as the proposed method just uses a simpler sensitivity function with linear regression",
    "NOVELTY"
  ],
  [
    "The idea of utilizing classification network for localizing an object is new",
    "NOVELTY"
  ],
  [
    ", but the ideas of weakly-supervised object localization is already explored in [ 1,2,3,4,5,6 ] .",
    "NOVELTY"
  ],
  [
    "Overall , I find the paper a promising contribution .",
    "NOVELTY"
  ],
  [
    "In my opinion , this is an interesting and promising direction for the use of deterministic quadrature rules in kernel approximation .",
    "NOVELTY"
  ],
  [
    "The generalization of advantage function is quite interesting",
    "NOVELTY"
  ],
  [
    "This is new and differs from most existing works on domain adaptation/generalization , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The new iterative method of the paper seems very interesting to",
    "NOVELTY"
  ],
  [
    "The new modules modules are relatively novel , and significantly outperform their closest architectural relatives , both in accuracy and convergence time .",
    "NOVELTY"
  ],
  [
    "Novel , well motivated approach",
    "NOVELTY"
  ],
  [
    "Really enjoyed the paper and approach",
    "NOVELTY"
  ],
  [
    "To some degree I do not find this to be a very inventive step as transfer learning has shown to able to cross much larger training data set alterations",
    "NOVELTY"
  ],
  [
    "While the results seem impressive",
    "NOVELTY"
  ],
  [
    "the method to obtain them is not very novel",
    "NOVELTY"
  ],
  [
    "as the novelty is by definition more limited than in papers proposing a new approach",
    "NOVELTY"
  ],
  [
    "the originality is limited because I think this work is a trivial extension of the previous work",
    "NOVELTY"
  ],
  [
    "I think the paper provides a good theoretical contribution in terms of interpreting many of the tricks used for improving GAN training",
    "NOVELTY"
  ],
  [
    "This paper gives a new approximation approach to the state-space formulation of Gaussian",
    "NOVELTY"
  ],
  [
    "This approach to hyper-parameter adjustments is trivial and not interesting --",
    "NOVELTY"
  ],
  [
    "other than 3.3 ) is original",
    "NOVELTY"
  ],
  [
    "VAE for trajectory embedding is new compared to recent related approaches .",
    "NOVELTY"
  ],
  [
    "Interesting , new meta-IRL method with limited empirical evaluation .",
    "NOVELTY"
  ],
  [
    "This paper is rather interesting",
    "NOVELTY"
  ],
  [
    "The theoretical results in the paper are very similar to the results given in Wu et al",
    "NOVELTY"
  ],
  [
    "so it is possible that I have overlooked at previous contributions from the literature that illustrate some of these concepts already",
    "NOVELTY"
  ],
  [
    "the proposal seems novel enough to me .",
    "NOVELTY"
  ],
  [
    "The idea of using color replacement and texture transfer is interesting and novel .",
    "NOVELTY"
  ],
  [
    "The paper is accessible in most cases and provides a novel optimization technique .",
    "NOVELTY"
  ],
  [
    "I didn\u00e2\u0080\u0099t feel like the ideas are particularly novel from a technical standpoint\u00e2\u0080\u0094the machine",
    "NOVELTY"
  ],
  [
    "learning aspects of the paper are fairly standard",
    "NOVELTY"
  ],
  [
    "I like the direction this research is going , and as far as I can see the approach is novel",
    "NOVELTY"
  ],
  [
    "the design of the architecture is beautiful",
    "NOVELTY"
  ],
  [
    "The idea is simple , so the technical contribution is a bit low .",
    "NOVELTY"
  ],
  [
    "the model the authors propose does not provide new ideas , and rather merges existing ones .",
    "NOVELTY"
  ],
  [
    "I find that the authors ' proposed method lacks proper evaluation and sufficient novelty .",
    "NOVELTY"
  ],
  [
    "This topic may not be novel enough , considering the current development in GAN and domain adaptation .",
    "NOVELTY"
  ],
  [
    "Further , the idea is also similar to many existing works in domain adaptation .",
    "NOVELTY"
  ],
  [
    "Nice and novel idea .",
    "NOVELTY"
  ],
  [
    "However , applying a deep neural network approach to data compression problem has already been discussed in several previous studies .",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is somewhat limited .",
    "NOVELTY"
  ],
  [
    "On the whole the paper presents an interesting and worthwhile contribution",
    "NOVELTY"
  ],
  [
    "the idea seems interesting from a practical point of view . The paper is quite clearly written an I could follow and understand the presented ideas . The problem and the solution is formally defined in a detailed way . To my knowledge , the problem tackled is novel , and so is its results .",
    "NOVELTY"
  ],
  [
    "hard to evaluation the contribution of this paper",
    "NOVELTY"
  ],
  [
    "The ideas presented in the paper are not ground-breakingly new",
    "NOVELTY"
  ],
  [
    ", but are a clever combination and implementation of existing ones .",
    "NOVELTY"
  ],
  [
    "Novel is the theoretical analysis of the preconditioner .",
    "NOVELTY"
  ],
  [
    "It is not clear to me whether the modification of conjugate gradients is meant to be novel",
    "NOVELTY"
  ],
  [
    "In general I like the paper and the corresponding idea .",
    "NOVELTY"
  ],
  [
    "This work presents a novel variational approach for image denoising .",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    "I suspect that the drawback of this method compared to existing ones is computational cost",
    "NOVELTY"
  ],
  [
    "While the proposed Stein gradient estimator is technically interesting",
    "NOVELTY"
  ],
  [
    "While the paper is similar in spirit to the work of Hebert-Johnson et al and Kearns et al , I feel like relaxing the fairness through awareness framework is a rather interesting contribution .",
    "NOVELTY"
  ],
  [
    "However , the paper is not very original , not from a mathematical perspective at least .",
    "NOVELTY"
  ],
  [
    "This reviewer very much liked the idea behind meta-paths and the central idea behind the `` attention scores `` .",
    "NOVELTY"
  ],
  [
    "The use of a Bayesian approach as opposed to a point estimate is interesting",
    "NOVELTY"
  ],
  [
    "even though the contribution is novel in the problem domain",
    "NOVELTY"
  ],
  [
    "and even though there is some novelty in using it for the problem domain , there is no novelty to the methodology ( Bayesian inference in a simple graphical model ) ,",
    "NOVELTY"
  ],
  [
    "with an interesting idea",
    "NOVELTY"
  ],
  [
    "The ideas themselves are interesting and , as far as I am aware , novel .",
    "NOVELTY"
  ],
  [
    "The proposed method seems to be lifted essentially whole from a recent paper",
    "NOVELTY"
  ],
  [
    "However , idea of using ensembles in the context of ( model-based ) RL is not novel ,",
    "NOVELTY"
  ],
  [
    "the proposed approach does not have strong novelty and I am not",
    "NOVELTY"
  ],
  [
    "and adds significant improvement to previous work on adding stochasticity to recurrent neural nets .",
    "NOVELTY"
  ],
  [
    "The proposed contribution is original .",
    "NOVELTY"
  ],
  [
    "The paper 's contributions are significant .",
    "NOVELTY"
  ],
  [
    "I think the trick of additive error term to the multiplicative error term is interesting and is exploited",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    "would benefit this work From a theoretical perspective , this paper provides a nice insight into the problem , as well as interesting theorems and solid proofs",
    "NOVELTY"
  ],
  [
    "Even if the originality of the algorithm is not outstanding",
    "NOVELTY"
  ],
  [
    "the results are",
    "NOVELTY"
  ],
  [
    "other algorithms , it constitutes a good advance in the state of the art for few-shot learning .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , it makes meaningful scientific contributions towards building deep interpretable and disentangled representations .",
    "NOVELTY"
  ],
  [
    "The competitive approach presented",
    "NOVELTY"
  ],
  [
    "is interesting but not really novel , thus the impact of this paper for a conference such as ICLR may be limited .",
    "NOVELTY"
  ],
  [
    "The technical results of the paper look quite similar to known margin bounds and I am afraid the contribution is minor or redundant .",
    "NOVELTY"
  ],
  [
    "But I still feel that the techniccal contribution is a bit weak .",
    "NOVELTY"
  ],
  [
    "This study is a quite interesting contribution because many existing efforts focus on improving differentiable architecture design for graph transformation and test it using chemical reaction data without considering what is learned after all",
    "NOVELTY"
  ],
  [
    "and the idea as a whole to be the `` right",
    "NOVELTY"
  ],
  [
    "I struggle to judge whether the improvements are significant or incremental",
    "NOVELTY"
  ],
  [
    "but overall the algorithm is intuitive and elegant",
    "NOVELTY"
  ],
  [
    "And their definition is clearly original .",
    "NOVELTY"
  ],
  [
    "Although using tensors to capture high-order interaction and performing dimension reduction over that are both not novel",
    "NOVELTY"
  ],
  [
    "between the proposed model and the previous models are not very clear",
    "NOVELTY"
  ],
  [
    "Method-wise , as discussed above , using tensors to capture high-order interaction and performing dimension reduction over that are both not novel .",
    "NOVELTY"
  ],
  [
    "My main concerns with this paper are novelty , reproducibility and evaluation .",
    "NOVELTY"
  ],
  [
    "but are minor contributions",
    "NOVELTY"
  ],
  [
    "and the contributions are largely based on prior works",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "to be marginal ( given the quality difference with already existing models",
    "NOVELTY"
  ],
  [
    "The ideas in this paper are quite nice",
    "NOVELTY"
  ],
  [
    "The idea is interesting and elegant .",
    "NOVELTY"
  ],
  [
    "It 's a novel GAN algorithm",
    "NOVELTY"
  ],
  [
    "======== The idea of training the generator in a GAN by using a GOF test is quite novel ( to my knowledge ) and interesting ( in my opinion ) .",
    "NOVELTY"
  ],
  [
    "different from",
    "NOVELTY"
  ],
  [
    "I like the novelty of the idea behind this paper and would very much like to see it accepted",
    "NOVELTY"
  ],
  [
    "Originality The main point of this paper has been demonstrated empirically in prior work .",
    "NOVELTY"
  ],
  [
    "it seems the theorems here are new",
    "NOVELTY"
  ],
  [
    "The techniques used in this paper are nice and insightful",
    "NOVELTY"
  ],
  [
    "I believe that the paper has a very nice set of new ideas in the context of hierarchical clustering",
    "NOVELTY"
  ],
  [
    "I agree that this paper provided a new type of feature CRF with mathematically grounded attention .",
    "NOVELTY"
  ],
  [
    "Although the model has quite a overlap with previous works",
    "NOVELTY"
  ],
  [
    "it still provides some new ideas",
    "NOVELTY"
  ],
  [
    "The model-based approach is disappointing compared to the model-free approach .",
    "NOVELTY"
  ],
  [
    "However , the model-free approach does not seem particularly novel in that it is just an extension of that from Tian et al",
    "NOVELTY"
  ],
  [
    "2017 ) plus some additional features",
    "NOVELTY"
  ],
  [
    "The idea of learning a model based on the features from a model-free agent seems novel",
    "NOVELTY"
  ],
  [
    "The technical contribution/novelty of the paper is marginal compared to [ 18 ] .",
    "NOVELTY"
  ],
  [
    "The idea of embedding data into a space that is not Euclidean is not new .",
    "NOVELTY"
  ],
  [
    "All in all the idea developed in the paper sounds interesting",
    "NOVELTY"
  ],
  [
    "It is not clear what the novelty is",
    "NOVELTY"
  ],
  [
    "New quantitative evaluation criteria based on motion",
    "NOVELTY"
  ],
  [
    "New dataset for robot arm pushing objects .",
    "NOVELTY"
  ],
  [
    "it seems that there is a novelty on the \u201c prediction with flow \u201d part of this method",
    "NOVELTY"
  ],
  [
    "Adversarial training objective alone is not new as claimed by the authors : The adversarial objective used in this paper is not new .",
    "NOVELTY"
  ],
  [
    "The adversarial objective is not novel as mentioned by the authors and has been used in [ 2,3 ] .",
    "NOVELTY"
  ],
  [
    "Most of the components are pretty standard , however I",
    "NOVELTY"
  ],
  [
    "value the part that seems pretty",
    "NOVELTY"
  ],
  [
    "novel to",
    "NOVELTY"
  ],
  [
    "me",
    "NOVELTY"
  ],
  [
    "The main contribution of this paper is interesting and novel ,",
    "NOVELTY"
  ],
  [
    "The contributions",
    "NOVELTY"
  ],
  [
    "The novelty is mostly incremental .",
    "NOVELTY"
  ],
  [
    "This is a very good paper that presents a novel approach to a very important computer vision problem .",
    "NOVELTY"
  ],
  [
    "Since metrics for kernelized analysis of dynamic system trajectories gains increasing interest in the community this contribution is generally interesting",
    "NOVELTY"
  ],
  [
    ".I am not entirely sure about the novelty or impact of the presented results .",
    "NOVELTY"
  ],
  [
    "Interesting idea to",
    "NOVELTY"
  ],
  [
    "learning approach",
    "NOVELTY"
  ],
  [
    "The work is moderately original .",
    "NOVELTY"
  ],
  [
    "my opinion is that the paper has significant contributions and the authors are willing and able to significantly reorganise the paper in a way to address our concerns",
    "NOVELTY"
  ],
  [
    "are not particularly surprising and the methods are not very innovative .",
    "NOVELTY"
  ],
  [
    "A major criticism of this paper is that the work in incremental .",
    "NOVELTY"
  ],
  [
    "I personally find the idea of incorporating confidence score into a link prediction model to achieve a more accurate model very interesting .",
    "NOVELTY"
  ],
  [
    "although I find the proposed model quite novel and interesting",
    "NOVELTY"
  ],
  [
    "in terms of significance and improvement over previous work , the contribution here is , in my opinion , limited . The fact that stochastic quantization induces sparsity for low target bit width is not new .",
    "NOVELTY"
  ],
  [
    "their optimal solution is quite similar to the QSGD scheme for a single non-zero quantization level",
    "NOVELTY"
  ],
  [
    "the idea of policy sketches is nice",
    "NOVELTY"
  ],
  [
    "but not sufficiently fleshed out to have any real impact .",
    "NOVELTY"
  ],
  [
    "the paper lacks of novelty and the",
    "NOVELTY"
  ],
  [
    "The contribution is relatively incremental",
    "NOVELTY"
  ],
  [
    "contributions",
    "NOVELTY"
  ],
  [
    "My main critique is the lack of novelty .",
    "NOVELTY"
  ],
  [
    "The theory introduces a novel notion of complexity , the so-called uniform shattering dimension .",
    "NOVELTY"
  ],
  [
    "But the proposed method is really not novel . The idea of using predecessor models have already been explored in multiple places",
    "NOVELTY"
  ],
  [
    "While the advance is in some sense fairly incremental , the centrality of unsupervised language modeling to modern deep NLP",
    "NOVELTY"
  ],
  [
    "While the task of predicting unseen predicates is interesting , the setting and the technique are similar to previous work on predicting other types of unseen labels ( e.g. , unseen objects",
    "NOVELTY"
  ],
  [
    "but is a rather direct application of existing methods",
    "NOVELTY"
  ],
  [
    "I believe the idea of approximating an expensive , high-accuracy classifier is new",
    "NOVELTY"
  ],
  [
    "it is very similar to a 2-stage cascade with different classifiers",
    "NOVELTY"
  ],
  [
    "the paper is less novel than it appears given recent results that are not discussed",
    "NOVELTY"
  ],
  [
    "The paper demonstrably advances state of the art .",
    "NOVELTY"
  ],
  [
    "Technical Novelty is Limited Compared to AQM The major departures from the AQM approach claimed in the paper",
    "NOVELTY"
  ],
  [
    "From my understand , this aspect of the approach is not novel .",
    "NOVELTY"
  ],
  [
    "The modifications made to adapt AQM to the GuessWhich setting presented here as AQM+ seem to be somewhat minor technical contributions .",
    "NOVELTY"
  ],
  [
    "Pros 1 .Novel goal-based exploration scheme Cons 1",
    "NOVELTY"
  ],
  [
    "The paper seems to be very thin technically",
    "NOVELTY"
  ],
  [
    "The reviewer thinks that this paper presents new results for the non-uniform probability distribution in solving nonconvex composite minimization problems . The algorithms are new and",
    "NOVELTY"
  ],
  [
    "I find the paper to be relatively incremental in terms of ML methods ,",
    "NOVELTY"
  ],
  [
    "but algorithmic and empirical contributions are I think rather small ( small or no empirical gains , incremental ideas ) .",
    "NOVELTY"
  ],
  [
    "To my knowledge this is the first successful application of deep learning to diplomacy .",
    "NOVELTY"
  ],
  [
    "Using energy-based formulation for graph neural network is not novel , and thus the paper lacks novelty in methodology point of view .",
    "NOVELTY"
  ],
  [
    "I do not believe the paper has sufficient novelty or experimental validation / qualitative examples to be a meaningful contribution to ICLR .",
    "NOVELTY"
  ],
  [
    "However , I felt the algorithmic contribution of the paper is not substantial .",
    "NOVELTY"
  ],
  [
    "The idea of the analysis is a refinement of the classic analysis of the greedy algorithm for set cover by Wolsey .",
    "NOVELTY"
  ],
  [
    "At a high level , the idea of the algorithm is very similar to previous streaming algorithms for the dual max-k-cover problem . The analysis however",
    "NOVELTY"
  ],
  [
    ", introduces new ideas as discussed above",
    "NOVELTY"
  ],
  [
    "The paper introduces a new problem which is quite natural",
    "NOVELTY"
  ],
  [
    "The algorithms are similar to previous ones for related problems , but",
    "NOVELTY"
  ],
  [
    "the ideas guiding the analysis are all new and interesting",
    "NOVELTY"
  ],
  [
    "The paper introduces a novel way to do architecture search that uses an RNN to guide the mutation operation .",
    "NOVELTY"
  ],
  [
    "This work seems novel and can be useful in the case where the learner can interact with the demonstrator .",
    "NOVELTY"
  ],
  [
    "The method proposed is original by focusing on the case of optimization problems with equality constraints , which has not been addressed before in the literature .",
    "NOVELTY"
  ],
  [
    "The results that simultaneously capture the phase transition behaviors of both statistical and computational boundaries for weekly supervised learning are novel , which may have impact on designing new algorithms that are efficient in both statistical and computational performances",
    "NOVELTY"
  ],
  [
    "The idea that uniform convergence bounds are inadequate for explaining generalization in some models /algorithms is not new .",
    "NOVELTY"
  ],
  [
    "but the empirical gains in terms of improving GAN metrics are relatively minor",
    "NOVELTY"
  ],
  [
    "Most the experimental improvements are incremental .",
    "NOVELTY"
  ],
  [
    "This paper opens up the new direction of considering higher-order interactions between multiple modalities . It can be seen as a novel application of existing techniques in tensors to multimodal learning .",
    "NOVELTY"
  ],
  [
    "The paper can be seen as incremental improvements on previous work that has used simple tensor products to representation multimodal data .",
    "NOVELTY"
  ],
  [
    "This paper will likely be a nice addition to the current models we have for processing multimodal data",
    "NOVELTY"
  ],
  [
    "The author novelly uses Transductive Rademacher complexity as the tool and provide elegant proofs for the results .",
    "NOVELTY"
  ],
  [
    "The idea that uses transducive Rademacher complexity is very smart and novel .",
    "NOVELTY"
  ],
  [
    "In my view the paper presents a relatively minor but still interesting extension of the work in Bernstein ( 2019 ) .",
    "NOVELTY"
  ],
  [
    "authors propose an analysis which offers a fresh view to this problem .",
    "NOVELTY"
  ],
  [
    "and the insight is very interesting . I enjoy reading the paper and I also think the contributions might be significant .",
    "NOVELTY"
  ],
  [
    "the result is essentially the same as that appearing",
    "NOVELTY"
  ],
  [
    "This appears to be the main novel idea of the paper .",
    "NOVELTY"
  ],
  [
    "I like the approach",
    "NOVELTY"
  ],
  [
    "The problem considered is novel .",
    "NOVELTY"
  ],
  [
    "The improvements seem to be quite modest which may have to do with AllReduce being very well optimized",
    "NOVELTY"
  ],
  [
    "I think this is quite a novel topic to work on",
    "NOVELTY"
  ],
  [
    "the paper seems to contain a non-trivial contribution",
    "NOVELTY"
  ],
  [
    "In terms of originality I believe the proposed method to be sufficiently novel and at no point felt this was merely an incremental improvement .",
    "NOVELTY"
  ],
  [
    "While the method for obtaining lower-variance gradients is interesting and",
    "NOVELTY"
  ],
  [
    "the application to learn optimizers is very much oversold",
    "NOVELTY"
  ],
  [
    "The problem is however that , except from advocating the use of these `` spin glass `` models studied back in the days by Seung",
    "NOVELTY"
  ],
  [
    "there are little new results presented in the paper",
    "NOVELTY"
  ],
  [
    "While such combination of multiple views is of course not new",
    "NOVELTY"
  ],
  [
    ", it is new as part of an end-to-end learnable approach .",
    "NOVELTY"
  ],
  [
    "Highly relevant prior work was overlooked",
    "NOVELTY"
  ],
  [
    "Thus , `` decision-based attacks `` are not new",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is the first attempt at using Anderson mixing in the MDP framework .",
    "NOVELTY"
  ],
  [
    "it is the first to introduce essential term selection to open-domain QA , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The above two proposed modules ( reader and selector ) are not very novel",
    "NOVELTY"
  ],
  [
    "Overall the paper is strong in originality , quality , clarity , and significance .",
    "NOVELTY"
  ],
  [
    "and the results are essentially incremental",
    "NOVELTY"
  ],
  [
    "But overall it seems like there is easily sufficient novelty compared to existing work because of both theoretical",
    "NOVELTY"
  ],
  [
    "justification for cycle-consistent bases compared to path-invariant bases",
    "NOVELTY"
  ],
  [
    "This paper makes several novel and important contributions in that direction .",
    "NOVELTY"
  ],
  [
    "This is an excellent paper overall , which advances state of the art in LLDE and entropy estimation .",
    "NOVELTY"
  ],
  [
    "but it was lacking on the novelty front",
    "NOVELTY"
  ],
  [
    "Overall , this does n't feel like a strong enough contribution for ICLR .",
    "NOVELTY"
  ],
  [
    "I 'm not particularly convinced by the case for novelty",
    "NOVELTY"
  ],
  [
    "The work seems novel in combination with the dataset , and an interesting",
    "NOVELTY"
  ],
  [
    "The paper has mainly one original idea",
    "NOVELTY"
  ],
  [
    "but on the other hand the idea itself is n't really outstanding",
    "NOVELTY"
  ],
  [
    "there are n't any other ideas or contributions of the paper",
    "NOVELTY"
  ],
  [
    "The paper relies heavily on prior work of Hoda et al .and Kroer et al .The originality of the present work appears to lie in the specific combination of techniques adopted from those prior works",
    "NOVELTY"
  ],
  [
    "To my knowledge , this paper provides many new ideas and contributions and is a considerable step forward in our understanding of approximation guarantees for these classical clustering procedures .",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper is the limited novelty , as the proposed design builds upon existing ideas and concepts . However , up to some point all the new ConvNet designs can be seen as incremental developments of the older ones , yet they are needed for the progress of the field .",
    "NOVELTY"
  ],
  [
    "This makes the paper original .",
    "NOVELTY"
  ],
  [
    "the authors propose an end to end learning algorithm based on gradient descent which is also original",
    "NOVELTY"
  ],
  [
    "to find the techniques here provide new",
    "NOVELTY"
  ],
  [
    "The idea of compression is very natural and has been explored by various previous works",
    "NOVELTY"
  ],
  [
    "While the idea of using the log trace covariance as a regularizer for the manifold is certainly interesting",
    "NOVELTY"
  ],
  [
    ", it seems fairly incremental upon previous work ( i.e. , DMWGAN ) .",
    "NOVELTY"
  ],
  [
    "I think this paper is novel , tackles a hard task",
    "NOVELTY"
  ],
  [
    "The paper is sufficiently novel and presented clearly .",
    "NOVELTY"
  ],
  [
    "Originality I think this is very original , and is an elegant way of adding the known physical process of image formation to the deep learning setup that GQN proposes . This is a natural yet original extension .",
    "NOVELTY"
  ],
  [
    "This unification is an improvement over previous literature in which a variety of specific noise models are studied ; the model and analysis here make a nice contribution to the field .",
    "NOVELTY"
  ],
  [
    "While the conceptual contribution is that the , the technical novelty is limited and mostly amounts to the appropriate choice of distributions in R and T and applying the discretization schemes to be able to compute the experiments",
    "NOVELTY"
  ],
  [
    "In general I like the idea ,",
    "NOVELTY"
  ],
  [
    "To me , it appears as if cR is not novel , but has instead been proposed in [ 3 ] previously .",
    "NOVELTY"
  ],
  [
    "The approach of representing the problem for structured decomposable circuits as a range sum computation problem is the main novelty of this paper .",
    "NOVELTY"
  ],
  [
    "but I 'm concerned about the novelty level of the paper .",
    "NOVELTY"
  ],
  [
    "The work is quite straight-forward and incremental as it basically replaces max-pooling with another function ( RELU ) .",
    "NOVELTY"
  ],
  [
    "As far as I know this work is original .",
    "NOVELTY"
  ],
  [
    "Overall , this is a complete work with novel interpretations .",
    "NOVELTY"
  ],
  [
    "It is novel and I believe",
    "NOVELTY"
  ],
  [
    "I like the idea of controlling the spread of the attention .",
    "NOVELTY"
  ],
  [
    "I believe that this paper contains interesting and novel ideas",
    "NOVELTY"
  ],
  [
    "The use of power diagrams to describe MASO output in this context seems new .",
    "NOVELTY"
  ],
  [
    "I think this paper is a huge advance in density modeling",
    "NOVELTY"
  ],
  [
    "As noted in the related work section this is not a completely new idea",
    "NOVELTY"
  ],
  [
    "and the idea looks original .",
    "NOVELTY"
  ],
  [
    "There are however 3 major issues with the current approach",
    "NOVELTY"
  ],
  [
    "In light of that work , there is very limited novelty in this paper .",
    "NOVELTY"
  ],
  [
    "and the method is novel",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "I believe the proposed method of estimating precision-recall is not novel .",
    "NOVELTY"
  ],
  [
    "The paper is original .",
    "NOVELTY"
  ],
  [
    "This work is very significant and original .",
    "NOVELTY"
  ],
  [
    "The first drawback of the paper is the limited novelty of the architecture .",
    "NOVELTY"
  ],
  [
    "the limited novelty on the modeling side",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- Overall , I think this is a promising strategy that seems to work very well on character-level language modeling .",
    "NOVELTY"
  ],
  [
    "Though the approach is interesting",
    "NOVELTY"
  ],
  [
    "Some of the techniques are actually very similar to what is used in this paper",
    "NOVELTY"
  ],
  [
    "In terms of core ML / core optimization contributions , the paper is weak .",
    "NOVELTY"
  ],
  [
    "and I think it does make a contribution",
    "NOVELTY"
  ],
  [
    "it feels like a work in progress rather than a complete piece of work",
    "NOVELTY"
  ],
  [
    "Novelty seems incremental",
    "NOVELTY"
  ],
  [
    "While it is an interesting idea",
    "NOVELTY"
  ],
  [
    ", it is not hugely novel",
    "NOVELTY"
  ],
  [
    "I would rate the architectural/theoretical contribution as not significant .",
    "NOVELTY"
  ],
  [
    "2 .The novelty is relatively small given previous work .",
    "NOVELTY"
  ],
  [
    "but I think that the paper does not have sufficient novelty .",
    "NOVELTY"
  ],
  [
    "but its contribution is limited because :",
    "NOVELTY"
  ],
  [
    "Many of the results have been already presented in previous works like Bietti",
    "NOVELTY"
  ],
  [
    "However all these methods are known and not new .",
    "NOVELTY"
  ],
  [
    "My major concern is the lack of novel contributions in this paper .",
    "NOVELTY"
  ],
  [
    "The idea of using the 3 primitive logic rules and applying the same MLP to all the permutations are interesting .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "The theorems in the paper is insightful for understanding the algorithm .",
    "NOVELTY"
  ],
  [
    ", an interesting and novel idea",
    "NOVELTY"
  ],
  [
    "These are the first such algorithms",
    "NOVELTY"
  ],
  [
    "The approach itself is also novel as far as I am aware",
    "NOVELTY"
  ],
  [
    "novel approach to estimating ridge leverage scores that may lead to more interesting work in the future - provide algorithms whose",
    "NOVELTY"
  ],
  [
    "The ideas are also very interesting .",
    "NOVELTY"
  ],
  [
    "The task is not new",
    "NOVELTY"
  ],
  [
    "Hence the novelty of the paper is limited .",
    "NOVELTY"
  ],
  [
    "The model the authors specified was innovative and practical",
    "NOVELTY"
  ],
  [
    "This is a very good paper , building on the idea of Restricted Kernel Machines ( drawing a nice parallel between Restricted Bolzman",
    "NOVELTY"
  ],
  [
    "the Kernel modelling literature ) .",
    "NOVELTY"
  ],
  [
    "and novel extensions to what appears to be previous work",
    "NOVELTY"
  ],
  [
    "This approach seems quite novel as it enables the repurposing of ImageNet classifiers to be used for counting dots in images , MNIST and CIFAR10 classifications .",
    "NOVELTY"
  ],
  [
    "The idea of augmenting natural images using 3D models is not new .",
    "NOVELTY"
  ],
  [
    "This is an excellent theoretical contribution .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is the combination of existing techniques into one algorithm .",
    "NOVELTY"
  ],
  [
    "While the idea behind this paper is interesting and their method does seem to provide improvements over other generative",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "The idea and intuition is definitely interesting . Although the idea of adapting DFO using MAB has been already explored , using MAB for choosing covariance adaptation scheme is definitely novel and interesting .",
    "NOVELTY"
  ],
  [
    "I find this unification very natural and not particularly novel/insightful .",
    "NOVELTY"
  ],
  [
    "The paper mostly extends existing tools and techniques to GLB problems",
    "NOVELTY"
  ],
  [
    "The proposed approach of combining copula and autoencoder as a generative model is quite novel .",
    "NOVELTY"
  ],
  [
    "interesting concept of combining algebraic structure with a data driven method",
    "NOVELTY"
  ],
  [
    "The toy example is novel and provides a concrete example demonstrating robustness-accuracy tradeoff , which was previously speculated .",
    "NOVELTY"
  ],
  [
    "but not particularly groundbreaking .",
    "NOVELTY"
  ],
  [
    "the theoretical contribution is not completely novel",
    "NOVELTY"
  ],
  [
    "Spiking models are very interesting class of models , which if attained would have a great impact on several other areas of machine learning .",
    "NOVELTY"
  ],
  [
    "The idea is innovative indeed .",
    "NOVELTY"
  ],
  [
    "The two techniques used in this paper are bidirectional LSTM ( which is not novel",
    "NOVELTY"
  ],
  [
    "which is novel )",
    "NOVELTY"
  ],
  [
    "On balance I quite like this paper , as it addresses an interesting problem , and applies two approaches ( one of which is novel ) , both showing very large improvement over the only previous work addressing this problem .",
    "NOVELTY"
  ],
  [
    "introduces a new idea",
    "NOVELTY"
  ],
  [
    "The analysis contains novel technicalities and can be of general interest for understanding the landscape of non-convex problems .",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting",
    "NOVELTY"
  ],
  [
    ", to the best of my knowledge novel , and have clear consequences",
    "NOVELTY"
  ],
  [
    "The strength of the paper are that the solution proposed ( dynamic approximation ) is original and sensible .",
    "NOVELTY"
  ],
  [
    "a novel adversarial attack on node embedding method based on random walks",
    "NOVELTY"
  ],
  [
    "This work follow the proposal Qiu et al . (",
    "NOVELTY"
  ],
  [
    "'s proof and present a novel approach to calculate the loss when the network changes by A ' .",
    "NOVELTY"
  ],
  [
    "3 .They present a new way to attack node embedding by factorizing a equivalent matrix .",
    "NOVELTY"
  ],
  [
    "While the main idea is almost trivial",
    "NOVELTY"
  ],
  [
    "if somewhat incremental and technical",
    "NOVELTY"
  ],
  [
    "paper about the generalization and convergence of GAIL",
    "NOVELTY"
  ],
  [
    "on the generalization aspects , the methodology here seems to largely parallel Arora et al . 's analysis of generalization in GANs",
    "NOVELTY"
  ],
  [
    "despite what seems to me to be a somewhat incremental nature",
    "NOVELTY"
  ],
  [
    "and `` Reinforcement learning by reward-weighted regression for operational space control `` which makes the contribution of this paper very incremental",
    "NOVELTY"
  ],
  [
    "This method is novel , afaict , and is based on interesting statistical hypotheses .",
    "NOVELTY"
  ],
  [
    "but the gains are somewhat incremental and may only apply to PPO",
    "NOVELTY"
  ],
  [
    "While the idea of using a downstream classification task to evaluate the quality of generative models has been explored before",
    "NOVELTY"
  ],
  [
    "I think that this is the first paper to evaluate GANs using such an evaluation metric",
    "NOVELTY"
  ],
  [
    "The ideas and models presented in this paper are not new ,",
    "NOVELTY"
  ],
  [
    "The novelty is marginal - some parts are not clear to me .",
    "NOVELTY"
  ],
  [
    "All components of the framework are quite standard and deja-vu",
    "NOVELTY"
  ],
  [
    "but I like the paper in general , and the results seem quite encouraging",
    "NOVELTY"
  ],
  [
    "The proposed framework does not offer any substantial modeling contribution",
    "NOVELTY"
  ],
  [
    "and the method lacks originality compared to existing work",
    "NOVELTY"
  ],
  [
    "I believe the significance and originality of this work to be lacking .",
    "NOVELTY"
  ],
  [
    "The paper fails to provide new insights to the reader .",
    "NOVELTY"
  ],
  [
    "makes the entire work somehow incremental",
    "NOVELTY"
  ],
  [
    "The paper contains sufficient novel",
    "NOVELTY"
  ],
  [
    "The paper brings new algorithm and new results in accelerated stochastic gradient methods .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the paper is the first to a ) use the median of means algorithm in RL/MDPs b ) derive bounds for MDPs with unbounded rewards c ) not have a dependence in M ( the max reward ) in the bounds .",
    "NOVELTY"
  ],
  [
    "1 .The idea of converting a pre-trained model with f ( w ) +||w-w*|| is interesting .",
    "NOVELTY"
  ],
  [
    "However at a more detailed level the proof is novel",
    "NOVELTY"
  ],
  [
    "Both the ( \\delta , p ) nondeterministic property and the echelon tree idea seem novel and applicable in other settings .",
    "NOVELTY"
  ],
  [
    "The work proposed in the paper is original in a way that they propose a GP for modeling PP where the kernel of GP is a function of inter-arrival times instead of the absolute time of the event in the sequence",
    "NOVELTY"
  ],
  [
    "I found this paper is interesting",
    "NOVELTY"
  ],
  [
    "Hyperbolic embeddings are a promising new research area that fits well into ICLR . Overall , the paper is written well and good to understand . It introduces interesting ideas that are promising to advance hyperbolic embeddings .",
    "NOVELTY"
  ],
  [
    "However , this insight alone seems not particularly novel",
    "NOVELTY"
  ],
  [
    "the value of the N-pair selection is sufficient to justify publication -- it is a nice idea that would probably be adopted and extended by other researchers",
    "NOVELTY"
  ],
  [
    "I believe the authors that this contribution is novel and",
    "NOVELTY"
  ],
  [
    "novel",
    "NOVELTY"
  ],
  [
    "although the basic MDP model",
    "NOVELTY"
  ],
  [
    "13 actions ) seem to be derived from a previous work and be extended",
    "NOVELTY"
  ],
  [
    "It adopts a simple but novel idea on SISR and shows clear improvement against existing method ( e.g. , SRGAN ) .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this paper is the first work to learn multi-modal probabilistic model for SISR .",
    "NOVELTY"
  ],
  [
    "The two-stage architecture is similar to the following generative models and SR methods",
    "NOVELTY"
  ],
  [
    "novel objective function that does not require labeled data",
    "NOVELTY"
  ],
  [
    "This is an elegant piece of work , an interesting extension of the convention DUDE .",
    "NOVELTY"
  ],
  [
    "Therefore , the novelty of the proposed tracking approach is limited .",
    "NOVELTY"
  ],
  [
    "and the proposed method combined with both graph- and sequence-based encoding is technically interesting",
    "NOVELTY"
  ],
  [
    "I believe that the paper in its current form has not completely studied the problem and hence I am giving the paper a weak reject score at this stage",
    "NOVELTY"
  ],
  [
    "Originality This paper makes a significant contribution in terms of proposing a new model for sharing causal relations .",
    "NOVELTY"
  ],
  [
    "The idea is appealing",
    "NOVELTY"
  ],
  [
    "The paper is an application paper and does not offer novel advances for the ICLR community .",
    "NOVELTY"
  ],
  [
    "Interesting/intriguing idea *",
    "NOVELTY"
  ],
  [
    "brushed off as if unimportant The idea of",
    "NOVELTY"
  ],
  [
    "While the idea may be appealing",
    "NOVELTY"
  ],
  [
    "I 'm not too familiar with related work in this area , but I believe the results are quite novel . Overall , this paper is a significant contribution .",
    "NOVELTY"
  ],
  [
    "The proposed classes are new but are minor modifications of existing ones .",
    "NOVELTY"
  ],
  [
    "I can not say that the proposed method is absolutely novel .",
    "NOVELTY"
  ],
  [
    "The basic idea is interesting",
    "NOVELTY"
  ],
  [
    "There seem to be no 'new ideas ' in this paper",
    "NOVELTY"
  ],
  [
    "I still find the contribution interesting and even enlightening .",
    "NOVELTY"
  ],
  [
    "However the novelty is limited which means that numerical experiments should be quite extensive to demonstrate a clear impact on the",
    "NOVELTY"
  ],
  [
    "The contribution to prove effectiveness of random projection for polygonal curves is novel and is a neat extension of previous work on median and center clustering of polygonal curves using Frechet distance .",
    "NOVELTY"
  ],
  [
    "As I understand , the sublinear dependence for 1-median clustering does not have much novelty beyond using a previously known sampling idea from Indyk 's thesis",
    "NOVELTY"
  ],
  [
    "method which , although very simple to understand and implement , is novel as far as I 'm aware of , and may be an inspiration for further meaningful advances in RL .",
    "NOVELTY"
  ],
  [
    "The approach looks very interesting",
    "NOVELTY"
  ],
  [
    "The basic idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "The application and the approach appear quite novel .",
    "NOVELTY"
  ],
  [
    "but at the very least the paper provides interesting new ideas for others to work on",
    "NOVELTY"
  ],
  [
    "The paper therefore lacks novelty .",
    "NOVELTY"
  ],
  [
    "but the work seems original",
    "NOVELTY"
  ],
  [
    "the paper seems original/novel , as far as I can tell .",
    "NOVELTY"
  ],
  [
    "From the paper 's exposition , it appears that this is a novel idea and , if so , would be certainly of interest to the machine learning community .",
    "NOVELTY"
  ],
  [
    "I liked the novelty of combining the use of GANs in new directions ( namely ES/GA ) .",
    "NOVELTY"
  ],
  [
    "Overall , I liked the work as it provides a fresh way of using GANs with another subfield ( ES/GA ) .",
    "NOVELTY"
  ],
  [
    "However , the idea of using multimodal VAE for ZSL is n't new or surprising and has been used in earlier papers too .",
    "NOVELTY"
  ],
  [
    "The proposed multimodal VAE model is very similar to the existing ones",
    "NOVELTY"
  ],
  [
    "Therefore , the methodological novelty of the work is somewhat limited .",
    "NOVELTY"
  ],
  [
    "Given that the technical novelty is somewhat limited , the paper falls short significantly on the experimental analysis .",
    "NOVELTY"
  ],
  [
    "The approach , and its constituent contributions , i.e .of using RL for program synthesis , and limiting to syntactically valid programs , are novel .",
    "NOVELTY"
  ],
  [
    "The improvements over the baseline methods is small but substantial",
    "NOVELTY"
  ],
  [
    "Claiming exploratory results as a contribution is bit weak in the paper , plus it is not a new dataset .",
    "NOVELTY"
  ],
  [
    "combining two existing components is ok but not enough novelty from my point of view .",
    "NOVELTY"
  ],
  [
    "but other than that , the technical novelty is scarce",
    "NOVELTY"
  ],
  [
    "It is the first paper analyzing difficulties one faces in optimizing multi-layer homogeneous functions",
    "NOVELTY"
  ],
  [
    "I like the idea of applying Information Theory to Deep Learning",
    "NOVELTY"
  ],
  [
    "I found this paper interesting and enjoyed reading it .",
    "NOVELTY"
  ],
  [
    "Significance -- -- -- -- -- -- -- -- The proposed construction is indeed interesting",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , both the idea of using the distribution in eq . ( 6 ) as a base distribution and the idea of using Given rotations in variational inference are also novel .",
    "NOVELTY"
  ],
  [
    "On the whole this is interesting work",
    "NOVELTY"
  ],
  [
    "I have concerns about the novelty of the two main contributions of this work",
    "NOVELTY"
  ],
  [
    "Originality The novelty of the method is limited .",
    "NOVELTY"
  ],
  [
    "Lacking technical novelty .",
    "NOVELTY"
  ],
  [
    "Overall I liked the method developed by this paper , it\u00e2\u0080\u0099s an interesting alternative to the SVCCA method of [ 1 ] .",
    "NOVELTY"
  ],
  [
    "The novelty of this algorithm is limited .",
    "NOVELTY"
  ],
  [
    "Thus , the contribution of this paper is limited .",
    "NOVELTY"
  ],
  [
    "It is also novel and interesting the addition of an attribute predictor in the system which provides additional information that can not be captured by the saliency map alone .",
    "NOVELTY"
  ],
  [
    "the introdution of attributes in the explanation process is a very interesting contribution since they provide the user an explanation that is a step closer to a description in natural language",
    "NOVELTY"
  ],
  [
    "I am not convinced that the contribution of this paper is enough , nor of its novelty .",
    "NOVELTY"
  ],
  [
    "The proposed approach is quite appealing",
    "NOVELTY"
  ],
  [
    "Overall , this paper is well written and the idea is interesting .",
    "NOVELTY"
  ],
  [
    "In my opinion , the contributions of this paper are expected",
    "NOVELTY"
  ],
  [
    "The PIB objective is new and different to the other objectives .",
    "NOVELTY"
  ],
  [
    "The idea using KL divergence creating a deficiency channel to learn data representation is very natural .",
    "NOVELTY"
  ],
  [
    "The presented idea seems novel .",
    "NOVELTY"
  ],
  [
    "I do not feel that there is a great deal of novelty in this paper",
    "NOVELTY"
  ],
  [
    "I am not sure about the main contribution",
    "NOVELTY"
  ],
  [
    "While the mixup method is not new",
    "NOVELTY"
  ],
  [
    "this work seems to be the first to use it for training well-calibrated models and convincingly demonstrate its applicability and advantage over several alternatives .",
    "NOVELTY"
  ],
  [
    "Novel design of new Bellman-like operators with better properties .",
    "NOVELTY"
  ],
  [
    "using data to learn exploration strategy in tis manner is a novel idea for bandits",
    "NOVELTY"
  ],
  [
    "minimal",
    "NOVELTY"
  ],
  [
    "The dataset is a very nice contribution",
    "NOVELTY"
  ],
  [
    "The paper tackles an interesting and challenging problem with a novel approach in sequence modeling .",
    "NOVELTY"
  ],
  [
    "All in all I find this paper interesting",
    "NOVELTY"
  ],
  [
    "This paper 's theoretical analysis does appear to set it apart from prior work",
    "NOVELTY"
  ],
  [
    "Since",
    "NOVELTY"
  ],
  [
    "the originality of the paper mainly lies in the bounds derivation and experiments",
    "NOVELTY"
  ],
  [
    "Therefore , I believe that this study has made an advance in the field of vison processing for the robotics .",
    "NOVELTY"
  ],
  [
    "The growing strategy identified in the paper as a superior alternative seems to be already known and used",
    "NOVELTY"
  ],
  [
    "The proposed SMILE estimator is natural .",
    "NOVELTY"
  ],
  [
    "The method is , to the best of my knowledge , novel , and is an innovative way to launch trigger attacks even when the adversary does not know what the final classes or task will be .",
    "NOVELTY"
  ],
  [
    "I think It\u00e2\u0080\u0099s nice to bring the idea of meta learning into learning the initial parameters of model and the objective function .",
    "NOVELTY"
  ],
  [
    "The contribution in terms of method is small",
    "NOVELTY"
  ],
  [
    "While based on existing embedding methods such as Patchy-San , the contribution of ego-centric convolution and multi-layer architechture is novel and has a lot of potential in applications .",
    "NOVELTY"
  ],
  [
    "I am unfamiliar with prior work in this application area",
    "NOVELTY"
  ],
  [
    "but maybe the work is novel with respect to the application of the regularized VAE framework to speech synthesis .",
    "NOVELTY"
  ],
  [
    "the application alone is in my opinion not a contribution that is significant enough for publication .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel idea to detect backdoor attacks in neural networks . Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "I think this is a promising approach",
    "NOVELTY"
  ],
  [
    "The main contribution of the paper is a clever interpolation scheme",
    "NOVELTY"
  ],
  [
    "The interpolation method is novel and",
    "NOVELTY"
  ],
  [
    "the originality and significance of this work is a significant drawback .",
    "NOVELTY"
  ],
  [
    "So the algorithms themselves are not particularly novel ,",
    "NOVELTY"
  ],
  [
    "This paper is interesting",
    "NOVELTY"
  ],
  [
    "I 'm willing to excuse the fact that the paper is only moderately novel",
    "NOVELTY"
  ],
  [
    "The interactive demo website provided with the submission is one of the most unique , enjoyable , and informative presentations of a machine learning result I have ever encountered .",
    "NOVELTY"
  ],
  [
    "while the idea presented in this paper is interesting ( using lattices as discrete latent variables )",
    "NOVELTY"
  ],
  [
    "but does n't provide much new insight",
    "NOVELTY"
  ],
  [
    "The main idea of relating the GNN to some CV tasks is really interesting .",
    "NOVELTY"
  ],
  [
    "I like the idea in general .",
    "NOVELTY"
  ],
  [
    "This is similar to attention models used by others",
    "NOVELTY"
  ],
  [
    "but I think it is novel when applying to this specific application domain .",
    "NOVELTY"
  ],
  [
    "Although natural and simple , the main main idea seems to be original .",
    "NOVELTY"
  ],
  [
    "The template-based prediction is novel",
    "NOVELTY"
  ],
  [
    "The main idea presented in the paper appears to be interesting and insightful , particularly for semantic parsing where access to parallel corpus is often limited .",
    "NOVELTY"
  ],
  [
    "It 's a nice idea",
    "NOVELTY"
  ],
  [
    "but can not say for sure whether the idea is novel/significant",
    "NOVELTY"
  ],
  [
    "I also think the work is original",
    "NOVELTY"
  ],
  [
    "From a theoretical standpoint , I think the approach is interesting and elegant .",
    "NOVELTY"
  ],
  [
    "The creation of the upper limit based on noise between and within subjects was a nice addition . 4 .Some relevant related work is discussed and this seems like a novel and interesting contribution .",
    "NOVELTY"
  ],
  [
    "6 .While this paper is not especially surprising or ground breaking",
    "NOVELTY"
  ],
  [
    "I think that technically this idea is new",
    "NOVELTY"
  ],
  [
    "the proof relies on a novel observation",
    "NOVELTY"
  ],
  [
    "this reviewer thinks this is a very interesting approach with a lot of potential",
    "NOVELTY"
  ],
  [
    "this reviewer believes the proposed model is very promising",
    "NOVELTY"
  ],
  [
    "The proposed method is novel ( as far as I can tell )",
    "NOVELTY"
  ],
  [
    "1 .Contribution of approach : The approach to use attention in this way is to my knowledge novel and interesting .",
    "NOVELTY"
  ],
  [
    "The approach itself is novel and interesting to my knowledge and speaks for acceptance .",
    "NOVELTY"
  ],
  [
    "provide a new algorithm that has better complexity compared to the uniform one and other existing methods",
    "NOVELTY"
  ],
  [
    "This paper indeed provides a novel algorithm for non-uniform subsample Newton method due to my knowledge . The theoretical result is new and has a significant impact in this area .",
    "NOVELTY"
  ],
  [
    "While the approach looks interesting , I have a few concerns : -- Using the Bayesian model comparison framework seems to be an interesting idea .",
    "NOVELTY"
  ],
  [
    "These points detract from a paper that otherwise makes an interesting contribution",
    "NOVELTY"
  ],
  [
    "This paper introduces a new and promising approach to the problem that",
    "NOVELTY"
  ],
  [
    "and the mathematical results contained in the paper are creative and nontrivial . Even the result restricted to planar graphs is interesting and insightful .",
    "NOVELTY"
  ],
  [
    "As far as I am aware this paper 's exploration of model-free robust RL is novel .",
    "NOVELTY"
  ],
  [
    "On one hand , using model-free unsupervised RL methods to learn intermediate-level skills is not a new idea .",
    "NOVELTY"
  ],
  [
    "approaching this problem via mutual information is , as far as I know , new to this field .",
    "NOVELTY"
  ],
  [
    "the novelty of this approach remains undecided",
    "NOVELTY"
  ],
  [
    "While each component is not novel",
    "NOVELTY"
  ],
  [
    ", the synthesis of the components has some novelty .",
    "NOVELTY"
  ],
  [
    "and some proofs contain interesting original ideas",
    "NOVELTY"
  ],
  [
    "In my view , this is a beautiful paper",
    "NOVELTY"
  ],
  [
    "========== The proposed objective seems novel to me compared to the existing methods",
    "NOVELTY"
  ],
  [
    "Further , the solution they propose is novel and a seems like a significant improvement over the extend state-of-the-art .",
    "NOVELTY"
  ],
  [
    "To clarify the contribution",
    "NOVELTY"
  ],
  [
    "convergence guarantee ) is different from that in [ Orabona & Pal , 2016 ]",
    "NOVELTY"
  ],
  [
    "a variant of their algorithm is proposed as a practical method for deep learning optimization , which is a very novel , original approach compared to existing methods like Adam/RMSpop/AdaDelta/etc .",
    "NOVELTY"
  ],
  [
    "the novelty",
    "NOVELTY"
  ],
  [
    "The idea of using IPVI for DGPs is interesting and it seems to perform competitively with VI and SGHMC",
    "NOVELTY"
  ],
  [
    "The application of IPVI to DGPs is certainly new and interesting , and I like the idea of parameter tying .",
    "NOVELTY"
  ],
  [
    "Implicit VI in itself is not new",
    "NOVELTY"
  ],
  [
    "the proposed algorithm can be seen as just a naive combination of clustering and meta-learning .",
    "NOVELTY"
  ],
  [
    "I have not seen it proposed before .",
    "NOVELTY"
  ],
  [
    "The idea behind tracing the part-whole assignments back to primary capsule layer is interesting and original .",
    "NOVELTY"
  ],
  [
    "I am still of the opinion that this paper represents a significant contribution .",
    "NOVELTY"
  ],
  [
    "and the ideas are also interesting and original .",
    "NOVELTY"
  ],
  [
    "This contribution seems incremental .",
    "NOVELTY"
  ],
  [
    "The contribution in 3.2 seems interesting .",
    "NOVELTY"
  ],
  [
    "But for machine learning this is a standard procedure , so has limited methodology novelty .",
    "NOVELTY"
  ],
  [
    "As an application paper , the proposed methods are somewhat incremental",
    "NOVELTY"
  ],
  [
    "form",
    "NOVELTY"
  ],
  [
    "Nevertheless , this paper clearly explores and offers a novel approach for more efficient on-policy exploration which allows for more stable learning compared to traditional approaches .",
    "NOVELTY"
  ],
  [
    "It 's use with SVRG feels like only an incremental improvement .",
    "NOVELTY"
  ],
  [
    "ClusterACDM and ClusterSVRG methods both are really novel and at the",
    "NOVELTY"
  ],
  [
    "but the methodological contribution is incremental , some",
    "NOVELTY"
  ],
  [
    "Framing optimizing as a sequence to sequence problem is not new .",
    "NOVELTY"
  ],
  [
    "The proposed regularizer is very similar to the method of Ross & Doshi .",
    "NOVELTY"
  ],
  [
    "Several novel ideas .",
    "NOVELTY"
  ],
  [
    "Very Good .",
    "NOVELTY"
  ],
  [
    "The `` lookahead `` nature of Optimistic Gittins is interesting and innovative .",
    "NOVELTY"
  ],
  [
    "The proposed technique is of modest contribution",
    "NOVELTY"
  ],
  [
    "but the technical novelty of this work is significantly limited by existing work that used similar ideas .",
    "NOVELTY"
  ],
  [
    "However , the model has minor novelty given existing work that has explored similar ideas .",
    "NOVELTY"
  ],
  [
    "The proposed methods are interesting and novel .",
    "NOVELTY"
  ],
  [
    "In terms of the technical contribution , it provides a fresh look at the construction of surrogate losses from the point of view of embeddings , proving the interesting result that every discrete loss can be embedded into a polyhedral loss as well as the converse .",
    "NOVELTY"
  ],
  [
    "addition to the literature on losses and surrogates",
    "NOVELTY"
  ],
  [
    "The quality of the paper is excellent in terms of novelty and originality .",
    "NOVELTY"
  ],
  [
    "This seems like too small a contribution to warrant a paper .",
    "NOVELTY"
  ],
  [
    "solutions are interesting",
    "NOVELTY"
  ],
  [
    "Comments about the method : I couldn \u2019 t find anything particularly novel about the method .",
    "NOVELTY"
  ],
  [
    "This clearly written and highly novel paper describes a critical gap in the causal inference literature .",
    "NOVELTY"
  ],
  [
    "While the paper is not perfect",
    "NOVELTY"
  ],
  [
    "I believe the significant novelty and potential impact on the community outweigh these weaknesses and that it is a significant contribution .",
    "NOVELTY"
  ],
  [
    "While the proposed model and experiments seem interesting",
    "NOVELTY"
  ],
  [
    "there seems to be limited novelty in the used model compared to prior works .",
    "NOVELTY"
  ],
  [
    "3 .It is the first robust regularizer that is able to provide non-trivial robustness guarantees for multiple lp balls",
    "NOVELTY"
  ],
  [
    "The problem they are addressing is novel , and they use a simple but effective approach to address that . The paper is well written and most of the details are clear . Their approach is novel in finding important subgraphs for the prediction .",
    "NOVELTY"
  ],
  [
    "id appealing . The idea of regarding the history as a tree looks very promising .",
    "NOVELTY"
  ],
  [
    "mechanical",
    "NOVELTY"
  ],
  [
    "It propose a new self-handicapping network which extents the original CAM network with multiple branches .",
    "NOVELTY"
  ],
  [
    "It is an elegant design .",
    "NOVELTY"
  ],
  [
    "Even though this paper draws",
    "NOVELTY"
  ],
  [
    "inspiration from previous work",
    "NOVELTY"
  ],
  [
    "the claimed contributions of the paper do n't seem to be significant enough",
    "NOVELTY"
  ],
  [
    "and the idea looks interesting",
    "NOVELTY"
  ],
  [
    "Connection with Nash equilibrium seems to be slightly overclaimed",
    "NOVELTY"
  ],
  [
    ", but the attempt is novel and interesting",
    "NOVELTY"
  ],
  [
    "The ideas of using ensemble of low-level policies is intuitive and appealing .",
    "NOVELTY"
  ],
  [
    "The approach is interesting",
    "NOVELTY"
  ],
  [
    "From what I can tell , the model itself is not new",
    "NOVELTY"
  ],
  [
    "as variational training of an energy model is the most natural and elegant",
    "NOVELTY"
  ],
  [
    "I think this is the most important contribution of the paper .",
    "NOVELTY"
  ],
  [
    "Overall I very much enjoy the presented insight of this paper into GAN .",
    "NOVELTY"
  ],
  [
    ", and the proof technique ( reduction to a zero-sum game ) is quite novel .",
    "NOVELTY"
  ],
  [
    "new possibilities such as entropy maximization which are not well-served by lower bounds like IWAE",
    "NOVELTY"
  ],
  [
    "I think this is a very nice new",
    "NOVELTY"
  ],
  [
    "The reason I am giving `` poster `` ranks is that I feel that the paper is to a large extent incremental over existing work .",
    "NOVELTY"
  ],
  [
    "Integrating CRFs with GNNs for node classification is not new ( [ 1",
    "NOVELTY"
  ],
  [
    "but this paper extended energy definition to capture high-order connections and use it for a new subsequent task",
    "NOVELTY"
  ],
  [
    "It is interesting and novel",
    "NOVELTY"
  ],
  [
    "but",
    "NOVELTY"
  ],
  [
    "proposes a creative but simple new definition ,",
    "NOVELTY"
  ],
  [
    "CIFAR10 I like the idea of building models that are memory efficient at training and at evaluation time",
    "NOVELTY"
  ],
  [
    "9 .The ideas presented in the paper seems related to general concept of hypernetworks , where one network learns ( or helps to learn ) paramenters of the other network",
    "NOVELTY"
  ],
  [
    "Overall , the paper presents interesting ideas with some degree of originality .",
    "NOVELTY"
  ],
  [
    "The idea of directly modifying the gradients to accomplish a certain task is intriguing .",
    "NOVELTY"
  ],
  [
    "the paper does not provide novel surprising results .",
    "NOVELTY"
  ],
  [
    "this limits the novelty of the results relative to existing literature .",
    "NOVELTY"
  ],
  [
    "it does not provide novel insights nor obtains current state-of-the-art results on CIFAR10",
    "NOVELTY"
  ],
  [
    "If the paper is about a new method , then the novelty is lacking .",
    "NOVELTY"
  ],
  [
    "from the viewpoint of modeling , it is just a smoothing penalized multivariate linear regression model for the least squares problem , which is very similar to many existing matrix/tensor completion methods , thus the novelty is rather limited .",
    "NOVELTY"
  ],
  [
    "by itself .",
    "NOVELTY"
  ],
  [
    "the idea of deforming images is new",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "The idea is a simple extension of existing work .",
    "NOVELTY"
  ],
  [
    "The results on word learning biases are not particularly surprising given previous work in this area",
    "NOVELTY"
  ],
  [
    "This seems like one of the most novel findings in the paper and is worth highlighting .",
    "NOVELTY"
  ],
  [
    "even though the architecture is not very novel",
    "NOVELTY"
  ],
  [
    "One originality of the method is the negative sampling strategy that includes negative TF-IDF retrieval as starting points to robustify the sequential extraction process",
    "NOVELTY"
  ],
  [
    "Measuring the function complexity using mutual information appears to be new in the study of deep learning .",
    "NOVELTY"
  ],
  [
    "The paper is rather incremental with respect to [ 31 ] .",
    "NOVELTY"
  ],
  [
    "However , I find that there is too little novelty in the paper with respect to the stacked hour glasses paper and that",
    "NOVELTY"
  ],
  [
    "I found the contributions quite straightforward ,",
    "NOVELTY"
  ],
  [
    "To my knowledge , this angle of analysis is new to the body of GAN research .",
    "NOVELTY"
  ],
  [
    "but not strong - The key results Thm1,2 are direct variations of differential privacy and may appear incremental rather than fundamental",
    "NOVELTY"
  ],
  [
    "This is an original approach .",
    "NOVELTY"
  ],
  [
    "In terms of novelty , the UNIT network can be treated as an extension of coGAN paper",
    "NOVELTY"
  ],
  [
    "Multi-task , especially the segmentation part is not novel for self-driving car prediction",
    "NOVELTY"
  ],
  [
    "it does not appear to have been used in current algorithms",
    "NOVELTY"
  ],
  [
    "However , the approach proposed is limited in novelty",
    "NOVELTY"
  ],
  [
    "My first concern is the limited novelty of the work .",
    "NOVELTY"
  ],
  [
    "there are too many existing works that are similar to the proposed one in one or more aspects",
    "NOVELTY"
  ],
  [
    "The main drawback of the paper , however , is whether the contributions are enough for this venue .",
    "NOVELTY"
  ],
  [
    "- interesting idea",
    "NOVELTY"
  ],
  [
    "The approach is quite new , in the sense that nobody has previously tackled the dropout problem in this way .",
    "NOVELTY"
  ],
  [
    "From this point , the novelty is not very strong .",
    "NOVELTY"
  ],
  [
    "The idea of constructing a smaller MDP whose Q-values can be computed exactly by dynamic programming on tabular states , then use these Q-values to help dealing with the instability issues in deep RL is very interesting .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this has not been done before .",
    "NOVELTY"
  ],
  [
    "this is a nice contribution to spectral graph theory and so I recommend acceptance",
    "NOVELTY"
  ],
  [
    "with a somewhat incremental conceptual contribution .",
    "NOVELTY"
  ],
  [
    "I consider this a novel contribution .",
    "NOVELTY"
  ],
  [
    "and the proposed notion of stability with respect to diffusion distances seems like an interesting and relevant way to extend this to signals on graphs",
    "NOVELTY"
  ],
  [
    "However , from the technical perspective , the reviewer feels this work has limited novelty and does not advance the research frontier by much .",
    "NOVELTY"
  ],
  [
    "The work of designing decoder on top of RL/control in order to generalize to new , unseen environments is very interesting , and is pretty novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "I think the LSH based attention quite novel and is a natural solution to reducing the complexity of the self-attention module .",
    "NOVELTY"
  ],
  [
    "I think this paper is a good contribution as it",
    "NOVELTY"
  ],
  [
    "the work seems to be sufficiently original with respect to its predecessor ( SUCRL ) and with respect to other published works in NIPS",
    "NOVELTY"
  ],
  [
    "Detailed comments This is a good contribution ,",
    "NOVELTY"
  ],
  [
    "although rather incremental with respect to Patrini et al . '",
    "NOVELTY"
  ],
  [
    "I am personally of the opinion that the field is in the unusual position of possessing too many tools that \u201c work \u201d and too few new ideas",
    "NOVELTY"
  ],
  [
    "Elegant as the idea sounds",
    "NOVELTY"
  ],
  [
    "A novel method for selecting candidate tests Overall , the paper presents the motivation",
    "NOVELTY"
  ],
  [
    "The first part of the paper , while not proposing new approaches , offers interesting insights into the performance of linear policies , given plethora of prior work on applying NN policies as default on these",
    "NOVELTY"
  ],
  [
    "This paper should be rejected because the originality of the proposed method over MixUp is marginal , and the improvement of classification accuracy is not surprising",
    "NOVELTY"
  ],
  [
    "The modification of label mixing ratios is not enough contribution .",
    "NOVELTY"
  ],
  [
    "The idea of using a sequentially structured inference network is interesting .",
    "NOVELTY"
  ],
  [
    "the solution is almost entirely based on previous work .",
    "NOVELTY"
  ],
  [
    "The most novel part of the paper is the learning of the multimodal features .",
    "NOVELTY"
  ],
  [
    "Overall it seems to be a limited contribution .",
    "NOVELTY"
  ],
  [
    "but the general idea of combining different specifications is quite promising",
    "NOVELTY"
  ],
  [
    "The proposed approach explicitly combines an established model with two components that are themselves well-established .",
    "NOVELTY"
  ],
  [
    "It 's fair to say that the novelty is relatively weak .",
    "NOVELTY"
  ],
  [
    "In terms of novelty",
    "NOVELTY"
  ],
  [
    "Thus , the idea is not as novel as the submission tries to present .",
    "NOVELTY"
  ],
  [
    "contribution . The reduction to OCO with memory is a nice idea",
    "NOVELTY"
  ],
  [
    "Overall , this paper has significant contribution both in terms of theory and experiments .",
    "NOVELTY"
  ],
  [
    "insightful",
    "NOVELTY"
  ],
  [
    "Over the idea is interesting",
    "NOVELTY"
  ],
  [
    "The paper seems original compared to a set of alternatives that the authors have provided and compared against .",
    "NOVELTY"
  ],
  [
    "The theoretical analysis and the prosed method are appealing .",
    "NOVELTY"
  ],
  [
    "3/5 The idea to use the Hellinger distance is neat .",
    "NOVELTY"
  ],
  [
    "This work does alleviate this problems but without open and easy-to-use software the impact is likely to be small",
    "NOVELTY"
  ],
  [
    "In terms of algorithmic contribution",
    "NOVELTY"
  ],
  [
    "my feeling is that",
    "NOVELTY"
  ],
  [
    "presently this paper does not contain a sufficient aggregation of novel research contribution and empirical validation .",
    "NOVELTY"
  ],
  [
    "The idea of using the Inverse Probability of Treatment Weighting ( IPTW ) to adjust for time-dependent confounding in the objective function is new .",
    "NOVELTY"
  ],
  [
    "The model is an interesting embodiment of the idea of predictive coding implemented using a end-to-end backpropable recurrent neural network architecture .",
    "NOVELTY"
  ],
  [
    "However , the proposed model is most probably novel in the way it feds back the error signal and implements the entire model as a single differentiable network .",
    "NOVELTY"
  ],
  [
    ", it is relatively novel to use multi-agent reinforcement learning in this field",
    "NOVELTY"
  ],
  [
    "a major concern of mine is the contribution of novelty of the manuscript .",
    "NOVELTY"
  ],
  [
    "However , both the hypothesis and the technical solution are lacking enough contributions of novelty .",
    "NOVELTY"
  ],
  [
    "The paper is an interesting",
    "NOVELTY"
  ],
  [
    "but incremental , improvement to the area of",
    "NOVELTY"
  ],
  [
    "while the results are somewhat strong , the ideas presented are small variations on existing systems .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "to be efficient .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed approach is novel , and there are many potential problems that could benefit from this idea .",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat limited , since the paper is combining two previously proposed ideas",
    "NOVELTY"
  ],
  [
    "Neat idea for exploring an experts behavior by changing the environment surrounding it ( probing it )",
    "NOVELTY"
  ],
  [
    "I like the idea of having a policy that tries to figure out the general behavior of a demonstrator by probing it",
    "NOVELTY"
  ],
  [
    "7 ]",
    "NOVELTY"
  ],
  [
    "which has some but limited originality",
    "NOVELTY"
  ],
  [
    "The previous work appears to already introduce all the necessary mechanisms for 3D generalization from multiple viewpoints",
    "NOVELTY"
  ],
  [
    "however the methods proposed are not particularly interesting , and the contributions to ML and NLP are overstated in my opinion",
    "NOVELTY"
  ],
  [
    "I understand that this is not the main contribution of the paper",
    "NOVELTY"
  ],
  [
    "the challenge of combining reasoning over continuous and discrete representations is not new .",
    "NOVELTY"
  ],
  [
    "It is the first time I have seen this novelty detection task .",
    "NOVELTY"
  ],
  [
    "While the learning architecture is not original in itself",
    "NOVELTY"
  ],
  [
    "I found the approach and the paper quite interesting\u00e2\u0080\u0094it 's a very different way of doing approximate posterior inference",
    "NOVELTY"
  ],
  [
    "I 'm not an expert on these new discrete random projection results , but this seems like a nice application of them .",
    "NOVELTY"
  ],
  [
    "is not very interesting , nor develops novel proof techniques",
    "NOVELTY"
  ],
  [
    "The algorithm uses several techniques from previous works and while not very novel combines previous ideas in a clever way .",
    "NOVELTY"
  ],
  [
    "This sort of approach of using two levels of learning algorithms is not particularly new to this approach , but the exact application is non-trivial .",
    "NOVELTY"
  ],
  [
    "The problem and algorithm are nice but there are two important drawbacks",
    "NOVELTY"
  ],
  [
    "3 .The work presented has its own originality in terms of both model architecture and stability solutions , which makes it a valuable contribution .",
    "NOVELTY"
  ],
  [
    "but limited in novelty in terms of the proposed architecture",
    "NOVELTY"
  ],
  [
    "The proposed approach is very similar in architecture to [ 1 * ,",
    "NOVELTY"
  ],
  [
    "3* ] , which are not discussed/referenced in the paper",
    "NOVELTY"
  ],
  [
    "I think the RKHS perspective that the authors advocate for here is actually quite interesting",
    "NOVELTY"
  ],
  [
    "and because the resulting training procedures seem to be essentially identical to previously-proposed approaches , the mere contribution of connecting these works to the RKHS norm does n't seem independently to be enough of a contribution in my mind",
    "NOVELTY"
  ],
  [
    "While many papers consider query answering in a knowledge graph , the complicated form of query considered in this paper is novel and interesting and seems to be a step forward .",
    "NOVELTY"
  ],
  [
    "I do not think turning an existing method SCOPE into the proximal version is quite interesting or has great contribution .",
    "NOVELTY"
  ],
  [
    "I quite like this paper and I think that it is a nice and incremental work in the field of Bayesian optimisation .",
    "NOVELTY"
  ],
  [
    "Although the problem of generating knockoffs based on VAE is novel",
    "NOVELTY"
  ],
  [
    "the main idea of this paper seems not entirely novel .",
    "NOVELTY"
  ],
  [
    "The technical contribution is rather incremental since there exist numerous works on introducing another discriminator to GAN , such as Triple-GAN .",
    "NOVELTY"
  ],
  [
    "I think this research is quite incremental over MobileNets and is unlikely to spur further research strains .",
    "NOVELTY"
  ],
  [
    "The novel aspect of this approach is that it takes into account temporal aspects , i.e .the performance of individual evaluators over time .",
    "NOVELTY"
  ],
  [
    "Personally , I liked the idea of using another colorization method to design cAdv and the use of K-means clustering to control the imperceptibility",
    "NOVELTY"
  ],
  [
    "but they are new to this area",
    "NOVELTY"
  ],
  [
    "The remaining components of the system do not seem to be novel .",
    "NOVELTY"
  ],
  [
    "the idea of automatically selecting the most suitable cameras for the triangulation purpose is interesting .",
    "NOVELTY"
  ],
  [
    "Overall , I find this work to be a really exciting advance on discrete adversarial attacks .",
    "NOVELTY"
  ],
  [
    "Originality As far as I know , this work is ( very ) original .",
    "NOVELTY"
  ],
  [
    "I find the idea natural and simple (",
    "NOVELTY"
  ],
  [
    "I also find the contribution a bit limited .",
    "NOVELTY"
  ],
  [
    "Unrolling sparse coding inference as a feed-foward network is not new .",
    "NOVELTY"
  ],
  [
    "The model , however , is insightful in other ways as well .",
    "NOVELTY"
  ],
  [
    "novel RNN architecture derived by their analysis",
    "NOVELTY"
  ],
  [
    "Although I found the idea quite interesting",
    "NOVELTY"
  ],
  [
    "The authors propose a novel measure to evaluate domain discrepancy ; the idea is interesting and novel .",
    "NOVELTY"
  ],
  [
    "and the baseline methods are a little out-of-date",
    "NOVELTY"
  ],
  [
    "Pros Novel treatment and formulation of meta-learning from the perspective of fast and slow learning process",
    "NOVELTY"
  ],
  [
    "The paper approaches the recently popular meta-learning from a novel perspective by decomposing the learning process into slow and fast ones .",
    "NOVELTY"
  ],
  [
    "To my acknowledge , the task and the count-based methods are not too novel .",
    "NOVELTY"
  ],
  [
    "While studying cross-entropy loss is interesting , the analysis techniques in this paper are very similar to Zhong et al .2017 , so this paper is incremental .",
    "NOVELTY"
  ],
  [
    "I feel the paper has some good contribution",
    "NOVELTY"
  ],
  [
    "It 's a neat idea",
    "NOVELTY"
  ],
  [
    "The paper proposes nothing novel in terms of methods , which is a serious weakness for a methods conference like ICLR .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work that has modelled azimuth angle detection with a Spiking NN .",
    "NOVELTY"
  ],
  [
    "My biggest concern with the paper is the generality of its contribution .",
    "NOVELTY"
  ],
  [
    ", and generally can provide a useful contribution .",
    "NOVELTY"
  ],
  [
    "I like the idea of having",
    "NOVELTY"
  ],
  [
    "In terms of novelty , currently the differences between the current work and previous attempts to develop benchmarks is unclear",
    "NOVELTY"
  ],
  [
    "I found this paper very interesting and the idea of training the network through the sampling procedure promising .",
    "NOVELTY"
  ],
  [
    "Overall , I appreciate the general idea and find the proposed approach very interesting .",
    "NOVELTY"
  ],
  [
    "the proposed idea is completely out-of-date as a submission for ICLR 2019",
    "NOVELTY"
  ],
  [
    "and has strong technical contributions",
    "NOVELTY"
  ],
  [
    "Limited novelty .",
    "NOVELTY"
  ],
  [
    "proposed scheme .",
    "NOVELTY"
  ],
  [
    "It proposes a fresh take on well-worn territory",
    "NOVELTY"
  ],
  [
    "the idea is novel to me",
    "NOVELTY"
  ],
  [
    "Overall , I think there 're novelty in computational efficiency gain .",
    "NOVELTY"
  ],
  [
    "I think it 's a nice idea",
    "NOVELTY"
  ],
  [
    "Though not particularly novel",
    "NOVELTY"
  ],
  [
    "no great theoretical novelty",
    "NOVELTY"
  ],
  [
    "the paper contains no original technical work .",
    "NOVELTY"
  ],
  [
    "These results are interesting and insightful to some extent .",
    "NOVELTY"
  ],
  [
    "A nice contribution to the semi-supervised clustering literature .",
    "NOVELTY"
  ],
  [
    "I still like the direction of this model and the learning-theory contribution of this paper .",
    "NOVELTY"
  ],
  [
    "Defined an interpolation techniques in latent state and demonstrated its success using different experiments The paper has solid original contribution",
    "NOVELTY"
  ],
  [
    "\u00c2 The method is new and original .",
    "NOVELTY"
  ],
  [
    "The strengths are as follows",
    "NOVELTY"
  ],
  [
    "Technically , the proposed SCDM is novel",
    "NOVELTY"
  ],
  [
    "Overall , this paper has good originality and quality from the technical aspect .",
    "NOVELTY"
  ],
  [
    "so there is only moderate novelty .",
    "NOVELTY"
  ],
  [
    "-- I liked the idea behind this paper .",
    "NOVELTY"
  ],
  [
    "Though somewhat new , the novelty of this paper may be incremental to me .",
    "NOVELTY"
  ],
  [
    "The proposed method looks novel to me .",
    "NOVELTY"
  ],
  [
    "While the idea of manuscript is interesting and promising for bioinformatics",
    "NOVELTY"
  ],
  [
    "but to the best of my knowledge this had never been done before and this appears to be well done .",
    "NOVELTY"
  ],
  [
    "As far as I know this work is original",
    "NOVELTY"
  ],
  [
    "It certainly adapts ideas from prior work but they are sufficiently different",
    "NOVELTY"
  ],
  [
    "that are not very unique in the general scientific community",
    "NOVELTY"
  ],
  [
    "I think it is a nice paper that makes significant contributions to the",
    "NOVELTY"
  ],
  [
    "The propose approach is a somewhat minor ( though impactful ) deviation from the Confident Multiple Choice Learning approach of [ 18 ]",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- As noted in the summary , the technical novelty in this submission is somewhat limited over prior work .",
    "NOVELTY"
  ],
  [
    "The contribution due to the meta algorithm is minor since classification with L^stab and L^adv has been studied before",
    "NOVELTY"
  ],
  [
    "REVIEW SUMMARY -- -- -- -- -- -- -- I believe that this paper addresses an important problem in a novel manner ( as far as I can tell )",
    "NOVELTY"
  ],
  [
    "The idea is sort of interesting",
    "NOVELTY"
  ],
  [
    "I found this paper to be very interesting",
    "NOVELTY"
  ],
  [
    "The theoretical results in the work are to the best of my knowledge novel .",
    "NOVELTY"
  ],
  [
    "This idea is not novel and has been used several times in the literature for regret minimization .",
    "NOVELTY"
  ],
  [
    "The novelty in this paper is also quite limited",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are far from sufficient",
    "NOVELTY"
  ],
  [
    "The Theorem 1 in this paper is a triangle inequality on the loss , and the observation about splitting the robust generalization into standard generalization error and stability , is not particularly new .",
    "NOVELTY"
  ],
  [
    "Overall I find the contributions of this paper to be not sufficient and can not recommend acceptance at this stage",
    "NOVELTY"
  ],
  [
    "and the connection to exploding gradients is perhaps the most interesting and useful part of the paper",
    "NOVELTY"
  ],
  [
    "This paper provides a new ( to me , anyway ) and thought-provoking analysis of RNNs .",
    "NOVELTY"
  ],
  [
    "The same applies to contraction results for the `` softmax `` Bellman operator -- these results are not novel at all",
    "NOVELTY"
  ],
  [
    "the background review on ANP is surprisingly informal with no technical detail at all",
    "NOVELTY"
  ],
  [
    "very incremental given the prior works of SNP and ANP",
    "NOVELTY"
  ],
  [
    "The technical contribution is low from a methods perspective , since the study is almost entirely empirical and does n't develop new technques",
    "NOVELTY"
  ],
  [
    "Hence the findings of 3.2 and 3.5 have limited novelty in light of",
    "NOVELTY"
  ],
  [
    "it is not introducing any significant new models",
    "NOVELTY"
  ],
  [
    "high , the proposed method for the SGD estimation is novel , while the second-order approximation is standard but reasonable .",
    "NOVELTY"
  ],
  [
    "The proposed formulation is a slightly different take on lossy compression , which has the potential to inspire novel solutions .",
    "NOVELTY"
  ],
  [
    "both have been shown in prior work and the novelty in this paper seems to be limited to putting together these two ideas",
    "NOVELTY"
  ],
  [
    "The authors of this paper propose a novel approach for symbolic regression .",
    "NOVELTY"
  ],
  [
    "but I do not think this submission is demonstrating any meaningful progress",
    "NOVELTY"
  ],
  [
    "I really like the paper , which demonstrates the powerfulness of spectral analysis",
    "NOVELTY"
  ],
  [
    "Novelty of the new algorithm is quite limited , as it simply uses a learned dynamics model and reward function to learn a value function .",
    "NOVELTY"
  ],
  [
    "but might not be the most insightful and important in practice .",
    "NOVELTY"
  ],
  [
    "I still think that the paper is a good contribution to the community since",
    "NOVELTY"
  ],
  [
    "In general , I like the idea of this work .",
    "NOVELTY"
  ],
  [
    "However , the analysis might not be novel since some are closely related to and adapted from [ 41 ] .",
    "NOVELTY"
  ],
  [
    "The reinforcement learning methodology is appropriate but",
    "NOVELTY"
  ],
  [
    "straightforward and closely resembles previous work for text modeling and dialogue generation . By itself the methodology does n't offer a new technique .",
    "NOVELTY"
  ],
  [
    "and I think the GAN formulation here is original .",
    "NOVELTY"
  ],
  [
    "AEB is not a novel approach",
    "NOVELTY"
  ],
  [
    "Also , the proposed method has limited novelty given the fact that Kronecker structure covariance matrix as posterior has been proposed in [ 2 ] .",
    "NOVELTY"
  ],
  [
    "Unfortunately , the technical value of the content and its novelty is very limited since the proof reduces to a very basic argument that counts invariances",
    "NOVELTY"
  ],
  [
    "Judging from Table 1 , the proposed method does not seem to provide a large contribution .",
    "NOVELTY"
  ],
  [
    "The main idea comes from the original algorithm , thus the originality of the paper is a bit incremental .",
    "NOVELTY"
  ],
  [
    "The earlier theoretical work",
    "NOVELTY"
  ],
  [
    "regarding the properties of binary classifiers is , in my opinion , less interesting and less novel",
    "NOVELTY"
  ],
  [
    "Summarization Generally , this paper provides a novel way to stabilize the training of GAN .",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper is lack of cohesion in contributions",
    "NOVELTY"
  ],
  [
    "The filters by themselves seem trivial and as such do not offer much novelty .",
    "NOVELTY"
  ],
  [
    "Finally , performance itself did not seem to improve significantly compared to previous methods/simple filters , and the novelty in terms of ML and insights about learning representations seemed limited .",
    "NOVELTY"
  ],
  [
    "The dataset by itself is a good contribution",
    "NOVELTY"
  ],
  [
    "Thus , the very topic of research is significantly novel and promising .",
    "NOVELTY"
  ],
  [
    "work addresses a novel point-based learning task",
    "NOVELTY"
  ],
  [
    "The notion of temporal dynamics being important for modeling the missing ness mechanism is interesting",
    "NOVELTY"
  ],
  [
    "This is a novel approach to this problem\u00e2\u0080\u0094I doubt that many researchers in this area have considered the relationship between temporal dynamics of users and item as related to the MNAR problem",
    "NOVELTY"
  ],
  [
    "1/ The mirror descent strategy is not new .",
    "NOVELTY"
  ],
  [
    "The setup in the paper for learning representations is different to many other approaches in the area , using to agents that communicate over descriptions of objects using different modalities",
    "NOVELTY"
  ],
  [
    "The primary weakness of this paper is that it is a `` straightfoward `` way to extend the BBP-MAP method to CNNs and RNNs , so the methodological novelty is weak relative to the BBP-MAP past work",
    "NOVELTY"
  ],
  [
    "I vote for a weak reject for this paper as I believe the contribution of the current paper is limited",
    "NOVELTY"
  ],
  [
    "I think the current contribution is not sufficient to merit a publication",
    "NOVELTY"
  ],
  [
    "The approach they study is easy to understand , the analysis of this paper is original and interesting .",
    "NOVELTY"
  ],
  [
    "comparatively small modelling innovation",
    "NOVELTY"
  ],
  [
    "The key contribution seems to be the formalization of some notion of spatial transformation",
    "NOVELTY"
  ],
  [
    "and hence I would rate that the contribution is not very significant",
    "NOVELTY"
  ],
  [
    "The proposed method is novel",
    "NOVELTY"
  ],
  [
    "Viewing the problem as a minmax saddle point problem is an interesting take and I find the use of the boolean constraint matrix novel .",
    "NOVELTY"
  ],
  [
    "despite the fact that the contribution is not very original and the",
    "NOVELTY"
  ],
  [
    "it is not clear that the universality is what makes it work",
    "NOVELTY"
  ],
  [
    "it is not clear that universality is the important advantage of Mint .",
    "NOVELTY"
  ],
  [
    "The method overall seems to be a very interesting structural approach to variational autoencoders",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper has a potentially strong idea",
    "NOVELTY"
  ],
  [
    "There are some interesting contributions , but maybe not enough for a full length paper .",
    "NOVELTY"
  ],
  [
    "but provides substantial novel content in a derivation of an entire class of \u00e2\u0080\u009cpower-law\u00e2\u0080\u009d codes that would induce the same relation",
    "NOVELTY"
  ],
  [
    "This is a strong submission with novel",
    "NOVELTY"
  ],
  [
    ", and novel ideas that elaborate on the concept of efficient coding .",
    "NOVELTY"
  ],
  [
    "with compelling ideas",
    "NOVELTY"
  ],
  [
    "No new contributions .",
    "NOVELTY"
  ],
  [
    "but somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The difference between CRPS-INTVL and MLE-INTVL is incremental and it \u2019 s unclear what the significant benefits are of CRPS vs MLE .",
    "NOVELTY"
  ],
  [
    "the paper introduces genuinely novel concepts and I strongly believe that it would be unfair to demand an empirical evaluation at the same scale as papers which make relatively minor adjustments to existing techniques",
    "NOVELTY"
  ],
  [
    "As far as I am aware , this is a highly novel approach to MBRL .",
    "NOVELTY"
  ],
  [
    "and it is fundamentally , conceptually different than existing MBRL approaches",
    "NOVELTY"
  ],
  [
    "in a creative and novel way ,",
    "NOVELTY"
  ],
  [
    "The main contribution , namely the method itself , is simple yet nontrivial and worth publishing",
    "NOVELTY"
  ],
  [
    "This work significantly improves upon Online Newton Step in a non-trivial way .",
    "NOVELTY"
  ],
  [
    "As acknowledged by the authors the fundamental ideas relating to the Gaussian case are not new",
    "NOVELTY"
  ],
  [
    "The approach is therefore very similar to the one of Pathak .",
    "NOVELTY"
  ],
  [
    "Most of the proofs are not original",
    "NOVELTY"
  ],
  [
    "while I commend the authors for an intriguing idea",
    "NOVELTY"
  ],
  [
    "Interesting idea (",
    "NOVELTY"
  ],
  [
    "I consider the proposed method as novel .",
    "NOVELTY"
  ],
  [
    "As I mentioned above , the choice of Lagrangian formulation seems natural",
    "NOVELTY"
  ],
  [
    "I really like this paper as it proposes a very simple and elegant approach to one shot learning by combining neural networks with non-parametric structures .",
    "NOVELTY"
  ],
  [
    "Overall , this paper proposes a novel and interesting idea",
    "NOVELTY"
  ],
  [
    "As far as I know , incorporating Hungarian matching to associate hypotheses and ground truths as part of an end-to-end pipeline is novel .",
    "NOVELTY"
  ],
  [
    "PowerSGD is the first gradient compression algorithm that is compatible with all-reduce based distributed applications compared to most of the previously proposed communication efficient distributed training algorithms",
    "NOVELTY"
  ],
  [
    "and while it combines two existing approaches ( actor-critic reinforcement learning for navigation , and belief propagation using graph convolution networks ) is sufficiently novel to be of interest to at least some members of the community .",
    "NOVELTY"
  ],
  [
    "As far as I am aware , using neural networks to define generalized value functions that are to be learned as an auxiliary task is a novel and interesting combination of existing ideas , and could be used in future work .",
    "NOVELTY"
  ],
  [
    "in that regard too , the authors present work that is new to the field",
    "NOVELTY"
  ],
  [
    "I do feel , however , that the novelty of the meta-gradient computation procedure is being overstated , as it seems equivalent to [ 1",
    "NOVELTY"
  ],
  [
    "The proposed method sounds interesting and promising to me .",
    "NOVELTY"
  ],
  [
    "Therefore the meta-update computation is not itself a novel contribution ,",
    "NOVELTY"
  ],
  [
    "This feels rather incremental .",
    "NOVELTY"
  ],
  [
    "EVALUATION I found this paper very interesting .",
    "NOVELTY"
  ],
  [
    "but to the best of my knowledge , none of them have managed to convert it into an improved approximation bound .",
    "NOVELTY"
  ],
  [
    "I found the idea of using controller modules for increment learning interesting",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is somewhat limited .",
    "NOVELTY"
  ],
  [
    "As far as a know , this is the first attempt towards mixing rate for multi-modal distributions that has polynomial dependence on everything .",
    "NOVELTY"
  ],
  [
    "the contribution of this paper might be eclipsed",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting",
    "NOVELTY"
  ],
  [
    "The novelty of the attack is a bit dim , since it seems it 's just the straightforward attack against the region cls defense",
    "NOVELTY"
  ],
  [
    "The provided analysis is insightful",
    "NOVELTY"
  ],
  [
    "I think the novelty of the attack is not very strong .",
    "NOVELTY"
  ],
  [
    "The analysis of section 4.1 is interesting , it was insightful and to the best of my knowledge novel .",
    "NOVELTY"
  ],
  [
    "It is hard for a reader to see novelties there",
    "NOVELTY"
  ],
  [
    "I found this idea interesting and natural",
    "NOVELTY"
  ],
  [
    "I found this sampling procedure interesting and may have applications in other machine learning / numerical linear algebra tasks .",
    "NOVELTY"
  ],
  [
    "the results on adaptivity ( to unknown effective dimension and smoothness ) are quite striking",
    "NOVELTY"
  ],
  [
    "much of this work appears to be a re-working of previous work , while Lemma B.4 and the remainder of Theorem 3.1 appear to be the main contributions",
    "NOVELTY"
  ],
  [
    "Regarding the usage of energy-based models , the idea is interesting .",
    "NOVELTY"
  ],
  [
    "Not much technical novelty 2",
    "NOVELTY"
  ],
  [
    "The proposed recurrent neural network architecture seems novel , technically",
    "NOVELTY"
  ],
  [
    "I 'm concerned that the contribution of this manuscript is a little incremental .",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "To begin with , the authors seem to be missing some recent developments in the field of deep learning which are closely related to the proposed",
    "NOVELTY"
  ],
  [
    "The approach is",
    "NOVELTY"
  ],
  [
    "not ground-breaking",
    "NOVELTY"
  ],
  [
    "novel semi-supervised approach to learning",
    "NOVELTY"
  ],
  [
    "the type of semi-supervised supervision proposed here appears novel",
    "NOVELTY"
  ],
  [
    "The idea of applying the Wasserstein distance and its derived GAN model on quantum data sounds interesting and straightforward .",
    "NOVELTY"
  ],
  [
    "The paper presents very interesting idea",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are rather incremental .",
    "NOVELTY"
  ],
  [
    "The extension is new",
    "NOVELTY"
  ],
  [
    "but does not contain enough content for the conference . I do not think this paper presents enough contributions .",
    "NOVELTY"
  ],
  [
    "The method in the paper is very similar to the existing discrete addressing scheme",
    "NOVELTY"
  ],
  [
    "since the conceptual contribution is relatively limited",
    "NOVELTY"
  ],
  [
    "The idea of using randomized strategies for two-player reinforcement learning is interesting and natural",
    "NOVELTY"
  ],
  [
    "the adaption of the methodology of hsieh et al is straightforward , limiting the strength of the theoretical contribution .",
    "NOVELTY"
  ],
  [
    "it is difficult to say whether the DRAGNN is novel .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "from a novelty standpoint my feeling is that this paper is somewhat limited",
    "NOVELTY"
  ],
  [
    "and the idea is novel .",
    "NOVELTY"
  ],
  [
    "The primary concern with the paper is not with the author \u2019 s contribution",
    "NOVELTY"
  ],
  [
    "The ideas introduced here are certainly not new",
    "NOVELTY"
  ],
  [
    "key contribution of the paper .",
    "NOVELTY"
  ],
  [
    "The method is novel and the",
    "NOVELTY"
  ],
  [
    "The result appears to be novel .",
    "NOVELTY"
  ],
  [
    "The ideas and style of research is nice .",
    "NOVELTY"
  ],
  [
    "While the algorithm itself seems a bit incremental",
    "NOVELTY"
  ],
  [
    "The idea of computing the exact distribution over all possible clusterings of the sample set seemed to be a novel idea . The introduction of cluster trellis and the recursive algorithms to compute the partition function and the optimal cluster were also novel .",
    "NOVELTY"
  ],
  [
    "The method is original and clearly",
    "NOVELTY"
  ],
  [
    "and I feel it makes an important contribution .",
    "NOVELTY"
  ],
  [
    "s very similar to a collection of ideas and tricks and techniques combined together",
    "NOVELTY"
  ],
  [
    "There are certain novelty in this paper that can be a nice contribution .",
    "NOVELTY"
  ],
  [
    "the paper under review bears some novelty because the other two papers focused on discovery of all `` heavier coins `` whereas this paper is able to find one heavy coin using only amortized complexity",
    "NOVELTY"
  ],
  [
    "This paper offers a pioneering advance to tackle this problem .",
    "NOVELTY"
  ],
  [
    "In particular the success of pre-embedding , unsupervised distributional methods is not new at all",
    "NOVELTY"
  ],
  [
    "my concern is still on the originality of the paper",
    "NOVELTY"
  ],
  [
    "Though this paper provides some contributions",
    "NOVELTY"
  ],
  [
    "of molecular graph representation",
    "NOVELTY"
  ],
  [
    "The paper introduced peer prediction , an area in computational economics and algorithmic game theory , to learning with noisy labels . This should be novel ( to the best of my knowledge ) and I like it !",
    "NOVELTY"
  ],
  [
    "the obtained loss is very similar to the general loss correction approach",
    "NOVELTY"
  ],
  [
    "This fact undermines the novelty of the paper",
    "NOVELTY"
  ],
  [
    "I find the paper to be an interesting contribution",
    "NOVELTY"
  ],
  [
    "Some novelty in the models",
    "NOVELTY"
  ],
  [
    "Novelty is in DDM and TDM and adaptation of BMM to the models .",
    "NOVELTY"
  ],
  [
    ", which extends existing theory of SVRG to cover parameter choices that are commonly made in practice .",
    "NOVELTY"
  ],
  [
    "I think that the paper provides nice contributions ,",
    "NOVELTY"
  ],
  [
    "The proposed algorithm and analysis are very similar to [ Kapralov and Talwar 2013 ] .",
    "NOVELTY"
  ],
  [
    "Though similar to previous algorithm of [ Kapralov and Talwar 2013 ] , their new algorithm is significantly different enough with different proven privacy and utility bounds .",
    "NOVELTY"
  ],
  [
    "but it 's not clear to me which part is novel and which part is from existing work",
    "NOVELTY"
  ],
  [
    "and is a novel contribution to compound question answering on KG",
    "NOVELTY"
  ],
  [
    "This attack seems similar to the approach studied in Carlini and Wagner",
    "NOVELTY"
  ],
  [
    "I do not find the results sufficiently novel or convincing .",
    "NOVELTY"
  ],
  [
    "This is a very interesting paper , with new ideas",
    "NOVELTY"
  ],
  [
    "The training procedure , based on observing the result of an action , is interesting as the examples are easy to collect",
    "NOVELTY"
  ],
  [
    "The generalized notion of Lagrangian multipliers is very interesting .",
    "NOVELTY"
  ],
  [
    "The technical contribution seems to be a bit limited .",
    "NOVELTY"
  ],
  [
    "The proposed techniques are a combination of previously published steps",
    "NOVELTY"
  ],
  [
    "However , both RVSM and RGSM have already been used as sparsification algorithms for DNNs",
    "NOVELTY"
  ],
  [
    "thus the contribution is largely reduced and the novelty appear to be limited",
    "NOVELTY"
  ],
  [
    "paper proposes a novel way to formulate intrinsic reward based on optical flow prediction error",
    "NOVELTY"
  ],
  [
    "I see the contribution of the paper as two-fold .",
    "NOVELTY"
  ],
  [
    "The authors , however , do a great job in proposing their novel contribution -",
    "NOVELTY"
  ],
  [
    "which can combine the best of existing estimaotrs in the OPE literature",
    "NOVELTY"
  ],
  [
    "I would vote for acceptance for this paper as it provides significantly novel contribution in existing literature of off-policy methods",
    "NOVELTY"
  ],
  [
    "I think the originality is fairly high . Although the PHATE algorithm exists in the literature , the Multislice kernel is novel , and the idea of visualizing the learning dynamics of the hidden neurons to ascertain things like catastrophic forgetting or poor generalization is ( to my knowledge ) novel .",
    "NOVELTY"
  ],
  [
    "I think the proposed idea is a little bit incremental .",
    "NOVELTY"
  ],
  [
    "2005 The originality of the paper lies in the practical and efficient implementation of G-Conv layers",
    "NOVELTY"
  ],
  [
    "paper",
    "NOVELTY"
  ],
  [
    "This generalization while new is not entirely surprising",
    "NOVELTY"
  ],
  [
    "The introduced model is elegant",
    "NOVELTY"
  ],
  [
    "; the algorithms for inference are non-trivial . From a practical perspective , one can not expect this contribution to be ground-breaking",
    "NOVELTY"
  ],
  [
    "The proposed method is intuitively appealing .",
    "NOVELTY"
  ],
  [
    "Given the results in [ 1",
    "NOVELTY"
  ],
  [
    ", this paper became significantly less novel",
    "NOVELTY"
  ],
  [
    "Currently I can see a few improvements of this paper over [",
    "NOVELTY"
  ],
  [
    "The result of the additive approximate supermodularity ( Theorem 2 ) , and its corresponding consequence in E-optimal designs ( Theorem 4 ) , seems to be new .",
    "NOVELTY"
  ],
  [
    "Although I think the bilinear modification make some sense intuitively",
    "NOVELTY"
  ],
  [
    "The analysis is inspiring for other researchers and contributes to the RL",
    "NOVELTY"
  ],
  [
    "the tools used to obtain this result are not highly original .",
    "NOVELTY"
  ],
  [
    "and the presented approach very interesting",
    "NOVELTY"
  ],
  [
    "In think that the approach of this paper is interesting .",
    "NOVELTY"
  ],
  [
    "and I find the contributions of the paper of interest",
    "NOVELTY"
  ],
  [
    "which while not being groundbreaking or overly novel is nice to see compiled into this particular form",
    "NOVELTY"
  ],
  [
    "The idea of constructing data from disentangled latent variables is not new",
    "NOVELTY"
  ],
  [
    "I think the paper introduces a couple of new techniques and new ideas and make a significant progress on the problem .",
    "NOVELTY"
  ],
  [
    "are not completely new",
    "NOVELTY"
  ],
  [
    "The ideas of using induced trees to parameterize SPN distribution and using regional graphs to parameterize the scope function are amazing",
    "NOVELTY"
  ],
  [
    "simple",
    "NOVELTY"
  ],
  [
    "and the contributions are significant",
    "NOVELTY"
  ],
  [
    "The idea of avoiding mode collapse by providing multiple samples to the discriminator is not new",
    "NOVELTY"
  ],
  [
    "The effort behind the work is",
    "NOVELTY"
  ],
  [
    "However , the idea does not seem different from already existing ones .",
    "NOVELTY"
  ],
  [
    "So I generally like the subject and theory of this paper very much .",
    "NOVELTY"
  ],
  [
    "To the best my knowledge , the proposed approach is a novel combination of well-known techniques .",
    "NOVELTY"
  ],
  [
    "The presented idea improves over the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "Interesting idea , and demonstration of a",
    "NOVELTY"
  ],
  [
    "more accurately weakly supervised",
    "NOVELTY"
  ],
  [
    "This is",
    "NOVELTY"
  ],
  [
    "This is a nice idea",
    "NOVELTY"
  ],
  [
    "I feel this is an interesting idea and can be resubmitted",
    "NOVELTY"
  ],
  [
    "The derivation and utilization of Hyperbolic space in Riemannian manifolds are largely similar to previous Hyperbolic approaches in word embeddings and attention mechanisms .",
    "NOVELTY"
  ],
  [
    "Technical wise the contribution is not significant .",
    "NOVELTY"
  ],
  [
    "it is more like an extended experiment report to me which is very valuable but lacks sufficient technical novelty expected at ICLR",
    "NOVELTY"
  ],
  [
    "I think that this work would be moderately original",
    "NOVELTY"
  ],
  [
    "Overall , the idea of combining low-communication methods with byzantine resilience is quite interesting .",
    "NOVELTY"
  ],
  [
    "although the presented ideas are promising",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "this may not itself be a significantly novel contribution",
    "NOVELTY"
  ],
  [
    "in term of methodology ( as described in Section 3 ) , the paper has little novelty .",
    "NOVELTY"
  ],
  [
    "The models described in the paper contain little novelty compared with previous work using autoencoder and LSTM for both extractive and abstractive summarization .",
    "NOVELTY"
  ],
  [
    "The first contribution , the new memory update rule and the Gaussian update , is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The idea",
    "NOVELTY"
  ],
  [
    "I like the ideas in the paper and they",
    "NOVELTY"
  ],
  [
    "Overall , my opinion of this paper is that it is really interesting and technically deep .",
    "NOVELTY"
  ],
  [
    "This is the first approach that I know of which attempts to train on the network architecture independently of the weight values .",
    "NOVELTY"
  ],
  [
    "The work seems quite original .",
    "NOVELTY"
  ],
  [
    "While I was originally unconvinced whether there was sufficient algorithmic novelty on the Meta-Learning side",
    "NOVELTY"
  ],
  [
    "Not only does this paper give new theoretical results",
    "NOVELTY"
  ],
  [
    "and the proposed technique is sufficiently novel",
    "NOVELTY"
  ],
  [
    "The general idea of using Bayesian optimization for tuning parameters in machine learning models is ( of course ) not new with one of the most popular papers presented in reference",
    "NOVELTY"
  ],
  [
    "To my knowledge , there has not been previous work addressing this particular problem .",
    "NOVELTY"
  ],
  [
    "Technically , there are no contributions .",
    "NOVELTY"
  ],
  [
    "Therefore , I do not see any new technical ideas .",
    "NOVELTY"
  ],
  [
    "The analysis in this paper is novel",
    "NOVELTY"
  ],
  [
    "The task of auto completion for UI layout design is relatively new .",
    "NOVELTY"
  ],
  [
    "The work is novel 2",
    "NOVELTY"
  ],
  [
    "are IMO a little out of proportion to the actual contribution of paper",
    "NOVELTY"
  ],
  [
    "Yet , the work is quite incremental and of limited significance , in that such EOC initialization was known to be important for controlling propagation of both activations and gradients with such networks",
    "NOVELTY"
  ],
  [
    "The contribution seems novel .",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting that using the context information to predict the position and shape of object instances in order to generate novel semantic maps .",
    "NOVELTY"
  ],
  [
    "that the idea to learning an invariant/factorized intermediate representation is interesting .",
    "NOVELTY"
  ],
  [
    "The general methods presented are not entirely new",
    "NOVELTY"
  ],
  [
    "The only downside in my eye is the fact a lot of its originality comes from previous papers .",
    "NOVELTY"
  ],
  [
    "This is an original idea which requires some time to digest .",
    "NOVELTY"
  ],
  [
    "The result is cute with interesting observations .",
    "NOVELTY"
  ],
  [
    "This paper provides some new insights into classification bias .",
    "NOVELTY"
  ],
  [
    "It will probably be a refreshing addition to the NIPS program",
    "NOVELTY"
  ],
  [
    "and the individual parts of the paper are interesting",
    "NOVELTY"
  ],
  [
    "interesting , novel EM algorithm for VQ-VAE",
    "NOVELTY"
  ],
  [
    "most of the empirical gain is attributable to knowledge distillation , which is not a novel contribution",
    "NOVELTY"
  ],
  [
    "The paper is a novel combination of known techniques",
    "NOVELTY"
  ],
  [
    "the proposed unbiased estimator is interesting",
    "NOVELTY"
  ],
  [
    "It tackles the main drawback of AIRL and the idea seems quite nice",
    "NOVELTY"
  ],
  [
    "This sounds incremental and I think the paper could emphasize much more why this idea is a significant advancement over previous works .",
    "NOVELTY"
  ],
  [
    "despite the seeming unfair comparison , this task is novel .",
    "NOVELTY"
  ],
  [
    "The proposed CoGAN is new",
    "NOVELTY"
  ],
  [
    "I haven \u2019 t seen anything specifically like this",
    "NOVELTY"
  ],
  [
    "t trivial and the basic idea is clever",
    "NOVELTY"
  ],
  [
    "The underlying idea is interesting",
    "NOVELTY"
  ],
  [
    "an interesting idea that pragmatically builds on existing work to provide a practical solution",
    "NOVELTY"
  ],
  [
    "Parts of the framework are not entirely new , occupancy functions have been used previously",
    "NOVELTY"
  ],
  [
    "it is unclear which parts of the framework are truly original contributions of the authors , as they are intertwined with definitions and theorems from other papers",
    "NOVELTY"
  ],
  [
    "3.2 are novel contributions , while the text in between seems to state previous work without proper citations",
    "NOVELTY"
  ],
  [
    "The handling label noises in unsupervised domain adaptation on person re-identification are new .",
    "NOVELTY"
  ],
  [
    "A drawback of existing",
    "NOVELTY"
  ],
  [
    "I am not sure about the degree of novelty",
    "NOVELTY"
  ],
  [
    "A very interesting approach .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed method of adding a correction term has not been introduced before .",
    "NOVELTY"
  ],
  [
    "However , it is more of an incremental contribution to the existing works",
    "NOVELTY"
  ],
  [
    "I am slightly concerned that its novelty is limited .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems suitable and has at least a small amount of novelty .",
    "NOVELTY"
  ],
  [
    "but the overall contribution is incremental .",
    "NOVELTY"
  ],
  [
    "off policy objective to solve imitation learning",
    "NOVELTY"
  ],
  [
    "The derivation of equation ( 12 ) is nice and intuitive , provide a potential on creating new imitation learning algorithm",
    "NOVELTY"
  ],
  [
    "paper 2",
    "NOVELTY"
  ],
  [
    "The task is not new .",
    "NOVELTY"
  ],
  [
    "Lack of novelty : The main idea of this paper ( i.e .regularizing the outputs from normal and randomized states ) is not really new because it has been explored before",
    "NOVELTY"
  ],
  [
    "the contributions are not enough as the ICLR publications",
    "NOVELTY"
  ],
  [
    "However , this idea is not completely new .",
    "NOVELTY"
  ],
  [
    "The idea to apply vector-valued RKHSs to the problem of quantile regression appears to be novel .",
    "NOVELTY"
  ],
  [
    "I like the idea because it is simple but appears to be effective",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "To train natural language systems by putting multiple agents within an interactive referential communication game is very nice .",
    "NOVELTY"
  ],
  [
    "of an interesting",
    "NOVELTY"
  ],
  [
    "The work seems to be a little bit incremental .",
    "NOVELTY"
  ],
  [
    "contribution 2",
    "NOVELTY"
  ],
  [
    "Using INT8 for training is very novel and useful .",
    "NOVELTY"
  ],
  [
    "The approach is novel , and is motivated by being able to learn policies for robotics .",
    "NOVELTY"
  ],
  [
    "Because the idea is interesting and novel",
    "NOVELTY"
  ],
  [
    "Increasing compositional generalization using equivariance is a very interesting idea",
    "NOVELTY"
  ],
  [
    "To the best of my understanding , this is the main motivation of this construction .",
    "NOVELTY"
  ],
  [
    "I liked the whole idea of developing a faster algorithm for active learning based on the nearest neighborhood method .",
    "NOVELTY"
  ],
  [
    "-I think the overall idea is novel and useful even though it is very simple .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is first work to theoretically show symplectic integrators can achieve acceleration by integrating a specific type of ODE ( i.e .the high-resolution polyak heavy-ball or NAG limiting ODE",
    "NOVELTY"
  ],
  [
    "There is clear novelty in this paper , even if slightly limited .",
    "NOVELTY"
  ],
  [
    "Although I was previously unfamiliar with the PCMC model , using a neural network parametrization seems novel and well motivated .",
    "NOVELTY"
  ],
  [
    "The paper is yet another combination of VAE/AdvNet/PixelCNN",
    "NOVELTY"
  ],
  [
    "One of the two major concerns I have is the novelty of this paper in terms of its methodology and empirical value to the community . The Pre-LN setting of Transformers has already been widely used",
    "NOVELTY"
  ],
  [
    "Despite the potential lack of novelty on",
    "NOVELTY"
  ],
  [
    "method , I do think investigating these myths and",
    "NOVELTY"
  ],
  [
    "Although technically rather straightforward",
    "NOVELTY"
  ],
  [
    ", the combination with CSC in the particular application context sounds fairly an original idea",
    "NOVELTY"
  ],
  [
    "the two losses introduced are not really new .",
    "NOVELTY"
  ],
  [
    "Thus it is not a novel contribution .",
    "NOVELTY"
  ],
  [
    "The paper presents a small interesting idea that is well presented and analyzed",
    "NOVELTY"
  ],
  [
    "I like the idea of following a formal representation of a visual attention model in the proposal generation , rather than a brute force dense CNN-based classification",
    "NOVELTY"
  ],
  [
    "I also consider the deep Q learning optimization approach to be interesting .",
    "NOVELTY"
  ],
  [
    "Relatively small novelty .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel up to my knowledge .",
    "NOVELTY"
  ],
  [
    "This is fantastic paper in all respects",
    "NOVELTY"
  ],
  [
    "Nice to see the concrete approximation having an impact in the quantization space .",
    "NOVELTY"
  ],
  [
    "My major concern is that the paper , including the motivation and illustrative example , are too similar to previous work",
    "NOVELTY"
  ],
  [
    "While this explanation ( rooted in the norm of gradients of neural networks being the culprit for the existence of adversarial examples ) is not new",
    "NOVELTY"
  ],
  [
    "and this work takes a novel approach",
    "NOVELTY"
  ],
  [
    "the ideas are interesting",
    "NOVELTY"
  ],
  [
    "Originality As noted previously , the method is an original alternative to the sequential extensions of DPP .",
    "NOVELTY"
  ],
  [
    "The fact that the paper does not come with substantial theoretical contributions/justification still stands out",
    "NOVELTY"
  ],
  [
    "There are little theoretical contributions .",
    "NOVELTY"
  ],
  [
    "In general , I like the paper : it tackles previously under-explored task and proposes a novel approach to tackle it .",
    "NOVELTY"
  ],
  [
    "The overall approach appears to be novel to me .",
    "NOVELTY"
  ],
  [
    "considering that zero-shot segmentation learning appears to be a novel task",
    "NOVELTY"
  ],
  [
    "A few points in the paper can be discussed in more details and clarified but I believe it is a nice contribution overall",
    "NOVELTY"
  ],
  [
    "Significance This is the first empirical work trying to fix the issue of non-translation equivariance in convolutional neural networks",
    "NOVELTY"
  ],
  [
    "The originality is limited .",
    "NOVELTY"
  ],
  [
    "The novelty in the paper is limited .",
    "NOVELTY"
  ],
  [
    "I like the authors ' idea for transfer learning without catastropic forgetting",
    "NOVELTY"
  ],
  [
    "Paper presents significant refinements to the 2011 's capsule system",
    "NOVELTY"
  ],
  [
    "Overall I believe the submission is sufficiently original , lacks in some respects regarding its quality and clarity and",
    "NOVELTY"
  ],
  [
    "in",
    "NOVELTY"
  ],
  [
    "While the overall concept of graph regularization is appealing",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel technique to perform fluid simulations",
    "NOVELTY"
  ],
  [
    "I view this as a significant contribution",
    "NOVELTY"
  ],
  [
    "My understanding is that ICLR primarily wants to promote general learning techniques and I am not convinced that this paper contains any significant contributions",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , adversarial manipulation of explanations was ( foreshadowed by previous research but ) new .",
    "NOVELTY"
  ],
  [
    "but it is also new",
    "NOVELTY"
  ],
  [
    "The methodological contribution is somewhat simple and limited",
    "NOVELTY"
  ],
  [
    "I find this approach interesting and like the paper overall .",
    "NOVELTY"
  ],
  [
    "the technical novelty of the appraoch is limited ,",
    "NOVELTY"
  ],
  [
    "While the overall novelty is a bit limited",
    "NOVELTY"
  ],
  [
    "paper addresses new problem with a new approach .",
    "NOVELTY"
  ],
  [
    "section",
    "NOVELTY"
  ],
  [
    "The problem is novel and practical .",
    "NOVELTY"
  ],
  [
    "The asynchronizing accumulating and synchronizing update is not novel .",
    "NOVELTY"
  ],
  [
    "The contribution is",
    "NOVELTY"
  ],
  [
    "providing a new perspective for domain adaptation",
    "NOVELTY"
  ],
  [
    "the results do not suggest any new finding or that",
    "NOVELTY"
  ],
  [
    "The approach seems somewhat novel",
    "NOVELTY"
  ],
  [
    "the contribution of the submission is pretty moderate .",
    "NOVELTY"
  ],
  [
    "The ideas in the paper are quite original .",
    "NOVELTY"
  ],
  [
    "The improvements are modest for the WebVision dataset .",
    "NOVELTY"
  ],
  [
    "the analysis basically follows the same outline and the high-level ideas are very similar .",
    "NOVELTY"
  ],
  [
    "the optimization result of this paper seems somewhat incremental based on that of [ 24 ]",
    "NOVELTY"
  ],
  [
    "The generalization result seems new to me",
    "NOVELTY"
  ],
  [
    "I still feel that the contribution of this paper given the results of Zhang et al . [ 24 ] is not substantial enough , as changing the loss does not seem to make a",
    "NOVELTY"
  ],
  [
    "and the generalization result given the optimization result does not seem to require very novel idea .",
    "NOVELTY"
  ],
  [
    "and brings new ideas .",
    "NOVELTY"
  ],
  [
    "It is an interesting and novel approach that could generalize well to interesting datastructures and algorithms .",
    "NOVELTY"
  ],
  [
    "From the point of view of the proposed architecture , the work is quite incremental .",
    "NOVELTY"
  ],
  [
    "it is an interesting idea and I believe deserves further experimentations in the future",
    "NOVELTY"
  ],
  [
    "The introduction of a node ranking term based on the graph structure is original .",
    "NOVELTY"
  ],
  [
    "Overall the paper reveals intriguing and interesting findings . The proposed method has several original aspects",
    "NOVELTY"
  ],
  [
    "The method presented in the paper seems quite novel .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- | This work , to my knowledge , appears to be original .",
    "NOVELTY"
  ],
  [
    "The idea of bypassing the use of public data by taking uniformly random samples seems interesting .",
    "NOVELTY"
  ],
  [
    "While the Morph-net appears novel",
    "NOVELTY"
  ],
  [
    "Overall , this paper present a nice idea .",
    "NOVELTY"
  ],
  [
    "The MDP-within-an-MDP approach is quite similar to the Pazis and Lagoudakis MDP decomposition for the same problem",
    "NOVELTY"
  ],
  [
    "This is a nice contribution to the online bandit optimization literature .",
    "NOVELTY"
  ],
  [
    "The exact NN architecture is not central to the ideas",
    "NOVELTY"
  ],
  [
    "This work heavily relies on the multi-agent aspect for novelty",
    "NOVELTY"
  ],
  [
    "The paper presents significant , novel work in a straightforward",
    "NOVELTY"
  ],
  [
    "The method is an interesting novel combination of existing ideas .",
    "NOVELTY"
  ],
  [
    "While the paper makes a decent presentation of the geometry of the generative setting",
    "NOVELTY"
  ],
  [
    "it is not novel",
    "NOVELTY"
  ],
  [
    "I can not identify a clear contribution or novelty in the paper which is the basis for my recommendation of rejection of the paper",
    "NOVELTY"
  ],
  [
    "The suggested optimization method is very interesting .",
    "NOVELTY"
  ],
  [
    "and although none of the idea are new here",
    "NOVELTY"
  ],
  [
    "and some results might be new",
    "NOVELTY"
  ],
  [
    "However , the paper contains only little novelty and does not provide sufficiently new scientific insights .",
    "NOVELTY"
  ],
  [
    "The framework proposed by the paper is a novel model ( GPN model ) based on the prototypical network . The prototype embeddings are refined iteratively through the current presentation and neighboring prototypes from similar tasks using a gating mechanism . The refinement process is similar to the multi-head mechanism but is new and unique",
    "NOVELTY"
  ],
  [
    "There doesn \u2019 t seem to be any deep theoretical insight .",
    "NOVELTY"
  ],
  [
    "Except the analyzing on IRGAN , the contribution of this paper is limited .",
    "NOVELTY"
  ],
  [
    "are good for supporting the analyzing but they are not quite novel",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is very limited",
    "NOVELTY"
  ],
  [
    "So the proposed method is a bit incremental .",
    "NOVELTY"
  ],
  [
    "I think the work is a little incremental since the key building blocks come from the SchNet .",
    "NOVELTY"
  ],
  [
    "in the static setting this projection idea seems the only additional step contributed by the paper compared to a few existing primal-dual algorithms for unconstrained consensus problem",
    "NOVELTY"
  ],
  [
    "1- My main concern is the novelty ,",
    "NOVELTY"
  ],
  [
    "finding adversarial examples in cross-modal learning is something new in the literature and could lead to more robust networks",
    "NOVELTY"
  ],
  [
    "Overall , there is no new idea in the paper .",
    "NOVELTY"
  ],
  [
    "One could argue that experiments could be conducted on different environments or that the novelty is limited",
    "NOVELTY"
  ],
  [
    "I like the main idea of the paper .",
    "NOVELTY"
  ],
  [
    "but novelty is limited ,",
    "NOVELTY"
  ],
  [
    "suboptimal",
    "NOVELTY"
  ],
  [
    "I am not aware of previous work on adversarial examples for generative networks , so this work is novel",
    "NOVELTY"
  ],
  [
    "However , the ideas are not novel as previous cited papers have tried to handle noise in the labels .",
    "NOVELTY"
  ],
  [
    "and the idea is interesting",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "There is no novelty for the proposed fast segmentation network detailed in Sec 3.2",
    "NOVELTY"
  ],
  [
    "The design of the fast segmentation network in this paper is boring and not much related to the title",
    "NOVELTY"
  ],
  [
    "the idea of using the marginal decrease as a guidance of coordinate selection is very interesting",
    "NOVELTY"
  ],
  [
    "I believe the paper provides interesting insight and ideas",
    "NOVELTY"
  ],
  [
    "However , there is no novel techniques proposed in this paper .",
    "NOVELTY"
  ],
  [
    "I should say that the paper is very novel in comparison to many of the works that apply deep learning for programming tasks .",
    "NOVELTY"
  ],
  [
    "The idea to train a classifier on whether a test will succeed and then to use feature attribution techniques for localizing the errors in the program is new , original and quite interesting .",
    "NOVELTY"
  ],
  [
    "I also think the work is very original and could lead to interesting follow up work .",
    "NOVELTY"
  ],
  [
    "The idea is novel , interesting and well-formulated , while the intuition could be better explained",
    "NOVELTY"
  ],
  [
    "While the idea of applying \u201c dual adversarial \u201d approaches is new in the context of NER , the technical novelty of each component is limited .",
    "NOVELTY"
  ],
  [
    "There is no technical novelty in applying adversarial training either ,",
    "NOVELTY"
  ],
  [
    "the algorithmic contribution is very minimal , no analytical understanding either .",
    "NOVELTY"
  ],
  [
    "The contribution is thus not very strong in terms of results",
    "NOVELTY"
  ],
  [
    "and provides some new insights on incorporating kernels in CNN .",
    "NOVELTY"
  ],
  [
    "The technical innovation of the paper is quite limited",
    "NOVELTY"
  ],
  [
    "but the contribution is also technically very simple .",
    "NOVELTY"
  ],
  [
    "The methodological contribution seems to be humble , however",
    "NOVELTY"
  ],
  [
    "I think the optimization approach proposed in the paper is novel enough to justify the high score",
    "NOVELTY"
  ],
  [
    "The idea of perturbing a continuous-valued embedding to improve a discrete optimization problem is very clever , and I do n't think I 've seen anything like it elsewhere .",
    "NOVELTY"
  ],
  [
    "the method ( which is an incremental improvement over previous work )",
    "NOVELTY"
  ],
  [
    "The algorithm outperforms Bayes filters for localisation in 2D and 3D and the idea of applying RL to minimise the entropy of position estimation is brilliant .",
    "NOVELTY"
  ],
  [
    "The Bayesian approach gives a natural approach to performing transfer and handling low data regimes",
    "NOVELTY"
  ],
  [
    "relatively novel",
    "NOVELTY"
  ],
  [
    "First SGD algorithm for",
    "NOVELTY"
  ],
  [
    "proposing to address the sample efficiency of distributed RL algorithms",
    "NOVELTY"
  ],
  [
    "Due to the fact that the optimal bound occurs for the true posterior , the PAC-bayesian bounds offer a novel interpretation as an objective for BNNs .",
    "NOVELTY"
  ],
  [
    "The flavor of the contribution here seems to improve",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting contribution .",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting approach with promising initial",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "the paper lacks novelty as multi-level fusion has been explored significantly and the changes are rather minor .",
    "NOVELTY"
  ],
  [
    "from previous",
    "NOVELTY"
  ],
  [
    "papers on approximating matrices with a subset of their columns , but the application of these results to sparse PCA is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The ideas presented in this paper represent somewhat of a synthesis of other ideas",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", this exact combination is novel .",
    "NOVELTY"
  ],
  [
    "and the introduced approach outperforms all of them",
    "NOVELTY"
  ],
  [
    "Clearly , the idea of using a randomized sketch for the Hessian is not new .",
    "NOVELTY"
  ],
  [
    "The proposed",
    "NOVELTY"
  ],
  [
    "I quite liked the revival of the dual memory system ideas and the cognitive ( neuro ) science inspiration .",
    "NOVELTY"
  ],
  [
    "I like the idea of using the information gain for exploration .",
    "NOVELTY"
  ],
  [
    "The work itself did not propose any new network properties or any new metric to measure .",
    "NOVELTY"
  ],
  [
    "While the idea itself is interesting",
    "NOVELTY"
  ],
  [
    "De-duplication modules of inter and intra object edges are interesting .",
    "NOVELTY"
  ],
  [
    "The proposed model is pretty hand-crafted .",
    "NOVELTY"
  ],
  [
    "I think the investigation of different mixing functions is original , interesting , and important .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of the paper is fairly incremental : both term ( 1 ) and ( 2 ) have been used before , just not their sum .",
    "NOVELTY"
  ],
  [
    "Cons Does not provide new theory but combines existing",
    "NOVELTY"
  ],
  [
    "ideas in a new manner",
    "NOVELTY"
  ],
  [
    "The proposed black-box reduction from tracking experts to competing with a static optimal expert is new ( as far as I know ) and a breakthrough in the theory . The algorithms are new",
    "NOVELTY"
  ],
  [
    "but simple .",
    "NOVELTY"
  ],
  [
    "The technical contribution is substantial and I recommend this paper for acceptance",
    "NOVELTY"
  ],
  [
    "Highly original . This development of a GAN without a separate discriminator is novel .",
    "NOVELTY"
  ],
  [
    "From a methodological point of view , there is nothing fundamentally novel ( it is very similar to the semi-supervised work of Kingma et al",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but lacking in terms of methodological advances .",
    "NOVELTY"
  ],
  [
    "The main drawback would be the rather incrementality of that paper",
    "NOVELTY"
  ],
  [
    "While the authors achieve SOA results on OmniGlot and do explore a few options , I feel the work still lacks originality in the formulation or does not have original contributions to either the architectures used or the optimization procedures employed .",
    "NOVELTY"
  ],
  [
    "The results given in the paper are novel",
    "NOVELTY"
  ],
  [
    "The theoretical parts of the paper are also quite simple extensions of well-known results",
    "NOVELTY"
  ],
  [
    "thus constitutes a nice addition to the recent literature on leveraging neural networks for IIG",
    "NOVELTY"
  ],
  [
    "2 .The interesting and novel part is the theoretical demonstration that a fixed number of neighbors can approximate well some algorithms in the literature",
    "NOVELTY"
  ],
  [
    "The bounds appear novel and contribute towards the analysis of the predict and optimize problem",
    "NOVELTY"
  ],
  [
    "This is an empirical paper , thus it does not provide technical contributions .",
    "NOVELTY"
  ],
  [
    "The idea of optimizing epsilon parameter by comparing the metric induced from Laplacian and the geometry ( tangent space ) determined without epsilon , is interesting .",
    "NOVELTY"
  ],
  [
    "this paper falls well short of the level of science and insight I would expect for ICLR",
    "NOVELTY"
  ],
  [
    "This paper appears to be the first to solve this problem , and make a connection to coordinate decent .",
    "NOVELTY"
  ],
  [
    "I think the point of view to look at the problem sounds novel and should be appreciated .",
    "NOVELTY"
  ],
  [
    "The idea of forcing different parts of the latent representation to be responsible for different attributes appears novel .",
    "NOVELTY"
  ],
  [
    "The proof techniques extend from previous works to allow for the generalization which is novel contribution and could be useful in other analyses",
    "NOVELTY"
  ],
  [
    "There is not much novelty in the proposed method",
    "NOVELTY"
  ],
  [
    "the conceptual/theoretical novelty that datasets can be compressed sub-linearly for a given model is not really that interesting",
    "NOVELTY"
  ],
  [
    "The idea of dealing with heterogeneous noise in BO is interesting .",
    "NOVELTY"
  ],
  [
    "I think the current manuscript lacks some insightful discussions of the new definition and theorems .",
    "NOVELTY"
  ],
  [
    "and the methodology proposed is novel and works well against a reinforcement-learning-based approach baseline .",
    "NOVELTY"
  ],
  [
    "The originality of the proposed approach is to use dilated convolutions to capture the long range dependencies in a GAN framework .",
    "NOVELTY"
  ],
  [
    "insight",
    "NOVELTY"
  ],
  [
    "improve upon and address the obvious limitations of previous work",
    "NOVELTY"
  ],
  [
    "I really do like the overall idea of the approach presented here",
    "NOVELTY"
  ],
  [
    "My main issue with the paper is the lack of novelty . The use of dynamic convolutions is by no means a novel idea and has been studied in multiple previous works in vision",
    "NOVELTY"
  ],
  [
    "most previous work focuses on leveraging dynamic kernels to use more parameters so the focus on accelerating CNNs is novel .",
    "NOVELTY"
  ],
  [
    "space",
    "NOVELTY"
  ],
  [
    "the paper interestingly generalizes some technical lemmas introduced in",
    "NOVELTY"
  ],
  [
    "The idea presented in this paper is quite interesting .",
    "NOVELTY"
  ],
  [
    "However , there are no significant technical innovations",
    "NOVELTY"
  ],
  [
    "This is relatively new and may lead to many potential future developments in this direction .",
    "NOVELTY"
  ],
  [
    "however , this paper mostly builds on existing technicals on learning forward and inverse models",
    "NOVELTY"
  ],
  [
    "However , overall I do think that the proposed method is novel , well theoretically grounded and is",
    "NOVELTY"
  ],
  [
    "The analysis becomes considerably more complicated , and the contribution seems to be novel and significant .",
    "NOVELTY"
  ],
  [
    "Overall , combining HER with language-based goals is an interesting and novel problem , and potentially a promising approach to solving language-conditioned reinforcement learning where sparse rewards are common .",
    "NOVELTY"
  ],
  [
    "It is",
    "NOVELTY"
  ],
  [
    "clustering papers , this",
    "NOVELTY"
  ],
  [
    "For all the additional complexity , this newly proposed method only slightly outperforms other semi-supervised methods like BT , JBT & Dual learning as seen in Tables 3 and 4",
    "NOVELTY"
  ],
  [
    "Despite the con of added complexity , I like the formulation of the new joint framework and I think this will serve as a good starting point for others to push in this direction further .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm/analysis is an application of stochastic proximal ( sub ) gradient descent and is thus not a significant contribution from the optimization point of view",
    "NOVELTY"
  ],
  [
    "I think this paper introduces some interesting ideas but is not mature enough yet for publication at NIPS",
    "NOVELTY"
  ],
  [
    "If Adversarial autoencoders are considered existing work , then novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "but the novelty seems limited .",
    "NOVELTY"
  ],
  [
    "The theorems are new and consistent .",
    "NOVELTY"
  ],
  [
    "The two contributions of this work are 1 ) A new approach to weight quantization using principles of NAS that is novel and promising",
    "NOVELTY"
  ],
  [
    "New insights/technical improvements in the broader field of NAS .",
    "NOVELTY"
  ],
  [
    "The methods are not all original ,",
    "NOVELTY"
  ],
  [
    "but are rather an interesting use-case/application of existing methods and are a useful contribution .",
    "NOVELTY"
  ],
  [
    "but I feel the model is novel enough and is well-justified by the optimality proofs and the quality of the generated samples",
    "NOVELTY"
  ],
  [
    "The model proposed in this paper seems novel and interesting .",
    "NOVELTY"
  ],
  [
    "Section 5 is below the standard of NIPS both in terms of novelty and significance",
    "NOVELTY"
  ],
  [
    "but I agree with the other reviewers that the paper brings insight and has potential",
    "NOVELTY"
  ],
  [
    ", and the authors present a novel approach to it .",
    "NOVELTY"
  ],
  [
    "The paper introduced interesting ideas on how to improve simulations for AV testing .",
    "NOVELTY"
  ],
  [
    "The paper is quite interesting and it",
    "NOVELTY"
  ],
  [
    "'s main",
    "NOVELTY"
  ],
  [
    "contribution is algorithmic",
    "NOVELTY"
  ],
  [
    "Overall , I do not think the insights claimed in the paper are especially novel .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is novel and interesting",
    "NOVELTY"
  ],
  [
    "The incremental novelty of the augmentation technique along with the new loss for the context of deep adversarial domain",
    "NOVELTY"
  ],
  [
    "The two architectures , though not novel enough , are towards representing \u201c non-additive utility \u201d .",
    "NOVELTY"
  ],
  [
    "the paper presents four original contributions",
    "NOVELTY"
  ],
  [
    "They are all indeed novel and beyond just a combination of existing techniques .",
    "NOVELTY"
  ],
  [
    "The paper is very insightful",
    "NOVELTY"
  ],
  [
    "I quite liked the idea to formulate the problem of finding a concept class with RTD > 3/2 VCD as a SAT",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first time that local Rademacher complexity is used to derive multi-class learning methods and as such this contribution is quite interesting and promising .",
    "NOVELTY"
  ],
  [
    "I like the general idea of the paper and",
    "NOVELTY"
  ],
  [
    "provides a new perspective to understand prior work * provides new useful algorithms cons",
    "NOVELTY"
  ],
  [
    "But the theoretical result is still novel and interesting .",
    "NOVELTY"
  ],
  [
    "The idea of identify the mode in the dataset using Bourgain theorem and construct mixture Gaussian for generators is very novel , at least to my knowledge .",
    "NOVELTY"
  ],
  [
    "While the contribution of using a standard family of distributions in a standard implicit model setup is limited",
    "NOVELTY"
  ],
  [
    "Despite being simple technique , the proposed pixel deconvolution layer is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed technique , despite being simple , is novel and interesting .",
    "NOVELTY"
  ],
  [
    "I think this is a nice contribution that does yield to some interesting insights .",
    "NOVELTY"
  ],
  [
    "I found the idea of having separate networks for the two phases of the algorithm ( instead of recollecting on-policy trial trajectories ) interesting and possibly applicable in other similar settings .",
    "NOVELTY"
  ],
  [
    "but contributes little",
    "NOVELTY"
  ],
  [
    "But I think the paper is lacking in innovation to solve this problem .",
    "NOVELTY"
  ],
  [
    "idea presented in this paper is novel",
    "NOVELTY"
  ],
  [
    "Such smoothing idea is not new , but was not investigated previously in wide range of machine learning tasks .",
    "NOVELTY"
  ],
  [
    "but the contribution is very limited",
    "NOVELTY"
  ],
  [
    "The gradient regularization is not novel The main contribution of the paper is to use the finite difference in the gradient regularization in order to improve the training time",
    "NOVELTY"
  ],
  [
    "The method of gradient regularization is not new",
    "NOVELTY"
  ],
  [
    "Overall I feel that the novelty of the proposed method is quite limited .",
    "NOVELTY"
  ],
  [
    "Overall this paper presents an interesting idea , that also scales to the deep RL algorithms .",
    "NOVELTY"
  ],
  [
    "The ideas presented in the paper are original .",
    "NOVELTY"
  ],
  [
    "The paper contributes novel theoretical ideas towards fixing this problems .",
    "NOVELTY"
  ],
  [
    "I think overall the paper has strong contributions and valuable insights",
    "NOVELTY"
  ],
  [
    "however the application of self-normalizing function to RNN seems novel",
    "NOVELTY"
  ],
  [
    "This paper can be considered as the first to apply chirality into the network structure design and",
    "NOVELTY"
  ],
  [
    "its effectiveness in some tasks that are related to chirality transform",
    "NOVELTY"
  ],
  [
    "Overall the theoretical contributions are reassuring albeit unsurprising and incremental .",
    "NOVELTY"
  ],
  [
    "The improvement over the forward method is somewhat incremental , but the idea is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "Introduced a novel approach to measure the parameter staleness , which helps penalize the gradients instead of the learning step .",
    "NOVELTY"
  ],
  [
    "Despite of its simplicity",
    "NOVELTY"
  ],
  [
    "My another concern is about a lack of novelty",
    "NOVELTY"
  ],
  [
    "3 .The proposed system is quite similar to Nogueira & Cho 2017 and Buck et al .2018 .I 'm not very sure the contribution of this work and its novelty .",
    "NOVELTY"
  ],
  [
    "The work is somewhat incremental and the novelty mostly lies in pulling a few different methods together that seem to work well in unison .",
    "NOVELTY"
  ],
  [
    "the development is arguably incremental",
    "NOVELTY"
  ],
  [
    "since the unified approach is simple yet novel",
    "NOVELTY"
  ],
  [
    "The proposed approach in the paper is somewhat undeveloped .",
    "NOVELTY"
  ],
  [
    "The work is fairly innovative in its approach , where an episodic memory is used to store agent \u2019 s observations while rewarding the agent for reaching novel observations not yet stored in memory",
    "NOVELTY"
  ],
  [
    "The idea of having a discriminator assess distance between states is interesting .",
    "NOVELTY"
  ],
  [
    "it is a",
    "NOVELTY"
  ],
  [
    "interesting idea and seems quite easy to",
    "NOVELTY"
  ],
  [
    "The method presented in this paper seems to be novel but lacks clarity unfortunately",
    "NOVELTY"
  ],
  [
    "the results are interesting , and the techniques are novel",
    "NOVELTY"
  ],
  [
    "The formulation is simple but possibly new in the graph analysis literature .",
    "NOVELTY"
  ],
  [
    "A combination fo Semi-implicit VI and graph VAE is new",
    "NOVELTY"
  ],
  [
    "Though interpreting CNN filter is a well-studied topic , learning the interpretability through pruning is new and interesting .",
    "NOVELTY"
  ],
  [
    "The choices of compression functions are intuitive and natural .",
    "NOVELTY"
  ],
  [
    "While this paper is more incremental and novelty may be slightly lacking",
    "NOVELTY"
  ],
  [
    "The idea , transforming the input data to an output space in which the data is distributed uniformly and thus indexing is easier , is interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is limited .",
    "NOVELTY"
  ],
  [
    "To me , there is little extension or novelty .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the results are novel and provide important extensions/improvements over the previous art .",
    "NOVELTY"
  ],
  [
    "Originality and significance is limited .",
    "NOVELTY"
  ],
  [
    "1 .The originality and significance is limited .",
    "NOVELTY"
  ],
  [
    "I find the contributions are very marginal .",
    "NOVELTY"
  ],
  [
    "This is an interesting contribution .",
    "NOVELTY"
  ],
  [
    "This work is probably the first to distill the structured manifold knowledge from a teacher network to a student network .",
    "NOVELTY"
  ],
  [
    "I can not see any contribution from the authors .",
    "NOVELTY"
  ],
  [
    "One concern for this paper is the level of novelty , as each major component of the proposed solution has been explored quite extensively in the existing literature ( as mentioned in the related work section ) .",
    "NOVELTY"
  ],
  [
    "Theorem 2 of the paper seemed novel and potentially promising to me .",
    "NOVELTY"
  ],
  [
    "I *love* the idea of learning a low-dimensional manifold of abstract states that capture causally relevant information",
    "NOVELTY"
  ],
  [
    "I felt that the causal extensions to the InfoGAN , while not an earth-shattering advance",
    "NOVELTY"
  ],
  [
    "-- -- The paper is a creative approach to reconciling efficiency and fairness in a graph-based setting .",
    "NOVELTY"
  ],
  [
    "This work seems closely related to Ai et al , SIGIR 2018 . Going from a single-shot decoding to sequential decoding is an incremental step",
    "NOVELTY"
  ],
  [
    "the real-world experiment seemed the most novel and compelling contribution",
    "NOVELTY"
  ],
  [
    "The paper has interesting contributions",
    "NOVELTY"
  ],
  [
    "but can be substantially stronger",
    "NOVELTY"
  ],
  [
    "paper is an interesting generalization of neural networks on Riemannian manifolds that are agnostic to space .",
    "NOVELTY"
  ],
  [
    "I also liked the idea of synthetic data to prove the point .",
    "NOVELTY"
  ],
  [
    "The idea does not seem to be novel , technical novelty is low",
    "NOVELTY"
  ],
  [
    "No obvious mistakes in the proposed method , but has very low novelty (",
    "NOVELTY"
  ],
  [
    "The ideas do not seem to be novel , and are mostly ( trivially ) using existing work as different components of the proposed technique .",
    "NOVELTY"
  ],
  [
    "Introduces an interesting architecture that uses two forms of attention : structural and temporal .",
    "NOVELTY"
  ],
  [
    "Technical-wise , the paper is relatively incremental -- all of the building blocks for performing tractable inference are standard",
    "NOVELTY"
  ],
  [
    "Overall , the novelty is not the strong suit of the paper .",
    "NOVELTY"
  ],
  [
    "I do like the idea of VSC and its ability to learn interpretable latent features for complex non-linear models though .",
    "NOVELTY"
  ],
  [
    "and the idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "interesting and novel idea Cons",
    "NOVELTY"
  ],
  [
    "This paper appears to present the first provably efficient algorithm for sampling from mixtures of log-concave distributions using only gradient information of the log-pdf .",
    "NOVELTY"
  ],
  [
    "although decomposition theorems have previously been used to analyze Markov chains , the decomposition theorems presented in this paper appear to be novel as well .",
    "NOVELTY"
  ],
  [
    "The paper is interesting , the topic recent and the methodology quite new",
    "NOVELTY"
  ],
  [
    "Overall the contribution of this paper seems small and the experimenal results insufficient .",
    "NOVELTY"
  ],
  [
    "Extending that to a more complex noise model seems like a rather small contribution .",
    "NOVELTY"
  ],
  [
    "This setting",
    "NOVELTY"
  ],
  [
    "Compared to GraphSage and FastGCN that have been developed previously , the layer-wise sampling scheme by this paper is novel and efficient . Also , the idea of applying skip-connections to preserve second-order proximity is interesting .",
    "NOVELTY"
  ],
  [
    "The proposal is maybe not too much innovative since it mostly employs already published techniques",
    "NOVELTY"
  ],
  [
    "the approach itself can be seen as a direct extension of the earlier advanced 'mixup ' scheme",
    "NOVELTY"
  ],
  [
    "Although their work is not extremely novel",
    "NOVELTY"
  ],
  [
    "Somewhat incremental",
    "NOVELTY"
  ],
  [
    "1 .The originality of this work is limited as presented above .",
    "NOVELTY"
  ],
  [
    "The novelty in the paper is quite limited and is mainly based on combining existing methods for pruning , weight sharing and quantization .",
    "NOVELTY"
  ],
  [
    "This is a novel variant of distillation and sounds like a simple to implement trick with beneficial results for increasing noise resiliency of networks .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge I have not seen precisely this combination of noise injection and distillation",
    "NOVELTY"
  ],
  [
    "The improvement over the existing method is incremental",
    "NOVELTY"
  ],
  [
    "The most pressing concern here is that there is n't a core new idea beyond the CMNF and OASIS algorithms .",
    "NOVELTY"
  ],
  [
    "As a down side , the novelty is somewhat low because the main algorithms already exist , and the new elements here are straight-forward adaptations of ideas from deep learning architectures that have been used in several other places already .",
    "NOVELTY"
  ],
  [
    "The construction of the distilled policy network sounds very similar to the architecture behind DRON .",
    "NOVELTY"
  ],
  [
    "if somewhat incremental , and rather standard",
    "NOVELTY"
  ],
  [
    "I find this approach very interesting , and a promising research direction .",
    "NOVELTY"
  ],
  [
    "The most novel and critical operation of this SGRU , to process the entities of the memory bank , is not even explained",
    "NOVELTY"
  ],
  [
    "Almost all progress is incremental",
    "NOVELTY"
  ],
  [
    "expressing the novel idea",
    "NOVELTY"
  ],
  [
    "On the one hand the idea seems very interesting and powerful as it does not seem to rely on pairs of corresponding training images .",
    "NOVELTY"
  ],
  [
    "The approach is a minor improvement over existing works , however",
    "NOVELTY"
  ],
  [
    "In general , the paper makes the impression that it is overselling the contribution a bit too much .",
    "NOVELTY"
  ],
  [
    "The whole pipeline incorporated with recurrent connections is novel for exploiting both motion and appearance information .",
    "NOVELTY"
  ],
  [
    "and the exploration strategy based on Q-maps is interesting",
    "NOVELTY"
  ],
  [
    "The idea of using spatial goals combined with a de-convolutional architecture is not new and goes back at least to",
    "NOVELTY"
  ],
  [
    "Given that the architecture is not very novel",
    "NOVELTY"
  ],
  [
    "The work is interesting and novel .",
    "NOVELTY"
  ],
  [
    "There is not much novelty in the paper",
    "NOVELTY"
  ],
  [
    "The message from the empirical validation is also not novel",
    "NOVELTY"
  ],
  [
    "The analysis in Sec 4.4 is insightful",
    "NOVELTY"
  ],
  [
    "the overall originality is somewhat limited as it is a fairly direct combination of data augmentation with meta-learning .",
    "NOVELTY"
  ],
  [
    "Nevertheless , the idea in this paper is original and",
    "NOVELTY"
  ],
  [
    "The idea of applying one LSTM for intra-clips ( short-time ) temporal feature extraction and another LSTM for inter-clips ( long-time ) temporal feature extraction , resulting in two-time-scale , looks reasonable choice but not novel .",
    "NOVELTY"
  ],
  [
    "Overall , although it achieves state-of-the-art performance on the task , none of the claimed contributions is novel or significant enough . It is a combination of existing ideas ( but giving good performance ) . The proposed training procedure is also weak to be considered as a scientific contribution .",
    "NOVELTY"
  ],
  [
    "The idea of locally aligning feature using self adaptive node with adaptive part based receptive field is pretty novel and interesting .",
    "NOVELTY"
  ],
  [
    "Global alignment is a feature alignment from based on MCD from [ 23 ] , so this part is not new",
    "NOVELTY"
  ],
  [
    "Aligning feature might not be new",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel saliency based attention mechanism that utilizes saliency in the top layer ( meta-controller ) with a new 2D Gaussian based attention map .",
    "NOVELTY"
  ],
  [
    "But to the best of my knowledge , such a problem setting",
    "NOVELTY"
  ],
  [
    "Somewhat lack of originality and poor experiments lead to low importance .",
    "NOVELTY"
  ],
  [
    "Beyond this , the paper does not provide any futher original idea . So , slight to no novelty .",
    "NOVELTY"
  ],
  [
    "Although the idea of this paper is interesting",
    "NOVELTY"
  ],
  [
    "the contribution is unclear",
    "NOVELTY"
  ],
  [
    "Therefore , the proposed method has limited technical contribution and novelty .",
    "NOVELTY"
  ],
  [
    "the novelty of `` adversarial program `` is quite limited .",
    "NOVELTY"
  ],
  [
    "The poisson-gamma-poisson motif proposed in this paper contains substantial originality .",
    "NOVELTY"
  ],
  [
    "In this work the authors make use of an already developed technique , so for this reason I do n't find the paper innovative on the technical side .",
    "NOVELTY"
  ],
  [
    "A novel idea of producing natural adversary examples with a GAN",
    "NOVELTY"
  ],
  [
    "The idea implementation is basic",
    "NOVELTY"
  ],
  [
    "the performance improvements are modest",
    "NOVELTY"
  ],
  [
    "However , the main technical contribution of this paper is otherwise not clear",
    "NOVELTY"
  ],
  [
    "The visualization strategies presented do n't appear to be particularly novel .",
    "NOVELTY"
  ],
  [
    "I 'm pretty sure this is the first paper to tackle this problem directly in general .",
    "NOVELTY"
  ],
  [
    "Overall this paper presents a strong and novel model with promising experimental results .",
    "NOVELTY"
  ],
  [
    "Overall , we liked the ideas and the work presented . We admit were somewhat surprised similar solutions have n't been tried in this area but the authors list related work so we conclude the approach is indeed novel and appear effective",
    "NOVELTY"
  ],
  [
    "While we are not vision experts it seems the work presented here suffers from several limitations compared to approaches taken in",
    "NOVELTY"
  ],
  [
    "and has significant contribution in the literature of nonvex optimization",
    "NOVELTY"
  ],
  [
    "The novelty of the work is limited .",
    "NOVELTY"
  ],
  [
    "which limits it novelty in this perspective",
    "NOVELTY"
  ],
  [
    "The technical novelty of the method is limited as there is a similar method proposed in [ 1 ] .",
    "NOVELTY"
  ],
  [
    "work is limited I would guess",
    "NOVELTY"
  ],
  [
    "I like the idea of the result .",
    "NOVELTY"
  ],
  [
    "It is original in the sense that this is the first empirical study on the forgettability of examples in during neural network training .",
    "NOVELTY"
  ],
  [
    "Lack of insight .",
    "NOVELTY"
  ],
  [
    "the idea of transferring the joint constraint structure to a ANN is indeed interesting",
    "NOVELTY"
  ],
  [
    "and here lies the major flaw of the contribution",
    "NOVELTY"
  ],
  [
    "The hierarchical attention model is an interesting contribution",
    "NOVELTY"
  ],
  [
    "in my opinion , the technical novelty of this paper is limited as it uses MLP mappings that in some sense aim at learning the inverse of the equation that generated the data .",
    "NOVELTY"
  ],
  [
    "The originality is in using a Langevin dynamics over the usual Passty algorithm .",
    "NOVELTY"
  ],
  [
    "The paper can be regarded as an adaption of the Seq2Seq framework with pointer networks on learning-to-rank tasks",
    "NOVELTY"
  ],
  [
    "this paper stills seems to a direct application with minor innovation on training approaches and loss functions",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "and is interesting",
    "NOVELTY"
  ],
  [
    "the contributions are rather incremental",
    "NOVELTY"
  ],
  [
    "While the technical contribution is limited",
    "NOVELTY"
  ],
  [
    "it seems that the construction of the augmented MDP and reward shaping indeed make the paper sufficiently novel for publication",
    "NOVELTY"
  ],
  [
    "The work is generally an incremental extension of EFEs to grouped data where the groups are known a priori .",
    "NOVELTY"
  ],
  [
    "The amortization approach is quite interesting",
    "NOVELTY"
  ],
  [
    "Neither the idea , nor the methods are original or new .",
    "NOVELTY"
  ],
  [
    "It seem novelty of the work is in proofs",
    "NOVELTY"
  ],
  [
    "The analysis presented in the paper is definitly insightful",
    "NOVELTY"
  ],
  [
    "but it is not original .",
    "NOVELTY"
  ],
  [
    "the fix does not provide new theoretical insights but it simply confirms what it was previously known",
    "NOVELTY"
  ],
  [
    "Most of the conclusions drawn in the paper follows from the previous work and are therefore not original .",
    "NOVELTY"
  ],
  [
    "The original contributions of the paper are very limited .",
    "NOVELTY"
  ],
  [
    "The authors do not present a significant new algorithmic or empierical innovation .",
    "NOVELTY"
  ],
  [
    "The approach is novel",
    "NOVELTY"
  ],
  [
    "This paper clearly build on a foundation of previous work ; but it 's",
    "NOVELTY"
  ],
  [
    "approach appears original to me",
    "NOVELTY"
  ],
  [
    "One reason is that the base architecture is not novel .",
    "NOVELTY"
  ],
  [
    "The work is also original --",
    "NOVELTY"
  ],
  [
    "there is a lot that is new",
    "NOVELTY"
  ],
  [
    "From both perspectives of methods and applications , the proposed model has very limited novelty .",
    "NOVELTY"
  ],
  [
    "paper with an interesting main idea",
    "NOVELTY"
  ],
  [
    "Using a sampled oracle to simulate a higher accuracy classifier was particularly clever",
    "NOVELTY"
  ],
  [
    "The general idea of the regularization that replaces the generation of noisy samples and optimization over it is conceptually appealing and seems practically",
    "NOVELTY"
  ],
  [
    "while I like the overall idea and find the work novel and potentially practical",
    "NOVELTY"
  ],
  [
    "Recovering model methodology is quite novel compared to traditional noise- elimination-based approaches .",
    "NOVELTY"
  ],
  [
    "and the method appears novel",
    "NOVELTY"
  ],
  [
    "The idea of training an energy-based model through gradient-based meta-learning seems novel and innovative .",
    "NOVELTY"
  ],
  [
    "I really enjoyed this paper - it 's creative , timely , interesting ,",
    "NOVELTY"
  ],
  [
    "the idea is novel",
    "NOVELTY"
  ],
  [
    "The key point of this paper is that the proposed algorithm is novel and combines the advantages of Imitation Learning and Model Base Reinforcement Learning .",
    "NOVELTY"
  ],
  [
    "Novel algorithm presented with success in simulation .",
    "NOVELTY"
  ],
  [
    "The conceptual and experimental contributions of the paper are significant and future works are likely to build upon them .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "Decision Although this paper gave a novel pooling method by incorporating the Wavelet theory",
    "NOVELTY"
  ],
  [
    "any new algorithm , and",
    "NOVELTY"
  ],
  [
    "Overall , I do not find the paper innovative enough for publication at top conferences like ICLR .",
    "NOVELTY"
  ],
  [
    "The techniques used to obtain the results are not novel",
    "NOVELTY"
  ],
  [
    "I agree with the authors that their proof has novel and interesting elements beyond the general approach provided in previous work .",
    "NOVELTY"
  ],
  [
    "Novelty is lacking .",
    "NOVELTY"
  ],
  [
    "they themselves note that the idea of using a smaller proxy like naive bayes for larger models like decision trees is not new",
    "NOVELTY"
  ],
  [
    "The idea of question generation : using logical form to generate meaningful questions for argumenting data of QA tasks is really interesting and useful .",
    "NOVELTY"
  ],
  [
    "The overall idea and motivation looks very similar to the coverage-enhanced models where the decoder also actively",
    "NOVELTY"
  ],
  [
    "I should say , there is certainly novelty .",
    "NOVELTY"
  ],
  [
    "To my knowledge , there is no other previous work on VI with the reparameterisation trick for BRNNs",
    "NOVELTY"
  ],
  [
    "the parameterisation of the conditional variational distribution q",
    "NOVELTY"
  ],
  [
    "( x",
    "NOVELTY"
  ],
  [
    ") using recognition model is interesting",
    "NOVELTY"
  ],
  [
    "The idea of modifying the model by introducing variables to obtain a looser bound which can accommodate a richer variational family is also not new",
    "NOVELTY"
  ],
  [
    "This largely reduces the novelty of this paper and make it incremental , because using virtual supernodes is not this paper \u2019 s original idea .",
    "NOVELTY"
  ],
  [
    "Overall , I find the problem formulation unique with a reasonably comprehensive treatment of the problem presented in the paper .",
    "NOVELTY"
  ],
  [
    "From a theory viewpoint , the paper offers new insights into Batch normalization and other normalization schemes .",
    "NOVELTY"
  ],
  [
    "Novelty : There does not seem to be methodological novelty . On the neuroscience side , using language models to show that context is important in the brain is also not a novel idea -- the paper even cites",
    "NOVELTY"
  ],
  [
    "The idea to study variable length context is interesting and novel",
    "NOVELTY"
  ],
  [
    "but it is original AFAIK . The idea of learning the basic relations between actions and state through self exploration is definitely interesting .",
    "NOVELTY"
  ],
  [
    "I think the paper presents an interesting idea which should be exposed to the community .",
    "NOVELTY"
  ],
  [
    "is a",
    "NOVELTY"
  ],
  [
    "but not a surprising new concept .",
    "NOVELTY"
  ],
  [
    "The parts of the architecture that are novel are the matching module , sub-pixel MAP approximation , and using a discretized Laplace distribution as target .",
    "NOVELTY"
  ],
  [
    "but not ground-breaking",
    "NOVELTY"
  ],
  [
    "I agree .The contribution of this paper of this paper is two-fold .",
    "NOVELTY"
  ],
  [
    "Pros 1 .I like the idea of this sentence- > tree- > sentence autoencoder for semi-supervised parsing . The authors proposed a novel and nice way to tackle key challenges in gradient computation .",
    "NOVELTY"
  ],
  [
    "Novelty The authors \u2019 method appears to provide improved results over the compared alternatives",
    "NOVELTY"
  ],
  [
    "it is worth noting that triplet-based embedding is not novel in its own right",
    "NOVELTY"
  ],
  [
    "As far as I can tell , this is novel work .",
    "NOVELTY"
  ],
  [
    "This paper adds an",
    "NOVELTY"
  ],
  [
    "this section does not really add much new information beyond what we could already infer given that the first stage alignment was so successful",
    "NOVELTY"
  ],
  [
    "This paper appears to be mostly a followup on the work of [ 19",
    "NOVELTY"
  ],
  [
    "While the work is novel",
    "NOVELTY"
  ],
  [
    "the current paper does not appear to have introduced sufficient `` other contributions",
    "NOVELTY"
  ],
  [
    "The framework is in general novel .",
    "NOVELTY"
  ],
  [
    "The technical contribution is incremental",
    "NOVELTY"
  ],
  [
    "But this is not a new view at all .",
    "NOVELTY"
  ],
  [
    "which are not new as well",
    "NOVELTY"
  ],
  [
    "The method is interesting and evidently effective .",
    "NOVELTY"
  ],
  [
    "the contribution of this paper to the literature is not clear",
    "NOVELTY"
  ],
  [
    "Beyond the isometry metric , the main innovation as far as I can see seems to be the hubness filtering , which is incremental and not ablated , so it is not",
    "NOVELTY"
  ],
  [
    ". The weak orthogonality constraint has already been used in",
    "NOVELTY"
  ],
  [
    "While there does exist work in modeling video data with deep generative models , the authors are the first ( to the best of my knowledge ) to propose a neural , end-to-end video codec based on VAEs and entropy coding .",
    "NOVELTY"
  ],
  [
    "Compared to other papers on neural architecture search",
    "NOVELTY"
  ],
  [
    "but the paper itself is incremental .",
    "NOVELTY"
  ],
  [
    "as I still feel the contribution seems a bit incremental over existing work",
    "NOVELTY"
  ],
  [
    "The general idea of perturbating the feature ( latent ) space is not a novel one , which has been studied in",
    "NOVELTY"
  ],
  [
    "I like the idea of encouraging constraints for generative models , which is useful and interesting .",
    "NOVELTY"
  ],
  [
    "given the published paper [ 1 ] , this work seems to be a bit incremental .",
    "NOVELTY"
  ],
  [
    "Overall the contribution of this paper does not seem to be strong enough .",
    "NOVELTY"
  ],
  [
    "On overall , the methodological ( or formulation-wise ) contributions are not major .",
    "NOVELTY"
  ],
  [
    "This approach seems quite similar to `` Neural Rerendering in the Wild `` ( Meshry et al ) at CVPR 2019",
    "NOVELTY"
  ],
  [
    "The obtained results constitute new state-of-the-art on HQ image datasets",
    "NOVELTY"
  ],
  [
    "3 .The method seems to",
    "NOVELTY"
  ],
  [
    "be a slight improvement on an existing method : the use of hierarchical clustering is nice",
    "NOVELTY"
  ],
  [
    "This is particularly problematic as the proposal seems to be a rather small tweak to prior work of two 2018 papers by Watanabe et al .But there is extensive other literature attempting to address this problem",
    "NOVELTY"
  ],
  [
    "but in my opinion is not very novel",
    "NOVELTY"
  ],
  [
    "but does not offer revolutionary new insights",
    "NOVELTY"
  ],
  [
    "and although the architecture is not that new",
    "NOVELTY"
  ],
  [
    "There are many ideas proposed in this paper .",
    "NOVELTY"
  ],
  [
    "The presented approach is interesting",
    "NOVELTY"
  ],
  [
    "The paper does not provide an improvement over WGAN-GP in this direction .",
    "NOVELTY"
  ],
  [
    "Strengths \u00e2\u0080\u0094 The proposed approach is intuitive , sufficiently novel , and outperforms prior work by a large",
    "NOVELTY"
  ],
  [
    "The novelty over the many existing attention architectures is established .",
    "NOVELTY"
  ],
  [
    "Overall , the idea proposed seems quite incremental",
    "NOVELTY"
  ],
  [
    "I think the idea of using project pursuit to find Monge map in high dimensional case is interesting",
    "NOVELTY"
  ],
  [
    "The use of selected projection in sliced Wasserstein is interesting , and the computational efficiency looks promising",
    "NOVELTY"
  ],
  [
    "I feel like the authors have found a very interesting approach for classless association which can be extended to lots of many-to-one problems",
    "NOVELTY"
  ],
  [
    "I think the paper make a very interesting contribution to spatio-temporal fixation prediction",
    "NOVELTY"
  ],
  [
    "The idea of learning a basis for the Koopman invariant subspace ( using deep neural networks ) seems very promising .",
    "NOVELTY"
  ],
  [
    "in my view , this is a rather minor modification of the algorithm proposed in Takeishi .",
    "NOVELTY"
  ],
  [
    "the main contribution",
    "NOVELTY"
  ],
  [
    "The modifications to existing algorithms (",
    "NOVELTY"
  ],
  [
    "appear minor",
    "NOVELTY"
  ],
  [
    ".This is a nice contribution to the literature on density functional estimation",
    "NOVELTY"
  ],
  [
    "presents a simple , but promising idea to simplify reinforcement learning methods . I so far have not seen the definition of non-permissible actions in the literature so I believe this is novel and makes intuitively also sense , as permissible actions can be identified in many scenarios .",
    "NOVELTY"
  ],
  [
    "and interesting",
    "NOVELTY"
  ],
  [
    "This is apparently the first study of program synthesis for differentiable programs . The idea of using program search for transfer learning is novel , and provides an interesting avenue",
    "NOVELTY"
  ],
  [
    "although the search methods themselves do n't seem novel",
    "NOVELTY"
  ],
  [
    "The originality of the paper is good .",
    "NOVELTY"
  ],
  [
    "the approach is relatively novel and well motivated",
    "NOVELTY"
  ],
  [
    "This is an interesting idea , and one I certainly wouldn \u2019 t have thought of on my own",
    "NOVELTY"
  ],
  [
    "the improvements are small (",
    "NOVELTY"
  ],
  [
    "The analysis in bounding the approximation factor ( Theorem 1 ) is interesting .",
    "NOVELTY"
  ],
  [
    "The paper does not provide significant algorithmic insights and a complete understanding , as existing clustering based NIPS papers",
    "NOVELTY"
  ],
  [
    "I like the general idea and find the paper easy to follow . Using the centering effect of batch norm to effectively bypass the need to define the universal negative class embedding is an interesting approach .",
    "NOVELTY"
  ],
  [
    "I think the problem and solution proposed",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting technical contribution -- namely",
    "NOVELTY"
  ],
  [
    "While the proposed method is clearly different , the goals are similar",
    "NOVELTY"
  ],
  [
    "The setup is interesting and seems novel .",
    "NOVELTY"
  ],
  [
    "It explores a novel task with a somewhat interesting approach ,",
    "NOVELTY"
  ],
  [
    "The paper is interesting and constitutes a useful contribution .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this general view of auxiliary variables , and of embedding samplers in latent space to obtain generative models is a novel contribution",
    "NOVELTY"
  ],
  [
    "This alone does not , in my opinion , constitute a sufficiently original contribution ,",
    "NOVELTY"
  ],
  [
    "is that the main contribution of the paper is of a `` didactic `` nature , rather than a practical one",
    "NOVELTY"
  ],
  [
    "A novel method to measure such overfitting is proposed - joint policy correlation .",
    "NOVELTY"
  ],
  [
    "This paper explores a very interesting idea ,",
    "NOVELTY"
  ],
  [
    "This paper is refreshing .",
    "NOVELTY"
  ],
  [
    "Despite the limited originality in the algorithm design",
    "NOVELTY"
  ],
  [
    "While the basic ideas explored here are interesting",
    "NOVELTY"
  ],
  [
    "while the ideas are conceptually",
    "NOVELTY"
  ],
  [
    "interesting , technically the paper does not contribute much .",
    "NOVELTY"
  ],
  [
    "however the contribution is somewhat limited .",
    "NOVELTY"
  ],
  [
    "Relu stability is apparently a new concept and the proposed regularization approximately enforces relu stability",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is somewhat limited , as the proposed architecture is constrained to one class",
    "NOVELTY"
  ],
  [
    "I am new to the domain of symbolic regression and found the article to",
    "NOVELTY"
  ],
  [
    "but its novelty is limited and the improvements are incremental .",
    "NOVELTY"
  ],
  [
    "the authors did not show any technical insight into the numerical results .",
    "NOVELTY"
  ],
  [
    "this paper did not provide any useful knowledge",
    "NOVELTY"
  ],
  [
    "while this paper introduced some",
    "NOVELTY"
  ],
  [
    "This seems to me a novel contribution to the field .",
    "NOVELTY"
  ],
  [
    ".To my knowledge the work is novel in that it characterizes the dependence of the excess risk on specific hyperparameters of SG -- iterations , step-size , mini-batch size -- - in addition to the number of random features used .",
    "NOVELTY"
  ],
  [
    "I like the idea of weight sharing which seems like a reasonable choice for model compression .",
    "NOVELTY"
  ],
  [
    "I think the paper tackles an interesting line of research with some interesting ideas",
    "NOVELTY"
  ],
  [
    "It seems like something very similar has already been done in",
    "NOVELTY"
  ],
  [
    "minor improvement in computational cost - investigation of classical FWRL technique in context of deep RL Cons",
    "NOVELTY"
  ],
  [
    "computational improvement seems very minor",
    "NOVELTY"
  ],
  [
    "In my view , the main contribution is incremental at best , and potentially identical to many existing implementations of HER .",
    "NOVELTY"
  ],
  [
    "The reconsideration of Floyd-Warshall RL in the context of deep neural networks is a refreshing idea",
    "NOVELTY"
  ],
  [
    "The main idea of designing a smoothing function specific to each problem instance seems novel and important , and surprising to me , personally .",
    "NOVELTY"
  ],
  [
    "Up to my best knowledge , achieving logarithmic regret in this particular setup is a novel and original result , which should be of interest to ( at least ) theory part of machine learning community .",
    "NOVELTY"
  ],
  [
    "the disturbance-action policy representation with its approximation properties , the reduction to OCO with memory , analysis of the algorithms by means of ideal state , actions and costs are not novel , but rather directly taken from [ 4 ] .",
    "NOVELTY"
  ],
  [
    "The idea to adopt approximated variances of gradients to reduce communication cost seems to be interesting .",
    "NOVELTY"
  ],
  [
    "The initiative is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Significance The main contribution of this work is of conceptual nature and illustrates how invertible networks are a promising framework for many inverse problems",
    "NOVELTY"
  ],
  [
    "I really like the main idea and think it is inspiring .",
    "NOVELTY"
  ],
  [
    "the experiments and technical contributions are rather limited .",
    "NOVELTY"
  ],
  [
    "This paper is a novel combination of an existing method [ 7,21 ] for 2D images , to an existing task ( point cloud feature learning ) .",
    "NOVELTY"
  ],
  [
    "However I 'm not confident if it is advancing the state-of-the-art due to a concern stated above",
    "NOVELTY"
  ],
  [
    "Nevertheless , the idea of interpolating pairs of latent features for network regularization is not very novel .",
    "NOVELTY"
  ],
  [
    "This paper is a novel extension of ideas from single agent RL to multi agent RL",
    "NOVELTY"
  ],
  [
    "In general , I find the idea original , and of potential practical use",
    "NOVELTY"
  ],
  [
    "but I believe the contribution of paper to be limited",
    "NOVELTY"
  ],
  [
    "I think this would be new and interesting .",
    "NOVELTY"
  ],
  [
    "all , I think the theoretical contribution is good enough .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the formula for the phase transition presented by the authors was not known before and is a significant and original contribution .",
    "NOVELTY"
  ],
  [
    "applying it to this problem seems to require some original and interesting problem specific analysis .",
    "NOVELTY"
  ],
  [
    "and provide new insights to the research field .",
    "NOVELTY"
  ],
  [
    "and with some novel results on community detection for the case of the so-called `` heterogeneous SBM `` .",
    "NOVELTY"
  ],
  [
    "The results are novel to the best of my knowledge and to a regime ( heterogeneous ) that no significant prior work exists .",
    "NOVELTY"
  ],
  [
    "The optimization problems used are not that novel .",
    "NOVELTY"
  ],
  [
    "The topic is not that novel",
    "NOVELTY"
  ],
  [
    "Contributions of novelty are limited .",
    "NOVELTY"
  ],
  [
    "As far as I know , the formulation of label consistency constraint is novel .",
    "NOVELTY"
  ],
  [
    "Technical contribution of this work is insufficient .",
    "NOVELTY"
  ],
  [
    "is somehow novel and",
    "NOVELTY"
  ],
  [
    "2 .Although achieving the state-of-the-art results , the contribution for the na\u00c3\u00afve combination of features from MFA-FS and Places CNN is limited as the other methods can easily run the similar procedure .",
    "NOVELTY"
  ],
  [
    "Personally , I do not find this particularly original , even with the addition of the zero-shot learning component .",
    "NOVELTY"
  ],
  [
    "the proposed idea of using a gedesic distance , similar to Isomaps , is very interesting .",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper has an interesting theoretical contribution",
    "NOVELTY"
  ],
  [
    "While the Dirichlet Process Mixture ( DPM ) is not new",
    "NOVELTY"
  ],
  [
    ", applying such nonparametric method to continual learning is new .",
    "NOVELTY"
  ],
  [
    "with an effective and novel solution",
    "NOVELTY"
  ],
  [
    "The paper is clear and develops interesting ideas relevant to semi-supervised graph node classification .",
    "NOVELTY"
  ],
  [
    "The originality is however relatively limited in a field where many recent papers have been",
    "NOVELTY"
  ],
  [
    "which potentially could contribute in a novel way to a relevant problem in the design of advanced materials",
    "NOVELTY"
  ],
  [
    "Regarding originality , the technical contributions , ( 1 ) an extension of the DDC-HM method to temporally extended ( recurrent ) encoding functions and ( 2 ) a way to train the model are original and nontrivial .",
    "NOVELTY"
  ],
  [
    "The proposed research direction of exploring models that learn from different types of conversational feedback is interesting and , to my knowledge , novel .",
    "NOVELTY"
  ],
  [
    "The proposed memory network extension incorporating forward prediction is interesting",
    "NOVELTY"
  ],
  [
    "Overall , this is a fairly good paper that makes an interesting contribution in terms of new tasks and models .",
    "NOVELTY"
  ],
  [
    "I think this is an interesting piece of work",
    "NOVELTY"
  ],
  [
    "the techniques described in the paper are all based on existing techniques , and the paper lacks the technical novelty .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the paper main idea is novel , and I find it very interesting .",
    "NOVELTY"
  ],
  [
    "The use of non-standard ways of introducing stochasticity to GAN generation is an interesting idea in itself .",
    "NOVELTY"
  ],
  [
    "I really like the core idea of the paper and would be happy if it were accepted based on that alone",
    "NOVELTY"
  ],
  [
    "I found this idea to be very interesting and reasonable , and as far as I know fairly novel .",
    "NOVELTY"
  ],
  [
    "This",
    "NOVELTY"
  ],
  [
    "the paper presents a promising idea but",
    "NOVELTY"
  ],
  [
    "Ultimately , I think the idea is a nice generalization of previous work",
    "NOVELTY"
  ],
  [
    "I agree with reviewer 3 that novelty is not the greatest",
    "NOVELTY"
  ],
  [
    "and the proposed algorithm is interesting and effective",
    "NOVELTY"
  ],
  [
    "The paper seems to be a simple extension of known results for non-convex optimization to saddle-point problems",
    "NOVELTY"
  ],
  [
    "Despite the optimization contribution seems to be marginal",
    "NOVELTY"
  ],
  [
    "Not much is new made in terms of the optimization",
    "NOVELTY"
  ],
  [
    "but the resulting algorithms",
    "NOVELTY"
  ],
  [
    "The work is novel and significant .",
    "NOVELTY"
  ],
  [
    "In my opinion , this paper has a natural extension of existing heavy ball methods in the literature but their theoretical analysis seems to be new although the proof technique is essentially based on the well-known KL condition",
    "NOVELTY"
  ],
  [
    "The local convergence result is also new .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel method for answering",
    "NOVELTY"
  ],
  [
    "The idea of sequential counting is novel and interesting . 2 .The analysis of model performance by grouping the questions as per frequency with which the counting object appeared in the training data is insightful .",
    "NOVELTY"
  ],
  [
    "Overall : The paper proposes a novel and interesting idea for solving counting questions in the Visual Question Answering tasks .",
    "NOVELTY"
  ],
  [
    "while",
    "NOVELTY"
  ],
  [
    "the proposed gate",
    "NOVELTY"
  ],
  [
    "is nothing technically groundbreaking",
    "NOVELTY"
  ],
  [
    "Although this paper seems to only combine existing techniques in community detection and node embedding into a co-train process",
    "NOVELTY"
  ],
  [
    "provide a new perspective of designing the shape/dimensionality of a network in a dynamic manner .",
    "NOVELTY"
  ],
  [
    "The approach is modestly novel compared to existing approaches and in",
    "NOVELTY"
  ],
  [
    "The idea of meta-RL , or more specifically , gradient-based meta-learning adapting to the environment , is natural and",
    "NOVELTY"
  ],
  [
    "no longer new",
    "NOVELTY"
  ],
  [
    "However , adopting the meta-RL method to learn the return function adaptively is certainly novel and interesting .",
    "NOVELTY"
  ],
  [
    "This paper contains novelty in terms of two",
    "NOVELTY"
  ],
  [
    "aspects",
    "NOVELTY"
  ],
  [
    "The derivation seems different from a standard semi-supervised VAE",
    "NOVELTY"
  ],
  [
    "The use of OT seems novel in this context .",
    "NOVELTY"
  ],
  [
    "It describes a direct application of na\u00efve learning tool ( random forest and neural network ) without sufficient insight .",
    "NOVELTY"
  ],
  [
    "The novelty of this work is very limited , if any .",
    "NOVELTY"
  ],
  [
    "The contribution are limited .",
    "NOVELTY"
  ],
  [
    "From the machine learning perspective , this work is a simple and direct application of existing machine learning tools..",
    "NOVELTY"
  ],
  [
    "The paper proposes a promising contribution to the domain",
    "NOVELTY"
  ],
  [
    "but my general feeling is that the paper and the corresponding work are not mature enough for publication at NIPS",
    "NOVELTY"
  ],
  [
    "general\u2014the methods here are quite specific to words and to NLI\u2014and the proposed methods yields only yield large empirical gains in a reduced-data setting",
    "NOVELTY"
  ],
  [
    "In my opinion , the main contribution of the work i.e .creation of barcodes is based on a rather trivial idea .",
    "NOVELTY"
  ],
  [
    "the concept of self-supervision is not first proposed by this paper . The proposed method is not novel .",
    "NOVELTY"
  ],
  [
    "The novel part of the paper over DANNs is the joint , end-to-end training of latent representations for missing data",
    "NOVELTY"
  ],
  [
    "This paper is a nice application of learning theory to mechanism design for combinatorial auctions .",
    "NOVELTY"
  ],
  [
    "the proposed idea is smart",
    "NOVELTY"
  ],
  [
    "While the ideas ( particularly the smooth rendering system ) are interesting",
    "NOVELTY"
  ],
  [
    "The smooth renderer , and in particular the advantages it has over existing differentiable renderers , seem like the most important contributions of the paper",
    "NOVELTY"
  ],
  [
    "Both modifications present some interesting ideas .",
    "NOVELTY"
  ],
  [
    "Also , using synthetic likelihoods in a Bayesian context is novel , to the best of my knowledge , and does seem to be somewhat empirically justified",
    "NOVELTY"
  ],
  [
    "All in all , there are some interesting ideas",
    "NOVELTY"
  ],
  [
    "The idea of TAP is novel and intuitively makes sense .",
    "NOVELTY"
  ],
  [
    "Overall I believe that the idea in this paper is a meaningful novel contribution .",
    "NOVELTY"
  ],
  [
    "In my view , the novelty of the approach is somewhat limited , as it seems like a straightforward application of the VIB from",
    "NOVELTY"
  ],
  [
    "I think the limited novelty is counterbalanced by the quality of empirical analysis",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is mostly empirical",
    "NOVELTY"
  ],
  [
    "Overall , the paper is clearly written and seems to be novel in its approach .",
    "NOVELTY"
  ],
  [
    "the novelty seems not high .",
    "NOVELTY"
  ],
  [
    "The proposed dataset MS MARCO is unique from existing datasets as it is a good representative of the QA task encountered by search engines .",
    "NOVELTY"
  ],
  [
    "Lack of technical novelty .",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    ".The rotational invariant version is appealing but also makes it clear that some of the appeal of the original GW distance is lost",
    "NOVELTY"
  ],
  [
    "In terms of novelty , the scalarization method of the vector-valued reward seems intuitive",
    "NOVELTY"
  ],
  [
    "it is also unclear why the representation of PWC in discrete case is novel .",
    "NOVELTY"
  ],
  [
    "However , the concept of conditioning in video generation is not a novel idea .",
    "NOVELTY"
  ],
  [
    ".Overall the submission provides an interesting new direction on learning system identification approaches , that while quite similar to existing work ( Yu et al 2017 ) , provides increased performance on two benchmark tasks .",
    "NOVELTY"
  ],
  [
    "The novelty of the submission is however limited and highly similar to current methods .",
    "NOVELTY"
  ],
  [
    "This is an interesting theoretical discovery .",
    "NOVELTY"
  ],
  [
    "It provides a novel combination of techniques",
    "NOVELTY"
  ],
  [
    "However , each part in isolation ( style encoder and embedding , etc ) is not novel .",
    "NOVELTY"
  ],
  [
    "I am not sure if ideas from the",
    "NOVELTY"
  ],
  [
    "the methodology is original",
    "NOVELTY"
  ],
  [
    "The min-max entropy modelling also appears to be a novel approach in terms of statistical relational modelling .",
    "NOVELTY"
  ],
  [
    "I don \u2019 t find the contribution that technically novel , and seems somewhat straightforward .",
    "NOVELTY"
  ],
  [
    "This work proposes interesting ideas and overall it constitutes an nice contribution .",
    "NOVELTY"
  ],
  [
    "these three modifications seem to contribute differently on different datasets .",
    "NOVELTY"
  ],
  [
    "The general approach of relating the activity of layers of a DNN to brain activity is not novel to this paper and there are recent publications in the visual system which employ this approach",
    "NOVELTY"
  ],
  [
    "While I am not too familiar with the surrounding literature , the ideas in this paper appear novel .",
    "NOVELTY"
  ],
  [
    "developing the idea",
    "NOVELTY"
  ],
  [
    "this work does constitute a contribution , albeit a modest one",
    "NOVELTY"
  ],
  [
    "and to my limited knowledge novel",
    "NOVELTY"
  ],
  [
    "The proposed method seems like an incremental extension of existing works .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well-written and presents an important novel contribution to the field in the ExactLine algorithm",
    "NOVELTY"
  ],
  [
    "The method introduced in the paper to learn how to explore is elegant , simple and seems robust .",
    "NOVELTY"
  ],
  [
    "even though the contributions are somewhat marginal and the experiments are not quite enough to establish the new relative attention mechanism as being superior",
    "NOVELTY"
  ],
  [
    "I like this paper",
    "NOVELTY"
  ],
  [
    "New architecture that can use all computed state history in a sequence + Outperforms previous methods in the used metrics Weaknesses",
    "NOVELTY"
  ],
  [
    "The proposed method is novel and interesting",
    "NOVELTY"
  ],
  [
    "It is a novel setup to consider reservoir sampling for episodic memory .",
    "NOVELTY"
  ],
  [
    "The improvements are not that large",
    "NOVELTY"
  ],
  [
    "A similar approach to the read again mechanism which is proposed in this paper has already been explored in",
    "NOVELTY"
  ],
  [
    ", the contributions of the paper in terms of ML point of view is very weak .",
    "NOVELTY"
  ],
  [
    "The framework appears quite novel to me .",
    "NOVELTY"
  ],
  [
    "All in all , I think that this is a strong contribution",
    "NOVELTY"
  ],
  [
    "The setting and the algorithm are interesting .",
    "NOVELTY"
  ],
  [
    "I agree that the derivation and how to implement task conditioning are novel and valuable .",
    "NOVELTY"
  ],
  [
    "The task conditioning is not new",
    "NOVELTY"
  ],
  [
    "the idea of learning conditioning metrics ( or features ) seems to be proposed already",
    "NOVELTY"
  ],
  [
    "This is an original and signifiance contribution .",
    "NOVELTY"
  ],
  [
    "The result is a paper which provides almost no interesting technical contribution",
    "NOVELTY"
  ],
  [
    "The model proposed is quite novel . The teacher network uses recent development in reinforcement learning and applies in an innovative way to provide a curriculum for abstract reasoning task . While other curriculum learning works exist , this is one of the first to use it for challenging visual reasoning tasks .",
    "NOVELTY"
  ],
  [
    "But the contribution relatively limited .",
    "NOVELTY"
  ],
  [
    "Decision The main contribution of this paper is hard to discern",
    "NOVELTY"
  ],
  [
    "but the ideas presented are interesting",
    "NOVELTY"
  ],
  [
    "The idea is original as far as I am aware of .",
    "NOVELTY"
  ],
  [
    "The idea is original as far as I am aware of . I like the idea of introducing diversity into ES .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , it is first proposed in J.",
    "NOVELTY"
  ],
  [
    "In itself this is a very natural idea ( and as such could be considered a bit incremental )",
    "NOVELTY"
  ],
  [
    "Considering that the algorithm merely applies the zeroth-order gradient estimator to min-max problems , the algorithm itself only makes up a somewhat novel contribution .",
    "NOVELTY"
  ],
  [
    "However , to the best of my knowledge , it has not been used in this context before and personally I find the algorithm quite appealing .",
    "NOVELTY"
  ],
  [
    "the scientific value of this work is appreciated and this work adds a lot to the community",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is not clear . Most of the approaches used are standard state-of-art methods and there are not a lot of novelties in applying those methods .",
    "NOVELTY"
  ],
  [
    "and thus may be limited in bringing in new techniques",
    "NOVELTY"
  ],
  [
    "But still I tend to think the above adaptations are rather straightforward and technically not quite novel .",
    "NOVELTY"
  ],
  [
    "The algorithm is a nice contribution to the recently introduced adaptive algorithms in that it unifies the stochastic and adversarial case with a single algorithm without ( much ) compromising the optimality in the former case .",
    "NOVELTY"
  ],
  [
    "But the idea of using LSTM-RNNs for SLAM problems is not new",
    "NOVELTY"
  ],
  [
    "I agree that there could potentially be great ideas in this paper .",
    "NOVELTY"
  ],
  [
    "Although I am no expert on learning causal interactions between point processes , the approach presented in the paper seems both novel and very promising .",
    "NOVELTY"
  ],
  [
    "My biggest concern is that the technical contributions of the paper are not clear at all . The motivation for the work ( avoiding high amplitude/frequency control inputs",
    "NOVELTY"
  ],
  [
    ") is certainly now new",
    "NOVELTY"
  ],
  [
    "The idea of using a constrained formulation is not novel either",
    "NOVELTY"
  ],
  [
    "and thus I do not see any novelty there either",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    "the exemplar application is too naive for illustrating the idea",
    "NOVELTY"
  ],
  [
    "while the idea is interesting and supported by experiments",
    "NOVELTY"
  ],
  [
    "My",
    "NOVELTY"
  ],
  [
    "is that in my opinion",
    "NOVELTY"
  ],
  [
    "paper is low , and the novelty is also somewhat limited due to the fact that the interpretation of SPN as mixture of trees was already given in",
    "NOVELTY"
  ],
  [
    "an interesting paper in terms of original derivation of results which have potential for future development",
    "NOVELTY"
  ],
  [
    "but the results are not novel enough , in my opinion , to grant publication at NIPS .",
    "NOVELTY"
  ],
  [
    "This seems like a new proposal for constructing a classifier based on a tree structure .",
    "NOVELTY"
  ],
  [
    "Overall , a very well-written paper with significant development on the problem .",
    "NOVELTY"
  ],
  [
    "Given the originality of the contributions 1 and 2 above",
    "NOVELTY"
  ],
  [
    "The proof technique is novel , and provides some insights in the geometry space of the loss surface .",
    "NOVELTY"
  ],
  [
    "the practical value of this paper is",
    "NOVELTY"
  ],
  [
    "As far as I know this is a completely novel idea .",
    "NOVELTY"
  ],
  [
    "The setting and algorithm are interesting",
    "NOVELTY"
  ],
  [
    "The idea to analyze the effective receptive field sounds novel .",
    "NOVELTY"
  ],
  [
    "The paper presented a solution that is weak compared to these recent results .",
    "NOVELTY"
  ],
  [
    "and original enough .",
    "NOVELTY"
  ],
  [
    "I liked the idea that using a cache model is like putting a prior on data so that the model prefers inputs similar to the training set",
    "NOVELTY"
  ],
  [
    "and the first and second contributions do not seem enough on their own",
    "NOVELTY"
  ],
  [
    "I 'm mainly concerned about the limited technical novelty",
    "NOVELTY"
  ],
  [
    "I would like to see this paper eventually published as I find the proposed technique original and quite relevant to current RL research",
    "NOVELTY"
  ],
  [
    "This is a interesting paper that introduces a ( seemingly novel ? )",
    "NOVELTY"
  ],
  [
    "this paper presents a novel method for improving neural network learning for a number of sequence based problems , and does so",
    "NOVELTY"
  ],
  [
    "differently from that approach , the current method does not introduce any additional clustering cost functions .",
    "NOVELTY"
  ],
  [
    ", and as far as I am aware the proposed approach to tackling this problem is new .",
    "NOVELTY"
  ],
  [
    "but the novelty seems to be present",
    "NOVELTY"
  ],
  [
    "I think the idea is decent",
    "NOVELTY"
  ],
  [
    "In some sense , what the paper proposed could be seen as a new approach to solve pLSI model .",
    "NOVELTY"
  ],
  [
    "The idea is very interesting",
    "NOVELTY"
  ],
  [
    "In my view the idea of training two networks `` against `` each other is very similar in spirit",
    "NOVELTY"
  ],
  [
    "I think this paper has proposed some new ideas for the VAE models",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper has an interesting idea .",
    "NOVELTY"
  ],
  [
    "it seems this may be an incremental improvement",
    "NOVELTY"
  ],
  [
    "General comments The paper provides an original theoretical contribution which should have impacts at least in methodological developments",
    "NOVELTY"
  ],
  [
    "Therefore , this work appears novel and interesting to me .",
    "NOVELTY"
  ],
  [
    "The main idea of the paper is an interesting and , at least to me , novel one .",
    "NOVELTY"
  ],
  [
    "-The proposed regularization scheme seems closely related to the approach taken in",
    "NOVELTY"
  ],
  [
    "But this approach is already used in various tasks",
    "NOVELTY"
  ],
  [
    "the proposed method ( in Section 3 ) using a multi-task learning objective with self-supervised losses seems to be incremental .",
    "NOVELTY"
  ],
  [
    "However , the contribution of the methodology is limited and some experimental results seem to incremental .",
    "NOVELTY"
  ],
  [
    "and makes an interesting contribution .",
    "NOVELTY"
  ],
  [
    "The proposed metric is a novel way of testing whether ground truth factors of variation have been identified .",
    "NOVELTY"
  ],
  [
    "The core idea is novel ,",
    "NOVELTY"
  ],
  [
    "The idea of using the knowledge in an existing landmark detection is interesting",
    "NOVELTY"
  ],
  [
    "However , the technical novelty of this paper is not very significant .",
    "NOVELTY"
  ],
  [
    "In contrast",
    "NOVELTY"
  ],
  [
    "I like the idea of the paper , however",
    "NOVELTY"
  ],
  [
    "The relation between RNN and kalman filter has also been explored before",
    "NOVELTY"
  ],
  [
    "It seems the idea is very similar to [ 1 ] .",
    "NOVELTY"
  ],
  [
    "This paper presents a novel deep anomaly detection model .",
    "NOVELTY"
  ],
  [
    "The authors make an effort to abstract the approach into a framework where other deep learning models and dimensionality reduction techniques",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited as it is mostly a combination of 2 existing methods .",
    "NOVELTY"
  ],
  [
    "and despite the",
    "NOVELTY"
  ],
  [
    "limited novelty",
    "NOVELTY"
  ],
  [
    "I think the paper makes a good contribution to anomaly detection",
    "NOVELTY"
  ],
  [
    "but the paper lacks enough novelty .",
    "NOVELTY"
  ],
  [
    "and insightful",
    "NOVELTY"
  ],
  [
    "I did n't think that the paper had enough scientific novelty to be an ICLR paper .",
    "NOVELTY"
  ],
  [
    "The practical improvements made are not specifically novel",
    "NOVELTY"
  ],
  [
    "The idea is novel .",
    "NOVELTY"
  ],
  [
    "The intuition behind the algorithm ( that one should try to speed up the propagation of rewards across multiple steps ) is not new",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge the specific algorithm proposed in this submission ( Alg .2 ) is novel , even if Alg .",
    "NOVELTY"
  ],
  [
    "This paper is the first attempt for literally realizing 'vision as inverse graphics ' . A highly original and inspiring work .",
    "NOVELTY"
  ],
  [
    "This is a highly original manuscript which goes beyond using known algorithms to study technically challenging problems and instead attempts to explain mechanisms of fundamental neuro-systems in the MEC and HCF .",
    "NOVELTY"
  ],
  [
    "This is not a technical novelty",
    "NOVELTY"
  ],
  [
    "The paper lack technical novelty .",
    "NOVELTY"
  ],
  [
    "The network architecture described is not terribly novel as many papers have explored pairing an auto-encoder with a classification task .",
    "NOVELTY"
  ],
  [
    "I do n't find the methods to be much of a contribution .",
    "NOVELTY"
  ],
  [
    "I believe this paper should be rejected because its motivation and technical framework are not novel enough in that 1 ) the motivation of decomposition along gradient matrix is already well-founded by a series of paper related to neural tangent kernel 2 ) the techniques used here also fall in a similar framework .",
    "NOVELTY"
  ],
  [
    "but it does n't provide new insights into optimization and generalization for deep nets . The motivation and logic behind are not novel enough , the main theorem neither .",
    "NOVELTY"
  ],
  [
    "learning binary dependencies between primitives is not novel here",
    "NOVELTY"
  ],
  [
    "but also intuitive",
    "NOVELTY"
  ],
  [
    "the method is incremental and",
    "NOVELTY"
  ],
  [
    "This method looks incremental to me because it is addressing the problem of pseudo-labelling for learning on a new dataset and instead of using confidence measures uses a random forest to assign labels .",
    "NOVELTY"
  ],
  [
    "Novel , principled sequence to sequence model .",
    "NOVELTY"
  ],
  [
    "The three enhancements proposed by the authors are long known and incremental",
    "NOVELTY"
  ],
  [
    "I think there are a lot of interesting ideas and the numerical improvements seem consistent with the method",
    "NOVELTY"
  ],
  [
    "Several attempts to employ hybrid architectures ( as defined in the text ) have been already proposed",
    "NOVELTY"
  ],
  [
    "Learning spectral distribution of kernel via optimising RFF samples is also not entirely new",
    "NOVELTY"
  ],
  [
    "and useful departure from the theory in vanilla GAN proposed in Goodfellow et al 2014",
    "NOVELTY"
  ],
  [
    "and the proposed framework of convex duality is quite novel and rigorously treated .",
    "NOVELTY"
  ],
  [
    "The proposed method is not novel .",
    "NOVELTY"
  ],
  [
    "The novelty and technical contribution is low .",
    "NOVELTY"
  ],
  [
    "The blackdoor for attack in this work , namely the softmax layer , is novel and interesting to me , at least to my knowledge .",
    "NOVELTY"
  ],
  [
    "this paper brings some new insights and results in robustness certification",
    "NOVELTY"
  ],
  [
    "The second contribution is quite novel .",
    "NOVELTY"
  ],
  [
    "It is hard to narrow down on the exact contributions of this paper",
    "NOVELTY"
  ],
  [
    "I believe this method is novel and natural and worth investigating .",
    "NOVELTY"
  ],
  [
    "I think this work is very novel and natural",
    "NOVELTY"
  ],
  [
    "but with relatively thin contributions besides the large amount of experiments .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "firstly because the ideas are not surprising",
    "NOVELTY"
  ],
  [
    "though it is somehow different from a typical technical paper",
    "NOVELTY"
  ],
  [
    "the technical contributions are lean . The three main components , 1 ) fitted value iteration ,",
    "NOVELTY"
  ],
  [
    "MPC and 3 ) exploration based on multiple value function estimates , are not novel .",
    "NOVELTY"
  ],
  [
    "the novelty of this work is not sufficiently high and its",
    "NOVELTY"
  ],
  [
    "Use of the search history proposed in this paper is not really new in ES community .",
    "NOVELTY"
  ],
  [
    "This paper addresses the theoretical aspect of the momentum and this may be new .",
    "NOVELTY"
  ],
  [
    "Overall , this paper could be an interesting contribution .",
    "NOVELTY"
  ],
  [
    "2 .The paper presents a novel method called MemoryGAN for GAN training .",
    "NOVELTY"
  ],
  [
    "Comments +The notion of hypothesis sensitivity coefficients",
    "NOVELTY"
  ],
  [
    "seem very similar to the notion of uniform argument stability of [ Liu et al.",
    "NOVELTY"
  ],
  [
    "the paper in its current form is not sufficiently mature to appear at ICLR",
    "NOVELTY"
  ],
  [
    "the idea is somehow interesting",
    "NOVELTY"
  ],
  [
    "The paper proposes novel techniques for private learning with PATE framework .",
    "NOVELTY"
  ],
  [
    "contributes meaningfully to the topic modeling",
    "NOVELTY"
  ],
  [
    "The evaluation methodology is a good idea",
    "NOVELTY"
  ],
  [
    "but is quiet trivial",
    "NOVELTY"
  ],
  [
    "The approach differs",
    "NOVELTY"
  ],
  [
    "The use of attention weights to regularize the latent states was fairly interesting .",
    "NOVELTY"
  ],
  [
    "As a result , the novelty of the proposed method was very incremental and limited from a technology perspective .",
    "NOVELTY"
  ],
  [
    "explores the rather intuitive and simple idea of sharing parameters between related tasks",
    "NOVELTY"
  ],
  [
    "The investigation on the depth where sharing should occur is quite interesting and related to the usual idea of higher transferable property low level features .",
    "NOVELTY"
  ],
  [
    "Evaluation -- -- -- -- The idea is novel and I find the discussion on the considered restriction on the hypothesis class interesting .",
    "NOVELTY"
  ],
  [
    "The method proposed seems to be novel and reasonable .",
    "NOVELTY"
  ],
  [
    "My only major concern is the degree of technical novelty with respect to the original DenseNet paper of Huang et al . ( 2017 ) .",
    "NOVELTY"
  ],
  [
    "However , this work is basically an extension of the DenseNet approach with a new problem statement and additional , in-depth analysis .",
    "NOVELTY"
  ],
  [
    "2 .The idea of applying Beta-Bernoulli Process to uncover the underlying global model from a pool of local models is interesting .",
    "NOVELTY"
  ],
  [
    "The idea is catchy and charmingly simple",
    "NOVELTY"
  ],
  [
    "The paper is fairly original in that it proposes a new tree-splitting criterion that seems to work very well when the leaves are linear models rather than constants . It also provides a novel application of several pieces of previous work , including LASSO and random forests .",
    "NOVELTY"
  ],
  [
    "paper does seem to advance the state of the art in learning with tree-based models .",
    "NOVELTY"
  ],
  [
    "This work is a novel combination of existing methods [ 2,18,22 ] .",
    "NOVELTY"
  ],
  [
    "The main issue is novelty",
    "NOVELTY"
  ],
  [
    "The technical contribution for MOO and MTL is limited since this paper just borrow the MOO optimization method directly from reference",
    "NOVELTY"
  ],
  [
    "The idea of using a `` fast `` linear learner on top of a slowly changing representation is not new in RL (",
    "NOVELTY"
  ],
  [
    "and the proof , in itself , does not provide particular mathematical novelty",
    "NOVELTY"
  ],
  [
    "The idea to build structured policy is novel for continuous control tasks .",
    "NOVELTY"
  ],
  [
    "I think the authors present an interesting and a novel idea that addresses an important problem of how to select an optimal CNN architecture . I think the major strength of",
    "NOVELTY"
  ],
  [
    "this paper is the novelty in the technical",
    "NOVELTY"
  ],
  [
    "approach",
    "NOVELTY"
  ],
  [
    "There has been a lot of incremental work on CNNs recently , that do not contribute much to the field despite very good performance in certain tasks .",
    "NOVELTY"
  ],
  [
    "In comparison , even though this paper",
    "NOVELTY"
  ],
  [
    "may not have the most impressive empirical",
    "NOVELTY"
  ],
  [
    "results , it presents a novel alternative to CNNs , which addresses an important CNN architecture selection problem .",
    "NOVELTY"
  ],
  [
    "However , I like the idea of the paper",
    "NOVELTY"
  ],
  [
    "This paper makes several excellent contributions . To my knowledge , this is the first paper to give compressed sensing style recovery guarantees for solving inverse problems with deep network priors like those in",
    "NOVELTY"
  ],
  [
    "10 ] . Also , to my knowledge , this is the first work applying these methods to the compressive phase retrieval problem .",
    "NOVELTY"
  ],
  [
    "and the contribution was clear",
    "NOVELTY"
  ],
  [
    "I think this paper is the first paper to come up with an algorithm that satisfies approximate EO at each round",
    "NOVELTY"
  ],
  [
    "though the idea is nice",
    "NOVELTY"
  ],
  [
    "The advance seems to be incremental .",
    "NOVELTY"
  ],
  [
    "The overall proposed model with a network trained using a combination of supervision and self-supervised 3D/2D consistency checks appears to be novel .",
    "NOVELTY"
  ],
  [
    "The novelty seems to be mainly application-driven rather than in any new learning or optimization techniques",
    "NOVELTY"
  ],
  [
    "and think it would contribute nicely to the literature",
    "NOVELTY"
  ],
  [
    "The method appears to be novel ,",
    "NOVELTY"
  ],
  [
    "community",
    "NOVELTY"
  ],
  [
    "I think the proposed idea is actually very interesting approach to learning the PDE solution in presence of non-differentability",
    "NOVELTY"
  ],
  [
    "and represents a concrete contribution to the language modelling literature",
    "NOVELTY"
  ],
  [
    "against adversarial examples generated in a black-box or white-box setting",
    "NOVELTY"
  ],
  [
    "Using a binary encoding of the input to reduce the attack surface is a brilliant idea .",
    "NOVELTY"
  ],
  [
    "The idea behind the paper ( optimizing for minimizing deficiency instead of sufficiency in IB ) is interesting",
    "NOVELTY"
  ],
  [
    "Although the entire idea is interesting",
    "NOVELTY"
  ],
  [
    "The main reasons are",
    "NOVELTY"
  ],
  [
    "the proposed model is not completely novel and",
    "NOVELTY"
  ],
  [
    "The idea of combining CP and Tucker is not new .",
    "NOVELTY"
  ],
  [
    "By looking Figure 3 , the proposed method , PComplEx , is not significantly better than the existing methods such as ComplEx",
    "NOVELTY"
  ],
  [
    "In addition to the idea , the paper is also novel in the sense that it brings together the recent advances in automatic differentiation and a neural network construction .",
    "NOVELTY"
  ],
  [
    "The PDE-inspired formulation of coupled ODE is very interesting and can enable utilization of decades of progress in efficiently solving particular classes of coupled equations , in deep learning",
    "NOVELTY"
  ],
  [
    "2 .The general idea of allowing activations and weights to evolve ( in particular , evolve independently ) is an interesting approach to enrich neuralODE representation .",
    "NOVELTY"
  ],
  [
    "2 .Leaving aside the claimed weakness of neuralODE , the idea of modeling weight evolution as ODE is itself very intellectually interesting and worthy of pursuit .",
    "NOVELTY"
  ],
  [
    "The authors explore and develop variational inference in such a setting and this appears to be a new idea in the field .",
    "NOVELTY"
  ],
  [
    "The idea is novel ,",
    "NOVELTY"
  ],
  [
    "paper contains a novel method for an established problem",
    "NOVELTY"
  ],
  [
    "The technique contribution is quite limited .",
    "NOVELTY"
  ],
  [
    "The main idea of this paper is very interesting and the results look encouraging .",
    "NOVELTY"
  ],
  [
    "The model proposed is very interesting",
    "NOVELTY"
  ],
  [
    "Overall I liked the idea of sketching in second order online optimization and its analysis ,",
    "NOVELTY"
  ],
  [
    "and I believe it is a good contribution",
    "NOVELTY"
  ],
  [
    "Intuitive and appealingly elegant method",
    "NOVELTY"
  ],
  [
    "fast .",
    "NOVELTY"
  ],
  [
    "The technical contribution of the proposed method is not clear .",
    "NOVELTY"
  ],
  [
    "The analysis of the model is interesting and insightful .",
    "NOVELTY"
  ],
  [
    "As far as I know , this is the first paper on generating protein structures usings GANs .",
    "NOVELTY"
  ],
  [
    "I did not find much insight in this paper",
    "NOVELTY"
  ],
  [
    "On the technical side , the novelty is incremental .",
    "NOVELTY"
  ],
  [
    "I enjoyed this paper and its approach to fairness in clustering .",
    "NOVELTY"
  ],
  [
    "I find the approach lacks novelty and is a straightforward application of the well established temperature scaling method and the expected calibration error to regression tasks .",
    "NOVELTY"
  ],
  [
    "While all the components are not overall novel",
    "NOVELTY"
  ],
  [
    ", the 3D planar regularization term is interesting .",
    "NOVELTY"
  ],
  [
    "though the technique itself is not new outside the sub-field of architecture search .",
    "NOVELTY"
  ],
  [
    "Weaknesses Apart from the contributions of compilation of different datasets which are already present , and classification results on them , there is not much novelty in the paper .",
    "NOVELTY"
  ],
  [
    "the contribution is limited to compiling existing datasets and defining a 60-20-20 train-validation-test split on them . There is no new",
    "NOVELTY"
  ],
  [
    "this is not a significant contribution .",
    "NOVELTY"
  ],
  [
    "However in its current state , the contributions are not significant enough .",
    "NOVELTY"
  ],
  [
    "The authors combine old ideas to prove lower bounds under different settings in a very clever way to get the required lower bound",
    "NOVELTY"
  ],
  [
    "the techniques used to prove the lower bounds in each of the pieces are not new .",
    "NOVELTY"
  ],
  [
    "it is unclear to me exactly how novel its contributions are .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is quite promising",
    "NOVELTY"
  ],
  [
    "The idea of using RNN to produce the description of the network and using RL to train the RNN is interesting and promising .",
    "NOVELTY"
  ],
  [
    ".I agreed with the author that the paper is not novel",
    "NOVELTY"
  ],
  [
    "It is a great contribution to combine all these components together in a relatively simple algorithm .",
    "NOVELTY"
  ],
  [
    ", original and significant",
    "NOVELTY"
  ],
  [
    "The paper constructs a VCBS algorithm with novelties in allowing soft constrains of the generated beams .",
    "NOVELTY"
  ],
  [
    "compared with the BAN method",
    "NOVELTY"
  ],
  [
    "but that the tools advocated are really rudimentary compared with what has been already proposed elsewhere .",
    "NOVELTY"
  ],
  [
    "I thought this was a well-developed and really intriguing paper with lots of good ideas",
    "NOVELTY"
  ],
  [
    "The problem setting is new and",
    "NOVELTY"
  ],
  [
    "the present paper is the first , to my knowledge , that tackles MMAP using algebraic computations , at least the way presented",
    "NOVELTY"
  ],
  [
    "I found this paper very interesting",
    "NOVELTY"
  ],
  [
    "and from my limited understanding of the literature , this seems like a novel and highly useful tool in the toolbox for verifying neural network models .",
    "NOVELTY"
  ],
  [
    ", given many existing efforts/algorithms",
    "NOVELTY"
  ],
  [
    "lack of originality of contributions makes it difficult to highly recommend the paper .",
    "NOVELTY"
  ],
  [
    "The work is an extension of a known technique ( DIM )",
    "NOVELTY"
  ],
  [
    "I vote for weak accept as the paper proposes a novel intrinsic reward for promoting synergetic behavior in multi-agent systems , while also demonstrating that such an intrinsic reward can be differentiable if a joint forward dynamics model is approximated in addition to individual forward dynamics models given each agent",
    "NOVELTY"
  ],
  [
    "The work has interesting ideas .",
    "NOVELTY"
  ],
  [
    "This is a nice idea as disentanglement enables transfer ( or should ) .",
    "NOVELTY"
  ],
  [
    "The LP and its dual for solving CMDP and POMCP for solving POMDP are not new",
    "NOVELTY"
  ],
  [
    "but using POMCP and the dual for solving CPOMDP is novel",
    "NOVELTY"
  ],
  [
    "is the novel training procedure",
    "NOVELTY"
  ],
  [
    "while the methods are not particularly novel",
    "NOVELTY"
  ],
  [
    "This paper 's contributions are mostly empirical .",
    "NOVELTY"
  ],
  [
    "The idea is quite interesting and is a nice synthesis of ideas from the VAE , graphical models and MCMC literature .",
    "NOVELTY"
  ],
  [
    "Although the contributions appear to be sufficiently novel .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the proposed approach is novel and nicely bridge programming by example and sketches by programmers .",
    "NOVELTY"
  ],
  [
    "The main originality of the paper is the proposal of a novel model construction for Bayesian graph models . Although related hierarchical constructions have been adopted in other areas like topic modelling , the proposed model is relatively new in Bayesian modelling for graph analysis",
    "NOVELTY"
  ],
  [
    "The idea of using uncertainty estimates obtained from Bayesian training to adjust weight updates is natural and potentially very promising .",
    "NOVELTY"
  ],
  [
    "While the idea is straightforward , and perhaps not a standalone contribution by itself",
    "NOVELTY"
  ],
  [
    "A novel graph kernel",
    "NOVELTY"
  ],
  [
    "In summary , novel",
    "NOVELTY"
  ],
  [
    "The idea is appealing",
    "NOVELTY"
  ],
  [
    "I think the contribution could be greater , and does not provide enough insights ( either theoretical or empirical ) to understand in which context the method is working",
    "NOVELTY"
  ],
  [
    "The novelties of the paper are presented very succinctly in less than a half page",
    "NOVELTY"
  ],
  [
    "While dynamic weight generation has been applied to a broad range of problems , this is the first work to address the vid2vid problem .",
    "NOVELTY"
  ],
  [
    "and provided a novel solution",
    "NOVELTY"
  ],
  [
    "The various components of the model are not novel ,",
    "NOVELTY"
  ],
  [
    "but the particular framework of putting them together is novel .",
    "NOVELTY"
  ],
  [
    "and provides novel , to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "idea is very natural",
    "NOVELTY"
  ],
  [
    "but their influence on the current state-of-the-art is negligible .",
    "NOVELTY"
  ],
  [
    "The influence is therefore practically marginal .",
    "NOVELTY"
  ],
  [
    "The novelty in the work seems quite limited mainly in terms of tensorflow implementation of the network pruning using a binary mask .",
    "NOVELTY"
  ],
  [
    "The novelty in terms of ideas and insights seems quite limited .",
    "NOVELTY"
  ],
  [
    "I think this paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "Given that the estimator is a path-norm regularized estimator , this seemed to be an incremental contribution .",
    "NOVELTY"
  ],
  [
    "The generalisation of TS to finite-horizon problems is not novel , and the exploration-exploitation trade-off has also been addressed in previous literature .",
    "NOVELTY"
  ],
  [
    "The setup is very toy ,",
    "NOVELTY"
  ],
  [
    "Introduces a new and interesting IRL",
    "NOVELTY"
  ],
  [
    "The proposed problem/theoretical result/algorithm are novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper is interesting",
    "NOVELTY"
  ],
  [
    "I like the idea of inverse rendering for scene understanding and modification ,",
    "NOVELTY"
  ],
  [
    "the work is original and the",
    "NOVELTY"
  ],
  [
    "but the novelty is limited .",
    "NOVELTY"
  ],
  [
    "the paper does describe a non-trivial contribution",
    "NOVELTY"
  ],
  [
    "The idea of lingering gradients is an interesting concept 2",
    "NOVELTY"
  ],
  [
    "lingering gradients 3",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "this is very interesting",
    "NOVELTY"
  ],
  [
    "unfortunately the contribution here is very small .",
    "NOVELTY"
  ],
  [
    "Therefore , the added novelty with respect to SUNCG is very limited .",
    "NOVELTY"
  ],
  [
    "the task proposed seems too simple considering the power of",
    "NOVELTY"
  ],
  [
    "and the models used to solve the task don \u2019 t seem to bring relevant novelties from previous approaches .",
    "NOVELTY"
  ],
  [
    "The proposed method looks novel to me",
    "NOVELTY"
  ],
  [
    "I really enjoyed the ideas presented in this paper . The connection to message routing networks is quite interesting . To the best of my knowledge this is novel , and , similar to other `` neuralifications `` of CS concepts [ 1 , 2",
    "NOVELTY"
  ],
  [
    "The proposed approach is simple and has an appealing compositional feature",
    "NOVELTY"
  ],
  [
    "and the novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "Low-rank tensors have been used to derive features in many prior works in NLP",
    "NOVELTY"
  ],
  [
    "The paper 's particular application to learning word embeddings ( PPMI factorization ) , however , is new although perhaps not particularly original .",
    "NOVELTY"
  ],
  [
    "Overall I do not see a substantial contribution from this paper .",
    "NOVELTY"
  ],
  [
    "I don \u2019 t see a significant enough algorithmic contribution from this paper to yield an ICLR acceptance",
    "NOVELTY"
  ],
  [
    "I think the proposed work is original .",
    "NOVELTY"
  ],
  [
    "that",
    "NOVELTY"
  ],
  [
    "Novelty/Originality The work is highly novel in that it proposes a new loss function and a new , efficient algorithm to solve the associated optimization problem .",
    "NOVELTY"
  ],
  [
    "to me the often marginal improvements obtained by these algorithmic components may not be counted any significant contribution",
    "NOVELTY"
  ],
  [
    ".While the same problem has been considered in the k-armed bandit setting ( and linear bandits ) before , the extension to the kernelized bandits setting is new and introduces additional challenges that require a different set of ideas .",
    "NOVELTY"
  ],
  [
    ".The connection between these two ideas is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "A novel approach to fully unsupervised anomaly detection that beats the state of the art .",
    "NOVELTY"
  ],
  [
    "Overall this is a good paper proposing a novel approach to fully unsupervised anomaly detection with state-of-the art results .",
    "NOVELTY"
  ],
  [
    "The methods are , to the best of my knowledge , original .",
    "NOVELTY"
  ],
  [
    "the paper has a unique idea",
    "NOVELTY"
  ],
  [
    "While the work of Soudry et al was the first step in this direction , this paper makes the above two very interesting generalizations of that work .",
    "NOVELTY"
  ],
  [
    "The proposed deep models are novel",
    "NOVELTY"
  ],
  [
    "My main concern is the lack of novelty in the methodology .",
    "NOVELTY"
  ],
  [
    "I enjoyed the paper",
    "NOVELTY"
  ],
  [
    "SUMMARY .The paper presents a novel approach to procedural language understanding .",
    "NOVELTY"
  ],
  [
    "The idea itself is intriguing",
    "NOVELTY"
  ],
  [
    "that introduces an approach to image restoration based on a `` hypothetical `` prior , the gradient of which can be approximated by a trained denoising autoencoder .",
    "NOVELTY"
  ],
  [
    "the network structure may not be novel , though",
    "NOVELTY"
  ],
  [
    "it seems to me that this drastic scheduling strategy sounds like very similar to the traditional approach that trains the floating point network first and then finetune the quantized one",
    "NOVELTY"
  ],
  [
    "I must say that I 'm not expert enough to assess the technical novelty of this paper over prior works",
    "NOVELTY"
  ],
  [
    "7 .One minor issue is the proposed method is incremental given the existing work [ 1 , 2 ] .",
    "NOVELTY"
  ],
  [
    "I .Originality Statistical tests for optimization are not new , in that regard the originality of the paper is low .",
    "NOVELTY"
  ],
  [
    "the ideas and developments in this paper are promising",
    "NOVELTY"
  ],
  [
    "While this paper is interesting and highlights advantages of modeling transformations of sequential data",
    "NOVELTY"
  ],
  [
    "I do n't think the contributions are currently sufficient for ICLR conference",
    "NOVELTY"
  ],
  [
    "given prior work on Progressive Nets and other methods using generative models for continual learning , novelty is limited .",
    "NOVELTY"
  ],
  [
    "In this respect , I 'm not sure that the work proposes something really novel from the modeling perspective",
    "NOVELTY"
  ],
  [
    "the paper studies this in the context of optimization and the theorem proposed in the paper is interesting and it adds some solidity to the contribution",
    "NOVELTY"
  ],
  [
    "the idea of tightening relaxation-based bounds by considering multiple ReLUs is a natural one ,",
    "NOVELTY"
  ],
  [
    "this work is original .",
    "NOVELTY"
  ],
  [
    "This is a strong paper that presents improved algorithms for many natural variants of the problem which were mostly studied before . The paper is also very well-written and uses many interesting ideas here and there",
    "NOVELTY"
  ],
  [
    "I doubt the novelty and effectiveness of the attention way used in the paper .",
    "NOVELTY"
  ],
  [
    "I appreciate that this is a novel application of optimal experimental design",
    "NOVELTY"
  ],
  [
    "but beyond that the main theoretical ideas are not novel .",
    "NOVELTY"
  ],
  [
    "novel approach to two-layer modeling",
    "NOVELTY"
  ],
  [
    "the originality ( application of DCNN ) and significance ( limited to ATM domain ) is very limited .",
    "NOVELTY"
  ],
  [
    "Overall the submission presents a novel , simple-yet-non-obvious change to existing approaches that can yield substantial improvements .",
    "NOVELTY"
  ],
  [
    "the experimental setup differs significantly from the claims of self-supervision and multi-task RL made in the introduction/method",
    "NOVELTY"
  ],
  [
    "The approach is novel .",
    "NOVELTY"
  ],
  [
    "The approach differs from previous work in the way that multiple possible futures are represented",
    "NOVELTY"
  ],
  [
    "For the first time , the paper connects the phenomenon with topological complexity of input data and decision super-level sets",
    "NOVELTY"
  ],
  [
    "which is inspiring",
    "NOVELTY"
  ],
  [
    "As far as I know the particular algorithm is novel",
    "NOVELTY"
  ],
  [
    "but I consider it incremental compared to what has been done before .",
    "NOVELTY"
  ],
  [
    "The proposed work is novel enough to my understanding .",
    "NOVELTY"
  ],
  [
    "I believe that the submission is sufficiently original , lacks quality and clarity in some respects",
    "NOVELTY"
  ],
  [
    "I feel that the idea presented here is not revolutionary or a very radical departure from what has been done before",
    "NOVELTY"
  ],
  [
    "Finite sample analysis of certainty equivalence method is not new in RL literature , especially for tabular MDPs .",
    "NOVELTY"
  ],
  [
    "The finite sample analysis of certainty equivalence in LQR and LQG was missing previously and the paper fills this gaps",
    "NOVELTY"
  ],
  [
    "While the analysis techniques used in paper existed before ( e.g.",
    "NOVELTY"
  ],
  [
    ", the final result is new to me .",
    "NOVELTY"
  ],
  [
    "The paper does not bring anything novel to the field of cross-lingual representation learning",
    "NOVELTY"
  ],
  [
    "I see this work as largely incremental ,",
    "NOVELTY"
  ],
  [
    "The actual model implementation is a straightforward extension of the Sent2Vec model to cross-lingual scenarios",
    "NOVELTY"
  ],
  [
    "so the paper is also very incremental from the methodological perspective",
    "NOVELTY"
  ],
  [
    "and it does appear incremental to me",
    "NOVELTY"
  ],
  [
    "A second issue I have is that unlike ERM , the \u00e2\u0080\u009cadversarial game\u00e2\u0080\u009d formulation has not been a standard scheme in the machine learning field yet",
    "NOVELTY"
  ],
  [
    "Both the algorithm and its analysis are very interesting .",
    "NOVELTY"
  ],
  [
    "This work contains plenty of novel material ,",
    "NOVELTY"
  ],
  [
    "I could not verify its novelty",
    "NOVELTY"
  ],
  [
    ", but this seems to be a great contribution .",
    "NOVELTY"
  ],
  [
    "The idea for connecting the expressive ability of CNNs with FNNs is interesting , which can fully take advantage of the power of FNNs to understand CNNs .",
    "NOVELTY"
  ],
  [
    "most of the analysis seems to be a marginal contribution over the work of Bartlett et al",
    "NOVELTY"
  ],
  [
    "The novelty of the algorithm lies in providing global convergence guarantees for the online version of CCA .",
    "NOVELTY"
  ],
  [
    "The idea is not entirely novel and there is already a class of methods based on regularization",
    "NOVELTY"
  ],
  [
    "However in its implementation , the specifics of the proposed method seem to be novel .",
    "NOVELTY"
  ],
  [
    "objectives",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel and interesting way to tackle the difficulties of performing inference atop HSMM .",
    "NOVELTY"
  ],
  [
    "is the first paper to proposes a GAN-style algorithm for the partial multi-label learning problem",
    "NOVELTY"
  ],
  [
    "Although the paper is not",
    "NOVELTY"
  ],
  [
    "perfect",
    "NOVELTY"
  ],
  [
    "and it is also the first paper ( thus it is novel ) to use the powerful deep neural networks into this problem",
    "NOVELTY"
  ],
  [
    "and represents a significant and original contribution to this line of research .",
    "NOVELTY"
  ],
  [
    "the paper offers little insight into the quantification of inductive biases by architecture",
    "NOVELTY"
  ],
  [
    "The main idea of trying to estimate the size of the support using a few samples by using birthday theorem seems new .",
    "NOVELTY"
  ],
  [
    "This paper presents a novel approach to feature extraction .",
    "NOVELTY"
  ],
  [
    "I think this is an interesting and novel take on feature extraction",
    "NOVELTY"
  ],
  [
    "The novelty seems quite limited ,",
    "NOVELTY"
  ],
  [
    "both novelty and impact seem limited .",
    "NOVELTY"
  ],
  [
    "The idea is not groundbreaking but seems sufficiently novel , especially in light of its effectiveness",
    "NOVELTY"
  ],
  [
    "on the whole I think it is a quality contribution and should be accepted",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is novel and interesting .",
    "NOVELTY"
  ],
  [
    "while",
    "NOVELTY"
  ],
  [
    "Overall , I find the core idea quite intuitive and elegant .",
    "NOVELTY"
  ],
  [
    "I vote to reject this paper because I do not feel that it has sufficient novelty to be a paper on its own in light of Lee et al , 2019 .",
    "NOVELTY"
  ],
  [
    "This paper improves upon existing approaches to the principle component projection problem in an interesting way .",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper in my opinion is that the innovations seem to be incremental and not based on any overarching insight or general principle .",
    "NOVELTY"
  ],
  [
    "I like the proposed method in this paper and consider this a significant contribution .",
    "NOVELTY"
  ],
  [
    "To my knowledge the proposed method is novel and the work offers new empirical insights surrounding robust training methods and Lipschitz constraints .",
    "NOVELTY"
  ],
  [
    "This idea is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The method seems original , and I am not aware of other approaches that share all of the characteristics of the one presented here .",
    "NOVELTY"
  ],
  [
    "Overall I would say that the method is presenting a number of incremental improvements over existing methods , that taken together amount to an important contribution to the literature",
    "NOVELTY"
  ],
  [
    "Technical innovation is fairly limited .",
    "NOVELTY"
  ],
  [
    "the paper does not make bold novelty claims and recognizes the contribution as being more empirical than technical",
    "NOVELTY"
  ],
  [
    "The contribution of this work is mostly empirical .",
    "NOVELTY"
  ],
  [
    "Novelty/Impact While the CGPM is a novel generalization of existing models , it does n't translate to any novel results about these kind of models .",
    "NOVELTY"
  ],
  [
    "but I find it lacking in originality",
    "NOVELTY"
  ],
  [
    ", making this an attractive approach . I really like the idea behind not making learning explicit",
    "NOVELTY"
  ],
  [
    "but means that in terms of originality this paper is n't as convincing",
    "NOVELTY"
  ],
  [
    "I do think this is an important and novel theoretical contribution .",
    "NOVELTY"
  ],
  [
    "The idea of maximizing the mutual information is novel for GANs .",
    "NOVELTY"
  ],
  [
    "The extension that is provided by the authors is very simple and intuitive .",
    "NOVELTY"
  ],
  [
    "My main criticism of this paper is its lack of novelty/originality .",
    "NOVELTY"
  ],
  [
    "The combinatorial ( meta- or super-class ) idea is interesting",
    "NOVELTY"
  ],
  [
    "The algorithms and intuitions based on novelty search are interesting and there are improvements over baseline NAS model with the same architecture",
    "NOVELTY"
  ],
  [
    "Several technical novelties are introduced to deal with the sparsity of relevant contexts and the difficulties with discrete latent variables and variably-sized element selection",
    "NOVELTY"
  ],
  [
    "The idea of the paper is a straightforward , intuitively appealing , clear improvement over the standard EFE model",
    "NOVELTY"
  ],
  [
    "The motivation of this paper is rather straightforward and not novel",
    "NOVELTY"
  ],
  [
    "and the approach is quite intuitive .",
    "NOVELTY"
  ],
  [
    "techniques",
    "NOVELTY"
  ],
  [
    "Interesting idea overall .",
    "NOVELTY"
  ],
  [
    "7 .There is nothing particularly unique about this setup for ZSL .",
    "NOVELTY"
  ],
  [
    "is interesting",
    "NOVELTY"
  ],
  [
    "The author 's model was quite novel in my opinion .",
    "NOVELTY"
  ],
  [
    "Weak reject because the idea is quite interesting",
    "NOVELTY"
  ],
  [
    "I like the idea but if we have a good model of the dynamics of the world",
    "NOVELTY"
  ],
  [
    "deep reinforcement learning based on using binary hashcodes . The approach is interesting , the presentation is didactical",
    "NOVELTY"
  ],
  [
    "The proposed method is novel",
    "NOVELTY"
  ],
  [
    "I believe this observation , though not entirely novel",
    "NOVELTY"
  ],
  [
    "key contributions . In particular , I find the basic of idea of introducing a component that represents fear natural , promising and novel .",
    "NOVELTY"
  ],
  [
    "To conclude , the submitted manuscript contains novel observations and results and is likely to draw additional attention to an important aspect of deep reinforcement learning .",
    "NOVELTY"
  ],
  [
    "While the works pointing to these problems are relatively new and might not have been available when the authors started working on this project",
    "NOVELTY"
  ],
  [
    "The idea of the model is pretty similar with Xu et al . [ 2018",
    "NOVELTY"
  ],
  [
    "presents a new idea that achieves excellent results at the level of",
    "NOVELTY"
  ],
  [
    "Show a novel mechanism to exploit spatial relation between superpixel and bounding box in an unsupervised way .",
    "NOVELTY"
  ],
  [
    "Novel video generation method for VSR and UVT .",
    "NOVELTY"
  ],
  [
    "It seems that the observations about modes and normalization outcome is new",
    "NOVELTY"
  ],
  [
    "the main result seems to be very incremental .",
    "NOVELTY"
  ],
  [
    "Overall , the main contribution of this paper is interesting with an intuitive interpolating approach",
    "NOVELTY"
  ],
  [
    "This paper can be situated as a new contribution combining these two strands of research",
    "NOVELTY"
  ],
  [
    "To summarize , the paper presents a very interesting idea .",
    "NOVELTY"
  ],
  [
    "The core idea of using relaxed inequality bounds in the optimization problem is original to the best of my knowledge , and",
    "NOVELTY"
  ],
  [
    "The contextualization of this work to related work -- particularly self-training and semi-supervised training -- is quite thin .",
    "NOVELTY"
  ],
  [
    "I find the core idea behind the paper quite interesting",
    "NOVELTY"
  ],
  [
    "One major issue with the paper is that all the main contribution seem to be in the appendix .",
    "NOVELTY"
  ],
  [
    "the paper introduces an interesting way of integrating two different experts to perform learning from demonstration .",
    "NOVELTY"
  ],
  [
    "The idea to of different subsystems for route planning and path planning are not new",
    "NOVELTY"
  ],
  [
    "but the way it 's done here does seem interesting to me",
    "NOVELTY"
  ],
  [
    "the novelty of the paper may be somewhat marginal .",
    "NOVELTY"
  ],
  [
    "Idea of using adaptive weights for each batch and using different mixture weights for different layers are interesting and novel .",
    "NOVELTY"
  ],
  [
    "I think the fundamental idea in the paper is interesting",
    "NOVELTY"
  ],
  [
    "although a similar ideas have been used for similar problems already",
    "NOVELTY"
  ],
  [
    "In general , the idea of this paper is novel and interesting , which provides a new way for human to understand the neural networks .",
    "NOVELTY"
  ],
  [
    "3 .Although the proposed method provided some new insights about the behavior of the neural networks",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "the method is interesting",
    "NOVELTY"
  ],
  [
    "And the settings considered in the paper are novel and original .",
    "NOVELTY"
  ],
  [
    "The work builds on the SCAL algorithm ,",
    "NOVELTY"
  ],
  [
    "but contains some novel aspects",
    "NOVELTY"
  ],
  [
    "This is a novel use of existing methods .",
    "NOVELTY"
  ],
  [
    "as I am concerned that the method is n't sufficiently novel ( although it is a novel use of existing methods ) .",
    "NOVELTY"
  ],
  [
    "Novel use of adversarial perturbation and temperature - Interesting analysis Cons",
    "NOVELTY"
  ],
  [
    "Does n't introduce and novel methods of its own",
    "NOVELTY"
  ],
  [
    "It is a new and powerful member of the family of VAEs .",
    "NOVELTY"
  ],
  [
    "this algorithm is very similar to W-GAN and there is no autoencoder there --",
    "NOVELTY"
  ],
  [
    "however I found the intuition behind the algorithm and its connection to GMMN and W-GAN interesting",
    "NOVELTY"
  ],
  [
    "The paper contains several interesting ideas and theoretical",
    "NOVELTY"
  ],
  [
    "I find the presented theory interesting",
    "NOVELTY"
  ],
  [
    "with limited technical novelty .",
    "NOVELTY"
  ],
  [
    "are not new",
    "NOVELTY"
  ],
  [
    "this particular combination is novel , and required a nontrivial effort deploy effectively .",
    "NOVELTY"
  ],
  [
    "The paper can be seen as an extension of the previous work [ 8 ] .",
    "NOVELTY"
  ],
  [
    "Although mode connectivity has been studied in the literature , to my knowledge , this is the first work to extensively study this topic in the context of attacks .",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u0094 Overall",
    "NOVELTY"
  ],
  [
    "the proposed formulation is novel and makes sense , and",
    "NOVELTY"
  ],
  [
    "in my opinion , its novelty and new insights are restricted",
    "NOVELTY"
  ],
  [
    "The ideas in the paper are good and novel in the context of tagging .",
    "NOVELTY"
  ],
  [
    "However , I doubt if this is novel enough by itself ,",
    "NOVELTY"
  ],
  [
    "This could be novel",
    "NOVELTY"
  ],
  [
    "Results are novel and relevant and",
    "NOVELTY"
  ],
  [
    "The proposed model is a generic meta-learning useful for both classification and reinforcement learning",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel to my knowledge and overcomes specificity of previous approaches while remaining efficient .",
    "NOVELTY"
  ],
  [
    "Overall , the proposed approach is novel and achieves good results on a range of tasks .",
    "NOVELTY"
  ],
  [
    "The novelty in this work is thin ,",
    "NOVELTY"
  ],
  [
    "I believe this work is novel .",
    "NOVELTY"
  ],
  [
    "I find this paper to be conceptually genius",
    "NOVELTY"
  ],
  [
    "The ideas are quite intriguing .",
    "NOVELTY"
  ],
  [
    "the work is incremental , the issues in the experiments limit potential impact of this paper .",
    "NOVELTY"
  ],
  [
    "There is an interesting new idea here which I think could be important going forward .",
    "NOVELTY"
  ],
  [
    "Despite my concerns about the empirical evaluation , I think the paper is a nice contribution to the conference .",
    "NOVELTY"
  ],
  [
    "Contribution seems minor",
    "NOVELTY"
  ],
  [
    "Originality is somehow limited",
    "NOVELTY"
  ],
  [
    "but the method appears to have a positive effect on neural network training .",
    "NOVELTY"
  ],
  [
    "I feel that the contributions are not significant enough ( in comparison to the prior work of Song et .al ) .Second , I feel that some of the",
    "NOVELTY"
  ],
  [
    "are not",
    "NOVELTY"
  ],
  [
    "The application to obtaining a global convergence result for robust elliptical MRFs seems original .",
    "NOVELTY"
  ],
  [
    "I believe that the paper is not ready to be submitted to a conference or journal .",
    "NOVELTY"
  ],
  [
    "The part on solving the duel bandit model seems novel and important to me",
    "NOVELTY"
  ],
  [
    "the former does not seem to be the main contribution of the paper .",
    "NOVELTY"
  ],
  [
    "Novelty may be a bit limited",
    "NOVELTY"
  ],
  [
    "but it works rather well",
    "NOVELTY"
  ],
  [
    "they also seem quite superficial",
    "NOVELTY"
  ],
  [
    "There just does not seem to be the same level of contribution as I would expect from an ICLR paper",
    "NOVELTY"
  ],
  [
    "+ result seem to be novel and significant as they give important insight about the impossibility of improving SGD types method for the strongly convex case + the analysis appears to be novel as well ,",
    "NOVELTY"
  ],
  [
    "mostly due to my feeling that the empirical contribution is interesting , but not novel enough for this conference",
    "NOVELTY"
  ],
  [
    ", and its originality is well stated by the authors , \u201c addressing the lifetime clustering problem without end-of-life signals for the first time \u201d .",
    "NOVELTY"
  ],
  [
    "I fail to see any novelty in the paper .",
    "NOVELTY"
  ],
  [
    "Therefore , I fail to see any novelty in this paper ( theoretical or empirical ) .",
    "NOVELTY"
  ],
  [
    "The idea of reconstructing images using random projections is not especially new",
    "NOVELTY"
  ],
  [
    "The proposed method is n't bad , and the idea is interesting .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel approach for pruning weights for network sparsification .",
    "NOVELTY"
  ],
  [
    "It presents a way of pruning GAN generator network and although of limited novelty",
    "NOVELTY"
  ],
  [
    "s contribution is very limited",
    "NOVELTY"
  ],
  [
    "The ideas presented in the paper are interesting and original .",
    "NOVELTY"
  ],
  [
    "The current submission does not fit the mold of a traditional NIPS paper .",
    "NOVELTY"
  ],
  [
    "Eq ( 1-6 ) are not novel but text suggests that it is",
    "NOVELTY"
  ],
  [
    "The paper exploits reinforcement learning to address code compilation , which is novel for me .",
    "NOVELTY"
  ],
  [
    "I am totally new in the area .",
    "NOVELTY"
  ],
  [
    "The idea for the algorithm is appealing , and it looks like it could find a",
    "NOVELTY"
  ],
  [
    "This looks like a promising idea",
    "NOVELTY"
  ],
  [
    "The novelty is limited",
    "NOVELTY"
  ],
  [
    "but it is a good idea to speed up the RC models .",
    "NOVELTY"
  ],
  [
    "I like the idea of data augmentation with paraphrasing .",
    "NOVELTY"
  ],
  [
    "I find this work novel and very well presented .",
    "NOVELTY"
  ],
  [
    "From a coding theoretic perspective the novelty is limited ,",
    "NOVELTY"
  ],
  [
    "and relatively novel .",
    "NOVELTY"
  ],
  [
    "The paper derives an interesting deep learning of policies which are novel work and interesting to the reader .",
    "NOVELTY"
  ],
  [
    "Therefore the novelty for this aspect seems a bit weak for me .",
    "NOVELTY"
  ],
  [
    "and the authors did not propose new extension for the K-FAC method , therefore the contribution of this matter is also quite thin .",
    "NOVELTY"
  ],
  [
    "but I do think the novelty of this work is a bit thin and the three contributions were not tied together with the main theme of the paper .",
    "NOVELTY"
  ],
  [
    "the proposed method is an easy extension of existing methodologies .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel idea , is overall clearly written , and presents an interesting contribution .",
    "NOVELTY"
  ],
  [
    "I think the idea of convolving the reward map is interesting",
    "NOVELTY"
  ],
  [
    "First of all , the idea of introducing Riemannian geometry is appealing .",
    "NOVELTY"
  ],
  [
    "This paper presents a novel concept of supervised learning , advocacy learning . In this framework , supervised learning procedure is given by two subnetworks , advocates and judge . Advocates generate evidence in the form of attention for individual classes and judge decide the final class labels . The main idea looks interesting",
    "NOVELTY"
  ],
  [
    "Although the idea looks interesting",
    "NOVELTY"
  ],
  [
    "I think the idea is brilliant .",
    "NOVELTY"
  ],
  [
    "The theoretical analysis in Section 3.2 is insightful .",
    "NOVELTY"
  ],
  [
    "the approach is insightful and intuitive",
    "NOVELTY"
  ],
  [
    "is interesting",
    "NOVELTY"
  ],
  [
    "I also liked the idea of guided adaption to make the program generator generalize beyond the synthetic template programs .",
    "NOVELTY"
  ],
  [
    "the paper introduces method",
    "NOVELTY"
  ],
  [
    "Initiation set classifier : This is an interesting approach .",
    "NOVELTY"
  ],
  [
    "It is an interesting and innovative idea to draw connection between GCN and MF .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is intuitive but I feel that it is highly related to the one in Khrulkov & Oseledets ( 2018 )",
    "NOVELTY"
  ],
  [
    "I would consider the novelty of this paper is not large enough",
    "NOVELTY"
  ],
  [
    "The main contribution therefore seems to be a different architecture for the explanation model Clarity",
    "NOVELTY"
  ],
  [
    "The result in this paper is quite incremental from the one in Vaswani et al 2019 , \u201c Fast and Faster Convergence of SGD for Over-Parameterized Models ( and an Accelerated Perceptron",
    "NOVELTY"
  ],
  [
    "It is unclear to me how the proposed approach is novel compared",
    "NOVELTY"
  ],
  [
    "I think the paper provides a nice idea with",
    "NOVELTY"
  ],
  [
    "The novelty of the method falls a little short for a full-scale conference paper .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel idea : Using a learned state-independent prior as opposed to using a learned state-dependent prior .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "my main concern is with the novelty .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the innovation in terms of the learning algorithm is limited and doesn \u2019 t seem to contribute much to the result .",
    "NOVELTY"
  ],
  [
    "Their idea of making an adaption to GAN architecture by replacing the generator by a classifier to select P from U and using the discriminator to distinguish whether the selected data is from P or U for PU learning is interesting , and benefits from not relying on the class prior estimation .",
    "NOVELTY"
  ],
  [
    "As far as I know , the proposed method is new and improve anomaly detection .",
    "NOVELTY"
  ],
  [
    "The modification of Deep SVDD are in a way minimalistic",
    "NOVELTY"
  ],
  [
    "The idea of learning the graph embedding by applying skip-thought model to random walk sequences is interesting .",
    "NOVELTY"
  ],
  [
    "Ability to equip any cubature method with uncertainty quantification seems useful and novel contribution .",
    "NOVELTY"
  ],
  [
    "the novelty of this work is not highly significant .",
    "NOVELTY"
  ],
  [
    "the model in the paper looks still interesting",
    "NOVELTY"
  ],
  [
    "My comments are as follows",
    "NOVELTY"
  ],
  [
    "The idea of integrating the GNN and FMs is interesting and intuitive .",
    "NOVELTY"
  ],
  [
    "Compared to previous video generation works , DVD-GAN is the first model to present compelling qualitative results on the UCF-101 and Kinetics-600 dataset",
    "NOVELTY"
  ],
  [
    "The main weakness of this paper is that it does not represent a significant advancement in our understanding of video generation using GANs . The novelty of DVD-GAN is also limited with respect to prior video GAN literature .",
    "NOVELTY"
  ],
  [
    "The Dual Video Discriminator by itself does not provide a novel contribution for a conference such as ICLR as it has already been proposed",
    "NOVELTY"
  ],
  [
    "2 ] .",
    "NOVELTY"
  ],
  [
    "Overall , I think this is an interesting idea .",
    "NOVELTY"
  ],
  [
    "does n't seem",
    "NOVELTY"
  ],
  [
    "To some extent , the real technical contributions of this work are partly weakened given the add-on combinations and the existence of similar methods .",
    "NOVELTY"
  ],
  [
    "In overall , I think this is interesting submission , with reasonable novel model",
    "NOVELTY"
  ],
  [
    "The only concern is that the proposed method is rather straightforward , and does not convey much insight to the NIPS society .",
    "NOVELTY"
  ],
  [
    "The paper is fairly original ,",
    "NOVELTY"
  ],
  [
    "This is a nice continuation of the works on embedding to distributions ( as opposed to points ) and also a natural and good application of Wasserstein distances .",
    "NOVELTY"
  ],
  [
    "To my knowledge the method proposed is novel , and seems appropriate for NIPS .",
    "NOVELTY"
  ],
  [
    "The method is kind of limited",
    "NOVELTY"
  ],
  [
    "The proposed system provides a interesting improvement of the MESSL approach",
    "NOVELTY"
  ],
  [
    "The idea sounds interesting",
    "NOVELTY"
  ],
  [
    "While the weak point is that this is an incremental work and a bit lack of innovation .",
    "NOVELTY"
  ],
  [
    "My overall impression is that there is little novelty in the proposed approach .",
    "NOVELTY"
  ],
  [
    "My overall impression is that there is not much novelty in the paper as it is simply a combination of well known techniques .",
    "NOVELTY"
  ],
  [
    "the results seem somewhat incremental .",
    "NOVELTY"
  ],
  [
    "As the contributions detailed above , this paper has good originality , which nicely connects the recent developments of graph neural networks and spectral hypergraph theory .",
    "NOVELTY"
  ],
  [
    "The optimization problem for complete orthogonal dictionary learning in this paper is very different from overcomplete dictionary learning in practice",
    "NOVELTY"
  ],
  [
    "The analysis for the manifold gradient methods is something new ,",
    "NOVELTY"
  ],
  [
    "but not very significant .",
    "NOVELTY"
  ],
  [
    "Originality Regarding the breadth of the analysis , this is highly original .",
    "NOVELTY"
  ],
  [
    "I find the main idea of the paper highly interesting and compelling .",
    "NOVELTY"
  ],
  [
    "it seems that the works build mainly on advances from Lin et al",
    "NOVELTY"
  ],
  [
    "but the authors do a promising job in combining the two",
    "NOVELTY"
  ],
  [
    "Pros -A very interesting approach in constructing an informative latent code for complicated scences using modular components",
    "NOVELTY"
  ],
  [
    "Even though the idea is somehow interesting and",
    "NOVELTY"
  ],
  [
    "this paper is very similar to standard semi-supervised learning approaches for natural images that employ image proposals ( i.e. , EM-based methods ) .",
    "NOVELTY"
  ],
  [
    "Overall the proposed approach is impressive and the intuition behind the paper is novel and easy to understand .",
    "NOVELTY"
  ],
  [
    "A key insight into the underlying structure of the data , enabling an algorithm with orders of magnitude speed up . - A new framing of the problem .",
    "NOVELTY"
  ],
  [
    "On the positive side , the main idea is very interesting and has a lot of potential .",
    "NOVELTY"
  ],
  [
    "the paper looks a bit incremental , given the prior existing work .",
    "NOVELTY"
  ],
  [
    "the ICAPS paper `` Hierarchical Linearly-Solvable Markov Decision Problems `` by Jonson et al .seems to be the first proposing a hierarchical embedding of LMDPs",
    "NOVELTY"
  ],
  [
    "I think that these contributions are of interest",
    "NOVELTY"
  ],
  [
    "The paper",
    "NOVELTY"
  ],
  [
    ", and proposes an interesting idea of representing graphs as multi-channel image-like structures .",
    "NOVELTY"
  ],
  [
    "The discussion of INT8 for Winograd is something that could have been new and interesting",
    "NOVELTY"
  ],
  [
    "-I liked the idea of exploring other avenues for approaching DeepRL problems , and challenging existing paradigms or trends .",
    "NOVELTY"
  ],
  [
    "It 's novel ,",
    "NOVELTY"
  ],
  [
    "although very specific to the proposed approach , and somewhat ad-hoc",
    "NOVELTY"
  ],
  [
    "`` binary shape descriptor `` -- indeed novel , and to me the most interesting component here .",
    "NOVELTY"
  ],
  [
    "`` -- I am not sure what 's novel here",
    "NOVELTY"
  ],
  [
    "I would not consider using Adam to be sufficiently novel for publication in this venue",
    "NOVELTY"
  ],
  [
    "The argument made about the explore-then-commit strategy in multi-armed bandit is very interesting and novel .",
    "NOVELTY"
  ],
  [
    "Originality I believe the Range Batchnorm and a systematic method to quantize models into 8 bit are novel .",
    "NOVELTY"
  ],
  [
    "the idea is novel and interesting",
    "NOVELTY"
  ],
  [
    "=========================================================================== Novelty and significance I really like the idea of doing math reasoning in latent space . The idea is definitely novel and interesting .",
    "NOVELTY"
  ],
  [
    "paper proposes a novel approach to address the issue of mode collapse in the GANs",
    "NOVELTY"
  ],
  [
    "The idea of representing relationships between hidden states using KL divergence between their ( distributions over ) corresponding hidden states is clever .",
    "NOVELTY"
  ],
  [
    "with some intriguing ideas and interesting",
    "NOVELTY"
  ],
  [
    "The proof appears to be non-trivial and novel . The paper",
    "NOVELTY"
  ],
  [
    "The two sets of figures and the two illustrating examples are particularly entertaining and enlightening . Although similar results have been proved in other work under various models , the current paper seems to be the first to prove the conjectured formula in its full generality and is able to identify a gap between information theoretic lower bounds and algorithmic upper bounds",
    "NOVELTY"
  ],
  [
    "The presented idea is nice",
    "NOVELTY"
  ],
  [
    "However , I feel like this work is incremental and does not vastly improve SoA .",
    "NOVELTY"
  ],
  [
    "The proposed normalization technique is original in the sense that the main difference in existing normalization techniques",
    "NOVELTY"
  ],
  [
    "The paper proposes a few important ideas .",
    "NOVELTY"
  ],
  [
    "The proposed approach sufficiently presents technical novelty .",
    "NOVELTY"
  ],
  [
    "Overall , the proposed idea is interesting .",
    "NOVELTY"
  ],
  [
    "from the point of view of the novelty , the paper does not appear an extremely strong contribution ,",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , constructing ambiguity sets beyond confidence bounds and credible regions is new to this work .",
    "NOVELTY"
  ],
  [
    "This paper is original in addressing a",
    "NOVELTY"
  ],
  [
    "1 .There is limited technical novelty as the entire method is mainly based on previous work on neural architecture search .",
    "NOVELTY"
  ],
  [
    "Generative modeling of representations is novel , afaik .",
    "NOVELTY"
  ],
  [
    "technique represents an advancement in the state-of-the-art or not",
    "NOVELTY"
  ],
  [
    "The work is somewhat novel and interesting",
    "NOVELTY"
  ],
  [
    "This is an interesting paper with some interesting insights on",
    "NOVELTY"
  ],
  [
    "Overall , the paper presents several incremental improvement over existing theories .",
    "NOVELTY"
  ],
  [
    "the novelty and the technical contribution are not sufficient for securing an acceptance .",
    "NOVELTY"
  ],
  [
    "This is a nice paper with some novel and significant contributions",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is the first paper that applies IB to train deep networks",
    "NOVELTY"
  ],
  [
    "Combining CNN outputs into a DCRF and back-projecting the errors of the DCRF into the CNNs is an interesting approach , already explored before for semantic image segmentation tasks [ 32 ] .",
    "NOVELTY"
  ],
  [
    "All these previous contributions , especially [ 32 ] , reduce the originality of the current submission .",
    "NOVELTY"
  ],
  [
    ", the definitions of the unary and pairwise potentials are interesting and can inspire the formulation of other types of geometric priors .",
    "NOVELTY"
  ],
  [
    "While the defense technique is certainly novel and inspired",
    "NOVELTY"
  ],
  [
    "Novel defense technique against very challenging white-box attacks .",
    "NOVELTY"
  ],
  [
    "The method is definitely new and previous work that attempted to do verification on rotation attacks is discussed",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", the sensitivity calculations in the SVM context is new as per my knowledge .",
    "NOVELTY"
  ],
  [
    ", it is of limited novelty",
    "NOVELTY"
  ],
  [
    "the theoretical analysis to deep autoencoder with weight tied encoder/decoder shows interesting properties",
    "NOVELTY"
  ],
  [
    "the techniques used are not novel",
    "NOVELTY"
  ],
  [
    "but the results are interesting",
    "NOVELTY"
  ],
  [
    "In conclusion I think that this paper provides a valuable contribution",
    "NOVELTY"
  ],
  [
    "It does not seem that original to me but the authors do combine the condition by Yaida with some more advanced testing statistics in a new way",
    "NOVELTY"
  ],
  [
    "Overall I",
    "NOVELTY"
  ],
  [
    "think the extension is quite natural",
    "NOVELTY"
  ],
  [
    "so the conceptual novelty is not that high .",
    "NOVELTY"
  ],
  [
    "The authors may have missed some relevant recent work",
    "NOVELTY"
  ],
  [
    "but their contributions are complementary",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first time someone has identified the skip connections security problem in ResNets .",
    "NOVELTY"
  ],
  [
    "The SEAL framework proposed on top of the theory is a nice way of learning heuristics by combining both classic node-level features and a recent graph convolutional network approach .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting .",
    "NOVELTY"
  ],
  [
    "I see the main contribution presented in the manuscript to be a very intuitive analysis tool for deep neural networks .",
    "NOVELTY"
  ],
  [
    "Overall , I liked the idea of exploiting the dual relationship between the code summarization and code generation tasks .",
    "NOVELTY"
  ],
  [
    "One thing that wasn\u00e2\u0080\u0099t clear to me was which parts of the dual relationship modeling were novel and which parts were taken from previous works",
    "NOVELTY"
  ],
  [
    "Novelty/originality is rather incremental .",
    "NOVELTY"
  ],
  [
    "The concept of formulating AL as a MDP for optimisation is now a standard idea",
    "NOVELTY"
  ],
  [
    "The idea is new ( to my understanding ) and interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of the method is questionable .",
    "NOVELTY"
  ],
  [
    "As such there isnt a major technical contribution imho in this work . Furthermore , the presented orthogonalization for easier inference has been used before in many works",
    "NOVELTY"
  ],
  [
    "Nevertheless there is value in novel results that may follow from previous works in a straightforward but non-trivial fashion",
    "NOVELTY"
  ],
  [
    "Except for observing the empirical weakness of fully quantized models , the technical contribution of the paper seems to be limited to combining the Lipschitz-based regularization and quantization .",
    "NOVELTY"
  ],
  [
    "The ideas of extension seem to be intuitive and not very novel",
    "NOVELTY"
  ],
  [
    "This seems to make the work a little bit incremental .",
    "NOVELTY"
  ],
  [
    "different from",
    "NOVELTY"
  ],
  [
    "The main concern I have about the paper is its novelty in terms of technical contribution .",
    "NOVELTY"
  ],
  [
    "1 .The contributions of this paper ( summarized above ) are original , useful and",
    "NOVELTY"
  ],
  [
    "2 .The new 'variance-reduced ' calibration approach is an interesting proposal .",
    "NOVELTY"
  ],
  [
    "Combining Bayesian quadrature with variational inference seems like a nice ( if inevitable ) idea",
    "NOVELTY"
  ],
  [
    "Training of optimal decision trees is clearly a problem that has seen a lot of prior work .",
    "NOVELTY"
  ],
  [
    "However , the authors extend this approach to decision trees in a non-trivial manner that adds substantial novelty",
    "NOVELTY"
  ],
  [
    "and this is a novel extension and application of the recently proposed distributed distributional codes Quality : High",
    "NOVELTY"
  ],
  [
    "This is",
    "NOVELTY"
  ],
  [
    "paper",
    "NOVELTY"
  ],
  [
    "contribution of the paper",
    "NOVELTY"
  ],
  [
    "and I guess they are not very important and novel",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting and some interesting experiments are presented .",
    "NOVELTY"
  ],
  [
    "but I found the results quite interesting",
    "NOVELTY"
  ],
  [
    "I evaluate the theoretical contribution to be quite strong",
    "NOVELTY"
  ],
  [
    "and the idea of using a blocked transducer is novel .",
    "NOVELTY"
  ],
  [
    "The mathematical guarantees are also new and may even offer new ways to interpret fine tuning methods that have been so successful in recent literature .",
    "NOVELTY"
  ],
  [
    "Nevertheless I find this method to be original and novel .",
    "NOVELTY"
  ],
  [
    "All in all , this is important , exciting , and novel work .",
    "NOVELTY"
  ],
  [
    "correctness and novelty The ideas of modeling frequency displacement by a transportation matrix and obtaining the optimal displacement by closed-form solution are very interesting .",
    "NOVELTY"
  ],
  [
    "But I am not sure if these ideas have already been proposed in preceding studies or not",
    "NOVELTY"
  ],
  [
    "On the positive side , the propose technique is simple , novel and clear ; presented with neat arguments , and derived in a theoretically sound way . I really enjoyed reading the paper even if I am familiar with the problem being",
    "NOVELTY"
  ],
  [
    "neither the idea /insights it brought can be applied onto other generative models",
    "NOVELTY"
  ],
  [
    "and provides some nice algorithms for the community",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is limited .",
    "NOVELTY"
  ],
  [
    "the novelty of the main theorems given the literature",
    "NOVELTY"
  ],
  [
    "Theorem 3.3 ( and Theorem 3.2 ) seems to be the most interesting/innovative one .",
    "NOVELTY"
  ],
  [
    "but not crucial enough to stand out as an innovation",
    "NOVELTY"
  ],
  [
    "The idea of performing PCA on the output of a NN for purposes of visualization is an interesting one",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "Overall the author 's idea of generating a rotation operator using the embedded input and the transformed hidden state at the previous step is clever .",
    "NOVELTY"
  ],
  [
    "I think this is a nice contribution",
    "NOVELTY"
  ],
  [
    "I found this paper interesting",
    "NOVELTY"
  ],
  [
    "Overall I like the direction the paper is taking .",
    "NOVELTY"
  ],
  [
    "The idea of modeling multi-objective as a logical language is novel .",
    "NOVELTY"
  ],
  [
    "The idea of modelling the interactions as the hyper edges of a hyper graph is",
    "NOVELTY"
  ],
  [
    "interesting but the proposed model seems to be technically equivalent to the original Finite Mixture Model",
    "NOVELTY"
  ],
  [
    "intuitive",
    "NOVELTY"
  ],
  [
    "but limited in evaluation and novelty",
    "NOVELTY"
  ],
  [
    "Our proposed approach represents the first physics-based simulation of its kind that supports MARL .",
    "NOVELTY"
  ],
  [
    "To the extent of my knowledge , the content is original .",
    "NOVELTY"
  ],
  [
    "the proposed AHash in this work is interesting and",
    "NOVELTY"
  ],
  [
    "I agree with the paper and also think that this is the first time that unrolled inference has been applied to ADMM",
    "NOVELTY"
  ],
  [
    "The metric is a new take on what creates good generalization bounds .",
    "NOVELTY"
  ],
  [
    "the paper introduces a potentially important idea , it is largely similar to the ideas in the paper on pairwise inner product similarity .",
    "NOVELTY"
  ],
  [
    "The techniques proposed in the paper is novel in general .",
    "NOVELTY"
  ],
  [
    "The dynamical systems view of the learning process is quite new to me ,",
    "NOVELTY"
  ],
  [
    "m aware of a few recent papers exploring this",
    "NOVELTY"
  ],
  [
    "and the dynamical systems perspective interesting",
    "NOVELTY"
  ],
  [
    "Overall I found this paper presented some interesting ideas",
    "NOVELTY"
  ],
  [
    "One major concern is that the proposed continuous relaxation training trick is previously studied and used in applications like hashing and this may not be treated as an inspiring technical contribution .",
    "NOVELTY"
  ],
  [
    "The idea is very interesting however",
    "NOVELTY"
  ],
  [
    "These ideas are probably new in Machine learning .",
    "NOVELTY"
  ],
  [
    "there are original contributions which could be worth a publication",
    "NOVELTY"
  ],
  [
    "This paper has a novel contribution , outperforms the baseline ( CCNF : CNF ( Chen et al . )",
    "NOVELTY"
  ],
  [
    "The multi-level attention is novel and indeed seems to work",
    "NOVELTY"
  ],
  [
    "Nice engineering achievement",
    "NOVELTY"
  ],
  [
    "but the results might be to incremental for NIPS .",
    "NOVELTY"
  ],
  [
    "the contribution is still very novel .",
    "NOVELTY"
  ],
  [
    "the theoretical contribution is to my opinion huge .",
    "NOVELTY"
  ],
  [
    "The novelty is low - No competitive baseline in experiments",
    "NOVELTY"
  ],
  [
    "It 's an interesting modification the the original algorithm .",
    "NOVELTY"
  ],
  [
    "though none of the pieces are particularly novel .",
    "NOVELTY"
  ],
  [
    "The neural architecture seems",
    "NOVELTY"
  ],
  [
    "sufficiently novel",
    "NOVELTY"
  ],
  [
    "and shows an interesting application of the Siamese architecture .",
    "NOVELTY"
  ],
  [
    "Also the novelty of the proposed idea is limited as Siamese networks are used for many years and this work only shows that they can be applied to a different task",
    "NOVELTY"
  ],
  [
    "In this sense , the paper does not propose any novel approaches . The theoretical results of the 1BITMC approach , which seem to be the main contributions of this paper , are mostly adapted from those of Davenport et al .2014 .Quality",
    "NOVELTY"
  ],
  [
    "Overall , I found this paper interesting and refreshing .",
    "NOVELTY"
  ],
  [
    "The theoretical contributions are perhaps not groundbreaking",
    "NOVELTY"
  ],
  [
    "but",
    "NOVELTY"
  ],
  [
    "the system-level optimization is a major contribution",
    "NOVELTY"
  ],
  [
    "Some might say the approach ( ensemble ) may not be novel enough .",
    "NOVELTY"
  ],
  [
    "I find this idea interesting and certainly worth publishing .",
    "NOVELTY"
  ],
  [
    "the paper has novel and interesting ideas",
    "NOVELTY"
  ],
  [
    "and novel theoretical techniques .",
    "NOVELTY"
  ],
  [
    "The approach is interesting and sounds novel to me",
    "NOVELTY"
  ],
  [
    "The work seems original to me .",
    "NOVELTY"
  ],
  [
    "I 'm a bit concerned about the technical novelty , however",
    "NOVELTY"
  ],
  [
    "the methods work well but the improvement over previous state-of-the-art is rather small in general .",
    "NOVELTY"
  ],
  [
    "it is a combination of familiar techniques . The BTL on the scores of the groups is already existing , the factorization method based on minimizing the nuclear norm is not new .",
    "NOVELTY"
  ],
  [
    "but does not represent a major breakthrough",
    "NOVELTY"
  ],
  [
    "it is hard to understand the contribution in this paper",
    "NOVELTY"
  ],
  [
    "The idea of training a Generative Adversarial Network combined with a Volumetric Network to generate 3D shape is definitely novel .",
    "NOVELTY"
  ],
  [
    "However , it gives me the impression that the method proposed is a combination of existing methods but applied to a novel problem setup , so the novelty is limited .",
    "NOVELTY"
  ],
  [
    ".The methodology and insights appear novel and well motivated",
    "NOVELTY"
  ],
  [
    "The proposed deep feature embedding framework is interesting and novel .",
    "NOVELTY"
  ],
  [
    "Although learning local distances to better capture the variation of feature space is not new in metric learning",
    "NOVELTY"
  ],
  [
    ", applying this idea to deep feature embedding in this way seems to be novel .",
    "NOVELTY"
  ],
  [
    "I think this work is interesting and novel",
    "NOVELTY"
  ],
  [
    "Nothing innovative .",
    "NOVELTY"
  ],
  [
    "The idea in the paper is good",
    "NOVELTY"
  ],
  [
    "this is a strong paper that has gotten a relatively old and appealing idea to work much better than in the past",
    "NOVELTY"
  ],
  [
    "I think the ideas explored in this paper are reasonably interesting",
    "NOVELTY"
  ],
  [
    "1 .The idea for this",
    "NOVELTY"
  ],
  [
    "1 .I \u2019 m not convinced about the magnitude of novelty in this paper .",
    "NOVELTY"
  ],
  [
    "It seems to me that the only novelty of this paper comes from the filtering techniques for false negative rewards , which I do not think is enough for this venue",
    "NOVELTY"
  ],
  [
    "Based on the paper , I 'm not quite sure whether the idea of training with L1 regularization and/or small weight pruning and/or ReLU pruning for the purpose of improving robustness / verifiability was an original idea of this paper .",
    "NOVELTY"
  ],
  [
    "Use of graph neural nets for few-shot learning is novel . - Introduces novel semi-supervised and active learning variants of few-shot classification .",
    "NOVELTY"
  ],
  [
    "Improvement in accuracy is small relative to previous work .",
    "NOVELTY"
  ],
  [
    "The originality of applying graph neural networks to the problem of few-shot learning and proposing semi-supervised and active learning variants of the task are the primary strengths of this paper .",
    "NOVELTY"
  ],
  [
    "Though novel",
    "NOVELTY"
  ],
  [
    ", the paper is novel and interesting",
    "NOVELTY"
  ],
  [
    "Although the novelty of the proposed methodology is somehow limited",
    "NOVELTY"
  ],
  [
    "The work is original in its modelling of meta architecture search .",
    "NOVELTY"
  ],
  [
    "handwritten character recognition , by itself , is not a new field , and the authors did not contribute sufficiently to the underlying theory or mechanics .",
    "NOVELTY"
  ],
  [
    "I think this work is original and interesting .",
    "NOVELTY"
  ],
  [
    "The approach seems original",
    "NOVELTY"
  ],
  [
    "impressive paper on rapid meta-learning",
    "NOVELTY"
  ],
  [
    ", to the best of my knowledge , the first one to emphasize the following two very important perspectives in robot learning",
    "NOVELTY"
  ],
  [
    "Overall I do think this is an interesting paper , with a novel approach to pure exploration in tabular MDPs under specific assumptions .",
    "NOVELTY"
  ],
  [
    "this approach was not ground-breaking",
    "NOVELTY"
  ],
  [
    "over-claimed",
    "NOVELTY"
  ],
  [
    "The ideas of this paper are quite neat \u00e2\u0080\u0094 I enjoyed it very much .",
    "NOVELTY"
  ],
  [
    "The combination of ideas and new approaches to coding are very cool .",
    "NOVELTY"
  ],
  [
    "Overall , I think that this paper has some interesting ideas and",
    "NOVELTY"
  ],
  [
    "the novelty and impact of the model is somewhat lacking .",
    "NOVELTY"
  ],
  [
    "I can not tell precisely the originality and significance",
    "NOVELTY"
  ],
  [
    "While going from real-valued embeddings to complex-valued embeddings was novel and addressed some of the issues with simple approaches based on real-valued embeddings",
    "NOVELTY"
  ],
  [
    "going beyond complex-valued embeddings may not be super novel",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "The model architecture is interesting , combining the benefits of a character-level model ( open vocabulary ) with those of a lexical model ( effective for frequent character sequences",
    "NOVELTY"
  ],
  [
    "I found Figure 3 to be very interesting .",
    "NOVELTY"
  ],
  [
    "This paper does a good job of articulating an interesting approach to the exploration problem using successor representations .",
    "NOVELTY"
  ],
  [
    "I found some novel works being done in the field that must be addressed and listed in the background and experiments",
    "NOVELTY"
  ],
  [
    "I think this paper 's contribution is sufficiently significant for NeurIPS publication .",
    "NOVELTY"
  ],
  [
    "To conclude , this paper is an incremental work with limited contributions .",
    "NOVELTY"
  ],
  [
    "The improvements relative to standard Sparse Coding seem very small",
    "NOVELTY"
  ],
  [
    "The advantage of VAEs over GANs is that we have natural ways of computing log-probabilities .",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "The authors provides a novel and interesting look into the problem of pure exploration in the multiple-answers setting .",
    "NOVELTY"
  ],
  [
    "the idea of the paper is simply combining a recent progress on the neural tangent kernel for overparametrized neural networks and a standard linear UCB algorithm",
    "NOVELTY"
  ],
  [
    "I liked the use of sparsity- and group-sparsity-promoting regularizers",
    "NOVELTY"
  ],
  [
    "network . A strength of the paper is that the proposed algorithm is interesting and intuitive , even if relatively",
    "NOVELTY"
  ],
  [
    "sub-algorithms",
    "NOVELTY"
  ],
  [
    "The cell naturally acts over sets of neighbors and transformers are a natural model to tackle this problem",
    "NOVELTY"
  ],
  [
    "The overall novelty of this approach is somewhat lacking in that previous methods have proposed training a classifier head on the discriminator and the discriminability metric proposed is simply the inception score of",
    "NOVELTY"
  ],
  [
    "Sections 3 and 4 are a nice and important contribution .",
    "NOVELTY"
  ],
  [
    "Review I find this paper to be novel and insightful",
    "NOVELTY"
  ],
  [
    "I found the ideas of the paper interesting enough to largely out-weigh the importance of a careful meta-parameter study",
    "NOVELTY"
  ],
  [
    "The technical approach proposed in this paper is straightforward and limited .",
    "NOVELTY"
  ],
  [
    "contribution in this paper is the use of flow-based models for video prediction , and it is the first work in this direction . The major",
    "NOVELTY"
  ],
  [
    "Theorems 2.4-2.6 are novel and introduces mathematical techniques are interesting .",
    "NOVELTY"
  ],
  [
    "This is interesting , and different from previous methods , which use either an explicit vector of factors that is input to a generator function , or object slots that are blended to form an image .",
    "NOVELTY"
  ],
  [
    "4 .The publicly-released codes could make great contributions",
    "NOVELTY"
  ],
  [
    "Cons 1 .It proposes an incremental change to the original Transformer by introducing recursive connection between multihead self-attention blocks with ACT .",
    "NOVELTY"
  ],
  [
    "the theoretical novelty w.r.t . ( Zou & Lerman , 2018 ) and ( Game , 2018 ) is partial and rather technical , so the originality of the present manuscript is limited b ) the improvement w.r.t .to other published method is rather small , so the performance gain is only partially justified by the quite complex theoretical construction .",
    "NOVELTY"
  ],
  [
    "and I like the overall theme of the paper",
    "NOVELTY"
  ],
  [
    "The use of RTS for benchmarking AI is not new",
    "NOVELTY"
  ],
  [
    "It lacks the simplicity and elegance of Go , while not being particularly useful for practical",
    "NOVELTY"
  ],
  [
    "I still think RTS for AI is not a new proposal",
    "NOVELTY"
  ],
  [
    "The idea of combining RVM and SVM is interesting",
    "NOVELTY"
  ],
  [
    "however , the novelty is quite limited",
    "NOVELTY"
  ],
  [
    "and provides novel theoretical results",
    "NOVELTY"
  ],
  [
    "but not a major research contribution",
    "NOVELTY"
  ],
  [
    "The idea of regularizing by the entropy is not novel",
    "NOVELTY"
  ],
  [
    "The authors present an intuitive method ( yet not novel ) for quantizing the weights of a neural network",
    "NOVELTY"
  ],
  [
    "very in touch with modern ML ideas",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel method for learning unsupervised representation for molecules .",
    "NOVELTY"
  ],
  [
    "I think the proposed method is still novel .",
    "NOVELTY"
  ],
  [
    "then an incremental work with limited innovation",
    "NOVELTY"
  ],
  [
    "builds upon the previous hashing-based approach by Charikar et al. , though the modification is trivial",
    "NOVELTY"
  ],
  [
    "space improvement over the previous approach is novel",
    "NOVELTY"
  ],
  [
    "the method is novel . The idea of sampling based on upper layers is itself interesting .",
    "NOVELTY"
  ],
  [
    "My problem with that paper is that even though at first glance learning adaptive feature maps seems to be an attractive approach , authors ' contribution is actually very little .",
    "NOVELTY"
  ],
  [
    "certainly not a novelty of that paper",
    "NOVELTY"
  ],
  [
    "but in my opinion without a substantial contribution and working only in a very limited setting when it is heavily relying on many unproven hacks and heuristics",
    "NOVELTY"
  ],
  [
    "The paper is original in that I have not seen a similar treatment",
    "NOVELTY"
  ],
  [
    "In my viewpoint , the novelty of this paper is somewhat novel .",
    "NOVELTY"
  ],
  [
    "In my view , the originality and significance is limited .",
    "NOVELTY"
  ],
  [
    "The novelty of the contribution is limited",
    "NOVELTY"
  ],
  [
    "I have trouble assessing the originality and significance of this work",
    "NOVELTY"
  ],
  [
    "This paper presents a novel way of pruning filters from convolutional neural networks with a strong theoretical justification .",
    "NOVELTY"
  ],
  [
    "So this alone does not seem very novel result .",
    "NOVELTY"
  ],
  [
    "The two methodological contributions appear to be original .",
    "NOVELTY"
  ],
  [
    "but only incrementally",
    "NOVELTY"
  ],
  [
    "In terms of originality , this seems to be a clear continuation from early work on SKI and SKIP .",
    "NOVELTY"
  ],
  [
    "this paper has fleshed out those previous ideas fully and produced an excellent architecture .",
    "NOVELTY"
  ],
  [
    "Compared to W_zca C , WC seems to be an incremental contribution .",
    "NOVELTY"
  ],
  [
    "The DESC oracle is novel and has a nice property .",
    "NOVELTY"
  ],
  [
    "While the attack itself is not novel ( which will require a major revision of the manuscript )",
    "NOVELTY"
  ],
  [
    "The concept of adversarial distributions is not new but is common in the literature of real-world adversarials that are robust to transformations and perturbations",
    "NOVELTY"
  ],
  [
    "While I like the idea of accuracy-iterations plots",
    "NOVELTY"
  ],
  [
    "the idea is not new",
    "NOVELTY"
  ],
  [
    "I like the ideas in this paper , and agree that empirically they",
    "NOVELTY"
  ],
  [
    "However , the ideas are not entirely novel , and the solution is somewhat limited in scope",
    "NOVELTY"
  ],
  [
    "To the best of my understanding , it also increases test time",
    "NOVELTY"
  ],
  [
    "Yet to the best of my knowledge the work presented is original",
    "NOVELTY"
  ],
  [
    "the paper lacks a sound and novel contribution .",
    "NOVELTY"
  ],
  [
    "However it has limited significance due to the lack of novel contributions .",
    "NOVELTY"
  ],
  [
    "The idea of using mutual information as some kind of regularization is also interesting .",
    "NOVELTY"
  ],
  [
    "the two first problems described",
    "NOVELTY"
  ],
  [
    "are original , interesting contributions to the field , of particular interest for people interested in applying information bottleneck concepts to supervised learning",
    "NOVELTY"
  ],
  [
    "the solution brought to the IB Lagrangian issues is simplistic though efficient",
    "NOVELTY"
  ],
  [
    "Given the limited technical novelty",
    "NOVELTY"
  ],
  [
    "It is very novel to use the Sharpley value and give its associated theoretical properties .",
    "NOVELTY"
  ],
  [
    "the idea in this work is interesting",
    "NOVELTY"
  ],
  [
    "In this sense , the work is fairly novel .",
    "NOVELTY"
  ],
  [
    "it seems that the proposed model is not significantly better than the previous models",
    "NOVELTY"
  ],
  [
    "the MCMC based method appears to mainly be a direct use of a mostly off-the-shelf idea ,",
    "NOVELTY"
  ],
  [
    "but the derivations of the Gibbs updates for the sufficient statistics based model are novel",
    "NOVELTY"
  ],
  [
    "I am not an expert in the field of multi-agent RL but got the feeling that the presented results are novel and extend current knowledge in an interesting and valuable way .",
    "NOVELTY"
  ],
  [
    "The idea to pool over the loss of future prediction is , to the best knowledge of the reviewer , quite original and appears highly relevant .",
    "NOVELTY"
  ],
  [
    "and presents a simple , but interesting twist on time series prediction .",
    "NOVELTY"
  ],
  [
    "Certainly , the idea of optimizing plans or trajectories using gradient methods is not new",
    "NOVELTY"
  ],
  [
    "because it seems like a good idea",
    "NOVELTY"
  ],
  [
    "I 'm not exactly sure how novel it is .",
    "NOVELTY"
  ],
  [
    "Interesting model",
    "NOVELTY"
  ],
  [
    "Overall , the proposed contribution is relatively incremental compared to ( Shi et al .2015 ) and ( Defferrad et al. , 2016 ) .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the idea to parametrise elements of a MSM using RNNs is original",
    "NOVELTY"
  ],
  [
    "This idea to me seems like a nice application of methods from deep learning towards more traditional statistical sciences , which may also help to publicise models such as MSMs to the NIPS community .",
    "NOVELTY"
  ],
  [
    "I feel that the paper does not provide significantly new results on these dimensions .",
    "NOVELTY"
  ],
  [
    "I still think the contribution is incremental so I maintain my score",
    "NOVELTY"
  ],
  [
    "However , I feel the contribution is limited as it only corrects the sub-optimal estimators in previous work .",
    "NOVELTY"
  ],
  [
    "The paper builds on DDPG and explores a novel modification to the architecture .",
    "NOVELTY"
  ],
  [
    "The proposed P-DQN architecture is interesting",
    "NOVELTY"
  ],
  [
    "The modification to DDPG is genuinely interesting and does result in an algorithm that is a hybrid between",
    "NOVELTY"
  ],
  [
    "and in that regard , I consider the first steps taken by this paper to be original .",
    "NOVELTY"
  ],
  [
    "The interpolation in the feature space is not a new idea and has been explored in Manifold Mixup [ 1 ] .",
    "NOVELTY"
  ],
  [
    "general , the paper presents an interesting idea",
    "NOVELTY"
  ],
  [
    "The method is relatively original and the coupled transition functions are quite interesting and are novel compared to existing work",
    "NOVELTY"
  ],
  [
    "The idea of applying RL on active learning with GCN seems to be new and it sounds natural and technically .",
    "NOVELTY"
  ],
  [
    "but its contributions are not quite as substantial",
    "NOVELTY"
  ],
  [
    "or surprising as those in stronger ICLR papers .",
    "NOVELTY"
  ],
  [
    "but the novelty is limited .",
    "NOVELTY"
  ],
  [
    "this prior work studies many of the aspects that are hinted as novel in this submission .",
    "NOVELTY"
  ],
  [
    "On a negative note , the novelty of the technical contributions is modest and",
    "NOVELTY"
  ],
  [
    "From a technical perspective , I do not find the proposed approach very novel .",
    "NOVELTY"
  ],
  [
    "it lacks domain insights",
    "NOVELTY"
  ],
  [
    "most aspects of this paper are a little dated 2 ) novelty is little 3",
    "NOVELTY"
  ],
  [
    "The idea of incorporating the relational information and subject special parameter ( MAML ) parts are very interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the idea in this paper is interesting and",
    "NOVELTY"
  ],
  [
    "and it helps generalize existing algorithms for Online Linear Optimization ( OCO ) or Learning with Expert Advice ( LEA ) through a novel reduction to a coin betting problem .",
    "NOVELTY"
  ],
  [
    "the generality that this approach provides and the simplicity of the resulting algorithms makes it quite attractive .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is the novel approach to selecting knowledge for open-domain dialogue .",
    "NOVELTY"
  ],
  [
    "I like the general idea of paper , and the simple technique to add noises in the first fully connected layer to get multiple outputs for the same input data point .",
    "NOVELTY"
  ],
  [
    "This paper clearly advances the body of work on neural intuitive physics by incorporating NEM entity representation to allow for less supervision .",
    "NOVELTY"
  ],
  [
    "These are moderately novel contributions and there are only minor weaknesses",
    "NOVELTY"
  ],
  [
    "this paper is too close in concept",
    "NOVELTY"
  ],
  [
    "However , I find that the proposed solution is an application of existing techniques , so it lacks on novelty and originality .",
    "NOVELTY"
  ],
  [
    "I think that this one in particular does not have enough novelty/substance to get accepted at such a competitive venue",
    "NOVELTY"
  ],
  [
    "so there is no original contribution here either (",
    "NOVELTY"
  ],
  [
    "which I think novel",
    "NOVELTY"
  ],
  [
    "The paper provides an interesting data collection scheme that improves upon standard collection of static databases that",
    "NOVELTY"
  ],
  [
    "The numerical experiments comparing with C-PSGD is very interesting and promising .",
    "NOVELTY"
  ],
  [
    "and interesting way to measure the margin in the context of deep networks that removes the exponential dependency of depth in the corresponding generalization bounds",
    "NOVELTY"
  ],
  [
    "I really like the fresh idea of simultaneous perturbations based analysis .",
    "NOVELTY"
  ],
  [
    "The paper lacks novelty and have very weak experiments .",
    "NOVELTY"
  ],
  [
    "The approach is novel since L2L provides a new perspective to zeroth-order optimization .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "The paper is also original since",
    "NOVELTY"
  ],
  [
    "it is quite different from previous Bayesian approach by explicitly parametrize the distribution by DNN",
    "NOVELTY"
  ],
  [
    "Trying to compute automatically keypoints without annotating them is a great idea and to the reviewer knowledge the first time to be presented .",
    "NOVELTY"
  ],
  [
    "My concerns are that the contributions of this paper seems rather incremental when compared to previous work .",
    "NOVELTY"
  ],
  [
    "My main hesitation for accepting this paper is that the method presented is not sufficiently different from previous work on preference-based RL",
    "NOVELTY"
  ],
  [
    "as Inference framework with a didactic example which , to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "RL as inference has inspired many interesting and novel techniques",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper makes a nice contribution .",
    "NOVELTY"
  ],
  [
    "The idea looks interesting and novel",
    "NOVELTY"
  ],
  [
    "Impression The problem formulation is very interesting",
    "NOVELTY"
  ],
  [
    "The concept of learning to explain is relatively new and unexplored .",
    "NOVELTY"
  ],
  [
    "However",
    "NOVELTY"
  ],
  [
    ", as far as I know , the proposed methodology is novel .",
    "NOVELTY"
  ],
  [
    "The uncertainty estimation idea seems disjoint from the main contribution",
    "NOVELTY"
  ],
  [
    "This is fairly similar to recent work on deep RS , though the network formulation has some differences",
    "NOVELTY"
  ],
  [
    "I really like the way dual decomposition applies",
    "NOVELTY"
  ],
  [
    "this extension is n't as novel",
    "NOVELTY"
  ],
  [
    "paper proposes a very interesting idea of loss function optimization",
    "NOVELTY"
  ],
  [
    "I like the idea .",
    "NOVELTY"
  ],
  [
    "The technical contributions are a clever and simple extension/combination of existing ideas such as \u00e2\u0080\u009cNeural Reasoner\u00e2\u0080\u009d",
    "NOVELTY"
  ],
  [
    "This novelty adds strength to this paper .",
    "NOVELTY"
  ],
  [
    "I think the two contributions stated in lines 43-46 are limited",
    "NOVELTY"
  ],
  [
    "2 .The use of object proposals is not novel as done already : [ 23",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "The paper presents a fresh-perspective on the problem of improving generalization and robustness to",
    "NOVELTY"
  ],
  [
    "A lot of this paper rehashes discussion from the prior work and does not seem sufficiently original .",
    "NOVELTY"
  ],
  [
    "The originality of the work is a bit limited , as it is a fairly straightforward ( but novel as far as I know ) combination of two recent papers",
    "NOVELTY"
  ],
  [
    "Overall , the proposed method is novel",
    "NOVELTY"
  ],
  [
    "tying the idea to the dynamical systems perspective is elegant",
    "NOVELTY"
  ],
  [
    "as authors stated the idea of using clipping is not a new .",
    "NOVELTY"
  ],
  [
    "Overall , I think that it is a good paper and has a significant contribution to the machine learning community .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but incremental that the method is almost similar to the 'RotDCF : Decomposition of convolutional filters for rotation-equivariant deep network ' .",
    "NOVELTY"
  ],
  [
    ", and the result is novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "the only improvements of the proposed algorithm over prior art is the empirical performance",
    "NOVELTY"
  ],
  [
    "the novelty of the approach is questionable , not only in light of recent papers but older literature",
    "NOVELTY"
  ],
  [
    "In general , the proposed model has novelty .",
    "NOVELTY"
  ],
  [
    "the direction of looking at bias attribution is novel .",
    "NOVELTY"
  ],
  [
    "This is an interesting contribution",
    "NOVELTY"
  ],
  [
    "but it seems to me that the results are too similar to the ones in Choromanska et al .and thus the novelty is seriously limited .",
    "NOVELTY"
  ],
  [
    "The idea of treating hyperedges as vertexes of another graph is novel",
    "NOVELTY"
  ],
  [
    "The novelty is restricted .",
    "NOVELTY"
  ],
  [
    "From the methodology perspective , I think this is a solid incremental contribution .",
    "NOVELTY"
  ],
  [
    "And it provides a novel way to do model compression for deep learning via Bayesian methods .",
    "NOVELTY"
  ],
  [
    "I find the approach original , and potentially interesting to the NIPS community .",
    "NOVELTY"
  ],
  [
    "The consequences of deviating from the demonstrated states in imitation learning have been recognized earlier",
    "NOVELTY"
  ],
  [
    "but this paper proposes a novel approach to this problem .",
    "NOVELTY"
  ],
  [
    "The main contributions of the paper can be seen as an incremental version of ( Franceschi et al , 2017 ) based on the proposal in ( Luketina et al. , 2016 ) . As such the impact of the contributions appears rather limited even though the experimental results show a better stability of the method compared to competitors .",
    "NOVELTY"
  ],
  [
    "Although the framework is new",
    "NOVELTY"
  ],
  [
    "and lacks of fair benchmarks",
    "NOVELTY"
  ],
  [
    "this paper has many interesting ideas",
    "NOVELTY"
  ],
  [
    "and describes some interesting ideas",
    "NOVELTY"
  ],
  [
    "of experimental evaluation",
    "NOVELTY"
  ],
  [
    "The main drawback is that perhaps the more novel part of this paper seems of limited use for now",
    "NOVELTY"
  ],
  [
    "The proposed set of models are novel in terms of both the generative models and inference techniques .",
    "NOVELTY"
  ],
  [
    "The major contributions are clear and significantly advance the state of research .",
    "NOVELTY"
  ],
  [
    "However , given existing results , the main theoretical contributions of this paper are about solving the problem ( 3 ) , which could be limited .",
    "NOVELTY"
  ],
  [
    "This paper proposed the first Frank-Wolf type method with theoretical guarantee for solving the considered constrained optimization problem in the stochastic setting",
    "NOVELTY"
  ],
  [
    "So I think the originality is ok",
    "NOVELTY"
  ],
  [
    "It presents a very nice proof of a prediction from statistical physics about the mutual information for symmetric rank-one matrix estimation .",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed method is limited and improvements are not surprising .",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "Overall , this paper \u2019 s contribution seems quite outdated and",
    "NOVELTY"
  ],
  [
    "Other Promoting diversity in ( deep ) generative models is n't a new topic .",
    "NOVELTY"
  ],
  [
    "-Using orthogonal encodings to decorrelate gradients is an interesting idea -Benchmark results appear promising compared to prior works Cons",
    "NOVELTY"
  ],
  [
    ", the application to this domain and empirical validation of the approach seem to be novel contributions",
    "NOVELTY"
  ],
  [
    "However , I agree that this particular version with NN-function approximators / amortized inference is novel and a worthwhile contribution .",
    "NOVELTY"
  ],
  [
    "the paper\u00e2\u0080\u0099s novelty is that it does not use all base classes equally to generate new data for a novel class but attempts to use only base classes whose semantics and statistics match the novel class",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    "and this paper provides a nice way of doing it",
    "NOVELTY"
  ],
  [
    "I think the regularisation techniques proposed to preserve the ordering of the discretised class label are quite clever",
    "NOVELTY"
  ],
  [
    "but the contribution itself is somehow limited (",
    "NOVELTY"
  ],
  [
    "As far as I know , the paper introduces an overall novel and interesting idea to generate point clouds with localized operations .",
    "NOVELTY"
  ],
  [
    "The method ( pipelining + smoothing ) is derivative .",
    "NOVELTY"
  ],
  [
    "I am not certain if the proof techniques are original or not . Overall , I would consider the paper to have low-to-medium originality .",
    "NOVELTY"
  ],
  [
    "But it is not a *new* contribution .",
    "NOVELTY"
  ],
  [
    "Although the idea is interesting",
    "NOVELTY"
  ],
  [
    "The formulation of the CDRE Eq",
    "NOVELTY"
  ],
  [
    "is quite intuitive",
    "NOVELTY"
  ],
  [
    "The density-ratio estimation algorithm for continual learning is new and interesting .",
    "NOVELTY"
  ],
  [
    "I am pretty new to the continual learning .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- -- -- -The paper is very original , the techniques used are new and relevant for optimization .",
    "NOVELTY"
  ],
  [
    "Though the current work is limited to the strongly convex case , the approach is sufficiently original to appeal",
    "NOVELTY"
  ],
  [
    "generalizations from the community",
    "NOVELTY"
  ],
  [
    "This is an interesting direction of work that does not simply attempt to reproduce previous results but explores a new procedure to get step-sizes of accelerated methods .",
    "NOVELTY"
  ],
  [
    "This paper would not be accepted for a journal obviously but its originality is what a conference like Neurips is seeking in my opinion",
    "NOVELTY"
  ],
  [
    "This is clearly a novel solution to an interesting but",
    "NOVELTY"
  ],
  [
    "so far , poorly explored",
    "NOVELTY"
  ],
  [
    "problem .",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting approach to the inductive learning problem , with a number of interesting ideas",
    "NOVELTY"
  ],
  [
    "I think that this paper ( if indeed novel ) is interesting",
    "NOVELTY"
  ],
  [
    "It is first novel attempt to maximize deep submodular funcions under matroid constraints .",
    "NOVELTY"
  ],
  [
    "the method is only moderately novel and the novel aspects are not convincingly shown to be beneficial",
    "NOVELTY"
  ],
  [
    "I find the approach to be interesting",
    "NOVELTY"
  ],
  [
    "Though the originality is limited",
    "NOVELTY"
  ],
  [
    "the whole construction of the model looks well",
    "NOVELTY"
  ],
  [
    "-metrics for monitoring the GAN performance is novel and very practical",
    "NOVELTY"
  ],
  [
    "and I found it quite interesting",
    "NOVELTY"
  ],
  [
    "This is a significant contribution and almost all of the technical body of the paper are proofs that lead to the theorem 2.3 which is using the above assumptions",
    "NOVELTY"
  ],
  [
    "this paper does not present anything that is particular novel on top of the SSNT .",
    "NOVELTY"
  ],
  [
    "The decoding algorithm presented in the appendix is relatively new .",
    "NOVELTY"
  ],
  [
    "with some",
    "NOVELTY"
  ],
  [
    "The authors introduce a new direction for supervised learning , which is a natural generalization of ERM and the work of",
    "NOVELTY"
  ],
  [
    "And it 's a quite novel model",
    "NOVELTY"
  ],
  [
    "although there are many places to improve",
    "NOVELTY"
  ],
  [
    "Although methodology wise this paper does n't introduce novel techniques",
    "NOVELTY"
  ],
  [
    "The contribution of the paper is significant",
    "NOVELTY"
  ],
  [
    "This latter contribution is perhaps a little thin",
    "NOVELTY"
  ],
  [
    "However this latter contribution seems handwavy .",
    "NOVELTY"
  ],
  [
    "It appears to be a novel application of meta-learning .",
    "NOVELTY"
  ],
  [
    "Overall it appears to be a novel and interesting contribution .",
    "NOVELTY"
  ],
  [
    "the paper is very novel and tries to solve a very challenging problem .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "The idea of using the multinomial regression as a way of producing features seems powerful in its simplicity",
    "NOVELTY"
  ],
  [
    "the contributions are clear",
    "NOVELTY"
  ],
  [
    "In terms of conceptual or theoretical novelty , the paper is limited",
    "NOVELTY"
  ],
  [
    "but the connection to watermarking seems novel and is nicely executed",
    "NOVELTY"
  ],
  [
    "I find the contributions are interesting",
    "NOVELTY"
  ],
  [
    "but incremental .",
    "NOVELTY"
  ],
  [
    "However , this is not an original contribution .",
    "NOVELTY"
  ],
  [
    "The novel contribution is minor and mainly on related empirical results .",
    "NOVELTY"
  ],
  [
    "Again , this is not a novel contribution but an application of previous definitions",
    "NOVELTY"
  ],
  [
    "There are no novel and well-abstracted theoretical results ( theorems ) given in the submission .",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting , and to the best of my knowledge novel , pipeline for learning a semantic map of the environment with respect to navigability , and simultaneously uses it for further exploring the environment .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of the paper is not significant enough to be accepted to ICLR .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel architecture for training adversarial networks in a semi-supervised settings",
    "NOVELTY"
  ],
  [
    "This work is primarily a synthesis of ideas and techniques explored in other works",
    "NOVELTY"
  ],
  [
    "The proposed spatial attention idea is simple yet promising .",
    "NOVELTY"
  ],
  [
    "orthogonality",
    "NOVELTY"
  ],
  [
    "MC and RIP are exploited from compressive sensing literature , and both of their combinations with CNN regularization seem new to me .",
    "NOVELTY"
  ],
  [
    ", and the authors present a genuinely novel new measure for attempting to understand the multitasking capability of networks .",
    "NOVELTY"
  ],
  [
    "The model ( GGNN ) is not particularly novel",
    "NOVELTY"
  ],
  [
    "It presents novel opportunities compared to textual or perceptual data , as its ( local ) semantics are well-defined and rich additional information can be extracted using well-known",
    "NOVELTY"
  ],
  [
    "The techniques are quite delicate and novel which are summarized in lemma 1 and Theorem 3",
    "NOVELTY"
  ],
  [
    "the paper presents novel theoretical convergence rates for SCMD which are almost optimal , up to a logarithmic term .",
    "NOVELTY"
  ],
  [
    "The main meat of the paper is novel theory which is quite satisfactory to me .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of the paper is somewhat limited [ but a little more than my initial assessment",
    "NOVELTY"
  ],
  [
    "The specific form of tempered distribution that is proposed in the paper is quite original .",
    "NOVELTY"
  ],
  [
    "It is hard to assess what is the contribution of the paper from a practical point of view as SGD automatically avoids possible training problems related to AV",
    "NOVELTY"
  ],
  [
    "Rotation and scale can have arbitrary precision , which is novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "In my opinion , this is a simple , attractive approach to rotation and scale equivariant CNNs",
    "NOVELTY"
  ],
  [
    "To my knowledge , the TGAN approach is novel .",
    "NOVELTY"
  ],
  [
    "Using SSA-based loss in combination with a new model architecture is perhaps new but it is yet another combination of existing building blocks",
    "NOVELTY"
  ],
  [
    "The model is a combination of existing elements but",
    "NOVELTY"
  ],
  [
    "I think the paper is a good contribution . It solves an important problem , suggests a novel algorithm",
    "NOVELTY"
  ],
  [
    "the contribution of the paper itself needs to be strengthened in both the theory and empirical sides .",
    "NOVELTY"
  ],
  [
    "I think the algorithmic novelty in the paper is fairly limited .",
    "NOVELTY"
  ],
  [
    "the limited algorithmic novelty is not the main concern",
    "NOVELTY"
  ],
  [
    "Overall , this paper is a follow-up work towards Bafna et al . ( 2018 ) but",
    "NOVELTY"
  ],
  [
    "is novel and explores to use the existing modules as a black box for visual question answering",
    "NOVELTY"
  ],
  [
    "I think overall it is an interesting idea to directly alter the input of the network in order to fit to the testing distribution",
    "NOVELTY"
  ],
  [
    "To the extent of my knowledge , this work is novel .",
    "NOVELTY"
  ],
  [
    "some of the algorithms tested are similar algorithms that have already been proven to work well in practice",
    "NOVELTY"
  ],
  [
    "because if community don \u2019 t use these metrics in the future , the contribution of the paper is minimal",
    "NOVELTY"
  ],
  [
    "the contribution of the paper is hard to be significant",
    "NOVELTY"
  ],
  [
    "While the idea to partition into subspaces and learn a different detection for each of them is novel",
    "NOVELTY"
  ],
  [
    "I do not see a clear novelty , nor a proof",
    "NOVELTY"
  ],
  [
    "that the proposed algorithm is theoretically sound",
    "NOVELTY"
  ],
  [
    "and interesting",
    "NOVELTY"
  ],
  [
    "All in all , the originality of the paper is lacking",
    "NOVELTY"
  ],
  [
    "and there are not much insights given by the paper into the novel problem .",
    "NOVELTY"
  ],
  [
    "but the analysis in this paper is novel",
    "NOVELTY"
  ],
  [
    "Also , technical contributions seem less .",
    "NOVELTY"
  ],
  [
    "The results for 8-bit precision are not new .",
    "NOVELTY"
  ],
  [
    "-Originality This paper clearly has originality to some extent as the proposed algorithm for OSCM has a",
    "NOVELTY"
  ],
  [
    "different merit from existing ones . However , it seems for me that the methodologies are not new but the authors carefully combine them to construct algorithms",
    "NOVELTY"
  ],
  [
    "the idea of reducing the number of gradient evaluations per function is unique",
    "NOVELTY"
  ],
  [
    "The application of RBSM seems nice so I raise my score",
    "NOVELTY"
  ],
  [
    "and the idea of exploiting persistent representations in the transformer seems promising .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the idea of using meta-learning to propose an alternative to the Scale-Invariance desirable property to show that it is possible to achieve a good clustering is new and interesting .",
    "NOVELTY"
  ],
  [
    "The proposed problem setting and approach are novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The beta-Bernoulli interpretation for model aggregation is new to me .",
    "NOVELTY"
  ],
  [
    "This method is novel to me",
    "NOVELTY"
  ],
  [
    "this paper has incremental contribution compared with Chen et al . ( 2016 ) .",
    "NOVELTY"
  ],
  [
    "Extending the algorithm from linear graph to non-linear graph is important but the technical contribution is incremental and thin .",
    "NOVELTY"
  ],
  [
    "the improvement over previous work is quite marginal .",
    "NOVELTY"
  ],
  [
    "The approach is incremental or not-so-novel in terms of meta-representation for neural networks .",
    "NOVELTY"
  ],
  [
    "The contributions in this paper are quite interesting and possibly significant . The",
    "NOVELTY"
  ],
  [
    "and gives a nice contribution",
    "NOVELTY"
  ],
  [
    "The novelty of the method is limited . It seems that there is very little innovation in terms of network architecture compared to Villegas et al .The difference is mainly on how the network is trained",
    "NOVELTY"
  ],
  [
    "Overall I think the contribution is not significant enough .",
    "NOVELTY"
  ],
  [
    "I believe paper has significant contributions",
    "NOVELTY"
  ],
  [
    "Having said that I find the ideas leading up to what the authors refers to as `` gradient starvation `` to be really interesting and that would be a great clear idea to focus on",
    "NOVELTY"
  ],
  [
    "Compared to the existing work of Bernstein et al , the novelty of the current submission is moderate .",
    "NOVELTY"
  ],
  [
    "If my understanding of the method is correct , the novelty is limited .",
    "NOVELTY"
  ],
  [
    "I find the proposed idea simple and elegant",
    "NOVELTY"
  ],
  [
    "-Generating embeddings to interpret SPNs is a novel idea .",
    "NOVELTY"
  ],
  [
    "-The author 's contribution is n't fully clear and there are multiple claims that need support",
    "NOVELTY"
  ],
  [
    "The general methodology is very similar to what was presented by Naesseth et al . ( 2014 ) in a previous NIPS conference .",
    "NOVELTY"
  ],
  [
    "However , the paper lacks originality and the novelty in the contribution is relatively incremental .",
    "NOVELTY"
  ],
  [
    "The ideas are interesting",
    "NOVELTY"
  ],
  [
    "The convergence analysis for SVRG-BB and SVRG- I is simple , but interesting",
    "NOVELTY"
  ],
  [
    "the application of a BB step size on SVRG is not a big contribution since SVRG calculates true gradients after each epoch",
    "NOVELTY"
  ],
  [
    "As far as I\u00e2\u0080\u0099m aware , the paper describes a novel and interesting approach for learning to \u00e2\u0080\u009cpermute `` local point neighborhoods in unordered point sets .",
    "NOVELTY"
  ],
  [
    "B .The proposed hierarchical convolution technique ( Section 3.1 ) is incremental to prior work ( e.g. , PointNet++ ) .",
    "NOVELTY"
  ],
  [
    "I thought the idea is nice",
    "NOVELTY"
  ],
  [
    "I would n't really frame it as such a novelty",
    "NOVELTY"
  ],
  [
    "it does not seem to be a particularly powerful theoretical contribution",
    "NOVELTY"
  ],
  [
    "The error bound of value iteration with the Boltzmann softmax operator and convergence & convergence rate results in this setting seem novel .",
    "NOVELTY"
  ],
  [
    "The novelty of the dynamic Boltzmann operator is somewhat thin",
    "NOVELTY"
  ],
  [
    "The idea of sampling from a DPPs , whose kernel is associated with the kernel of the RKHS , is interesting and novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Compared to [ 3 ] , I do think the theoretical contribution ( better convergence rate ) is significant .",
    "NOVELTY"
  ],
  [
    "and the contribution of each trick would be a bit unclear",
    "NOVELTY"
  ],
  [
    "The technical contributions are also not novel .",
    "NOVELTY"
  ],
  [
    "I like the idea of phrase-to-phrase translation and the relatively simple architecture proposed in the paper .",
    "NOVELTY"
  ],
  [
    "In these respects the paper is novel and thought-provoking .",
    "NOVELTY"
  ],
  [
    "While the",
    "NOVELTY"
  ],
  [
    "and provides insight into web traversal and query answering as a promising benchmark for intelligent agents .",
    "NOVELTY"
  ],
  [
    "While the paper does not make any particularly novel contributions in terms of algorithms",
    "NOVELTY"
  ],
  [
    "and the triplet loss proposal for adversarial examples is original , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "using t-SNE to visualize the behaviour of adversarial examples is not a new idea and has been used in a variety of papers in a similar way",
    "NOVELTY"
  ],
  [
    "I do not believe this component of the contribution is as significant as the proposal of the new loss function",
    "NOVELTY"
  ],
  [
    "the assumptions 1 and 2 are much stronger than previous works , making the universality of the theory limited",
    "NOVELTY"
  ],
  [
    "Among the first papers that I know of to provide theoretical results for estimation in dynamic graph models",
    "NOVELTY"
  ],
  [
    "but it 's unclear if this is a novel finding in this paper",
    "NOVELTY"
  ],
  [
    "Summary of evaluation There is not much novelty in this idea",
    "NOVELTY"
  ],
  [
    "Novel latent method for goal conditioned prediction ( sequential and hierarchical ) + Really cool experiments on navigation using the predicted frames",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel latent variable method for goal oriented video prediction which is then used to enable an agent to go from point A to point B. I feel this paper brings nice insights useful for the model based reinforcement learning literature where the end goal can be guided by an",
    "NOVELTY"
  ],
  [
    "The paper has some interesting ideas",
    "NOVELTY"
  ],
  [
    "The technique used in this work is a mix of SGD and",
    "NOVELTY"
  ],
  [
    "The idea to use reconstruction as regularization method is not new .",
    "NOVELTY"
  ],
  [
    "I think there is enough novelty to warrant publication .",
    "NOVELTY"
  ],
  [
    "The probabilistic approach also seems novel .",
    "NOVELTY"
  ],
  [
    "the technical contribution is somewhat limited -- most of it is in step 1",
    "NOVELTY"
  ],
  [
    "I am not sure whether the contribution is enough",
    "NOVELTY"
  ],
  [
    "The temporal regularization proposed in this paper is very similar to the total variation penalty used extensively in statistics and image processing .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "Novelty is a little on the lower side",
    "NOVELTY"
  ],
  [
    "The proposed approach using syntactic and lexical diversity modelling within the latent space to generate diverse image captions is novel .",
    "NOVELTY"
  ],
  [
    "This work builds upon previous work but derives several results that are interesting in their own right",
    "NOVELTY"
  ],
  [
    "While the results on image generative modeling are promising",
    "NOVELTY"
  ],
  [
    "the underlying approach itself is not novel and as authors acknowledge",
    "NOVELTY"
  ],
  [
    "The paper is interesting and brings new theoretically thoughts to understand the distillation method .",
    "NOVELTY"
  ],
  [
    "The idea to extend and use deep canonical correlation analysis for a depth completion framework is clearly novel and sets this work apart from previous methods . The network architecture itself is a reasonable combination of",
    "NOVELTY"
  ],
  [
    "This work is the first one to address this issue , and the proposed model is novel and interesting . I particularly like the idea that incorporates the latent factors into the design of the triggering kernel so that those excitation effects can be encoded into the latent factors as well .",
    "NOVELTY"
  ],
  [
    "The idea of 'learning ' prior information about the heavy hitters seems original .",
    "NOVELTY"
  ],
  [
    "It seems like a creative and interesting place to use machine learning .",
    "NOVELTY"
  ],
  [
    "this is an innovative paper , proposing a new class of attacks that totally makes sense in my opinion .",
    "NOVELTY"
  ],
  [
    "The idea is new and I haven\u00e2\u0080\u0099t seen it being used in 3D before",
    "NOVELTY"
  ],
  [
    "The paper presents an original and new method for 3D instance segmentation .",
    "NOVELTY"
  ],
  [
    "I think that this is an nice piece of work , which provides an incremental contribution to the already widely developed theory of stochastic optimisation algorithms for",
    "NOVELTY"
  ],
  [
    "ML",
    "NOVELTY"
  ],
  [
    "although I think that the contribution is mostly incremental , since ( to the best of my knowledge ) the proofs do not seem to introduce a major novelty .",
    "NOVELTY"
  ],
  [
    "The contribution of this work seems to be enabling the use of deeper neural network than in Chen et al",
    "NOVELTY"
  ],
  [
    "The technical contribution has limited novelty",
    "NOVELTY"
  ],
  [
    "variational methods for approximating the partition function of discrete graphical models",
    "NOVELTY"
  ],
  [
    "the `` local `` sense in which this paper proposes using them is interesting .",
    "NOVELTY"
  ],
  [
    "While the methodology is interesting",
    "NOVELTY"
  ],
  [
    "the main contribution is the analytical formula ( I have no idea whether this is original",
    "NOVELTY"
  ],
  [
    "From the point of view of contribution , it is building heavily on the SSC framework , effectively introducing the missing data points aspect to the original algorithm",
    "NOVELTY"
  ],
  [
    "This work is original and of good quality",
    "NOVELTY"
  ],
  [
    "I believe this is a strong paper presenting state-of-the-art research",
    "NOVELTY"
  ],
  [
    "I do not find the paper to be a contribution significant enough for ICLR .",
    "NOVELTY"
  ],
  [
    "While the novelty is clear there",
    "NOVELTY"
  ],
  [
    "Although the proposed model achieves state of the art performance on this task , it is only incremental .",
    "NOVELTY"
  ],
  [
    "The paper does introduce some new application of resNet with interesting skip connections",
    "NOVELTY"
  ],
  [
    "The work seems very promising and represents one of the first attempts to learn stimulus intensity .",
    "NOVELTY"
  ],
  [
    "While the state representation is a simple successor representation , the action abstraction is a simple method that seems novel .",
    "NOVELTY"
  ],
  [
    "Combining PGMs and deep learning/ neural networks is a very active and promising area of research .",
    "NOVELTY"
  ],
  [
    "I think the proposed method seems to be somewhat novel",
    "NOVELTY"
  ],
  [
    "-- I found it challenging to identify a novel contribution",
    "NOVELTY"
  ],
  [
    "The proposed GSM model is not new and only re-uses building blocks from the related work",
    "NOVELTY"
  ],
  [
    "the main weak point that the novelty of the approach is limited remains valid of course",
    "NOVELTY"
  ],
  [
    "In general , I do not see enough novelty in the proposed method ,",
    "NOVELTY"
  ],
  [
    "I feel that it might lack novelty .",
    "NOVELTY"
  ],
  [
    "the contributions of this paper would be nullified",
    "NOVELTY"
  ],
  [
    "The main contribution is a novel combination of mostly existing techniques .",
    "NOVELTY"
  ],
  [
    "Treating the quantization as noise has been proposed in a different form in McKinstry et al .2018 .Gradual quantization appears novel",
    "NOVELTY"
  ],
  [
    "but is also the least interesting of the techniques . Therefore , novelty on ideas/methods is somewhat limited",
    "NOVELTY"
  ],
  [
    "but not terribly novel .",
    "NOVELTY"
  ],
  [
    "I did not find too many significant differences between this paper and [",
    "NOVELTY"
  ],
  [
    "in the design of encoder-decoder architecture as well as the learning procedure",
    "NOVELTY"
  ],
  [
    "The key findings ( and similar results",
    "NOVELTY"
  ],
  [
    "i.e .F-Principle seems to have already appeared in previous works",
    "NOVELTY"
  ],
  [
    "and not novel",
    "NOVELTY"
  ],
  [
    "This is a welcome contribution to the dialogue literature",
    "NOVELTY"
  ],
  [
    "The proof technique for the hardness results is a modification of previous results and it is perhaps a smaller contribution than the statement of the results themselves",
    "NOVELTY"
  ],
  [
    "links up",
    "NOVELTY"
  ],
  [
    "This paper should be accepted because the results are interesting , relevant , novel",
    "NOVELTY"
  ],
  [
    "The paper is incremental work upon previous research (",
    "NOVELTY"
  ],
  [
    "While the results are interesting",
    "NOVELTY"
  ],
  [
    "While the modeling using such a simple parametric model in a Bayesian pomdp is not a new",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "The idea is intriguing , even though",
    "NOVELTY"
  ],
  [
    "not entirely novel",
    "NOVELTY"
  ],
  [
    "idea",
    "NOVELTY"
  ],
  [
    "and provides a polynomial time algorithm",
    "NOVELTY"
  ],
  [
    "The idea is original and very interesting as it brings some efficient machine learning techniques where existing ABC methods may fail or struggle .",
    "NOVELTY"
  ],
  [
    "This is not novel enough .",
    "NOVELTY"
  ],
  [
    "Lack of technical contributions",
    "NOVELTY"
  ],
  [
    "seems to be straightforward .",
    "NOVELTY"
  ],
  [
    "Using a mixture of Gaussians rather than a Gaussian in Bayes by Backprop is a natural extension and therefore the novelty seems low",
    "NOVELTY"
  ],
  [
    "The proposed idea is novel .",
    "NOVELTY"
  ],
  [
    "The main concept of the paper is not different from existing deep generative model ( DGM ) formulations where the postulated likelihood is a finite mixture of Gaussians .",
    "NOVELTY"
  ],
  [
    "intuitive ( but not particularly novel )",
    "NOVELTY"
  ],
  [
    "2 .The basic motivation and observations are the same as InfoVAE , so it 's not completely novel .",
    "NOVELTY"
  ],
  [
    "I think the idea is interesting enough",
    "NOVELTY"
  ],
  [
    "The idea of using a sliding window over a growing window in active batch selection is interesting .",
    "NOVELTY"
  ],
  [
    "Despite the method having limited novelty ( sliding window instead of a growing window )",
    "NOVELTY"
  ],
  [
    "It appears to me that the novelty of the paper is limited",
    "NOVELTY"
  ],
  [
    "I found it very difficult to work out what the contribution of this paper is over previous work",
    "NOVELTY"
  ],
  [
    "The approach to using selfplay RL seems almost identical in each case , so there doesn \u2019 t appear to be a technical contribution .",
    "NOVELTY"
  ],
  [
    "However , this is as far as I am aware the first work applying these techniques to text classification ,",
    "NOVELTY"
  ],
  [
    "`` For each length it contains `` Originality : moderate , as the novelty with respect to recent neural-symbolic approaches is not entirely clear",
    "NOVELTY"
  ],
  [
    "Overall the idea is , while simple , interesting and potentially promising",
    "NOVELTY"
  ],
  [
    "this kind of dimensionality reduction has been explored with other techniques",
    "NOVELTY"
  ],
  [
    "I believe",
    "NOVELTY"
  ],
  [
    "as this is not a novel proposition",
    "NOVELTY"
  ],
  [
    "the algorithm does not appear to be a substantial improvement over existing algorithms",
    "NOVELTY"
  ],
  [
    "I found this paper very interesting",
    "NOVELTY"
  ],
  [
    "This paper suggests a novel and compact neural network architecture which uses the information within bag-of-words features .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is simple and does not provide completely new idea",
    "NOVELTY"
  ],
  [
    ", but this paper has a clear contribution connecting the previous main idea of feature extraction , bag-of-words , and the prevailing blackbox algorithm , CNN .",
    "NOVELTY"
  ],
  [
    "To the best knowledge of the reviewer , the proposed method is well motivated and novel , and provides a scalable method for verifying ( instead of lower",
    "NOVELTY"
  ],
  [
    "the improvement of the proposed model over the previous state of the art is limited .",
    "NOVELTY"
  ],
  [
    "Using surface reflectance decomposition to reduce photometric inconsistency in projection-based self-supervision is also novel for this task .",
    "NOVELTY"
  ],
  [
    "I feel the latest version of",
    "NOVELTY"
  ],
  [
    "Even if the idea of joining BA / SfM and deep learning is not new",
    "NOVELTY"
  ],
  [
    ", the authors propose an interesting novel formulation .",
    "NOVELTY"
  ],
  [
    "I think the algorithmic idea in this paper is a step in the right direction and can be of interest for the community .",
    "NOVELTY"
  ],
  [
    "I think the idea is novel and",
    "NOVELTY"
  ],
  [
    "researchers to select the regularization parameters",
    "NOVELTY"
  ],
  [
    "the contribution is incremental and more importantly the paper",
    "NOVELTY"
  ],
  [
    "Overall , I thus believe this manuscript does not contribute enough new insights , given the technical interpretation problem and that there was considerable knowledge about the curves measured beforehand",
    "NOVELTY"
  ],
  [
    "I 'm uncertain about the novelty of the approach",
    "NOVELTY"
  ],
  [
    "the contribution placement apt",
    "NOVELTY"
  ],
  [
    "Strengths The paper introduces new technical insights to understand their bound",
    "NOVELTY"
  ],
  [
    "The paper proposed the way to estimate coefficient",
    "NOVELTY"
  ],
  [
    "and I think this is the biggest contribution of this paper and is interesting .",
    "NOVELTY"
  ],
  [
    "Weakness The main theorem of this paper is an extension of existing methods , so the novelty of theoretical analysis is somewhat limited .",
    "NOVELTY"
  ],
  [
    "I like the approach of the proposed method",
    "NOVELTY"
  ],
  [
    "especially tuning coefficient during training procedure although novelty in the theoretical analysis is somewhat limited .",
    "NOVELTY"
  ],
  [
    "As far as I know , this formulation of generative impersonation attacks is novel",
    "NOVELTY"
  ],
  [
    "The theoretical analysis is insightful .",
    "NOVELTY"
  ],
  [
    "I think the paper is of limited novelty",
    "NOVELTY"
  ],
  [
    "The approach of the paper is mostly intuitive .",
    "NOVELTY"
  ],
  [
    "this broad scope dilutes the impact of the paper ; the contribution of the work as a whole is incoherent .",
    "NOVELTY"
  ],
  [
    ", the results are novel",
    "NOVELTY"
  ],
  [
    "Overall , the idea is an incremental one , although interesting largely based on the fact that this works .",
    "NOVELTY"
  ],
  [
    "The idea of utilizing learning models for generating questions and modeling human-generated questions intuitive",
    "NOVELTY"
  ],
  [
    "Overall , I do not find enough novelty from any aspects while the overall effort of this paper is appreciated . - The problem is not entirely novel as [ 1-3 ] have explored asking questions with neural networks learning to generate programmatic questions .",
    "NOVELTY"
  ],
  [
    "but in point of view of the out-of-distribution detection task , the proposed method seems to be an incremental task and far from the state-of-the-art .",
    "NOVELTY"
  ],
  [
    "The novelty seems a little straight-forward .",
    "NOVELTY"
  ],
  [
    "I think the uniqueness of both the problem and the solution were overemphasized .",
    "NOVELTY"
  ],
  [
    "but the problem itself is n't new",
    "NOVELTY"
  ],
  [
    "There is no significant contribution in the theoretical part",
    "NOVELTY"
  ],
  [
    "I believe that the contributions of this paper are significant .",
    "NOVELTY"
  ],
  [
    "different and follows naturally from the discussion within the paper",
    "NOVELTY"
  ],
  [
    "I think the paper studies and interesting question and provides novel theoretical results .",
    "NOVELTY"
  ],
  [
    "Originality Formulation of prediction method ( MCW ) using the maximal correlation and correlation function is novel .",
    "NOVELTY"
  ],
  [
    "The combined routing procedure seems to be novel , while the individual parts are inspired by self-attention in the transformer and Gumbel-softmax decisions as used in discrete domains like text processing",
    "NOVELTY"
  ],
  [
    "The work is clearly original and first contribution of a kind .",
    "NOVELTY"
  ],
  [
    "paper presents a very interesting idea on modeling the action space . I think the idea of learning actions from current and future states are novel ,",
    "NOVELTY"
  ],
  [
    "The proposed PoseWarper network is novel and makes sense . Even though similar ideas",
    "NOVELTY"
  ],
  [
    "have been explored in the literature",
    "NOVELTY"
  ],
  [
    ", I still found the ideas presented in the paper novel for body pose estimation .",
    "NOVELTY"
  ],
  [
    "interesting techniques",
    "NOVELTY"
  ],
  [
    "I quite enjoyed reading the paper as the work in it seems original , solid and complete ( even a",
    "NOVELTY"
  ],
  [
    "I like the idea of depthmap super-resolution for generating high resolution shapes .",
    "NOVELTY"
  ],
  [
    "Regarding weaknesses , the use of silhouettes and depthmaps for shape reconstruction is not new",
    "NOVELTY"
  ],
  [
    "The method itself is a fairly simple trick and one could argue that , overall , this is incremental work .",
    "NOVELTY"
  ],
  [
    "and the contributions are clear",
    "NOVELTY"
  ],
  [
    "but relatively simple and",
    "NOVELTY"
  ],
  [
    "The reader finds that the proposed approach is interesting .",
    "NOVELTY"
  ],
  [
    "I would n't consider any particular aspect of this paper to be that novel , but it is a nice combination of leveraging active self-supervised learning to generate spatial affordance information for fusion with a geometric planner .",
    "NOVELTY"
  ],
  [
    "I found the idea of using an auxiliary loss when training a VAE may cause the latent space coding direction change novel and interesting .",
    "NOVELTY"
  ],
  [
    "but this does not appear to be a contribution of this work",
    "NOVELTY"
  ],
  [
    "This idea is something new ,",
    "NOVELTY"
  ],
  [
    "although quite straight-forward",
    "NOVELTY"
  ],
  [
    "Originality This paper does not focus on developing a novel method .",
    "NOVELTY"
  ],
  [
    "Simply combining these methods does not seem novel .",
    "NOVELTY"
  ],
  [
    "I think the contribution of this paper would be reasonable",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    ", as they address the choice of step size in one of the most used optimization methods machine learning and are novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The paper looks like a follow up paper of the author \u2019 s previous paper Cazenave ( 2016a ) , however , the contribution over the previous paper is not clear .",
    "NOVELTY"
  ],
  [
    "-novel notion that guarantees adaptive generalization -the paper shows that previous notions guaranteeing generalization all imply a bound on Local Statistical Stability Cons",
    "NOVELTY"
  ],
  [
    "The only novel aspect of this contribution is the introduction of the bit-serial compute unit",
    "NOVELTY"
  ],
  [
    "the idea of bit-serial computation is certainly quite interesting .",
    "NOVELTY"
  ],
  [
    "The construction in this paper seems interesting and",
    "NOVELTY"
  ],
  [
    "A new network based on graph neural networks .",
    "NOVELTY"
  ],
  [
    "They consider a challenging problem , propose a novel and not immediately obvious solution ,",
    "NOVELTY"
  ],
  [
    "and the approach seems to me to be new and worth studying",
    "NOVELTY"
  ],
  [
    "I 'm not extremely familiar with the DRO literature , but , as far as I know , the use of MMD for DRO , as well as the connection to kernel ridge regression ( KRR ) , and the proposed regularizer are novel . The generalization bound for KRR is not novel , but the proof approach is novel , and could likely be applied to other problems .",
    "NOVELTY"
  ],
  [
    "Given that this paper not only provides a clear presentation of the DRO framework for a Stat/ML audience but also supplies novel implications for a standard learning algorithm ( kernel ridge regression ) , I",
    "NOVELTY"
  ],
  [
    "the contribution of this work is fairly limited Therefore",
    "NOVELTY"
  ],
  [
    "The paper 's analysis is relatively novel and insightful .",
    "NOVELTY"
  ],
  [
    "I think the main idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting approach",
    "NOVELTY"
  ],
  [
    "The authors failed to bring the novel idea .",
    "NOVELTY"
  ],
  [
    "At the same time , I like the idea of studying a bunch of proposed measures and attempting to gain new insights .",
    "NOVELTY"
  ],
  [
    "The idea and formulation are original and highly central to many problems in reinforcement learning .",
    "NOVELTY"
  ],
  [
    "I find it hard to understand the contributions of the paper",
    "NOVELTY"
  ],
  [
    "Their formalization , algorithms and theoretical and empirical results look new .",
    "NOVELTY"
  ],
  [
    "I 'm not sure if the authors were the first to present this approach of analyzing the effects of convolutions from a `` patch perspective ``",
    "NOVELTY"
  ],
  [
    "but I think this is a clever approach",
    "NOVELTY"
  ],
  [
    "I also like the idea of factoring",
    "NOVELTY"
  ],
  [
    "layer ``",
    "NOVELTY"
  ],
  [
    "Analyzing the convergence rates of natural gradient methods for general deep neural networks is an open problem , to best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The idea to adapt random projection methods to time series by using random filters is interesting and the method outperforms fixed window based features .",
    "NOVELTY"
  ],
  [
    "the proposed method is very interesting and inspiring .",
    "NOVELTY"
  ],
  [
    "The proposed parallelization is original with respect to existing methods and it should indeed lead to less communications than other methods",
    "NOVELTY"
  ],
  [
    "The methodology of this work is basically combining the existing technology and is not novel enough .",
    "NOVELTY"
  ],
  [
    "MTS ) , but I 'm not sure about how novel and nontrivial the results of this paper are since I 'm not familiar with the settings of this paper and",
    "NOVELTY"
  ],
  [
    "While the paper adopts the core design choices from recent prior art",
    "NOVELTY"
  ],
  [
    "the proposed methodology",
    "NOVELTY"
  ],
  [
    "( especially ii",
    "NOVELTY"
  ],
  [
    ") is sufficiently novel to",
    "NOVELTY"
  ],
  [
    "be published as a main-track conference paper",
    "NOVELTY"
  ],
  [
    "As far as I can see , there is nothing really new being proposed here in terms of practical consequences .",
    "NOVELTY"
  ],
  [
    "I am not saying the additional theoretical insight from this work here ( over previous K-FAC work )",
    "NOVELTY"
  ],
  [
    "is not useful",
    "NOVELTY"
  ],
  [
    "Overall , the proposed method has a lack novelty and thorough comparison against BRN .",
    "NOVELTY"
  ],
  [
    "The paper makes several minor contributions",
    "NOVELTY"
  ],
  [
    "the use of the faster SAEL 3.2.1 over CryptoNet \u2014 not really an innovation per se 2",
    "NOVELTY"
  ],
  [
    "In the context of application of HE , the idea is novel to my knowledge",
    "NOVELTY"
  ],
  [
    "Overall , the paper proposes a new method and gives an alternative view on the VAE model .",
    "NOVELTY"
  ],
  [
    "I still think that the paper does not give new insights",
    "NOVELTY"
  ],
  [
    "Considering MDL interpretation of VAE it is not new ( see",
    "NOVELTY"
  ],
  [
    ". Therefore , the contribution of this paper is very limited .",
    "NOVELTY"
  ],
  [
    "The proposed strategy of handling view-missing is novel and elegant compared with existing strategies .",
    "NOVELTY"
  ],
  [
    "The designed clustering-like loss is interesting",
    "NOVELTY"
  ],
  [
    "the authors present this argument in a stringent yet insightful way in the language of curvature of Riemannian manifolds",
    "NOVELTY"
  ],
  [
    "The paper lacks novelty and significant contributions due to the following .",
    "NOVELTY"
  ],
  [
    "So the technique does not seem to be new .",
    "NOVELTY"
  ],
  [
    "One is whether attention regulation is novel enough or not",
    "NOVELTY"
  ],
  [
    "but , to the best of my knowledge , the specific combination and formulation is novel ,",
    "NOVELTY"
  ],
  [
    "No suggestions or potential solutions is proposed in this paper , which weaken the contribution of this paper .",
    "NOVELTY"
  ],
  [
    "The method is novel .",
    "NOVELTY"
  ],
  [
    "I do not feel that this work provides much new insight into why global robustness is interesting to examine .",
    "NOVELTY"
  ],
  [
    "The non-asymptotic proof is also a novel contribution and will be helpful to further develop the theory of NTK .",
    "NOVELTY"
  ],
  [
    "The idea of learning an input-dependent subgraph using GNN seems new . - The proposed way to reduce the complexity by restricting the attention horizon sounds interesting and seems necessary for scaling up .",
    "NOVELTY"
  ],
  [
    "The overall architecture looks like a fairly complicated combination of neural networks",
    "NOVELTY"
  ],
  [
    "The theoretical analysis in Section 3 is novel , interesting and solid .",
    "NOVELTY"
  ],
  [
    "in the RNN case , constraining the singular values of the weight matrix is not a new idea .",
    "NOVELTY"
  ],
  [
    "2 .Somewhat incremental method .",
    "NOVELTY"
  ],
  [
    "and it proposes a novel direction for research .",
    "NOVELTY"
  ],
  [
    "This contribution is not novel enough for NIPS .",
    "NOVELTY"
  ],
  [
    "Compared with",
    "NOVELTY"
  ],
  [
    "Material is original to my knowledge .",
    "NOVELTY"
  ],
  [
    "Interesting idea that seems promising",
    "NOVELTY"
  ],
  [
    "but this is a minor contribution on top of GCN and 3D representations have been widely studied in the vision community",
    "NOVELTY"
  ],
  [
    "It is nice to see the application of Fourier sampling to geometric primitives in a sensible manner and I am positive about that part of the paper",
    "NOVELTY"
  ],
  [
    "I like the paper as it feels like a very natural solution to combine retrieval with text generation methods",
    "NOVELTY"
  ],
  [
    "significance The work builds heavily on CD but has the hierarchical extension is original and significant",
    "NOVELTY"
  ],
  [
    "The proposed Sparsegen framework is novel that not only houses a number of existing probability mapping functions but also generates two new ones showing positive results on standard NLP tasks .",
    "NOVELTY"
  ],
  [
    "executed , novel study .",
    "NOVELTY"
  ],
  [
    "This is an intriguing idea .",
    "NOVELTY"
  ],
  [
    "The method is inspired",
    "NOVELTY"
  ],
  [
    "I do n't think the extension is trivial",
    "NOVELTY"
  ],
  [
    "The second contribution on an algorithm that adaptively schedules the learning rate is novel , and not something I have seen before .",
    "NOVELTY"
  ],
  [
    "and the novelty of this work is rather weak given the above mentioned 2019 publication",
    "NOVELTY"
  ],
  [
    "Although , the use of conditional GANs for characterizing biases in classifiers is novel",
    "NOVELTY"
  ],
  [
    "I think the manuscript in its current state is not significant enough to justify a publication at NeurIPS . The proposed work is a purely empirical analysis , no significant theoretical or technical contribution was made",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "The idea of estimating the threshold has some novel contribution to the computational psychology society .",
    "NOVELTY"
  ],
  [
    "However , the algorithms used in this paper are not novel because the author uses these algorithm without much modifications based on the previous work",
    "NOVELTY"
  ],
  [
    "and the method is novel",
    "NOVELTY"
  ],
  [
    "For the special case of Orlicz norm , the row sampling algorithm according to the Orlicz norm leverage score is a novel algorithm that can improve the previous results",
    "NOVELTY"
  ],
  [
    "Overall I think the paper has several interesting ideas .",
    "NOVELTY"
  ],
  [
    "Usage of dataset splitting for learning this common mean is novel and the transfer risk bound shows how the splitting of the dataset is affected under the strong assumption E",
    "NOVELTY"
  ],
  [
    "The idea of improved bounds for streaming algorithms using machine learning oracle seems to be very appealing to me . The authors present novel theoretical results supporting this .",
    "NOVELTY"
  ],
  [
    "Thus , I quite like the idea of SCE from that point of view .",
    "NOVELTY"
  ],
  [
    "I like the idea in this paper that use not just one but multiple attentional vectors to extract multiple representations for a sentence .",
    "NOVELTY"
  ],
  [
    "The reviewer thinks that the paper has presented some new theoretical",
    "NOVELTY"
  ],
  [
    "the paper presents improvements of the BCFW",
    "NOVELTY"
  ],
  [
    "this paper",
    "NOVELTY"
  ],
  [
    "To my best knowledge , the proposed approach is novel , and the authors provide nice theoretical",
    "NOVELTY"
  ],
  [
    "The explanation of instability and noise injection is not new",
    "NOVELTY"
  ],
  [
    "and the proposed algorithm is novel .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is different from previous work",
    "NOVELTY"
  ],
  [
    "I found the paper interesting .",
    "NOVELTY"
  ],
  [
    "While I think that the paper contains many interesting ideas",
    "NOVELTY"
  ],
  [
    "The proposed method is innovative and highly different from standard LSTM-based approaches of late .",
    "NOVELTY"
  ],
  [
    "As listed above , the paper makes significant novel contributions to formalizing robustness in the considered setting and provides both experimental and theoretical evidence for increased robustness .",
    "NOVELTY"
  ],
  [
    "Overall , I find the main idea of the paper interesting .",
    "NOVELTY"
  ],
  [
    "From an algorithmic standpoint , the paper does not introduce new methods and relies on well-known reinforcement learning techniques .",
    "NOVELTY"
  ],
  [
    "The proposed methodology of applying specific RL techniques such as DDPG to pricing appears novel .",
    "NOVELTY"
  ],
  [
    "The idea of using the metric called maximum observed relevance to characterize the regret bound is very interesting .",
    "NOVELTY"
  ],
  [
    "Theoretical contribution is minor . There is no novelty in the policy update and the policy structure .",
    "NOVELTY"
  ],
  [
    "I lean to reject this paper because the contributions , even if interesting , do not lead to any new understanding of the topic .",
    "NOVELTY"
  ],
  [
    "however I found the actual contribution limited because",
    "NOVELTY"
  ],
  [
    "Collection new data using google search then run existing methods has limited contribution .",
    "NOVELTY"
  ],
  [
    "1 .While the basic idea is not so exciting",
    "NOVELTY"
  ],
  [
    "-A novel method in an important and interesting direction .",
    "NOVELTY"
  ],
  [
    "Lack of novelty \u2013 Most of the components of the proposed algorithm have been researched in other works .",
    "NOVELTY"
  ],
  [
    "the paper is rather thought-provoking",
    "NOVELTY"
  ],
  [
    "The MFA part is rather classical but interesting and natural .",
    "NOVELTY"
  ],
  [
    "Originality The evaluation method is , to the best of my knowledge , novel .",
    "NOVELTY"
  ],
  [
    "but using it for image generation is somewhat original",
    "NOVELTY"
  ],
  [
    "Significance I really like the general message of this paper",
    "NOVELTY"
  ],
  [
    "is thought provoking",
    "NOVELTY"
  ],
  [
    "The idea of passing gradients for multi-task learning is interesting",
    "NOVELTY"
  ],
  [
    "the extension to density estimators is an original novelty of this paper",
    "NOVELTY"
  ],
  [
    "I feel that the novelty of this paper is not significant .",
    "NOVELTY"
  ],
  [
    "My concern is that the contribution of the paper on the theoretical or methodological side seems a bit weak .",
    "NOVELTY"
  ],
  [
    "The `` reweighting `` approach proposed in Eq .5 is not new",
    "NOVELTY"
  ],
  [
    "However I was unable to identify any real novelty in the theory",
    "NOVELTY"
  ],
  [
    "Good . I think the notion of minimum supervision ratio is interesting and novel .",
    "NOVELTY"
  ],
  [
    "This work has some contribution on the theoretical side but I believe its empirical contribution is limited .",
    "NOVELTY"
  ],
  [
    "The idea of trying to balance the compactness and generalization is new to me .",
    "NOVELTY"
  ],
  [
    "The algorithm and theoretical results presented are to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "While the",
    "NOVELTY"
  ],
  [
    "results are",
    "NOVELTY"
  ],
  [
    "interesting I find very few original ideas in this paper .",
    "NOVELTY"
  ],
  [
    "Because of this I find the paper to be a bit lacking on the novelty quotient",
    "NOVELTY"
  ],
  [
    "Unsupervised MT in itself is not a new idea",
    "NOVELTY"
  ],
  [
    "the approach is a combination of existing approaches and ideas with a slight modification to enable temporal processing .",
    "NOVELTY"
  ],
  [
    "I think the novelty of the paper is very limited",
    "NOVELTY"
  ],
  [
    "but it is unclear if the paper is advancing the state of the art by including the uncertainty model",
    "NOVELTY"
  ],
  [
    "1- The proposed zero-shot learning from scratch setting",
    "NOVELTY"
  ],
  [
    "The paper defines both and explores their importance with clear and novel experiment-designs and metrics .",
    "NOVELTY"
  ],
  [
    "While at first glance the submission seems incremental",
    "NOVELTY"
  ],
  [
    "I feel that the presented results are too incremental .",
    "NOVELTY"
  ],
  [
    "However neither the methodology not the results are novel / surprising",
    "NOVELTY"
  ],
  [
    "there seems to be relatively limited novelty",
    "NOVELTY"
  ],
  [
    "One aspect does does strike me as novel is the `` gated composition module ``",
    "NOVELTY"
  ],
  [
    "I like this idea",
    "NOVELTY"
  ],
  [
    "The paper proposes an interesting idea of selecting samples to annotate jointly by maximizing the mutual information between a batch of samples and model weights instead of selecting them independently for each batch .",
    "NOVELTY"
  ],
  [
    "The novelty is incremental . This paper directly combines well-known techniques and does not make any new contribution from the machine learning perspective .",
    "NOVELTY"
  ],
  [
    "Overall this is an okay paper with limited novelty",
    "NOVELTY"
  ],
  [
    "somewhat unsatisfying is that the paper makes rather incremental progress",
    "NOVELTY"
  ],
  [
    "and I also think the derivation and analysis of SMA and CCCP is interesting in its own right",
    "NOVELTY"
  ],
  [
    "the paper is interesting and makes a contribution",
    "NOVELTY"
  ],
  [
    "Thus , this work is novel and contains significant theoretical contributions .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is a well written piece that provides novel contributions to the field of reinforcement learning .",
    "NOVELTY"
  ],
  [
    "Secondly , the authors present a novel algorithm that very closely predicts human behavior for both doing and showing how to accomplish a task .",
    "NOVELTY"
  ],
  [
    "in a field littered with advancements based solely on mathematical acrobatics . I deeply enjoyed the bridging between human behavior and computational models for artificial intelligent behavior .",
    "NOVELTY"
  ],
  [
    "However , the contribution is minimal .",
    "NOVELTY"
  ],
  [
    "In short , this paper has very little concrete mathematical or computational contribution .",
    "NOVELTY"
  ],
  [
    "The new contribution of the work is relatively small .",
    "NOVELTY"
  ],
  [
    "This part is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The part on generalization bounds and consistency is highly similar to [ 8 ] , and is a relatively small contribution .",
    "NOVELTY"
  ],
  [
    "Overall , the novelty seems somewhat incremental , but I still feel the work is concrete and meaningful .",
    "NOVELTY"
  ],
  [
    "mean field theory for information flow in a neural network with quantized activations has not yet been studied",
    "NOVELTY"
  ],
  [
    ".The proposed graphical model is similar to that of Edwards & Storkey ( 2017 ) , though the frame-level Seq2Seq makes the proposed method sufficiently original",
    "NOVELTY"
  ],
  [
    "The study of disentanglement for sequential data is also fairly novel .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel method for explaining VQA systems .",
    "NOVELTY"
  ],
  [
    "but a good piece of incremental science .",
    "NOVELTY"
  ],
  [
    "Idea somewhat incremental",
    "NOVELTY"
  ],
  [
    "The proposed subsampling procedure is simple , interesting , and novel .",
    "NOVELTY"
  ],
  [
    "I like the idea of using Poisson sampling",
    "NOVELTY"
  ],
  [
    "If you are using environments with discrete actions and performing prediction I am not sure if that can be called imaginative",
    "NOVELTY"
  ],
  [
    "The current work is very similar to such works , in the sense that it tries to combine the higher-level features with the lower-level features",
    "NOVELTY"
  ],
  [
    "Compared to such works , it lacks both novelty and insights about what works and why it works .",
    "NOVELTY"
  ],
  [
    "Overall I think the current work lacks novelty , significance and solid experiments to be accepted to ICLR",
    "NOVELTY"
  ],
  [
    "and contains interesting contributions",
    "NOVELTY"
  ],
  [
    "The main weakness of the paper is that it is mainly based on further tuning the existing BERT model and lacks novel contribution in model architecture .",
    "NOVELTY"
  ],
  [
    "Beyond this , even though it 's interesting , there isn \u2019 t enough contribution in the paper .",
    "NOVELTY"
  ],
  [
    "fine-tune the compact model on target task This idea is not significantly new since it is quite common to apply distillation to compress models",
    "NOVELTY"
  ],
  [
    "Overall I think this work is somewhat incremental , and falls below the acceptance threshold",
    "NOVELTY"
  ],
  [
    "The idea of using a `` non-linear gain normalization `` to adjust atom selection in sparse coding is interesting and as far as I know novel , while providing interesting empirical results",
    "NOVELTY"
  ],
  [
    "Overall I like the approach in the paper . It proposes a nice 2 pronged method for exploiting exploration via intrinsic rewards for multi-agent systems .",
    "NOVELTY"
  ],
  [
    "This design seems rather unique in that this part of the policy can optimizing for which intrinsic reward to toggle based on the extrinsic rewards observed",
    "NOVELTY"
  ],
  [
    "Novel ideas , and the",
    "NOVELTY"
  ],
  [
    "Overall the paper makes an interesting point and offers a novel perspective",
    "NOVELTY"
  ],
  [
    "4 .It is not clear which parts of Sec .4 are novel and which are not .",
    "NOVELTY"
  ],
  [
    "I feel this paper has some potentially interesting ideas",
    "NOVELTY"
  ],
  [
    "This is an interesting paper with a good idea",
    "NOVELTY"
  ],
  [
    "The idea of dynamically predicting the scale or receptive field is interesting .",
    "NOVELTY"
  ],
  [
    "not as strong as the most",
    "NOVELTY"
  ],
  [
    "original paper that develops convergence results",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "t",
    "NOVELTY"
  ],
  [
    "The ideas presented in this paper are conceptually interesting .",
    "NOVELTY"
  ],
  [
    "It is highly original due to the unified general framework for handling differing graph topologies .",
    "NOVELTY"
  ],
  [
    "and seems to be novel .",
    "NOVELTY"
  ],
  [
    "I like the ideas in the paper",
    "NOVELTY"
  ],
  [
    "Approach is novel and incorporates ideas from generative modeling into feature augmentation in an interesting way .",
    "NOVELTY"
  ],
  [
    "The main issue with the paper is the main idea is similar to [ 1,2",
    "NOVELTY"
  ],
  [
    "5 ]",
    "NOVELTY"
  ],
  [
    "The reviewer votes for rejection as the method has limited novelty",
    "NOVELTY"
  ],
  [
    "First , the novelty of this paper is trivial , in my opinion , the Eq .2 is the only contribution of this paper .",
    "NOVELTY"
  ],
  [
    "From the point of view of statistical learning , and as a possible user , I find the overall idea intriguing and",
    "NOVELTY"
  ],
  [
    "context biasing and the specific approach appears quite simple",
    "NOVELTY"
  ],
  [
    "The idea is novel to some extent",
    "NOVELTY"
  ],
  [
    ", as previous paper had already tried to combine pointer-based and standard models",
    "NOVELTY"
  ],
  [
    "The ideas are straightforward but ( to my knowledge ) new and apparently effective .",
    "NOVELTY"
  ],
  [
    "The summing algorithm is simple and closely related to previous work on the subject such as 23 .",
    "NOVELTY"
  ],
  [
    "I think the novelty in this paper is not sufficient to justify acceptance to this conference .",
    "NOVELTY"
  ],
  [
    "This is an interesting contribution that should be published somewhere",
    "NOVELTY"
  ],
  [
    "I thus believe the overall contribution is not sufficient for ICLR .",
    "NOVELTY"
  ],
  [
    "The changes made to the basic Q-learning setup , albeit novel and with desirable properties",
    "NOVELTY"
  ],
  [
    "While I am no expert in this particular area",
    "NOVELTY"
  ],
  [
    "the visual question answering task in the CLEVR dataset",
    "NOVELTY"
  ],
  [
    "The proposed model is novel and interesting .",
    "NOVELTY"
  ],
  [
    "While the general idea is not novel",
    "NOVELTY"
  ],
  [
    "Good new implementation of an existing idea -",
    "NOVELTY"
  ],
  [
    "The idea of using a clustering approach , combined with inference of latent variables ( e.g .true states ) is novel and creative , and excellent fit for this type of application .",
    "NOVELTY"
  ],
  [
    "I like the idea of mining the relation between tasks and handle it by the proposed meta-knowledge graph .",
    "NOVELTY"
  ],
  [
    "2 .The proposed meta-knowledge graph is novel for capturing the relation between tasks and address the problem of task heterogeneity .",
    "NOVELTY"
  ],
  [
    "The paper is rather incremental than innovative . However , the technical improvement is non-trivial and interesting for the community .",
    "NOVELTY"
  ],
  [
    "and provide some novel insights into the privacy approaches via posterior sampling",
    "NOVELTY"
  ],
  [
    "The proposed Lyapunov-function based approach for policy optimization is certainly appealing and the derived algorithms make sense to me . This paper provides a solid contribution to the safe RL literature though there are two main reasons that dampen the excitement about the presented results",
    "NOVELTY"
  ],
  [
    "the contribution is solid but seems to be of somewhat incremental nature to me , combining existing recent techniques by Chow et al",
    "NOVELTY"
  ],
  [
    "It should also be noted that there seems to be no architectural or algorithmic novelty in the proposal which specializes this technique for program induction as opposed to general meta learning/ k-shot learning .",
    "NOVELTY"
  ],
  [
    "Although the proposed idea is quite interesting",
    "NOVELTY"
  ],
  [
    "The proposed SGLD-SA algorithm , together with its convergence properties , is very interesting .",
    "NOVELTY"
  ],
  [
    "It seems that this paper only introduced Bayesian inference in the output layers .",
    "NOVELTY"
  ],
  [
    "Hierarchical recommendation algorithms are not new to the community",
    "NOVELTY"
  ],
  [
    "This mechanism while novel",
    "NOVELTY"
  ],
  [
    ", feels a bit clunky and awkward",
    "NOVELTY"
  ],
  [
    "In terms of contributions , the proposal consists essentially of combining previous proposed ideas to obtain further advances",
    "NOVELTY"
  ],
  [
    "and provides a novel solution",
    "NOVELTY"
  ],
  [
    "The paper is complete in that it tackles an important problem , provides a novel solution",
    "NOVELTY"
  ],
  [
    "while this paper can be improved in some key ways",
    "NOVELTY"
  ],
  [
    "it does make an interesting contribution",
    "NOVELTY"
  ],
  [
    "the results here might not come as a complete surprise",
    "NOVELTY"
  ],
  [
    "the contribution on collaborator selection is interesting",
    "NOVELTY"
  ],
  [
    "Usage of bounding and nested batches are clever ideas 3",
    "NOVELTY"
  ],
  [
    "The technique is as far as I can tell novel , and does seem to represent an improvement over existing approaches for similar multi-bit quantization strategies .",
    "NOVELTY"
  ],
  [
    "From machine learning perspective , the novelty of this work is limited .",
    "NOVELTY"
  ],
  [
    "I have some significant reservations about the novelty and the technical content . The proposed model does n't quite bring anything new to the table .",
    "NOVELTY"
  ],
  [
    "Although there are some valid concerns",
    "NOVELTY"
  ],
  [
    "and provides an interesting approach to the task .",
    "NOVELTY"
  ],
  [
    ", however seem to be of rather minor novelty .",
    "NOVELTY"
  ],
  [
    "The paper claims two main novelties : ( 1 ) conic convolutions and ( 2 ) using the DFT magnitude for rotation invariant classification in the context of CNNs .",
    "NOVELTY"
  ],
  [
    "While ( 1 ) seems novel , the",
    "NOVELTY"
  ],
  [
    "Novelty ( 2 ) is only because it has n't been used in the context of CNNS , but there is no technical novelty here .",
    "NOVELTY"
  ],
  [
    "The topic of the paper is novel and interesting",
    "NOVELTY"
  ],
  [
    "this contribution seems to be rather limited .",
    "NOVELTY"
  ],
  [
    "In general , I think that the contributions of the paper are relevant and original .",
    "NOVELTY"
  ],
  [
    "Most of the theoretical results ( proposition 1 and 2 ) are not original as they follow directly from previous work on the tree OT metrics .",
    "NOVELTY"
  ],
  [
    "Since it is already extensively known that autoregressive CNNs and attentional models can achieve this , the *CNN* part of the paper can not be counted as a novel contribution .",
    "NOVELTY"
  ],
  [
    "I really like the interaction between Bayesian machine learning and temporal logics in the paper",
    "NOVELTY"
  ],
  [
    "This paper is original to the best of my knowledge in the sense that the concept space is a finite subset of well formed formulas of a Modal logic ( LTL ) consisting of three proposed",
    "NOVELTY"
  ],
  [
    "structures as well as the proposal of three distinctly different but suitable priors used for the inference which are also empirically investigated",
    "NOVELTY"
  ],
  [
    "I deem the contributions significant and novel .",
    "NOVELTY"
  ],
  [
    "the idea to optimize the upper bound for the latent model seems new and interesting .",
    "NOVELTY"
  ],
  [
    "The derivation of the dual formulation is novel - The dual formulation simplifies adversarial training",
    "NOVELTY"
  ],
  [
    "hence the novelty of the proposed method is in doubt",
    "NOVELTY"
  ],
  [
    "The adversarial examples that the authors construct , experimentally , are impressive and striking .",
    "NOVELTY"
  ],
  [
    "a new approach to the NetTrim algorithm , which is somewhat original , and a new generalization bound for the algorithm .",
    "NOVELTY"
  ],
  [
    "I like the linear system perspective on the update rule of temporal difference learning .",
    "NOVELTY"
  ],
  [
    "Overall I like the perspective provided by paper .",
    "NOVELTY"
  ],
  [
    "and I do like the idea and its presentation in this paper .",
    "NOVELTY"
  ],
  [
    "The method is a nice variation on the normalizing flows idea .",
    "NOVELTY"
  ],
  [
    "I think this is an interesting idea that has a lot of potential",
    "NOVELTY"
  ],
  [
    "While I find the problem and the solutions interesting and somehow novel",
    "NOVELTY"
  ],
  [
    "novel assumption of linear reward and consumption generation",
    "NOVELTY"
  ],
  [
    "The idea of using adversarial subspaces to characterize a task is a novel idea which seems to work to some degree .",
    "NOVELTY"
  ],
  [
    "while the proposed model seems novel",
    "NOVELTY"
  ],
  [
    "for",
    "NOVELTY"
  ],
  [
    "The idea is very inspiring in the paper .",
    "NOVELTY"
  ],
  [
    "The new technique is conceptually interesting .",
    "NOVELTY"
  ],
  [
    "the paper is conceptually interesting and",
    "NOVELTY"
  ],
  [
    "but seems incremental over Russo and Van Roy .",
    "NOVELTY"
  ],
  [
    "The idea and the theoretical results are interesting .",
    "NOVELTY"
  ],
  [
    "The idea is good and novel .",
    "NOVELTY"
  ],
  [
    "this is indeed the first work for handling this task using binding-unbinding mechanism .",
    "NOVELTY"
  ],
  [
    "While the idea for obtaining a variational upper bound on the generative mutual information is novel and clever",
    "NOVELTY"
  ],
  [
    "The paper suggests what appears to be a nice framework and simple procedure for controlling the information flow in a GAN",
    "NOVELTY"
  ],
  [
    "the paper offers what appears to be a very clever idea",
    "NOVELTY"
  ],
  [
    "I think this is a very interesting theory paper .",
    "NOVELTY"
  ],
  [
    "the idea of channel pruning has been extensively studied in previous works , and the channel pruning search algorithm is very similar previous one-shot NAS framework",
    "NOVELTY"
  ],
  [
    "In terms of technical novelty , the work is relatively incremental :",
    "NOVELTY"
  ],
  [
    "the two claimed contributions of the paper",
    "NOVELTY"
  ],
  [
    "the paper doesn \u2019 t really attempt to make major technical contribution",
    "NOVELTY"
  ],
  [
    "I am not totally convinced when it comes to the value of the actual novel aspects of this paper . Much of the empirical analysis of experience replay",
    "NOVELTY"
  ],
  [
    "etc\u2026 ) was not surprising or particular novel in my eyes .",
    "NOVELTY"
  ],
  [
    "As far as I know the idea proposed is original and very useful to alleviate",
    "NOVELTY"
  ],
  [
    "Interesting idea .",
    "NOVELTY"
  ],
  [
    "it seems novel to adapt the idea of DIP for defining complex latent space .",
    "NOVELTY"
  ],
  [
    "This paper is",
    "NOVELTY"
  ],
  [
    "definitely ``",
    "NOVELTY"
  ],
  [
    "groundbreaking `` in that it makes a true extension to the existing literature",
    "NOVELTY"
  ],
  [
    "The extensions from single agent to multi-agent are natural , but also non-trivial , and it seems like this is a genuinely novel piece of work that can be interesting to both side ( exploration and multi-agent ) .",
    "NOVELTY"
  ],
  [
    "This work appears to be a first of its kind .",
    "NOVELTY"
  ],
  [
    "Generating CNN filters conditioned on other feature is not new for video generation",
    "NOVELTY"
  ],
  [
    "While I agree with the other reviewers that the individual parts of the idea are not new",
    "NOVELTY"
  ],
  [
    ", I find the combination elegant -",
    "NOVELTY"
  ],
  [
    "a whole that is greater than the sum of its parts",
    "NOVELTY"
  ],
  [
    "To my knowledge , a multi-output GP model capable ( in principle ) of handling any type and number of outputs has not been proposed before .",
    "NOVELTY"
  ],
  [
    "the current model design andinference algorithm are okay but do n't constitute major technical contributions .",
    "NOVELTY"
  ],
  [
    "As it stands , I think the contributions of this paper is limited",
    "NOVELTY"
  ],
  [
    "There is no new theoretical development . * the elements of the neural network architecture are not new/novel and",
    "NOVELTY"
  ],
  [
    "I could not tell if there is any novelty on this part of the paper and it seems that the only difference between this paper and Sengupta and Qian",
    "NOVELTY"
  ],
  [
    "The technical approach is not particularly novel .",
    "NOVELTY"
  ],
  [
    "The local reprarametrisation trick it self is not new and applying it to a multinomial distribution ( with one repetition ) instead of a Gaussian is straight forward ,",
    "NOVELTY"
  ],
  [
    "but its application for learning discrete networks is to my best knowledge novel and interesting",
    "NOVELTY"
  ],
  [
    "Though Mirror Descent is not their original",
    "NOVELTY"
  ],
  [
    "idea , but using it in the context of learning quantized network is novel and interesting .",
    "NOVELTY"
  ],
  [
    "As someone not super familiar with NN quantization , this work seems like a good contribution .",
    "NOVELTY"
  ],
  [
    "The idea of calculating the shift ( i.e the flow ) of the feature maps that are optimised for action recognition is interesting .",
    "NOVELTY"
  ],
  [
    "but the contribution in the paper seems to claim similar contribution to Sun et al in proposing the flow layer",
    "NOVELTY"
  ],
  [
    "5 .Flow-of-flow which is pushed from the abstract of the paper as novel , fails to produce valuable results towards the end .",
    "NOVELTY"
  ],
  [
    "It is not a breakthrough",
    "NOVELTY"
  ],
  [
    "but indeed provides",
    "NOVELTY"
  ],
  [
    "insights",
    "NOVELTY"
  ],
  [
    "However , to the best of our knowledge , these are some necessary simplifications , given current technical limit and significant lack of theoretical understanding of neural networks .",
    "NOVELTY"
  ],
  [
    "presenting real progress in the field",
    "NOVELTY"
  ],
  [
    "The architecture itself is not very different from commonly used DCGAN variants",
    "NOVELTY"
  ],
  [
    "To my best knowledge , the results are original",
    "NOVELTY"
  ],
  [
    "The methodologies of analysis belong to classical asymptotic statistics , but",
    "NOVELTY"
  ],
  [
    "the problem analyzed is new",
    "NOVELTY"
  ],
  [
    "The analysis provided advances the state of the art in a demonstrable way . The analysis is theoretically unique .",
    "NOVELTY"
  ],
  [
    "The idea of introducing relational knowledge into deep reinforcement learning algorithm is novel and timely considering the usefulness of relational representations .",
    "NOVELTY"
  ],
  [
    "The relational representation network using pairwise interaction itself is not novel and has been studied extensively",
    "NOVELTY"
  ],
  [
    "the improvements of the proposed method are marginal .",
    "NOVELTY"
  ],
  [
    "However , considering many other related work mentioned by the paper , the novelty in this paper is quite limited .",
    "NOVELTY"
  ],
  [
    "Exploiting the MAP-perturb approach for model parameter learning appears to be new and should have an impact to the field , as it essentially relies on established inference methods .",
    "NOVELTY"
  ],
  [
    "The proposed approach is somewhat novel and extends prior work on using shared replay buffers and asymmetric actor critic methods to accelerate training",
    "NOVELTY"
  ],
  [
    "The paper strengthens an existing condition and gives a tighter regret bound for CMAB-T problems .",
    "NOVELTY"
  ],
  [
    "and the proposed approach and the experimental results are interesting .",
    "NOVELTY"
  ],
  [
    "the approach itself is quite interesting",
    "NOVELTY"
  ],
  [
    "O2 .The use of measure theory is not new",
    "NOVELTY"
  ],
  [
    "but the connections to function approximation were interesting",
    "NOVELTY"
  ],
  [
    "Ring-GNN is a simple but interesting idea",
    "NOVELTY"
  ],
  [
    "Q1.1 I really liked the use of the CSL task",
    "NOVELTY"
  ],
  [
    "I would not say that the question being investigated is particularly original , nor is the basic framework of using order parameters and deriving ODEs for the evolution of these parameters",
    "NOVELTY"
  ],
  [
    "I would emphasize that using this approach to resolve questions regarding implicit regularization in SGD and quantify over-parameterization directly is a novelty",
    "NOVELTY"
  ],
  [
    "The paper is interesting and novel enough that despite the limitations , I am supportive of publishing it . It introduces new ideas that I find refreshing .",
    "NOVELTY"
  ],
  [
    "Using fast randomized numerical linear algebra techniques to provably and practically improve the performance of AdaGrad and AdaFull is a wonderful idea and this paper initiates what could be a very interesting",
    "NOVELTY"
  ],
  [
    "the particular algorithm and modifications they propose are quite natural and consequently it is difficult to pinpoint where the novelty in the approach is",
    "NOVELTY"
  ],
  [
    "Moderate novelty , network morphism is not novel",
    "NOVELTY"
  ],
  [
    ", applying it to architecture search is novel",
    "NOVELTY"
  ],
  [
    "However since theoretically it is not that novel",
    "NOVELTY"
  ],
  [
    "This is an original and significant contribution .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the proposed method is novel and its",
    "NOVELTY"
  ],
  [
    "Finally , the novelty from a deep learning perspective is limited .",
    "NOVELTY"
  ],
  [
    "and the results are novel .",
    "NOVELTY"
  ],
  [
    "the improvements of their method over the baseline ( II-KD ) seem marginal there",
    "NOVELTY"
  ],
  [
    "The approach is novel and interesting and while it is only verified in the paper for two Cloze-style tasks",
    "NOVELTY"
  ],
  [
    "Introducing this edge normalization is a novel contribution",
    "NOVELTY"
  ],
  [
    "Incremental novelty about channel sampling .",
    "NOVELTY"
  ],
  [
    "Doing edge normalization in the PC-DARTS is indeed novel",
    "NOVELTY"
  ],
  [
    "Proposed edge normalization is not a new sampling policy but a new search space .",
    "NOVELTY"
  ],
  [
    "It is completely reasonable to me the contribution of this paper is introducing a novel edge-normalization that is simple and effective to improve the DARTS based",
    "NOVELTY"
  ],
  [
    "This is a nice idea",
    "NOVELTY"
  ],
  [
    "Although the idea to train an ensemble of learning machines is not new , see e , .g",
    "NOVELTY"
  ],
  [
    "However , the contribution of this paper is very incremental .",
    "NOVELTY"
  ],
  [
    "Somewhat interesting combination of previous ideas",
    "NOVELTY"
  ],
  [
    "For these reasons , it seems like the paper combines several existing lines of work with limited novelty .",
    "NOVELTY"
  ],
  [
    "The application to Wasserstein distance is natural and also generalizes the `` sliced approximation `` of Wasserstein which uses 1-dimensional embeddings of the pointsets ( i.e. ,",
    "NOVELTY"
  ],
  [
    "The upside is that idea at the base of this paper , while simple , is nice",
    "NOVELTY"
  ],
  [
    "I do like the suggested approach and find it interesting .",
    "NOVELTY"
  ],
  [
    "The approach is an interesting mixture of the old and the new .",
    "NOVELTY"
  ],
  [
    "Some ideas seem very related to previous work in the literature",
    "NOVELTY"
  ],
  [
    "The idea",
    "NOVELTY"
  ],
  [
    "Though results are rather incremental for KITTI",
    "NOVELTY"
  ],
  [
    "This is an original work to my best knowledge .",
    "NOVELTY"
  ],
  [
    "However , consider the work is highly original and the high quality of the presented experiments",
    "NOVELTY"
  ],
  [
    "Overall , I found this paper quite interesting .",
    "NOVELTY"
  ],
  [
    "As someone who knows little about this",
    "NOVELTY"
  ],
  [
    "what 's novel",
    "NOVELTY"
  ],
  [
    "However , the matrix proposed in this paper is quite different from that used in existing methods .",
    "NOVELTY"
  ],
  [
    "The novelty here compared to existing works is that both the objective function and the truncation rule are new .",
    "NOVELTY"
  ],
  [
    "Originality The division of the input space and the analytical formulation of the gradient are interesting",
    "NOVELTY"
  ],
  [
    "the analysis framework relies on novel but reasonable distribution assumptions",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge , the proposed algorithm is new in this area .",
    "NOVELTY"
  ],
  [
    "I think there is some significant contribution in this paper .",
    "NOVELTY"
  ],
  [
    "much of the interpretation is a simple extension of the previously proposed interpretation of dropout in feedforward case",
    "NOVELTY"
  ],
  [
    "and can hardly be considered as a significant novelty , and the empirical novelty is also diminished because of the previous paper from Moon et al",
    "NOVELTY"
  ],
  [
    "To my knowledge this is the first paper that explores this view of fault-tolerance ( already established in other contexts ) .",
    "NOVELTY"
  ],
  [
    "but I believe this approach is novel .",
    "NOVELTY"
  ],
  [
    "The idea of considering the neighbourhoods of increasing size centred at individual vertices is not new .",
    "NOVELTY"
  ],
  [
    "the immediate impact of the approach may be limited",
    "NOVELTY"
  ],
  [
    "The idea of employing the discrete VAE framework to perform hashing-based collaborative filtering is interesting .",
    "NOVELTY"
  ],
  [
    "From the perspective of applications , I think it is somewhat novel .",
    "NOVELTY"
  ],
  [
    "The idea of using discrete VAE for hashing tasks has been explored before",
    "NOVELTY"
  ],
  [
    "The novelties of the model is limited .",
    "NOVELTY"
  ],
  [
    "The result is what seems to me to be a significant achievement and definitely a novel contribution .",
    "NOVELTY"
  ],
  [
    "Overall This paper represents a significant advance in the challenge problem of action-conditional video prediction .",
    "NOVELTY"
  ],
  [
    "My main concerns are the novelty .",
    "NOVELTY"
  ],
  [
    "The concept of pyramid network idea is not really new",
    "NOVELTY"
  ],
  [
    "the authors did not provide any discoveries concerning new",
    "NOVELTY"
  ],
  [
    "considering gradient information is not new",
    "NOVELTY"
  ],
  [
    "The presented theory seems to be well established and original .",
    "NOVELTY"
  ],
  [
    "The contributions and results of this paper are not significant",
    "NOVELTY"
  ],
  [
    "If that is the case , the paper does not have any original contribution .",
    "NOVELTY"
  ],
  [
    "The paper is original .",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is reduced to",
    "NOVELTY"
  ],
  [
    "this is actually the only technical contribution of the paper and the authors fail at emphasizing it .",
    "NOVELTY"
  ],
  [
    "however , this submission does not provide sufficient novel ideas .",
    "NOVELTY"
  ],
  [
    "1 .The proposed system is very similar to Eigen et al and Liu et al",
    "NOVELTY"
  ],
  [
    "From what I can tell , the observation that the adversarial perturbation is coupled with only the first layer and the exploitation of this to create the YOLO method is novel and an interesting contribution to the literature that could potentially inspire a lot of follow-up work .",
    "NOVELTY"
  ],
  [
    "Using random connections is not a new idea in CNNs .",
    "NOVELTY"
  ],
  [
    "Considering this , the novelty of this work is weakened .",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u00a2 Compared with previous space-time video modeling works",
    "NOVELTY"
  ],
  [
    "it is a nice extension of AmbientGAN",
    "NOVELTY"
  ],
  [
    "The local preference model of a learner in the machine teaching setting appears to be an interesting contribution to the field .",
    "NOVELTY"
  ],
  [
    "this paper has several important contributions , and the formalisms presented here open the door for others to work in this area",
    "NOVELTY"
  ],
  [
    "the MARNN architecture is interesting",
    "NOVELTY"
  ],
  [
    "The introduction and abstract over-sell the contribution of the paper .",
    "NOVELTY"
  ],
  [
    "The suggested model outperforms others on three QA",
    "NOVELTY"
  ],
  [
    "None of the suggested models are novel in themselves .",
    "NOVELTY"
  ],
  [
    "Overall , I find the overall approach quite incremental .",
    "NOVELTY"
  ],
  [
    "Even if similar techniques have been used previously in machine learning , the way in which the method is applied in here seems to be new .",
    "NOVELTY"
  ],
  [
    "The paper presents a clever idea that could help make SPENs more practical",
    "NOVELTY"
  ],
  [
    "the principal contribution of the sequence tagging experiments seems top be different than what is advertised earlier on in the paper .",
    "NOVELTY"
  ],
  [
    "So , currently , it does not seem to be a valid novel contribution in this work compared to previous works .",
    "NOVELTY"
  ],
  [
    "I think this is a high quality contribution",
    "NOVELTY"
  ],
  [
    "The idea seems to be novel to me .",
    "NOVELTY"
  ],
  [
    "The paper introduces a nice idea ,",
    "NOVELTY"
  ],
  [
    "The proposed framework is interesting and seems general for the factual visual question answering task .",
    "NOVELTY"
  ],
  [
    "the technical novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "the idea looks very original and promising",
    "NOVELTY"
  ],
  [
    "The formulation is novel and elegant",
    "NOVELTY"
  ],
  [
    "As far I can see , the formulation is novel .",
    "NOVELTY"
  ],
  [
    "the manuscript does not make any progress towards this",
    "NOVELTY"
  ],
  [
    "This concept is not new .",
    "NOVELTY"
  ],
  [
    "But to the best of my knowledge , this is the first paper that applies this concept to the open world classification task .",
    "NOVELTY"
  ],
  [
    "This is an extremely impressive piece of",
    "NOVELTY"
  ],
  [
    "The combination of GANs and knockoff filter is a very promising and intriguing idea . The use of the modified discriminator to ensure that the generated knockoffs satisfy the necessary swap condition is novel and intuitively sound .",
    "NOVELTY"
  ],
  [
    "and incorporating these ideas is a good start",
    "NOVELTY"
  ],
  [
    "The improvement over prior work seems to be relatively small ( but it is consistent across tasks ) .",
    "NOVELTY"
  ],
  [
    "I suppose one could argue that the close connection to existing methods means that this paper is not innovative enough .",
    "NOVELTY"
  ],
  [
    "I liked the idea of combining parts of two trajectories and to the best of my knowledge it is new .",
    "NOVELTY"
  ],
  [
    "Although the novelty of the method is not really impressive",
    "NOVELTY"
  ],
  [
    "My main concern with this paper is regarding the novelty",
    "NOVELTY"
  ],
  [
    "The authors seem to claim a novel GAN architecture by using an adversarial auto-encoder-based architecture .",
    "NOVELTY"
  ],
  [
    "This work is interesting and worth publishing in NIPS because it tackles the problem of rank selection for low-rank tensor approximation in a novel way ,",
    "NOVELTY"
  ],
  [
    "+ the proposed work is a nice application of an encoder-decoder architecture in case of multivariate time series Weaknesses",
    "NOVELTY"
  ],
  [
    "there is no methodological novelty",
    "NOVELTY"
  ],
  [
    "and lack of methodological novelty",
    "NOVELTY"
  ],
  [
    "I think this will be a much better contribution to the field with these additions",
    "NOVELTY"
  ],
  [
    "and their experimental methodology seems original",
    "NOVELTY"
  ],
  [
    "I think with more datasets and perhaps different model architectures , this can become a nice contribution to the field",
    "NOVELTY"
  ],
  [
    "I think this is a relatively trivial application of [ Hanin and Sellke , 2018 ] , and so does not contribute much to the body of ML knowledge",
    "NOVELTY"
  ],
  [
    "2 .The authors present conditions for consistency of their modified Mondrian Forest , which is novel .",
    "NOVELTY"
  ],
  [
    "The contribution of this work is",
    "NOVELTY"
  ],
  [
    "I think the contributions listed at the end of section 1 are incremental , as i. linear input and output warpings have been considered before in multiple contexts",
    "NOVELTY"
  ],
  [
    "Thus I think the proposed idea is a little bit incremental .",
    "NOVELTY"
  ],
  [
    "the contribution is quite limited and not particularly novel .",
    "NOVELTY"
  ],
  [
    "The mixture of subspaces extension is interesting",
    "NOVELTY"
  ],
  [
    "presented approach",
    "NOVELTY"
  ],
  [
    "The idea is novel and the paper is well-written",
    "NOVELTY"
  ],
  [
    "The approach is also clearly novel , and is interesting .",
    "NOVELTY"
  ],
  [
    "This in itself is a good idea",
    "NOVELTY"
  ],
  [
    ", but overall is an incremental improvement .",
    "NOVELTY"
  ],
  [
    "I found the additional analysis on the dynamic node embeddings insightful and it is reassuring that it confirms the claims",
    "NOVELTY"
  ],
  [
    "I currently don \u2019 t see this as a major contribution of this paper",
    "NOVELTY"
  ],
  [
    "the domain discriminator has certain novelty and can be applied to other methods",
    "NOVELTY"
  ],
  [
    "3 .The novelty of this paper is somewhat limited while missing some relevant works",
    "NOVELTY"
  ],
  [
    "While the notion of specialization has been studied previously , this specific formulation with its switching between two MOs ( 'model selecting sample ' and 'sample selecting model ' ) is new and is of significance to the ML community ,",
    "NOVELTY"
  ],
  [
    "Though not much studied , this topic is not new [ ref 1 ] ,",
    "NOVELTY"
  ],
  [
    "In terms of the methodology , the novelty is quite limited .",
    "NOVELTY"
  ],
  [
    "due to lack of novelty , I think this submission may not be qualified for acceptance at this moment",
    "NOVELTY"
  ],
  [
    "Even if the technical contribution is limited",
    "NOVELTY"
  ],
  [
    "As so , this is incremental work , although some hurdles have to be overcome in order to extend the results in this new setting .",
    "NOVELTY"
  ],
  [
    "The BCOP parametrization of gradient-norm preserving convolutional layers seems a novel application of previous work ( Xiao et al .2018 ) .The disconectedness result for 1-D convolutions adds to the understanding of the difficulty of the problem .",
    "NOVELTY"
  ],
  [
    "While not technically novel , the combined approach gives some insights in what works and",
    "NOVELTY"
  ],
  [
    "I think this paper introduces an interesting and novel approach for VQA",
    "NOVELTY"
  ],
  [
    "This is a elegant approach that naturally exploits the standard so-called cluster assumption in SSL .",
    "NOVELTY"
  ],
  [
    "the improvement of the model architecture is minor",
    "NOVELTY"
  ],
  [
    "`` ARAE `` This is a very nice paper with a clear idea",
    "NOVELTY"
  ],
  [
    ", and the proposed approach both novel and original .",
    "NOVELTY"
  ],
  [
    "unlike other",
    "NOVELTY"
  ],
  [
    "The contribution is a bit incremental compared to [ 4 ] , but there are clear differences , and the algorithms constructed go beyond what was possible through [ 4 ] .",
    "NOVELTY"
  ],
  [
    "I will now discuss the quality , clarity , originality , and significance of this work",
    "NOVELTY"
  ],
  [
    "This work is relatively original .",
    "NOVELTY"
  ],
  [
    "I 'm not certain how novel the proof techniques are",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel method for sampling examples for experience replay .",
    "NOVELTY"
  ],
  [
    "I do like the idea of the paper .",
    "NOVELTY"
  ],
  [
    "While this is a novel concept and interesting",
    "NOVELTY"
  ],
  [
    "The paper proposes a new feedback model which is new",
    "NOVELTY"
  ],
  [
    "However , the algorithmic idea and analysis is not new .",
    "NOVELTY"
  ],
  [
    "I think the feedback model they consider and the goal of the paper is novel .",
    "NOVELTY"
  ],
  [
    "The lack of significant novelty in theory is made up by the extensive experimental evaluation",
    "NOVELTY"
  ],
  [
    "Novel feedback model",
    "NOVELTY"
  ],
  [
    "it is not clear that the proposed methods improve over previous approaches",
    "NOVELTY"
  ],
  [
    "I also agree with the other reviewers that the paper in the present stage has not yet demonstrated sufficient technical contributions",
    "NOVELTY"
  ],
  [
    "SSD model , the novelty on each modification is limited",
    "NOVELTY"
  ],
  [
    "general , the proposed work is very interesting",
    "NOVELTY"
  ],
  [
    "I believe the central idea of the work is novel ,",
    "NOVELTY"
  ],
  [
    "Though the idea of using structural knowledge to directly shape the distribution of interpretable posteriors such as size and number of objects is novel",
    "NOVELTY"
  ],
  [
    "I am not so sure if this idea is generalizable enough",
    "NOVELTY"
  ],
  [
    "to warrant a major original contribution .",
    "NOVELTY"
  ],
  [
    "although the method proposed is clearly novel in someway and could be applied to a variety of tasks",
    "NOVELTY"
  ],
  [
    "Though I would love to see more concrete examples , I still think that the conceptual insights are novel enough to warrant an acceptance .",
    "NOVELTY"
  ],
  [
    "However , the novelty is very limited . To decouple the dependency between the head size and the embedding size is not a novel point .",
    "NOVELTY"
  ],
  [
    "Quality The paper proposes a novel , principled method for learning a non-autoregressive sequence model .",
    "NOVELTY"
  ],
  [
    "Significance This is an interesting model",
    "NOVELTY"
  ],
  [
    "The assumptions to aid the proof are very natural and much softer than the existing literature",
    "NOVELTY"
  ],
  [
    "As far as I \u2019 m concerned , the setting is very close to real deep neural networks and the paper is a breakthrough in the area .",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u009d The paper proposes a novel approach for transfer learning among tasks with subtle changes by adopting HiP-MDP .",
    "NOVELTY"
  ],
  [
    "1 .The new formulation seems interesting",
    "NOVELTY"
  ],
  [
    "seems to be a trivial borrowing of an existing idea in crowd sourcing from 1979 . It is not clear whether Section 4.2 ( error estimation ) is an original contribution or not , but even if it is original Lemma 1 seems marginally trivial .",
    "NOVELTY"
  ],
  [
    "Overall , I think the work is novel and interesting .",
    "NOVELTY"
  ],
  [
    "so it 's hard for me to think what 's new in the section",
    "NOVELTY"
  ],
  [
    "Currently , this paper tries to present interesting ideas without very deep investigations",
    "NOVELTY"
  ],
  [
    "However , the result is a bit incremental , and not really about learning",
    "NOVELTY"
  ],
  [
    "It is an interesting work but it is not sure that there is a difference in contribution when compared to previous work .",
    "NOVELTY"
  ],
  [
    "The core technical parts of the paper , Section 2.3 and Section 3 look like solid and novel contributions",
    "NOVELTY"
  ],
  [
    "and I think its quite interesting .",
    "NOVELTY"
  ],
  [
    "additional insight into this new algorithm",
    "NOVELTY"
  ],
  [
    "the technique is as far as I am aware novel",
    "NOVELTY"
  ],
  [
    "The general idea of architecture learning is clearly not novel but what really matters is an instantiation of the idea",
    "NOVELTY"
  ],
  [
    "I find the methodological contribution in the paper to be somewhat limited since the main idea of the model was initially proposed in the prior work (",
    "NOVELTY"
  ],
  [
    "The idea of using a nonparametric model for CL is interesting and can lead to follow-up work .",
    "NOVELTY"
  ],
  [
    "The combination of reward decomposition and distributional RL provides novelty and as demonstrated in the experimental section better agent performance by exploiting task structure",
    "NOVELTY"
  ],
  [
    "But I feel that the neat way in which the paper combines everything is very original .",
    "NOVELTY"
  ],
  [
    "but the careful computation of the variation bound is definitely novel",
    "NOVELTY"
  ],
  [
    "The authors proposed a novel method for positive-unlabeled learning .",
    "NOVELTY"
  ],
  [
    "The main idea is simple and interesting .",
    "NOVELTY"
  ],
  [
    "Although the problem setting is quite different , the idea of this paper is partially similar to the importance weighting technique adopted in some recent domain adaptation methods",
    "NOVELTY"
  ],
  [
    "This paper makes novel contributions in the following",
    "NOVELTY"
  ],
  [
    "proposing a new dataset for nowcasting",
    "NOVELTY"
  ],
  [
    "This is novel up to my knowledge . The random matrix theory ( establishing the value of the overlap ) behind the work is interesting and non-trivial .",
    "NOVELTY"
  ],
  [
    "The main contributions and pros of the paper are 1",
    "NOVELTY"
  ],
  [
    "This is a very interesting paper and it suggests a novel way to think of `` implicit regularization `` .",
    "NOVELTY"
  ],
  [
    "Novelty .There is something new here , but not much .",
    "NOVELTY"
  ],
  [
    "From a theoretical perspective there is not much new .",
    "NOVELTY"
  ],
  [
    "Even though the method combines the previous general learning frameworks , the proposed algorithm for LEARNABLE CLUSTERING OBJECTIVE ( LCO ) is novel , and fits very well in this framework .",
    "NOVELTY"
  ],
  [
    "1 .This work seems to be the first to propose a convergent RL algorithm for MFG that is able to approximately find the mean-field equilibrium .",
    "NOVELTY"
  ],
  [
    "I thought that the paper presented some interesting ideas but amongst the many things discussed there is very little which is empirically gratified",
    "NOVELTY"
  ],
  [
    "To my knowledge , the ideas presented in the paper are original and hint at potentially interesting viewpoints of optimization .",
    "NOVELTY"
  ],
  [
    "The hierarchical setup , and the finding that successful learning here depends on the curriculum , is intriguing indeed .",
    "NOVELTY"
  ],
  [
    "I think it scores well on originality .",
    "NOVELTY"
  ],
  [
    "Though straightforward , the proposed framework for program synthesis is novel .",
    "NOVELTY"
  ],
  [
    "Although the idea of reparametrization itself is not new",
    "NOVELTY"
  ],
  [
    ", applying that for the purpose of training a binary or ternary network , and sample the pre-activations instead of weights is novel .",
    "NOVELTY"
  ],
  [
    "The taxonomy is clearly a novel valuable contribution .",
    "NOVELTY"
  ],
  [
    "is a nice paper with nice ideas",
    "NOVELTY"
  ],
  [
    "The rough approximation provided in Theorem 3.2 is interesting .",
    "NOVELTY"
  ],
  [
    "Weakness Although there is an impressive performance gain , the contribution of the paper seems to be marginal .",
    "NOVELTY"
  ],
  [
    "it is hard to say there is a contribution to the idea of sentence discriminator and sentence reader \u2014 people have used this framework for large-scale QA a lot",
    "NOVELTY"
  ],
  [
    "However , this contribution is marginal as well since its role is almost the same as sentence discriminator plus pretraining methods which have widely used already .",
    "NOVELTY"
  ],
  [
    ", the idea in the paper is similar to the methods that have widely used already .",
    "NOVELTY"
  ],
  [
    "The contributions of the paper seem good ,",
    "NOVELTY"
  ],
  [
    "but perhaps rather incremental , and not ground-breakingly novel . The paper advocates for the use of absolute discounting , and gives good arguments in favor , including theoretical properties and some experimental results . But the technique as such is n't especially novel ,",
    "NOVELTY"
  ],
  [
    "The core idea of mixing the latent spaces of two data samples is interesting and the results seem to indicate that it improves generalization",
    "NOVELTY"
  ],
  [
    "I regard the contribution as novel and exciting .",
    "NOVELTY"
  ],
  [
    "The idea is a good one and is great incremental research building on the top of previous ideas .",
    "NOVELTY"
  ],
  [
    "A novel end-to-end model for the task of machine comprehension rather than using hand-crafted features .",
    "NOVELTY"
  ],
  [
    "paper is a novel PAC-Bayesian risk bound",
    "NOVELTY"
  ],
  [
    "Though the originality of the work is somewhat weak",
    "NOVELTY"
  ],
  [
    "the problem setting is novel and I",
    "NOVELTY"
  ],
  [
    "and rather light in terms of novel ideas",
    "NOVELTY"
  ],
  [
    "The proof techniques are interesting .",
    "NOVELTY"
  ],
  [
    "The concept of cost-sensitive submodularity is interesting",
    "NOVELTY"
  ],
  [
    "However , I feel that the novelty of this paper is limited , and do not provide much new insights .",
    "NOVELTY"
  ],
  [
    "the paper has a clear contribution",
    "NOVELTY"
  ],
  [
    "This paper discovers some interesting properties of deep linear networks",
    "NOVELTY"
  ],
  [
    "The paper is an interesting combination of classical optimization and deep learning .",
    "NOVELTY"
  ],
  [
    "This submitted paper has several novelties that make the new contributions relevant to be presented in NIPS 2016.First of all",
    "NOVELTY"
  ],
  [
    "I would like to understand the technical novelty of the paper better .",
    "NOVELTY"
  ],
  [
    "ingredient is a novel algorithm for layer-wise adversarial ( re- ) training via convex relaxations .",
    "NOVELTY"
  ],
  [
    ".The proposed methodology seems original and novel .",
    "NOVELTY"
  ],
  [
    "Weakness The main drawback of the paper is the lack of novelty in proposed method .",
    "NOVELTY"
  ],
  [
    "While I do not think the experimental results offers new insights",
    "NOVELTY"
  ],
  [
    "The difference from the original AAE is rather small and straightforward , making the novelty mainly in the choice of task , focusing on discrete vectors and sequences .",
    "NOVELTY"
  ],
  [
    "My main concern is novelty .",
    "NOVELTY"
  ],
  [
    "again hardly a novel insight",
    "NOVELTY"
  ],
  [
    "2015 .While the paper introduces a new method with several small improvement over ( Papailiopoulos et al .2014 ) , the work remains overall incremental and the significance of the contribution from a technical point of view is limited .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel in disentangling the content and the view of objects in a GAN and training the GAN with pairs of objects .",
    "NOVELTY"
  ],
  [
    "Given state-of-the-art in this topic of regressions over networks , embedding the idea into a recurrent neural setting is novel ,",
    "NOVELTY"
  ],
  [
    "but only marginally so",
    "NOVELTY"
  ],
  [
    "The technical contribution is not enough .",
    "NOVELTY"
  ],
  [
    "the proposed method seems not significantly different from the architecture search method in [ 1 ]",
    "NOVELTY"
  ],
  [
    "Overall , this is a borderline contribution with some interesting motivation , original ideas",
    "NOVELTY"
  ],
  [
    "Original and well-motivated idea",
    "NOVELTY"
  ],
  [
    "clear",
    "NOVELTY"
  ],
  [
    "-- Method -- Methodology-wise , the novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "considering the limited novelty of methodology",
    "NOVELTY"
  ],
  [
    "The extension of Capacitron to existing methods such as",
    "NOVELTY"
  ],
  [
    "Application of learning models to RL is not novel",
    "NOVELTY"
  ],
  [
    "The idea of parameterizing an RL algorithm by goals is not particularly novel .",
    "NOVELTY"
  ],
  [
    "the notion of parameterizing the policy by the goal state is not particularly novel .",
    "NOVELTY"
  ],
  [
    "the goal necessarily is included as part of the state space -- -so the idea of GDQN is n't really that new",
    "NOVELTY"
  ],
  [
    "The idea seems interesting",
    "NOVELTY"
  ],
  [
    "The idea of taking advantage of von Mises-Fisher distributions is not novel in the context of DL/DNN research community .",
    "NOVELTY"
  ],
  [
    "However , as described in the paper , the incorporation of von Mises-Fisher for calculating loss function seems to be novel , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Overall , basically I like the idea of the proposed method .",
    "NOVELTY"
  ],
  [
    "Thought the attempt of this paper is interesting",
    "NOVELTY"
  ],
  [
    "This is a highly novel approach for fairness that is likely to have a great impact on machine learning . The paper is extremely interesting , very novel",
    "NOVELTY"
  ],
  [
    "The paper lacks novelty .",
    "NOVELTY"
  ],
  [
    "The possibility of recovering communities smaller than sqrt ( log n ) based on convex optimization is an appealing theoretical result .",
    "NOVELTY"
  ],
  [
    "It is a nice idea",
    "NOVELTY"
  ],
  [
    "Firstly , the idea of using RL to learn parse trees using downstream tasks is very interesting and novel .",
    "NOVELTY"
  ],
  [
    ", and presents a compelling innovation in the field of recurrent neural nets which has deep ties with the theory of frequency decomposition of time series data .",
    "NOVELTY"
  ],
  [
    "The phased input gate is an elegant idea , somewhat similar to considering the projection of a time series on a Fourier basis , which clearly improve the speed at which LSTMs can learn by considerably reducing the number of updates necessary and therefore allowing full propagation in time of gradients .",
    "NOVELTY"
  ],
  [
    ", straightforward yet innovative",
    "NOVELTY"
  ],
  [
    "The proposed method has clear advantages over prior work",
    "NOVELTY"
  ],
  [
    "Overall , a lot of the material in this manuscript did n't strike me as particularly deep or original .",
    "NOVELTY"
  ],
  [
    "so no novelty on the problem setting",
    "NOVELTY"
  ],
  [
    "Overall , I think this is a good paper that provides a novel way of looking at and solving problems in GANs .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper seems novel .",
    "NOVELTY"
  ],
  [
    "I think the most interesting contribution of this paper",
    "NOVELTY"
  ],
  [
    "optimization-physics connection",
    "NOVELTY"
  ],
  [
    "The Gaussian approximations and moment propagation approximations are clever and highly original",
    "NOVELTY"
  ],
  [
    "although the derivation is rather heuristic .",
    "NOVELTY"
  ],
  [
    "method is novel and nice",
    "NOVELTY"
  ],
  [
    "the contributions are substantial",
    "NOVELTY"
  ],
  [
    "The idea of using a latent mixture of Gaussian 's to variationally encode high-dimensional data is not new .",
    "NOVELTY"
  ],
  [
    "My only concern is novelty .",
    "NOVELTY"
  ],
  [
    "hypothesis",
    "NOVELTY"
  ],
  [
    "in spite of a few",
    "NOVELTY"
  ],
  [
    "discussed a relevent problem , and introduced a novel fix .",
    "NOVELTY"
  ],
  [
    "this paper has good contributions and worth to publish",
    "NOVELTY"
  ],
  [
    "For the first time in the literature , this paper proposed the concept of \u2018 label leaking",
    "NOVELTY"
  ],
  [
    "Originality The authors state the concept of deletion efficient learning is novel , and based on this it appears that the ideas presented in the paper are new . Also , the two algorithms appear to the best of my knowledge to be new variants of k-means .",
    "NOVELTY"
  ],
  [
    "and the proposed idea is novel and interesting",
    "NOVELTY"
  ],
  [
    "I general I think the idea of learning a conditional distribution to constrain the use of rules is an interesting and novel idea .",
    "NOVELTY"
  ],
  [
    "method which is not new",
    "NOVELTY"
  ],
  [
    "All though none of these ideas are new , they haven \u2019 t been combined in this way before",
    "NOVELTY"
  ],
  [
    "I like the basic idea of this work and it seems that the authors have successfully modified the model designed for a somewhat artificial bAbI task and managed to show strong performance on the more real VQA task",
    "NOVELTY"
  ],
  [
    "are already in largescale use",
    "NOVELTY"
  ],
  [
    "This paper is original .",
    "NOVELTY"
  ],
  [
    "at this stage the",
    "NOVELTY"
  ],
  [
    "This is a nice addition to existing graph embedding algorithms which are either unsupervised or only consider a single label type for semi-supervised learning tasks .",
    "NOVELTY"
  ],
  [
    "I feel the idea of this paper is interesting",
    "NOVELTY"
  ],
  [
    "a novel idea of utilizing a set of priors",
    "NOVELTY"
  ],
  [
    "The software",
    "NOVELTY"
  ],
  [
    "and makes a significant contribution",
    "NOVELTY"
  ],
  [
    "of deep learning because of the unique structure of the data --",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "The idea is novel",
    "NOVELTY"
  ],
  [
    "The proposed 2-Component shared embedding is a very interesting and neat idea",
    "NOVELTY"
  ],
  [
    "Overall , the paper is a novel paper and with clear motivation",
    "NOVELTY"
  ],
  [
    "Such a nonconvex optimization approach and its landscape analysis are novel and interesting .",
    "NOVELTY"
  ],
  [
    "The model is novel and makes good use of both statistical and biophysical models .",
    "NOVELTY"
  ],
  [
    "The idea presented in the paper is interesting and original .",
    "NOVELTY"
  ],
  [
    "While searching for adversarial examples in the embedding space is not something new",
    "NOVELTY"
  ],
  [
    "The paper has a really cool theoretical contribution",
    "NOVELTY"
  ],
  [
    "The connection of CNNs to latent structural SVM is interesting",
    "NOVELTY"
  ],
  [
    "the transferring of ideas between these two camps",
    "NOVELTY"
  ],
  [
    "3 .The `` gradient coherence `` in the paper is not new .",
    "NOVELTY"
  ],
  [
    "branching and gating is not new [ 3 ] [ 4 ] .",
    "NOVELTY"
  ],
  [
    "This",
    "NOVELTY"
  ],
  [
    "It is not clear to me if there are any novel technical ideas in the proofs",
    "NOVELTY"
  ],
  [
    ", but the idea of studying the SQ complexity of neural networks in order to obtain lower bounds for a more realistic class of nets is ( as far as I can tell ) novel and clever .",
    "NOVELTY"
  ],
  [
    "the proposed model is interesting and relevant",
    "NOVELTY"
  ],
  [
    "I find the paper very interesting .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this is the first work that combines predefined and generic representations with modern CNN architectures achieving competitive performance to high performing approaches .",
    "NOVELTY"
  ],
  [
    "2017 .Especially the idea of approximating a complex model with a less complex one is not new .",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u009d Overall I think the paper proposes and evaluates a novel idea in a satisfactory way",
    "NOVELTY"
  ],
  [
    "Ultimately I think the idea in the paper is novel and has potential .",
    "NOVELTY"
  ],
  [
    "There is not enough novelty with the proposed method .",
    "NOVELTY"
  ],
  [
    "Although the used technique IBP is not new",
    "NOVELTY"
  ],
  [
    "although not novel",
    "NOVELTY"
  ],
  [
    "2 .MS MARCO dataset has novel useful characteristics compared to existing reading comprehension datasets \u2013",
    "NOVELTY"
  ],
  [
    "Overall I find the results of the paper as interesting contributions to trend filtering literature and I recommend to accept the paper",
    "NOVELTY"
  ],
  [
    "The idea is good",
    "NOVELTY"
  ],
  [
    "I feel that the originality of the paper is thus severely undermined .",
    "NOVELTY"
  ],
  [
    "The main concern of the package is on novelty .",
    "NOVELTY"
  ],
  [
    "While the novelty is not very large",
    "NOVELTY"
  ],
  [
    "it seems like a solid step in an interesting direction",
    "NOVELTY"
  ],
  [
    "This paper is novel in its modelling of hyperparameter optimisation with DPP",
    "NOVELTY"
  ],
  [
    "the novelty and the significance of the other contributions are limited",
    "NOVELTY"
  ],
  [
    "this feels like a somewhat significant contribution that introduces some new ideas to resolve an open question",
    "NOVELTY"
  ],
  [
    "I fail to see the significance nor the novelty",
    "NOVELTY"
  ],
  [
    "The paper provides a couple of novel insights",
    "NOVELTY"
  ],
  [
    "The idea of parameter sharing is not novel",
    "NOVELTY"
  ],
  [
    "however , this paper designs a series of novel variants of the standard building blocks",
    "NOVELTY"
  ],
  [
    "The problem considered in this paper has not been extensively studied yet .",
    "NOVELTY"
  ],
  [
    "It is very nice to motivate the problem with an",
    "NOVELTY"
  ],
  [
    "One downside though is that the techniques seem a straightforward extension of existing ones .",
    "NOVELTY"
  ],
  [
    "In total , the techinical novelty of the paper is very limited , as it mostly brings together ideas from the literature .",
    "NOVELTY"
  ],
  [
    "it does not have neither a groundbreaking idea , a groundbreaking application nor a groundbreaking theory .",
    "NOVELTY"
  ],
  [
    "The improvement to BFP is refreshing .",
    "NOVELTY"
  ],
  [
    "The paper does not provide a substantial amount of new results",
    "NOVELTY"
  ],
  [
    "A novel idea that is fairly well conveyed .",
    "NOVELTY"
  ],
  [
    "While the RWA was an interesting idea with bad results",
    "NOVELTY"
  ],
  [
    "the paper is clearly written and adding discount to RWA , while a small change , is original .",
    "NOVELTY"
  ],
  [
    "this paper",
    "NOVELTY"
  ],
  [
    "Also , it introduces novel ways of parameterizing the inference network by constructing a variational approximation over the noise term rather than the state",
    "NOVELTY"
  ],
  [
    "This paper 's main contribution of recall-precision balanced topic model is quite original , as",
    "NOVELTY"
  ],
  [
    "no other",
    "NOVELTY"
  ],
  [
    "topic model",
    "NOVELTY"
  ],
  [
    "tries to balance recall and precision",
    "NOVELTY"
  ],
  [
    "The actual technique presented is not original , but an application of the standard ESN approach .",
    "NOVELTY"
  ],
  [
    ") , though even then I would probably miss some originality in the approach .",
    "NOVELTY"
  ],
  [
    "Using expected curvature is a pretty interesting idea",
    "NOVELTY"
  ],
  [
    "This paper is reasonably clear originality : This paper is original .",
    "NOVELTY"
  ],
  [
    "The high-level idea also looks interesting .",
    "NOVELTY"
  ],
  [
    "However , the aggregation techniques are not novel contributions but augmentation to the RNN architecture .",
    "NOVELTY"
  ],
  [
    "The idea of leveraging generative models ' knowledge of `` maps `` to perform visual localization is interesting .",
    "NOVELTY"
  ],
  [
    "The reviewer does not find enough novelty from the proposed model , which is an iterative improvement on GQNs .",
    "NOVELTY"
  ],
  [
    "the reviewer does not find enough novelty from any aspects except the idea of utilizing a generative model for visual localization with implocitly learned maps",
    "NOVELTY"
  ],
  [
    "However , the paper does not propose to solve a novel problem , nor does it present a very novel method .",
    "NOVELTY"
  ],
  [
    "Although the idea of using existing generative networks for localization is interesting",
    "NOVELTY"
  ],
  [
    "The problem formalisation is interesting and , as far as I know , novel .",
    "NOVELTY"
  ],
  [
    "I think that the contributions of the paper are rather marginal .",
    "NOVELTY"
  ],
  [
    "The questions proposed in the paper are interesting and novel .",
    "NOVELTY"
  ],
  [
    "It present a novel approach that can potentially be of interest to many practitioners .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is sufficient .",
    "NOVELTY"
  ],
  [
    "I think that contributions of the paper are good enough to accept the paper .",
    "NOVELTY"
  ],
  [
    "but it seems like a small variation from existing work in the area",
    "NOVELTY"
  ],
  [
    "it is theoretically interesting",
    "NOVELTY"
  ],
  [
    "this",
    "NOVELTY"
  ],
  [
    "I think that the technical contribution is interesting .",
    "NOVELTY"
  ],
  [
    "Given the existing work ( Goel et al .2018 ) , I am concerned that the current work is a bit incremental .",
    "NOVELTY"
  ],
  [
    "While the theoretical novelty of the method is limited",
    "NOVELTY"
  ],
  [
    "the algorithm design is a bit different from traditional AdaGrad as their H matrix is the historical average of all past gradient square",
    "NOVELTY"
  ],
  [
    "The authors describe a novel approach for dealing with adversarial examples from a security standpoint -- namely",
    "NOVELTY"
  ],
  [
    "-- The novelty of the work is questionable . While the development is different , the final example for equivarification of a neural network is very similar to the existing works by Cohen and Welling .",
    "NOVELTY"
  ],
  [
    "While this relation between regularization and stability is not new in optimization/statistics",
    "NOVELTY"
  ],
  [
    "it seems to be invoked with proofs in this specific application for the first time",
    "NOVELTY"
  ],
  [
    "The numerical algorithm is",
    "NOVELTY"
  ],
  [
    "a minor variation of previously proposed Wasserstein GAN algorithms",
    "NOVELTY"
  ],
  [
    "SIGNIFICANCE The paper does not provide a strikingly new point",
    "NOVELTY"
  ],
  [
    "but it \u2019 s novelty is low .",
    "NOVELTY"
  ],
  [
    "because the dataset seems easy and the improvements over previous works is small",
    "NOVELTY"
  ],
  [
    "After",
    "NOVELTY"
  ],
  [
    "Novelty is fairly low . The changes in SEGNN compared to previous works are incremental or not novel , and the overall idea is the same as AlphaGo/Zero .",
    "NOVELTY"
  ],
  [
    "\u2014\u2014\u2014 Although finding a connection between two seemingly distinct phenomena is novel and interesting",
    "NOVELTY"
  ],
  [
    "This is an interesting model that nicely extends work in this area .",
    "NOVELTY"
  ],
  [
    "Using regression to map the latent variables to the extrinsic variables is a nice approach",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "While previously explored in Machine Translation , the turbo-learning approach of joint training caption and image generation is novel and interesting .",
    "NOVELTY"
  ],
  [
    "To our knowledge , the idea of reformulation of the problem and the proposed benchmarks is new .",
    "NOVELTY"
  ],
  [
    "and makes novel contributions to the analysis of the energy landscape of neural networks",
    "NOVELTY"
  ],
  [
    "The construction of the family of subgraph is novel and may find applications elsewhere .",
    "NOVELTY"
  ],
  [
    "in terms of technical novelty and empirical evidence the paper can be further improved",
    "NOVELTY"
  ],
  [
    "but I",
    "NOVELTY"
  ],
  [
    "but again somewhat derived from previous works",
    "NOVELTY"
  ],
  [
    "of the resulting complexities .",
    "NOVELTY"
  ],
  [
    "is a good and pioneered work on the binary network",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    "I believe the approach is a good , interesting idea .",
    "NOVELTY"
  ],
  [
    "The method for regularizing the samples is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "steps involves careful engineering and for each there are some minor novel components .",
    "NOVELTY"
  ],
  [
    "Although the model itself is not very novel",
    "NOVELTY"
  ],
  [
    "it seems",
    "NOVELTY"
  ],
  [
    "although the approach itself is not very novel as pointed out by R4 -- copy mechanisms have been used for sequence to sequence models",
    "NOVELTY"
  ],
  [
    "To my knowledge , the phenomenon that only a few parameters are important has been observed before by many papers",
    "NOVELTY"
  ],
  [
    "The idea of using decoy images is interesting",
    "NOVELTY"
  ],
  [
    "but computationally expensive",
    "NOVELTY"
  ],
  [
    ", novel ( to the best of my knowledge ) , and would be of interest to those in the community who work on point processes .",
    "NOVELTY"
  ],
  [
    "novelty is well beyond the NIPS level .",
    "NOVELTY"
  ],
  [
    "the results are novel .",
    "NOVELTY"
  ],
  [
    "However , the novelty is not very big compared ,",
    "NOVELTY"
  ],
  [
    "and with a solid contribution",
    "NOVELTY"
  ],
  [
    "The presented algorithm and its accompanied guaranteed convergence are indeed very interesting .",
    "NOVELTY"
  ],
  [
    "which introduces an interesting new method for multi-agent RL",
    "NOVELTY"
  ],
  [
    "- interesting application of attention mechanism to multi-agent RL",
    "NOVELTY"
  ],
  [
    "The novelty is hard to define .",
    "NOVELTY"
  ],
  [
    "The proposed approach is rather incremental and lacks novelty .",
    "NOVELTY"
  ],
  [
    "with very limited new methodological or algorithm contributions",
    "NOVELTY"
  ],
  [
    "I found it insightful and would happily read a paper such as this one that would analysis/proves this",
    "NOVELTY"
  ],
  [
    "While the idea of moving the processing for machine learning into silicon contained within the ( SSD ) data storage devices is intriguing and offers the potential for low-power efficient computation",
    "NOVELTY"
  ],
  [
    "but they give novel tasks they made even without comparing with previous works",
    "NOVELTY"
  ],
  [
    "the general idea",
    "NOVELTY"
  ],
  [
    "is nice",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "The method it proposes is also a na\u00efve extension of existing methods . Both the problem setting and the technique does not have novelty .",
    "NOVELTY"
  ],
  [
    "The motivated problem is not new .",
    "NOVELTY"
  ],
  [
    "One of the key contributions of this paper is a novel algorithm .",
    "NOVELTY"
  ],
  [
    "The discussion on the forgetting-reversibility tradeoff , albeit hampered by the confusing example ( see below ) , is insightful and may inspire additional research directions .",
    "NOVELTY"
  ],
  [
    "Throughout this work , there is no any insight technical contribution .",
    "NOVELTY"
  ],
  [
    "The technical contribution is limited . Throughout this work , there is no any insight technical contribution in terms of either algorithm or framework .",
    "NOVELTY"
  ],
  [
    "However , this work seems like an incremental improvement over Hazan et al 2018 . To this regard , the only novelty that was the framing of One-shot NAS as a recovery of boolean functions from their sparse Fourier expansions is not new either .",
    "NOVELTY"
  ],
  [
    "I think the proposed method is interesting",
    "NOVELTY"
  ],
  [
    "However , the conceptual idea of feedforward anticipation of a reflex controller is interesting enough to me that I was pleased with the paper",
    "NOVELTY"
  ],
  [
    "Interesting idea for bringing some benefits of graphical models into Neural Networks using a regularizer",
    "NOVELTY"
  ],
  [
    "For the machine learning perspective , the paper does not really provide a significant contribution as it applies standard GP regression .",
    "NOVELTY"
  ],
  [
    "However , none of these components seem actually new as they use",
    "NOVELTY"
  ],
  [
    "The result itself may not be super novel as noted in the related work but it 's still a strict improvement over previous results which is often constrained to ReLU activation function",
    "NOVELTY"
  ],
  [
    "The idea is novel , the paper",
    "NOVELTY"
  ],
  [
    "I found the paper interesting",
    "NOVELTY"
  ],
  [
    "and novel",
    "NOVELTY"
  ],
  [
    "It combines the recent methods and improves them in an interesting direction .",
    "NOVELTY"
  ],
  [
    "I like the idea of generally approximating gradients in more specific layers that are usually not easy to compute .",
    "NOVELTY"
  ],
  [
    "I like the approach as the paper improves on a previous method D-Learner and is able to combine different SSL strategies ,",
    "NOVELTY"
  ],
  [
    "using adaptations to entropy regularisation rule .",
    "NOVELTY"
  ],
  [
    "the technical contributions of the paper are limited . Adaptive basis functions and their sparse combinations are decades old ideas",
    "NOVELTY"
  ],
  [
    "While the application of these ideas to few shot regression does appear to be novel",
    "NOVELTY"
  ],
  [
    "this combination don \u2019 t seem to provide an obvious improvement over existing alternatives .",
    "NOVELTY"
  ],
  [
    "and novel",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "I am worried about the ability of VAE in generating novel images",
    "NOVELTY"
  ],
  [
    "this seems to be a well-written and novel contribution .",
    "NOVELTY"
  ],
  [
    "There are two novelties with this criterion",
    "NOVELTY"
  ],
  [
    "This is a very interesting paper , with multiple complementary ideas . It advocates model-based active exploration ( model learning + seeking regions of uncertainty ) . Instead of doing this in raw state space , it proposes a method for abstracting states to symbols based on factoring and clustering the state space . The exploration is then done by MCTS-planning in a ( sampled ) symbolic model . The task setup evaluates pure exploration ( ignoring all rewards ) on a two different domains . This approach to unsupervised hierarchical reinforcement learning is novel and ambitious",
    "NOVELTY"
  ],
  [
    "Finally",
    "NOVELTY"
  ],
  [
    "the novelty in extending Capsule Networks to a siamese architecture is arguably pretty incremental .",
    "NOVELTY"
  ],
  [
    "Novelty is incremental",
    "NOVELTY"
  ],
  [
    "However , the novelty of this contribution is limited and may not meet the publication standard of ICLR .",
    "NOVELTY"
  ],
  [
    "Technically , there are three novel contributions",
    "NOVELTY"
  ],
  [
    "but incremental .",
    "NOVELTY"
  ],
  [
    "By listing these theoretical and technical contributions , overall I find that most of these contributions are incremental and not significant enough for ICLR .",
    "NOVELTY"
  ],
  [
    "One of the arguments is that the work presented in this paper is a great success in engineering but it lacks technical novelty and therefore can not be accepted by the conference",
    "NOVELTY"
  ],
  [
    "Novelty w.r.t .works tackling catastrophic forgetting , most notably EWC , is minimal .",
    "NOVELTY"
  ],
  [
    "there is no inherent difference , between EWC and the proposed algorithm",
    "NOVELTY"
  ],
  [
    "However , my feeling is that the paper falls short in terms of making sufficient new contributions for an ICLR paper .",
    "NOVELTY"
  ],
  [
    "The key contribution one looks for is in terms of new insights on why and when each approach works",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "the novelty and technical contributions are limited .",
    "NOVELTY"
  ],
  [
    "The novelty and technical contributions are limited .",
    "NOVELTY"
  ],
  [
    "There are few if any valuable ideas in the field of evolutionary computing and I am glad to see the authors use sensible gradient-based learning for GPO",
    "NOVELTY"
  ],
  [
    "It seems that the proposed algorithm is not very original because its two parts",
    "NOVELTY"
  ],
  [
    "The main novelty with this paper is the proposed SGR algorithm and associated theory",
    "NOVELTY"
  ],
  [
    "I like this paper , I think it\u00e2\u0080\u0099s a",
    "NOVELTY"
  ],
  [
    "However , the new bounds proposed ( Theorem 1 , Theorem 6 ) , seem like small improvements over the previously proposed bounds , with no other novel interpretations or insights into deep architectures .",
    "NOVELTY"
  ],
  [
    "The improvement on Zaslavsky 's theorem is interesting",
    "NOVELTY"
  ],
  [
    "and makes some interesting points",
    "NOVELTY"
  ],
  [
    "it presently is n't a significant enough contribution to warrant acceptance .",
    "NOVELTY"
  ],
  [
    "Using multiple steps is however not novel .",
    "NOVELTY"
  ],
  [
    "I find the ideas presented in this paper very interesting .",
    "NOVELTY"
  ],
  [
    "Many of the ideas presented are novel .",
    "NOVELTY"
  ],
  [
    "and as such constitutes a large advance in this nascent area of machine learning .",
    "NOVELTY"
  ],
  [
    "but I do n't think there was enough novel content in this paper to justify acceptance to ICLR",
    "NOVELTY"
  ],
  [
    "the paper is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "The impact of its contribution is limited .",
    "NOVELTY"
  ],
  [
    "The approach is interesting and natural .",
    "NOVELTY"
  ],
  [
    "etc ... The proposed method is interesting and has a lot of potential .",
    "NOVELTY"
  ],
  [
    "The paper introduces a novel slice-based programming abstraction .",
    "NOVELTY"
  ],
  [
    "The ideas in the paper are simple and original .",
    "NOVELTY"
  ],
  [
    "All these ideas seem quite original and might inspire other avenues of research along the same path .",
    "NOVELTY"
  ],
  [
    "the originality of the approach remains welcome .",
    "NOVELTY"
  ],
  [
    "While the proposed schemes of novel inlier-ness score ( weighted sum vs. max route ) , novel regularization scheme and ensemble of less correlated neural decision trees are extremely interesting",
    "NOVELTY"
  ],
  [
    "and this paper presents a fresh look at a non-SMBO alternative",
    "NOVELTY"
  ],
  [
    "yet innovative and effective .",
    "NOVELTY"
  ],
  [
    "This idea of separating the learning of Q-values from the incorporation of adversarial defenses is promising .",
    "NOVELTY"
  ],
  [
    "Overall , although the algorithmic novelty is promising , it is relatively minor .",
    "NOVELTY"
  ],
  [
    "In addition , technical contributions of the paper are rather limited .",
    "NOVELTY"
  ],
  [
    "The novelty of each is limited .",
    "NOVELTY"
  ],
  [
    "To my best knowledge , this work seems to be the first work which firstly use first-order gradient to compute the negative-curvature for escaping saddle points .",
    "NOVELTY"
  ],
  [
    "such as Neon2 proposed by Allen-Zhu et al .So I think that this paper has very strong novelty and makes great contributions to optimization area , especially for escaping saddle points",
    "NOVELTY"
  ],
  [
    "Yet , the techniques for bounding each term seem borrowed and adapted from previous papers analyzing SGD for least-squares problems -related papers are adequately cited",
    "NOVELTY"
  ],
  [
    "but lack from real novel ideas",
    "NOVELTY"
  ],
  [
    "This is a great paper using optimal transport theory for generative and implicit models .",
    "NOVELTY"
  ],
  [
    "3 .The application is new",
    "NOVELTY"
  ],
  [
    ", since the previous flow models are all applied to generate synthetic images .",
    "NOVELTY"
  ],
  [
    "The 3rd issue is that the novelty for the novelty detection part in the proposed GAN seems quite incremental .",
    "NOVELTY"
  ],
  [
    "Novelty detection sounds very data mining rather than machine learning",
    "NOVELTY"
  ],
  [
    "I am not sure they are really novelty detection tasks because the real novelty detection tasks should be fully exploratory",
    "NOVELTY"
  ],
  [
    "Relatively unique problem ( but unusual",
    "NOVELTY"
  ],
  [
    "and unintuitive setup",
    "NOVELTY"
  ],
  [
    "Overall , I think this is a great idea .",
    "NOVELTY"
  ],
  [
    "The contribution in terms of designing R ( w ) and the logit pair loss function is trivial .",
    "NOVELTY"
  ],
  [
    "The discretization scheme presented seems remanescent of projection methods such as the one described in [ 1 ] .",
    "NOVELTY"
  ],
  [
    "Overall , this is a nice contribution that unifies some parallel lines of inquiry concerning explainability , and attention mechanism for different NLP tasks .",
    "NOVELTY"
  ],
  [
    "NLP tasks and the implications for explainability is interesting",
    "NOVELTY"
  ],
  [
    ", and nicely analyses this approach theoretically and empirically .",
    "NOVELTY"
  ],
  [
    "Even though the proposed approach is based on the work `` Improving Spiking Dynamical Networks",
    "NOVELTY"
  ],
  [
    "its transfer to deep neural networks is new and of significance",
    "NOVELTY"
  ],
  [
    "Lack of novelty .",
    "NOVELTY"
  ],
  [
    "I think the analysis is interesting and the ideas are novel",
    "NOVELTY"
  ],
  [
    "I do have serious concerns that in practice the improvement over GAIL is rather small and no one will use this algorithm as an actual replacement",
    "NOVELTY"
  ],
  [
    "The difference between the null distribution of the considered test statistic and the non-null distribution is quite interesting",
    "NOVELTY"
  ],
  [
    "and it is a really nice algorithmic framework",
    "NOVELTY"
  ],
  [
    "The approach is quite appealing because it provides composition",
    "NOVELTY"
  ],
  [
    "Overall , the paper provides a very good contribution .",
    "NOVELTY"
  ],
  [
    "The paper significantly improves upon the best known results in online linear optimization with access to approximation oracles .",
    "NOVELTY"
  ],
  [
    "in the supplementary material .",
    "NOVELTY"
  ],
  [
    "and relatively novel machine learning problem",
    "NOVELTY"
  ],
  [
    "the paper introduces interesting ideas despite the flaws outlined above",
    "NOVELTY"
  ],
  [
    "Overall , I find the idea quite appealing .",
    "NOVELTY"
  ],
  [
    "The ideas used are not very novel",
    "NOVELTY"
  ],
  [
    "but it is interesting as it is one of the first works in the domain .",
    "NOVELTY"
  ],
  [
    "1 .The novelty appears to be limited . The presented framework looks quite similar to the recent work Spyros Gidaris and Nikos Komodakis .",
    "NOVELTY"
  ],
  [
    "The contribution is not extremely novel : the change with respect to weight normalization is minor .",
    "NOVELTY"
  ],
  [
    "From a theory viewpoint , the paper offers new insights into Batch normalization and other normalization schemes .",
    "NOVELTY"
  ],
  [
    "The idea of using meta-learning to deal with the forgetting issue is interesting .",
    "NOVELTY"
  ],
  [
    "the idea of using group action theory seems interesting .",
    "NOVELTY"
  ],
  [
    "The originality of the approach lies in the decomposition of the policy in two terms",
    "NOVELTY"
  ],
  [
    "The originality is limited though .",
    "NOVELTY"
  ],
  [
    "This paper introduces a simple but highly original idea , leading to a really impressive",
    "NOVELTY"
  ],
  [
    "Thus I believe the paper has considerable novelty .",
    "NOVELTY"
  ],
  [
    "but the problem setup feels like a novel image ( background + object + mask ) generation problem .",
    "NOVELTY"
  ],
  [
    "This work is indeed interesting and insightful .",
    "NOVELTY"
  ],
  [
    "This paper draws from many fields ( especially neural architecture search",
    "NOVELTY"
  ],
  [
    ") , but its core is a unique and powerfuly original idea .",
    "NOVELTY"
  ],
  [
    "and is sure to be widely cited",
    "NOVELTY"
  ],
  [
    "The connection between MC-Boost and MV-SVM is interesting",
    "NOVELTY"
  ],
  [
    "The paper gives a combination of many existing techniques to address the new problem",
    "NOVELTY"
  ],
  [
    ".Therefore , the novelty is limited",
    "NOVELTY"
  ],
  [
    "-- The idea of dynamic programming adopted in this paper is a little incremental compared with Chen\u00e2\u0080\u0099s divide-and-conquer algorithm .",
    "NOVELTY"
  ],
  [
    "Overall , I found the ideas in the paper interesting ,",
    "NOVELTY"
  ],
  [
    "the technical result given in the paper is not really a technical improvement of the prior result",
    "NOVELTY"
  ],
  [
    "I do clearly see the technical novelty of the paper .",
    "NOVELTY"
  ],
  [
    "I feel that the paper has some interesting theoretical advancement in the theoretical study of bandit algorithms",
    "NOVELTY"
  ],
  [
    "I found the encoding of the programs/ASTs to matrices and the use of CNN quite interesting .",
    "NOVELTY"
  ],
  [
    "The application of prediction attribution to bug localization is also interesting and most likely novel .",
    "NOVELTY"
  ],
  [
    "This falls into the category of quantization or binarization , which is not super novel in the area of model compression",
    "NOVELTY"
  ],
  [
    "This paper seems original , while",
    "NOVELTY"
  ],
  [
    "and the paper makes an interesting contribution in this direction",
    "NOVELTY"
  ],
  [
    "This has already been successfully applied in multiple domains eg",
    "NOVELTY"
  ],
  [
    "this paper claims both as novelties while not",
    "NOVELTY"
  ],
  [
    "offering any improvement / comparison",
    "NOVELTY"
  ],
  [
    "The work is original . It contributes a novel model which takes a ranking rather than classification perspective on the problem ;",
    "NOVELTY"
  ],
  [
    "optimization",
    "NOVELTY"
  ],
  [
    ", yet powerful",
    "NOVELTY"
  ],
  [
    "greedy",
    "NOVELTY"
  ],
  [
    "This paper presents a welcome contribution to the saturated literature on embeddings . The whole idea of compositionally and its application to speaker diarization and multi-object detection is novel .",
    "NOVELTY"
  ],
  [
    "The contribution is rather incremental .",
    "NOVELTY"
  ],
  [
    "While the problem itself in its basic version has been studied already , this paper presents improved algorithms and analysis as well as extensions of the considered constraints involving substantial different analysis .",
    "NOVELTY"
  ],
  [
    "The paper describes an interesting extension of the SSC algorithm to allow joint matrix completion and sparse representation",
    "NOVELTY"
  ],
  [
    "I also think that this work is sufficiently original , related to what one could expect form a",
    "NOVELTY"
  ],
  [
    "software component",
    "NOVELTY"
  ],
  [
    "Indeed the modularization of inference per layers is a very interesting idea",
    "NOVELTY"
  ],
  [
    "It is the first time I heard of the concept of EFCE , and it strikes me as a reasonable solution concept",
    "NOVELTY"
  ],
  [
    "The proposed formulation as bilinear saddle-point problem should be a novel contribution",
    "NOVELTY"
  ],
  [
    "I think this contribution itself is sufficient to get the paper accepted in NeurIPS",
    "NOVELTY"
  ],
  [
    "The use of the one-SVM in the experiments was interesting",
    "NOVELTY"
  ],
  [
    "The core contributions of the paper",
    "NOVELTY"
  ],
  [
    "However , I am unable to assess the technical novelty of this work as it seems to heavily rely on prior work which in turn use techniques from random matrix theory .",
    "NOVELTY"
  ],
  [
    "This concern further weakens the contributions of this work .",
    "NOVELTY"
  ],
  [
    "This is an interesting paper introducing a novel and important contribution to the field .",
    "NOVELTY"
  ],
  [
    "I do not see any original technical aspect",
    "NOVELTY"
  ],
  [
    "The methods presented in the paper are not novel",
    "NOVELTY"
  ],
  [
    "The main novelties are the geometrical analysis on the contribution of each word of the sentence to the sentence overall semantic meaning",
    "NOVELTY"
  ],
  [
    "I like the problem introduced in the paper and the approach",
    "NOVELTY"
  ],
  [
    "Authors address a novel problem setting with combination of old techniques .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this paper is probably the first one to apply few-shot learning concept into high-level computer vision tasks .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is very interesting and has advantages on space and computational complexities , in comparing with state-of-the-art algorithms",
    "NOVELTY"
  ],
  [
    "The approach of the paper is closely related to the approach of [ 22",
    "NOVELTY"
  ],
  [
    "In all , this paper proposed some interesting",
    "NOVELTY"
  ],
  [
    "Overall , this paper has a nice idea",
    "NOVELTY"
  ],
  [
    "As far as I know , this is the first work to use normalizing flows for inpainting and compressed sensing .",
    "NOVELTY"
  ],
  [
    "I find it overly simplistic )",
    "NOVELTY"
  ],
  [
    "but I nonetheless find that the paper brings an interesting new idea to the table",
    "NOVELTY"
  ],
  [
    "While the overall contribution is modest ( extending off-policy actor-critic to the application of dialogue generation )",
    "NOVELTY"
  ],
  [
    "Overall , I do n't think this paper provides sufficiently novel or justified contributions compared to the baseline approach of Ulyanov and Lebedev .",
    "NOVELTY"
  ],
  [
    ", I find the idea quite interesting",
    "NOVELTY"
  ],
  [
    "3 that the paper is interesting from the engineering perspective",
    "NOVELTY"
  ],
  [
    "and it lacks novelty",
    "NOVELTY"
  ],
  [
    "The resulting proposal is very similar to [",
    "NOVELTY"
  ],
  [
    "In terms of contributions , the paper is weak .",
    "NOVELTY"
  ],
  [
    "very similar work has been done in",
    "NOVELTY"
  ],
  [
    "Not enough contributions ( almost trivial extension over existing algorithms ) .",
    "NOVELTY"
  ],
  [
    "but does n't feel like a significant contribution on its own",
    "NOVELTY"
  ],
  [
    "The paper has an interesting theoretical contribution .",
    "NOVELTY"
  ],
  [
    "I don \u2019 t think the paper is novel enough as a number of knowledge distillation works exist which are closely related",
    "NOVELTY"
  ],
  [
    "My main concern is the limited novelty of the work .",
    "NOVELTY"
  ],
  [
    "The idea of extending Riemannian Langevin dynamics to functional spaces is elegant",
    "NOVELTY"
  ],
  [
    "The paper seems to have an interesting",
    "NOVELTY"
  ],
  [
    "each of 1-3 above is a straightforward application of an idea that appears elsewhere to spectral graph convolutions , making the work seem incremental",
    "NOVELTY"
  ],
  [
    "and the proposed method is original and works well .",
    "NOVELTY"
  ],
  [
    "I like the idea of coupling the construction of the feature space with the underlying optimization process .",
    "NOVELTY"
  ],
  [
    "I think the work provides some novel contributions .",
    "NOVELTY"
  ],
  [
    "the theoretical derivations seem to be original to me .",
    "NOVELTY"
  ],
  [
    "the theoretical part of the work ( Section 3 ) does not really belong to my area of expertise",
    "NOVELTY"
  ],
  [
    "and makes an interesting contribution .",
    "NOVELTY"
  ],
  [
    "I found the paper enlightening , based on a neat idea .",
    "NOVELTY"
  ],
  [
    "Thus , I think the idea in this paper is novel and may have influence on the literature",
    "NOVELTY"
  ],
  [
    "The paper proposes a very novel technique to hijack a physics simulator at each sample statement and to couple it with a PPL inference engine that works closely with the original simulator to produce high quality proposals to guide inference .",
    "NOVELTY"
  ],
  [
    "This paper proposed an interesting and intuitive question generation model .",
    "NOVELTY"
  ],
  [
    "While it goes beyond the naive two-stage approach",
    "NOVELTY"
  ],
  [
    "the technical novelty remains limited .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed method , relying on a combination of co-teaching and pseudo-labeling , is limited .",
    "NOVELTY"
  ],
  [
    "The translation of the network into a predictive embedding that serves as a good proxy for use in a causal inference procedure is interesting and promising .",
    "NOVELTY"
  ],
  [
    "and the approach is promising",
    "NOVELTY"
  ],
  [
    "their algorithm is almost the same as Wang et al",
    "NOVELTY"
  ],
  [
    "I think this small changes does not really qualify as a new algorithm",
    "NOVELTY"
  ],
  [
    "In the introduction of equation 1 , the break even point concept seems to be novel in the context of learning trajectory .",
    "NOVELTY"
  ],
  [
    "I still believe this is a novel and valuable contribution and will be of interest to the community",
    "NOVELTY"
  ],
  [
    "I like the method .",
    "NOVELTY"
  ],
  [
    "however paper in its current form seems as a small incremental improvement over sota , and could be significantly improved by for example",
    "NOVELTY"
  ],
  [
    "The idea presented in the paper is interesting",
    "NOVELTY"
  ],
  [
    "I think the idea is interesting but",
    "NOVELTY"
  ],
  [
    "I believe the community will find intuitions , methods , and theory developed by the authors interesting .",
    "NOVELTY"
  ],
  [
    "the embedding of the proposed trajectory convolution in recent convolutional literature adds to the clarity and insight of the trajectory convolution itself",
    "NOVELTY"
  ],
  [
    "-- The difference and novelty with respect to the Trajectory-Pooled Deep-Convolutional Descriptor ( TDD ) is clear and fair .",
    "NOVELTY"
  ],
  [
    "-- The first aspect is that the proposed trajectory convolution does not add much to the current 3D convolutional network setup .",
    "NOVELTY"
  ],
  [
    "the current improvements are small",
    "NOVELTY"
  ],
  [
    "The paper is creative",
    "NOVELTY"
  ],
  [
    "Novelty/originality : interesting non-deep contribution",
    "NOVELTY"
  ],
  [
    "This paper is a nice addition to the literature on active learning , straddling the theoretical realm and the practically motivated algorithm design issues that arise when dealing with realistic oracles ( e.g. , human annotators who may initially not have enough confidence to generate labels for the given queries , but would gain confidence after having seen enough queries of this sort",
    "NOVELTY"
  ],
  [
    "Limited with respect to the original definition of algorithmic robustness Significance",
    "NOVELTY"
  ],
  [
    "The paper provides a new theoretical analysis for stochastic learning of Deep Networks",
    "NOVELTY"
  ],
  [
    "but the contribution is limited in its present form .",
    "NOVELTY"
  ],
  [
    "-New theoretical study for DL algorithms -Focus on adversarial learning Cons -I find the contribution a bit limited -Some aspects have to be precised /more argumented -Experimental study could have been more complete Comments",
    "NOVELTY"
  ],
  [
    "already appeared in the proof of results of Xu",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel class of threat models for crafting adversarial examples .",
    "NOVELTY"
  ],
  [
    "Although the proposed functional adversarial attack is novel",
    "NOVELTY"
  ],
  [
    "Overall , I felt that this paper lacked a substantial enough contribution . * The key contributions over previous work seems to be entirely contained in Sec .3.1 and 3.2",
    "NOVELTY"
  ],
  [
    "The improvement over previous work is marginal .",
    "NOVELTY"
  ],
  [
    "it did n't seem to be a `` contribution ``",
    "NOVELTY"
  ],
  [
    "Core ideas seem promising",
    "NOVELTY"
  ],
  [
    "This reduces the novelty and technical contribution of this paper",
    "NOVELTY"
  ],
  [
    "The proposed method makes heavy use of prior machinery",
    "NOVELTY"
  ],
  [
    "and as such , the algorithmic novelty is limited .",
    "NOVELTY"
  ],
  [
    "The problem formulation seems novel as multi-objective scenarios are quite relevant in practice .",
    "NOVELTY"
  ],
  [
    "This work is one of many recent papers trying to understand generalization in deep networks . Their description of the activation space of networks that generalize compared to those that memorize is novel .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited as most of the proposed regularizers are more or less straightforward modifications over DeCov .",
    "NOVELTY"
  ],
  [
    "However , I would consider both of them to be rather incremental contributions , as they are variants of already existing architectures and not significantly novel .",
    "NOVELTY"
  ],
  [
    "I do n't consider the contribution of this paper to be particularly significant .",
    "NOVELTY"
  ],
  [
    "The weakly-convex concept considered in this paper is very similar to the bounded non-convexity considered in the paper",
    "NOVELTY"
  ],
  [
    "I like this approach .",
    "NOVELTY"
  ],
  [
    "The results are not stunning and could be presented better , but this seems like a very creative solution to the right problem .",
    "NOVELTY"
  ],
  [
    "the proposed network architecture is static , and thus the main idea of having multiple modules in a network is not novel as other approaches using static network architectures such as [ A",
    "NOVELTY"
  ],
  [
    "the improvements over black-box models are mostly marginal",
    "NOVELTY"
  ],
  [
    "The paper is an interesting and timely",
    "NOVELTY"
  ],
  [
    "Analyzing the convergence of the general-form off-policy updates in Equation 4 is novel and important .",
    "NOVELTY"
  ],
  [
    "I really like the paper and the approach",
    "NOVELTY"
  ],
  [
    "I think it is a good paper , with a very nice theoretical contribution",
    "NOVELTY"
  ],
  [
    "While the idea of viewing control as inference is far from new",
    "NOVELTY"
  ],
  [
    "the idea of using SMC in this context is clearly novel as far as I can see .",
    "NOVELTY"
  ],
  [
    "However , the particular construction proposed in this paper is refreshingly novel and interesting .",
    "NOVELTY"
  ],
  [
    "Novel approach to nonlinear/non-Gaussian Bayesian state estimation",
    "NOVELTY"
  ],
  [
    "I think the presentation of this density modelling shortcoming is a good contribution but leaves a bit to be desired",
    "NOVELTY"
  ],
  [
    "The contribution in terms of the theory of using random features to perform kernel ridge regression is novel , and interesting .",
    "NOVELTY"
  ],
  [
    "-The idea of applying technique to generalize single-line handwriting recognition to multi-line is both an elegant idea and a natural next",
    "NOVELTY"
  ],
  [
    "Even though the connection is new and interesting , the contribution of the paper is not significant enough .",
    "NOVELTY"
  ],
  [
    "although not strictly novel because I am aware of other methods that use the derivatives of the predictive model for localising the discriminative signal",
    "NOVELTY"
  ],
  [
    "As such , I find this work to be highly original ,",
    "NOVELTY"
  ],
  [
    "This is original idea .",
    "NOVELTY"
  ],
  [
    "I think the idea is really interesting and I",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this paper is the first research on inferring specifications from demonstrations in the MDP framework .",
    "NOVELTY"
  ],
  [
    "Although the idea and the algorithms developed are really interesting",
    "NOVELTY"
  ],
  [
    "The result is novel and significantly improving over known results ( from $ \\sqrt { T } $ to $ \\log ( T ) $ .",
    "NOVELTY"
  ],
  [
    "I like the overall direction and idea of modelling correlation between the target distribution and the data distribution to deal with noisy labels .",
    "NOVELTY"
  ],
  [
    "The use of unitary matrices for recurrent neural networks are still relatively new",
    "NOVELTY"
  ],
  [
    "new",
    "NOVELTY"
  ],
  [
    "Analysis does not provide any new insights .",
    "NOVELTY"
  ],
  [
    "Hence I think the novelty of the paper is very little",
    "NOVELTY"
  ],
  [
    "This paper introduces a clear new module into the crowded space of contextual models for semantic segmentation .",
    "NOVELTY"
  ],
  [
    "the improvements over the state-of-the-art are very minor",
    "NOVELTY"
  ],
  [
    "This paper offers good novelty and it is technically interesting .",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    "The algorithm is applied on top of any optimization techniques .",
    "NOVELTY"
  ],
  [
    "The fact that the algorithm can be applied on top of standard optimization techniques makes it very appealing from practical point of view .",
    "NOVELTY"
  ],
  [
    "I think the proposed approach is very interesting and I am looking forward to the public release of its implementation",
    "NOVELTY"
  ],
  [
    "My major concern is the significance and originality of the proposed method .",
    "NOVELTY"
  ],
  [
    "I 'm not sure that this can be a significant contribution",
    "NOVELTY"
  ],
  [
    "The basic modeling approach of propagating homogeneity through an input-convex net is elegant , and conceptually appealing .",
    "NOVELTY"
  ],
  [
    "In terms of originality , adapting parallel inference framework in a manifold setting is original and new as I know .",
    "NOVELTY"
  ],
  [
    "If this could be corrected , the rest of the paper makes a small contribution , but in the context of a new objective function .",
    "NOVELTY"
  ],
  [
    "I do not believe that there are novel insights in the paper that will generalize to other tasks",
    "NOVELTY"
  ],
  [
    "3 .The \u201c Pure Neuron Detector \u201d procedure is very interesting , as it reduces the problem of learning a group of weights to a much easier problem , learning a single weight vector .",
    "NOVELTY"
  ],
  [
    "//arxiv.org/abs/1712.00779 These paper are relatively new but very relevant",
    "NOVELTY"
  ],
  [
    "This is a practical contribution but not a theoretical contribution",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , such results for quickshift are new",
    "NOVELTY"
  ],
  [
    "As far as I know , the proposed approach is novel . It is clear that Section 3 is original .",
    "NOVELTY"
  ],
  [
    "it is hard to analyze which part in Section 4 is novel and which part is already known",
    "NOVELTY"
  ],
  [
    "I really enjoyed the exposition and found the line of research original and interesting .",
    "NOVELTY"
  ],
  [
    "I do not see any novelty in the concept of decoupling \u00e2\u0080\u009cwhat\u00e2\u0080\u009d and \u00e2\u0080\u009chow.\u00e2\u0080\u009d It is also worth noting that there is a rich literature on hierarchical reinforcement learning",
    "NOVELTY"
  ],
  [
    ", the novelty is not that great .",
    "NOVELTY"
  ],
  [
    "but currently it is not mature in terms of results obtained",
    "NOVELTY"
  ],
  [
    "I do n't know the aggregation literature extremely well , but the authors ' approach to the elicitation problem ( finding optimal partitions of the probability simplex to use as queries ) strikes me as novel .",
    "NOVELTY"
  ],
  [
    "The metric is novel and straightforward",
    "NOVELTY"
  ],
  [
    "The above mentioned existing work makes the contributions of this submission less",
    "NOVELTY"
  ],
  [
    "s cleverness , novelty",
    "NOVELTY"
  ],
  [
    "This paper is very inspiring .",
    "NOVELTY"
  ],
  [
    "Overall this paper is well constructed and improves the problem from a novel point of view",
    "NOVELTY"
  ],
  [
    "The Drop-Net Trick is interesting .",
    "NOVELTY"
  ],
  [
    "3 .This paper lack original technical contribution from themselves .",
    "NOVELTY"
  ],
  [
    "The \u201c obverter \u201d technique is quite interesting since it incorporates the concept from the theory of mind which is similar to human alignment or AGI approach .",
    "NOVELTY"
  ],
  [
    "Though this paper employs an interesting method , it lacks some technical contribution from themselves .",
    "NOVELTY"
  ],
  [
    "contributions are not clear .",
    "NOVELTY"
  ],
  [
    ", these are minor contributions from an architectural perspective .",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting",
    "NOVELTY"
  ],
  [
    "While the paper follows quite closely to Raginsky et al . ( 2018",
    "NOVELTY"
  ],
  [
    ") , the author makes the novel contributions clear .",
    "NOVELTY"
  ],
  [
    "The part on the definition of Wasserstein barycenters on quotient spaces seems novel and might be of independent interest .",
    "NOVELTY"
  ],
  [
    "I am not sure the proposed Wasserstein barycenter is a helpful contribution",
    "NOVELTY"
  ],
  [
    "The paper seems to be promising from the sequence learning point of view as it can produce sequences of considerably higher quality",
    "NOVELTY"
  ],
  [
    "The methods are novel and have good intuition .",
    "NOVELTY"
  ],
  [
    "The analysis of insertion order by part of speech was interesting",
    "NOVELTY"
  ],
  [
    "but does not make deep technical contributions and does not present a comprehensive evaluation or highly insightful empirical results .",
    "NOVELTY"
  ],
  [
    "Empathic This appears to be the key contribution though related work certainly infringes on its novelty",
    "NOVELTY"
  ],
  [
    "I have not seen the framework being discussed in the machine learning literature before",
    "NOVELTY"
  ],
  [
    "Unfortunately with the task and analysis falling short , the model itself does not provide enough novelty to really motivate accepting this paper in this format .",
    "NOVELTY"
  ],
  [
    "The idea is appealing to me theoretically as a proof of concept",
    "NOVELTY"
  ],
  [
    "this work significantly moves the-state-of-the-art",
    "NOVELTY"
  ],
  [
    "AM-GAN is an incremental work by applying AM to GAN",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are in parts surprising and overall interesting .",
    "NOVELTY"
  ],
  [
    "- novel and interesting idea for memory access - nicely",
    "NOVELTY"
  ],
  [
    "I do not think this paper has made a lot of contribution to either differential privacy or active learning .",
    "NOVELTY"
  ],
  [
    "There is almost no theoretical contribution made by this paper .",
    "NOVELTY"
  ],
  [
    "My primary concern with the paper is the lack of novelty and relatively little in the way of contributions to the ICLR community .",
    "NOVELTY"
  ],
  [
    "The technical novelty seems to be limited to new notation for existing work",
    "NOVELTY"
  ],
  [
    "This is an interesting approach .",
    "NOVELTY"
  ],
  [
    "this is an interesting paper with a good idea",
    "NOVELTY"
  ],
  [
    "but the training technique is not mature enough for publication",
    "NOVELTY"
  ],
  [
    "Overall the approach is interesting and has an interesting flavor of combining neural networks with basic properties of physics .",
    "NOVELTY"
  ],
  [
    "The approach is interesting . While other methods have tried to build models that can deal with physical predictions , the idea of summing over pair-wise terms , to the best of my knowledge , is novel and much more in-line with the underlying principles of mechanics .",
    "NOVELTY"
  ],
  [
    "Comments The proposed method based on Fourier Transform is quite interesting",
    "NOVELTY"
  ],
  [
    "Recommendation Overall , I believe that the proposed framework is quite interesting and novel , and is able to improve on prior work of the literature and get near optimal bounds to many interesting problems .",
    "NOVELTY"
  ],
  [
    "The motivation of the line attractor is novel and effective .",
    "NOVELTY"
  ],
  [
    "RNNs ) but to the best of my knowledge RNNs have never be applied to higher order logical formulae before .",
    "NOVELTY"
  ],
  [
    "but is somewhat lacking in novelty",
    "NOVELTY"
  ],
  [
    "I don \u2019 t doubt this paper makes some interesting and important contributions",
    "NOVELTY"
  ],
  [
    "In Section 4 , the idea of smoothing explanations is not novel",
    "NOVELTY"
  ],
  [
    "but the analysis leading to Theorems 4.1 and 4.2 is novel .",
    "NOVELTY"
  ],
  [
    "The idea of guiding the agents toward the actions that they can not do without concurrent cooperation is interesting .",
    "NOVELTY"
  ],
  [
    "I think that the paper could be an interesting contribution for ICLR",
    "NOVELTY"
  ],
  [
    "paper provides new insight into the theory of inertial methods",
    "NOVELTY"
  ],
  [
    "but lacked a crisp formalization",
    "NOVELTY"
  ],
  [
    "Such measure is highly novel and might prove to be a good candidate for the study of the complexity of networks in function space . The characterization of the two regimes ( linear and 'post-linear ' ) is also novel and interesting .",
    "NOVELTY"
  ],
  [
    "This characterization seems to be new in the literature",
    "NOVELTY"
  ],
  [
    "The results in the paper are interesting and novel .",
    "NOVELTY"
  ],
  [
    "The framework proposed by the authors has some similarities with predictive coding proposed for vision",
    "NOVELTY"
  ],
  [
    "Novel , multi-agent in nature , approach to one-class classification - Proposed method build a complex system",
    "NOVELTY"
  ],
  [
    "this paper is not really introducing new class of models",
    "NOVELTY"
  ],
  [
    "natural and I believe it would be interesting to the ML community",
    "NOVELTY"
  ],
  [
    "GANs are a very interesting idea , which I have n't heard of so far .",
    "NOVELTY"
  ],
  [
    "The paper has limited novelty .",
    "NOVELTY"
  ],
  [
    "while the paper provides an interesting observation",
    "NOVELTY"
  ],
  [
    ", it has limited contributions due to lack of novelty .",
    "NOVELTY"
  ],
  [
    "The new theory can be expanded into a novel algorithm .",
    "NOVELTY"
  ],
  [
    "The attempt to incorporate lambda into feature learning is really interesting .",
    "NOVELTY"
  ],
  [
    "the proposed solution is interesting and could indeed end up being a useful contribution to the literature",
    "NOVELTY"
  ],
  [
    "I can not measure the contribution of the new method with the limited empirical analysis provided in the paper",
    "NOVELTY"
  ],
  [
    "Originality This is an application paper , proposing a new model/task combination . I am not an expert in the area , but the application of using zero-positive learning with autoencoders to such low-level hardware instrumentation data was an interesting new idea to me .",
    "NOVELTY"
  ],
  [
    "I find that this is a very elegant and promising approach for finding better architectures .",
    "NOVELTY"
  ],
  [
    "From my understanding the contributions for the field of super-resolutions are novel",
    "NOVELTY"
  ],
  [
    "Although the algorithm seems to have some novelty",
    "NOVELTY"
  ],
  [
    "The paper provides a new method which is easy to understand",
    "NOVELTY"
  ],
  [
    "It is a strong contribution to the",
    "NOVELTY"
  ],
  [
    "The contributions of the papers are enough to be considered for a poster presentation",
    "NOVELTY"
  ],
  [
    "and makes a modest but clear contribution to the field",
    "NOVELTY"
  ],
  [
    "The proposed resolution , to add this discontinuous step function in",
    "NOVELTY"
  ],
  [
    "with floor is a very interesting",
    "NOVELTY"
  ],
  [
    "However , the novelty is rather limited as similar ideas have been undertaken",
    "NOVELTY"
  ],
  [
    "While using spherical topology for embeddings is not anything new",
    "NOVELTY"
  ],
  [
    "I have not seen it applied in this manner",
    "NOVELTY"
  ],
  [
    "The extension to multivariate information measures is an original advance in the context of prior literature ,",
    "NOVELTY"
  ],
  [
    "even though I liked the idea and the approach to the problem",
    "NOVELTY"
  ],
  [
    "novel approach for doing hierarchical deep RL",
    "NOVELTY"
  ],
  [
    "2 .Use of HER in a novel way ( on goals and actions ) to learn from failed attempts at reaching subgoals from lower levels .",
    "NOVELTY"
  ],
  [
    "Fusing both the modalities as early as the visual feature extraction is novel idea , to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "I continue to feel that the paper has novel contributions bringing new insights which future works can build on",
    "NOVELTY"
  ],
  [
    "I found this quite insightful .",
    "NOVELTY"
  ],
  [
    "Novel architecture for graph to sequence learning .",
    "NOVELTY"
  ],
  [
    "However , the modelling contribution is relatively limited and it feels like for this to be a really strong contribution more insight into the graph encoder design",
    "NOVELTY"
  ],
  [
    "The idea of student/teacher transfer with sample weighting is novel and interesting .",
    "NOVELTY"
  ],
  [
    "since the method proposed is novel and seems promising",
    "NOVELTY"
  ],
  [
    "The proposed general meta-learning framework that aims to learn the meta-learner that approximates the predictive distribution over multiple tasks is quite novel and makes sense .",
    "NOVELTY"
  ],
  [
    "This is an interesting idea",
    "NOVELTY"
  ],
  [
    "Originality To the best of my knowledge the presented framework for task delegability is novel",
    "NOVELTY"
  ],
  [
    "While , the main theoretical contributions are perhaps marginal with regard to prior work",
    "NOVELTY"
  ],
  [
    ", the problem setting ( RL ) seems novel and the two theorems in this context are interesting .",
    "NOVELTY"
  ],
  [
    "The ideas presented are interesting",
    "NOVELTY"
  ],
  [
    "this is an okay paper with limited innovation",
    "NOVELTY"
  ],
  [
    "the paper does not show clear improvements over existing methods using the proposed framework .",
    "NOVELTY"
  ],
  [
    "The algorithmic contribution is relatively minor , while the technical merits of the approach are questionable .",
    "NOVELTY"
  ],
  [
    "Therefore , the idea itself is not so novel and innovative .",
    "NOVELTY"
  ],
  [
    "The authors present an interesting and novel architecture in PEARL .",
    "NOVELTY"
  ],
  [
    "This paper proposes an interesting idea for event sequence clustering .",
    "NOVELTY"
  ],
  [
    "The main issue of this paper is the lack of novelty : the three evaluated approaches ( Diag LSTM , QRNN and Gated ConvNet ) are not novel , the only novelty is the addition of a 1D convolution , which is not enough for a conference like ICLR .",
    "NOVELTY"
  ],
  [
    "but its novelty is too limited for ICLR",
    "NOVELTY"
  ],
  [
    "Overall I think the paper does not have a significant enough contribution or impressive enough results to be published .",
    "NOVELTY"
  ],
  [
    "and the core idea seems interesting .",
    "NOVELTY"
  ],
  [
    "I particularly found the bound computed without the use of an optimal discriminator unique and interesting .",
    "NOVELTY"
  ],
  [
    "While I believe that the proposed network is an interesting idea",
    "NOVELTY"
  ],
  [
    "The paper 's idea is very interesting .",
    "NOVELTY"
  ],
  [
    "Recommendation While the contributions in this work are not staggeringly innovative ,",
    "NOVELTY"
  ],
  [
    "but the main issue with this paper is that it lacks enough innovation with respect to theory or empirical study .",
    "NOVELTY"
  ],
  [
    "the idea of shuffling original data to automatically construct supervised data sets and feeding them to a supervised learning system is a natural idea , which has been attempted before",
    "NOVELTY"
  ],
  [
    "2 .The combination of the above two inference methods on S ( N ) LDS is new to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "this paper is interesting",
    "NOVELTY"
  ],
  [
    "I really like the idea of explicitly modelling the mask/missingness vector",
    "NOVELTY"
  ],
  [
    "because this is not the first",
    "NOVELTY"
  ],
  [
    "2 .The dialogue act tag set used in the paper is not original to Ivanovic ( 2005",
    "NOVELTY"
  ],
  [
    "Overall I find this to be a strong contribution",
    "NOVELTY"
  ],
  [
    "Regularizing by enforcing the training steps to keep co-label similarities is interesting idea but not very novel",
    "NOVELTY"
  ],
  [
    "As for the model itself , I donot find very significant novelty .",
    "NOVELTY"
  ],
  [
    "The overall framework of this paper is somehow similar to [ 1 ] and",
    "NOVELTY"
  ],
  [
    "The theoretical framework presented is novel and significant , as it provides a unified view of the two main approaches for neural waveform generation .",
    "NOVELTY"
  ],
  [
    "This is a nice paper promoting a simple , but effective core idea \u00e2\u0080\u0094 that parameters of a layer might be usefully generated based on the context of their input rather statically fixed for all examples",
    "NOVELTY"
  ],
  [
    "the work does have some novelty",
    "NOVELTY"
  ],
  [
    "The authors provide an interesting theoretical analysis and a novel algorithm in the adversarial context setting .",
    "NOVELTY"
  ],
  [
    "I generally like the paper and its geometrical lens on the problem .",
    "NOVELTY"
  ],
  [
    "-- Conclusion -- I like the paper and the idea in general .",
    "NOVELTY"
  ],
  [
    "The over idea appears to novel , despite its connections to various previous attempts to angular separation",
    "NOVELTY"
  ],
  [
    "Unclear novelty .",
    "NOVELTY"
  ],
  [
    "1 .In terms of the contribution of the paper , a lookahead alignment mechanism , while interesting , and well motivated in the paper , is a bit unclear if it is significant enough a contribution",
    "NOVELTY"
  ],
  [
    "experiments are not very insightful",
    "NOVELTY"
  ],
  [
    "the paper\u00e2\u0080\u0099s contribution is somewhat limited",
    "NOVELTY"
  ],
  [
    ", some are novel and",
    "NOVELTY"
  ],
  [
    "in a way that unifies advances in the area",
    "NOVELTY"
  ],
  [
    "The object similarity based on shared attributes was a quite interesting idea like collaborative filtering .",
    "NOVELTY"
  ],
  [
    "This work is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "similarities to past work deep metric learning",
    "NOVELTY"
  ],
  [
    "This makes the contribution of this paper in terms of the method hard to judge .",
    "NOVELTY"
  ],
  [
    "The idea of studying based on the combination of the results from two previous papers is quite natural",
    "NOVELTY"
  ],
  [
    "The novelty of the algorithm itself is limited",
    "NOVELTY"
  ],
  [
    "it is not clear to me that these are some novel results that can better help adversarial training",
    "NOVELTY"
  ],
  [
    "I vote for acceptance of this paper since this studies a nice novel problem that has practical motivations , and establishes the first algorithm analyzing noisy comparison feedbacks",
    "NOVELTY"
  ],
  [
    "but mainly theoretical since there is no algorithmic innovation",
    "NOVELTY"
  ],
  [
    "Novelties over state-of-the-art are well described and the authors do not oversell their method",
    "NOVELTY"
  ],
  [
    "Originality Unfortunately , the originality is very low . Combining reinforcement learning with auxiliary objectives is not novel and has been studied in the Atari domain",
    "NOVELTY"
  ],
  [
    "The conceptual idea of using a reconstruction loss for images as auxiliary objective is not novel either and has been presented in earlier work already , see Shelhamer et al .The idea of sharing parameters between RL and auxiliary components is also not novel",
    "NOVELTY"
  ],
  [
    "I still feel that the novelty of the work is very limited and the authors ' response to lacking novelty does not convince me .",
    "NOVELTY"
  ],
  [
    "I think that the idea is interesting",
    "NOVELTY"
  ],
  [
    "however I have some reservations about novelty",
    "NOVELTY"
  ],
  [
    "so it feels as if this paper is a good realization of an incremental idea",
    "NOVELTY"
  ],
  [
    "Overall , the paper proposes a working system that seems to be interesting .",
    "NOVELTY"
  ],
  [
    "I have three major concerns , including a lack of novelty , unconvincing experiments",
    "NOVELTY"
  ],
  [
    "In terms of positioning , I find the idea of the paper interesting",
    "NOVELTY"
  ],
  [
    "A good idea ,",
    "NOVELTY"
  ],
  [
    "Overall , the primary contribution here seems to be a novel method for learning the length of the shortest path ( in [ O , T ] ) between any pair of high-dimensional observations as well as a policy for navigating between them , using distributional RL .",
    "NOVELTY"
  ],
  [
    "The techniques seem original .",
    "NOVELTY"
  ],
  [
    "and gives improved ( for-all )",
    "NOVELTY"
  ],
  [
    "and ends with a limited memory discussion which however seems not to give much novel on top of [ 9,10 ]",
    "NOVELTY"
  ],
  [
    "My main concern is",
    "NOVELTY"
  ],
  [
    "although the paper introduces no new methodology",
    "NOVELTY"
  ],
  [
    ", their dataset is to my knowledge a first-of-its-kind and their design , construction , and use of the robotic camera rig to generate is novel and unusual in the field . This kind of work is innovative and shows an attention to",
    "NOVELTY"
  ],
  [
    "The paper provides strong connections in novel areas .",
    "NOVELTY"
  ],
  [
    "Even though the idea of convex networks were not new",
    "NOVELTY"
  ],
  [
    ", this work is novel in extending input convex RNN and applying it into dynamic control problems .",
    "NOVELTY"
  ],
  [
    "Similar regularizers were considered before , however",
    "NOVELTY"
  ],
  [
    ", the learning rate schedule is novel and very technical .",
    "NOVELTY"
  ],
  [
    "While this manuscript proposes a reasonable contribution",
    "NOVELTY"
  ],
  [
    "I enjoyed reading the paper for its conceptual novelty .",
    "NOVELTY"
  ],
  [
    "It is a new way of thinking about representation learning .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is somewhat weakened given the existence of previous related-works ( ShiftNet/Active Convolution/MobileNet ) .",
    "NOVELTY"
  ],
  [
    "My main concern is the limited novelty of the proposed method , which is essentially an application of a well-known approach",
    "NOVELTY"
  ],
  [
    "The proposed approach follows largely the existing work and thus its technical novelty is weak .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "Present work , however interesting with regard to its potential implications , strays away from providing such theoretical insights and suffices with demonstrating limited improvements in empirical tasks",
    "NOVELTY"
  ],
  [
    "The core idea of the paper is quite interesting and seems to result in higher semi-supervised accuracy than prior work .",
    "NOVELTY"
  ],
  [
    "Without deeper insights of the proposed method , the novelty of this paper is not sufficient .",
    "NOVELTY"
  ],
  [
    "The specification language seems to be similar to past work , being a restricted form of temporal logic .",
    "NOVELTY"
  ],
  [
    "I doubt that such modifications might contain little novelty , and the algorithmic contribution of this paper is incremental .",
    "NOVELTY"
  ],
  [
    "If the authors ' summary of the prior literature is correct , the POMDP model seems new and interesting as it is a normative model , whereas previous models were descriptive .",
    "NOVELTY"
  ],
  [
    "This certainly makes the contribution of the paper to be minor .",
    "NOVELTY"
  ],
  [
    "I think the novelty of this paper is not obvious",
    "NOVELTY"
  ],
  [
    "Neither the modules themselves nor the way of combining them are novel to me",
    "NOVELTY"
  ],
  [
    "The analysis part seems interesting and innovative to me .",
    "NOVELTY"
  ],
  [
    "The way to generate new mask is a very smart design to me . This should be the most important contribution of the paper .",
    "NOVELTY"
  ],
  [
    "While the idea is quite interesting",
    "NOVELTY"
  ],
  [
    "I found the results very interesting",
    "NOVELTY"
  ],
  [
    "The methods are not necessarily original",
    "NOVELTY"
  ],
  [
    "The paper quality is mediocre overall",
    "NOVELTY"
  ],
  [
    "though I do like the idea and do want to see it published",
    "NOVELTY"
  ],
  [
    "I like the ideas in the paper",
    "NOVELTY"
  ],
  [
    "The philosophy of this type of approaches is very similar to the one of the paper",
    "NOVELTY"
  ],
  [
    "and quite original",
    "NOVELTY"
  ],
  [
    "The Bayesian view , however , is not really novel , but rather an obvious extension of [",
    "NOVELTY"
  ],
  [
    "I do not see significant improvements over prior work",
    "NOVELTY"
  ],
  [
    "The methodological novelty right now is vague to me as",
    "NOVELTY"
  ],
  [
    "This approach is original and significant",
    "NOVELTY"
  ],
  [
    "though the presented results are a bit on the thin side .",
    "NOVELTY"
  ],
  [
    "Intensity-free methods are an interesting alternative to standard approaches for TPPs and fit well into ICLR",
    "NOVELTY"
  ],
  [
    "The paper proposes interesting ideas to learn non-parametric distributions over event sequences using CNFs and the initial experimental results are indeed",
    "NOVELTY"
  ],
  [
    "contributions somewhat insufficient . The proposed approach seems to consist mostly of applications of existing techniques and of only few technical contributions .",
    "NOVELTY"
  ],
  [
    "The paper is based on ideas already known .",
    "NOVELTY"
  ],
  [
    "The combination of these two techniques is however novel .",
    "NOVELTY"
  ],
  [
    "The idea is a combination of already known techniques put in practice for the VAE .",
    "NOVELTY"
  ],
  [
    "The concept of SAE has already been considered in a few papers",
    "NOVELTY"
  ],
  [
    "and the explicit recurrent state is a nice contribution and addition to the IR model proposed in Godbole et al. , 2019",
    "NOVELTY"
  ],
  [
    "I found the basic idea and result interesting",
    "NOVELTY"
  ],
  [
    "I found this to be an interesting paper introducing new methods that leveraging low-rank structure to embed transition distributions and time-varying states . I think the idea of the diffusion distance can inspire further work in distance metrics for sequential models as well as new learning paradigms .",
    "NOVELTY"
  ],
  [
    "I enjoyed this paper",
    "NOVELTY"
  ],
  [
    ", the ideas are ( to my knowledge ) novel and make sense ,",
    "NOVELTY"
  ],
  [
    "Overall , I think the idea is good .",
    "NOVELTY"
  ],
  [
    "The language is new , though",
    "NOVELTY"
  ],
  [
    "simple",
    "NOVELTY"
  ],
  [
    "Interesting and fairly elegant idea",
    "NOVELTY"
  ],
  [
    "I find the novelty of the paper limited :",
    "NOVELTY"
  ],
  [
    "Not too much novelty in the idea , but good execution",
    "NOVELTY"
  ],
  [
    "The idea of embedding in a Wasserstein space is original ( up to my knowledge ) and well described .",
    "NOVELTY"
  ],
  [
    "I am not sure what is novel in the proposed model .",
    "NOVELTY"
  ],
  [
    "but I am not sure of the contribution of",
    "NOVELTY"
  ],
  [
    "I liked the idea of using some form of linearization of the Fisher information matrix to learn a feature vector .",
    "NOVELTY"
  ],
  [
    "The theory of the paper is nice .",
    "NOVELTY"
  ],
  [
    "Overall , the proposed method is very interesting .",
    "NOVELTY"
  ],
  [
    "this method only combines existing techs ,",
    "NOVELTY"
  ],
  [
    ", and lacks novelty",
    "NOVELTY"
  ],
  [
    "there are few novel aspects",
    "NOVELTY"
  ],
  [
    "The contributions from the two stages , both initialization and local refinement , seem to be novel enough to allow better statistical accuracies with few number of measurements near information-theoretic limit and lead better empirical results .",
    "NOVELTY"
  ],
  [
    "The generalization of various algorithms presented in the paper is interesting .",
    "NOVELTY"
  ],
  [
    "although this idea seems novel and valid for this application",
    "NOVELTY"
  ],
  [
    "which hints that the original contribution is too incremental",
    "NOVELTY"
  ],
  [
    "Overall , I don \u2019 t think that the contributions of this paper are enough for publication .",
    "NOVELTY"
  ],
  [
    "At this stage , there is not enough contribution in terms of novelty nor delta in performance .",
    "NOVELTY"
  ],
  [
    "Overall , this paper was fairly well written and seems to have an original approach towards inducing low-rank structure on the space of activations in some intermediate layer in a computationally efficient way without changing the underlying model .",
    "NOVELTY"
  ],
  [
    "-- I can not really gauge the significance of the result against other existing approaches towards low-dimensional representations because of my limited familiarity with the relevant literature",
    "NOVELTY"
  ],
  [
    "While the idea of exploring the structures of relu neural networks for training based on group theory on graphs is interesting",
    "NOVELTY"
  ],
  [
    "I do not see the truly contribution of the proposed method .",
    "NOVELTY"
  ],
  [
    "I agree the low-rank representation idea is straightforward and clever",
    "NOVELTY"
  ],
  [
    "The analysis of the dynamics that maps weights on particules and described then the dynamics via an analog of the Dean 's equation ( relatively well known in statistical physics ) is interesting and will be particularly appealing to physics audience .",
    "NOVELTY"
  ],
  [
    "yet the approach is interesting as well as the theoretical results .",
    "NOVELTY"
  ],
  [
    "It is a really novel and promising direction worth exploring further in the future .",
    "NOVELTY"
  ],
  [
    "I like the idea",
    "NOVELTY"
  ],
  [
    "I do not see much novelty in it",
    "NOVELTY"
  ],
  [
    "even if it is only a modest contribution on the theory side",
    "NOVELTY"
  ],
  [
    "In my point of view , the key idea of this paper is highly close to [ 1 ] and [ 3 ] .",
    "NOVELTY"
  ],
  [
    "Much of the mathematical treatment of the curvature was already discussed by Martens and Grosse and Botev et al in previous works",
    "NOVELTY"
  ],
  [
    "The idea of using the reconstructor as an adversary in the framework seems so intuitive",
    "NOVELTY"
  ],
  [
    "However , the novelty is limited since the difference between the proposed method and Soft Actor Critic",
    "NOVELTY"
  ],
  [
    "While the process for sampling fields is simple , it is original and useful/ 2 .",
    "NOVELTY"
  ],
  [
    "The setting where an adversary has access to a large neural net model and the verifier has access to a small one is quite original and interesting .",
    "NOVELTY"
  ],
  [
    "I can \u2019 t tell which aspects are meant to be novel",
    "NOVELTY"
  ],
  [
    "Though it is unclear from the",
    "NOVELTY"
  ],
  [
    "the findings do present interesting contributions",
    "NOVELTY"
  ],
  [
    "well",
    "NOVELTY"
  ],
  [
    "and the model is original enough that it should n't be an issue",
    "NOVELTY"
  ],
  [
    "it is a promising approach",
    "NOVELTY"
  ],
  [
    "Since the applying RL in combinatorial optimization is not new",
    "NOVELTY"
  ],
  [
    "The proposed method draws on previous related approaches but contains significant novel contributions .",
    "NOVELTY"
  ],
  [
    "The proposed view of learning with point clouds is , as far as I know , novel .",
    "NOVELTY"
  ],
  [
    "the proposed method is generally novel while it bases on solid and well-known foundations",
    "NOVELTY"
  ],
  [
    "I recognize the innovation in terms of methodology made by this application work",
    "NOVELTY"
  ],
  [
    "2 Dance generation is not totally new .",
    "NOVELTY"
  ],
  [
    "The paper has some nice contributions",
    "NOVELTY"
  ],
  [
    "Overall , I really enjoyed this paper , which proposed a novel way to regularise posteriors to force them to encode information .",
    "NOVELTY"
  ],
  [
    "The concept itself is only moderately novel , as all of the components",
    "NOVELTY"
  ],
  [
    "There is no new machine learning content .",
    "NOVELTY"
  ],
  [
    "My primary concern remains about novelty",
    "NOVELTY"
  ],
  [
    "I am not sure if the techniques used in the paper are relatively novel ( from a theoretical point of view",
    "NOVELTY"
  ],
  [
    "While the setting of policy evaluation is novel",
    "NOVELTY"
  ],
  [
    "The idea of leveraging multiple modulators for domain-agnostic image recognition is interesting and heuristic , thus the proposed framework shows some novelty .",
    "NOVELTY"
  ],
  [
    "The idea is to make deep models more robust to different image domains , which is interesting and heuristic",
    "NOVELTY"
  ],
  [
    "however at the same time , these ideas are not really new",
    "NOVELTY"
  ],
  [
    "While the angle based approach presented here is interesting and intuitively appealing",
    "NOVELTY"
  ],
  [
    "Additionally , this is kind of an orthogonal contribution to past papers leveraging experience replay , which could potentially be modified and improved based on this approach",
    "NOVELTY"
  ],
  [
    "the paper is not mature enough",
    "NOVELTY"
  ],
  [
    "I find most of the discussions and experiments to be interesting and insightful .",
    "NOVELTY"
  ],
  [
    "The method is novel",
    "NOVELTY"
  ],
  [
    "Combining internal and external information for superior restoration performance is not new",
    "NOVELTY"
  ],
  [
    "Although the idea of generating images from sounds with the aid of Generative Adversarial Networks is quite novel and interesting",
    "NOVELTY"
  ],
  [
    "This could be a novel , interesting idea with the potential to generate new research directions .",
    "NOVELTY"
  ],
  [
    "Visual reference resolution is a nice and intuitive idea on visual dialog dataset .",
    "NOVELTY"
  ],
  [
    "but it is an incremental improvement over some already restrictive theoretical analyses .",
    "NOVELTY"
  ],
  [
    "to the best of my knowledge , adding persona information to an adversarial multi-turn dialogue model is novel",
    "NOVELTY"
  ],
  [
    "the authors explore two different approaches to build the discriminator ( s ) and the idea of adding a second discriminator that predicts the attributes seems interesting .",
    "NOVELTY"
  ],
  [
    "Novelty : The idea of learning speaker-specific attribute embeddings is very similar to the Speaker Model proposed by Li et al . ( 2016",
    "NOVELTY"
  ],
  [
    "The idea of adding a discriminator that predicts the attributes seems interesting .",
    "NOVELTY"
  ],
  [
    "but seemingly it does n't really contribute to the federated learning algorithm .",
    "NOVELTY"
  ],
  [
    "In addition to not be very novel , I think the method has some flaws .",
    "NOVELTY"
  ],
  [
    "is very interesting , and an important contribution",
    "NOVELTY"
  ],
  [
    "It also improves upon the dependence on error probability over previous works .",
    "NOVELTY"
  ],
  [
    "Various computationally efficient and sample optimal estimators have been proposed before",
    "NOVELTY"
  ],
  [
    "I very much like the idea",
    "NOVELTY"
  ],
  [
    "This algorithm is not highly innovative .",
    "NOVELTY"
  ],
  [
    "I like the contribution of the paper which tries to build connections between GNNs and distributed computing models .",
    "NOVELTY"
  ],
  [
    "The depth and width dependency results are novel in the context of GNNs .",
    "NOVELTY"
  ],
  [
    ".That seems like an incremental-step compared to previous results that write down the PDE (",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed algorithm may be limited .",
    "NOVELTY"
  ],
  [
    "I find this work to be original and the proposed algorithm to be novel .",
    "NOVELTY"
  ],
  [
    "I find the idea of learning different weights for different data points interesting and promising .",
    "NOVELTY"
  ],
  [
    "Overall the proposed idea is interesting , and the use of human experiments to improve a reinforcement learning algorithm offers interesting perspectives .",
    "NOVELTY"
  ],
  [
    "The paper presents novel theoretical results on generalization bounds via compression .",
    "NOVELTY"
  ],
  [
    "The result is novel and quite interesting .",
    "NOVELTY"
  ],
  [
    "I believe the paper has a descent idea",
    "NOVELTY"
  ],
  [
    "It is a simple yet novel way to incorporate a model ,",
    "NOVELTY"
  ],
  [
    "I 'm unsure about the novelty of the method itself .",
    "NOVELTY"
  ],
  [
    "Although this is not the first time Thompson sampling has been proposed for the problem",
    "NOVELTY"
  ],
  [
    ", the smart idea of sampling twice and following it up by a UCB-elimination step is quite novel , and supplemented by fairly competitive analytical guarantees .",
    "NOVELTY"
  ],
  [
    "The idea of using training set statistics for learning embeddings is quite interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is limited so far as I can tell",
    "NOVELTY"
  ],
  [
    "The novelty of the work is limited ,",
    "NOVELTY"
  ],
  [
    "However the paper is held back by the lack of novelty and",
    "NOVELTY"
  ],
  [
    "The contributions in this paper appear novel",
    "NOVELTY"
  ],
  [
    "The idea is already introduced by Xiong et al",
    "NOVELTY"
  ],
  [
    "Not much novelty or surprise , given the success of AlphaGo .",
    "NOVELTY"
  ],
  [
    "I could not see exactly what is the novelty/creativity in terms of how MCTS is applied for this specific problem of KGC .",
    "NOVELTY"
  ],
  [
    ".The novelty of the proposal is somewhat questionable , because reinforcement learning has already been introduced for KGC",
    "NOVELTY"
  ],
  [
    "but it seems that this work is the first to apply transfer learning in the controller to this setting",
    "NOVELTY"
  ],
  [
    "This is apparently a novel idea in the Deep RL based controller setting of neural architecture search although it has been done in other settings",
    "NOVELTY"
  ],
  [
    "Overall the weakness of this paper to me is that the approach is of limited novelty and is very straightforward from past work on transfer learning and neural architecture search .",
    "NOVELTY"
  ],
  [
    "this seems like a fairly small but well considered and executed piece of work .",
    "NOVELTY"
  ],
  [
    "I find the proposed method to be quite interesting .",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "there is a substantial amount of work in this field , I believe that their approach is novel and has its own merits .",
    "NOVELTY"
  ],
  [
    "The theoretical and empirical analysis are new .",
    "NOVELTY"
  ],
  [
    "The idea of improving model robustness using unlabeled data is interesting and is likely to inspire more efforts in this direction .",
    "NOVELTY"
  ],
  [
    "A novel idea of modeling the relationship among the four sub-bands in the clique up-sampling module in IRN .",
    "NOVELTY"
  ],
  [
    "and presents a novel formulation and strong results for the FVQA task .",
    "NOVELTY"
  ],
  [
    "My understanding is that the proposed work is a somewhat incremental improvement over Unsuperpoint",
    "NOVELTY"
  ],
  [
    "Overall , I think the improvements are a bit incremental , but the experiments seem to support the claim that they are beneficial .",
    "NOVELTY"
  ],
  [
    "This paper has some novelty and",
    "NOVELTY"
  ],
  [
    "and there are good ideas in the paper .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper proposes an interesting idea of using momentum with promising results to learn sparse neural networks .",
    "NOVELTY"
  ],
  [
    "the algorithm is novel and represents a nice contribution .",
    "NOVELTY"
  ],
  [
    "I think the proposed method is novel .",
    "NOVELTY"
  ],
  [
    "I think the contributions in this paper is reasonably significant .",
    "NOVELTY"
  ],
  [
    "I have found the paper interesting . The topic is relevant and the approach is interesting",
    "NOVELTY"
  ],
  [
    "Overall I think the proposed method is interesting .",
    "NOVELTY"
  ],
  [
    "The novelty here feels a bit limited .",
    "NOVELTY"
  ],
  [
    "the paper is interesting",
    "NOVELTY"
  ],
  [
    "The overall method is basically a modification of the variance-reduced SGLD algorithm on an online sampling problem",
    "NOVELTY"
  ],
  [
    "While the method is not very original , online sampling with SG-MCMC algorithms has been an open problem and",
    "NOVELTY"
  ],
  [
    "the whole paper (",
    "NOVELTY"
  ],
  [
    "the proof technique ) is sufficiently original",
    "NOVELTY"
  ],
  [
    "The proposed method is interesting",
    "NOVELTY"
  ],
  [
    "and to my knowledge the proposed VHE method is novel",
    "NOVELTY"
  ],
  [
    "The authors include their phrase-to-word alignment system among their list of contributions , but that portion of the work appears less novel",
    "NOVELTY"
  ],
  [
    "Showing existence of the phase transition in the noiseless setting is new . Studying the noisy version of the pooled data problem is another novel contribution .",
    "NOVELTY"
  ],
  [
    "The idea seems interesting",
    "NOVELTY"
  ],
  [
    "The theoretical result is the key technical contribution of this paper",
    "NOVELTY"
  ],
  [
    "although the algorithm is somehow incremental",
    "NOVELTY"
  ],
  [
    "Novel loss function for metric learning , which works well over standard approaches",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is two fold",
    "NOVELTY"
  ],
  [
    "The idea of applying the metric ( s ) to select a layer from which the consecutive layers are truncated is intriguing , for the sake of model compression .",
    "NOVELTY"
  ],
  [
    "The work is more alike a course project than a novel scientific contribution , with all the metrics mainly inherited from the evaluation of clustering and other existing literatures",
    "NOVELTY"
  ],
  [
    "however I do think that the reduced space complexity is novel",
    "NOVELTY"
  ],
  [
    "While I think this paper makes an independent and useful contribution",
    "NOVELTY"
  ],
  [
    "The other two modifications are either not novel",
    "NOVELTY"
  ],
  [
    "The proposed solution is an incremental step considering the relaxation proposed by Guzman .",
    "NOVELTY"
  ],
  [
    "-Nice formulation , which I believe is novel .",
    "NOVELTY"
  ],
  [
    "the idea of using surrogate labels to learn representation is also not new .",
    "NOVELTY"
  ],
  [
    "interesting",
    "NOVELTY"
  ],
  [
    "but the perspective is original enough",
    "NOVELTY"
  ],
  [
    "Combining generative network models for modeling cascades is an interesting and useful novel contribution .",
    "NOVELTY"
  ],
  [
    "I found the idea of having an implicit prior quite interesting",
    "NOVELTY"
  ],
  [
    "Overall -- -- -- -- I liked the paper a lot",
    "NOVELTY"
  ],
  [
    "The contribution of this work is not significant .",
    "NOVELTY"
  ],
  [
    "Comments The paper presents a nice framework that summarizes both multi-label classification and hierarchical clustering .",
    "NOVELTY"
  ],
  [
    "Originality The paper is original .",
    "NOVELTY"
  ],
  [
    "This work also seems incremental due to its resemblance with CD .",
    "NOVELTY"
  ],
  [
    "After reading other reviews and reading the revised paper I do think this approach of this paper is novel and can potentially lead to a gain .",
    "NOVELTY"
  ],
  [
    "present interesting ideas",
    "NOVELTY"
  ],
  [
    "Novelty is not that strong for a NIPS poster .",
    "NOVELTY"
  ],
  [
    "The introduction of the kernel inception metric is well-motivated and novel , to my knowledge .",
    "NOVELTY"
  ],
  [
    "In short , this paper is very novel and solid .",
    "NOVELTY"
  ],
  [
    "Even though AMTL operates on task relations and Deep-AMTFL is on feature learning , the main ideas of both methods are very similar",
    "NOVELTY"
  ],
  [
    "tasks with higher training losses will contribute less to other tasks ' model or feature representations",
    "NOVELTY"
  ],
  [
    "Even though the regularizers seem a bit different , the large similarity with AMTL decreases the novelty of this work .",
    "NOVELTY"
  ],
  [
    "The concrete approach seems to be rather novel",
    "NOVELTY"
  ],
  [
    "paper combines advances that",
    "NOVELTY"
  ],
  [
    "Unfortunately , I do not see any relevant technical novelty ,",
    "NOVELTY"
  ],
  [
    "To me , the takeaway that pre-processing is important and existing models are sensitive to pre-processing is not a new finding .",
    "NOVELTY"
  ],
  [
    "I have yet to see actionable development in this paper as it consists",
    "NOVELTY"
  ],
  [
    "Overall , this is an interesting paper , offering a novel solution to tackle the degradation in accuracy occuring in ternary quantization techniques because of the number of quantization steps .",
    "NOVELTY"
  ],
  [
    "The connection between the proper scoring rule and weight update function is intuitive and interesting .",
    "NOVELTY"
  ],
  [
    "While the use of auxiliary tasks to improve training of models including RL agents is not new",
    "NOVELTY"
  ],
  [
    "However , the contribution is relatively incremental given previous work on RL for navigation and on auxiliary tasks .",
    "NOVELTY"
  ],
  [
    "-I feel overall the contribution is not very novel .",
    "NOVELTY"
  ],
  [
    "I find the proposed algorithm very far from the usual SGD-based training methods",
    "NOVELTY"
  ],
  [
    "This is novel",
    "NOVELTY"
  ],
  [
    "This is novel",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is weak ,",
    "NOVELTY"
  ],
  [
    "The contribution of the current version is limited .",
    "NOVELTY"
  ],
  [
    "I \u2019 m not sure how strong novelty this paper brings in terms of technical contributions .",
    "NOVELTY"
  ],
  [
    "The idea of maximizing the minimum total variation is novel and interesting - The",
    "NOVELTY"
  ],
  [
    "seems to",
    "NOVELTY"
  ],
  [
    "work better than current SOTA approaches for generating diverse behavior Negative Points",
    "NOVELTY"
  ],
  [
    "1.The main idea of the paper has shown in other related works and",
    "NOVELTY"
  ],
  [
    "first order bound for OLO is new .",
    "NOVELTY"
  ],
  [
    "Though its theoretical guarantee is not optimal , the algorithm looks interesting and computationally efficient compared with previous optimal but sophisticated algorithm MYGA . The paper is well-written . The idea and analysis in this paper are new , and provide a new approach to analyze general online learning and bandits .",
    "NOVELTY"
  ],
  [
    ", and so the contribution is limited .",
    "NOVELTY"
  ],
  [
    "The proposed UMAL is novel .",
    "NOVELTY"
  ],
  [
    "This is a very interesting work",
    "NOVELTY"
  ],
  [
    "The idea to restrict the analysis to stationary points that are sufficiently good ( e.g. , with objective above a certain value ) is not new but",
    "NOVELTY"
  ],
  [
    "nevertheless insightful",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "and conveys an interesting new formulation of GANs .",
    "NOVELTY"
  ],
  [
    "The tools and techniques are somewhat similar to the work of Abbe-Sandon on SBMs",
    "NOVELTY"
  ],
  [
    "This paper can be regarded as an engineering work for a new domain of problem with little technical novelty . - From the perspective of NAS research , the proposed approach has little technical novelty",
    "NOVELTY"
  ],
  [
    "Given that the NAS is only applied to CNN backbones in this paper , the novelty ( of proposing a new task ) may be further weakened . - The novelty of this work over existing works of \u201c NAS on detection \u201d (",
    "NOVELTY"
  ],
  [
    "is not justified",
    "NOVELTY"
  ],
  [
    "mainly due to lack of technical novelty",
    "NOVELTY"
  ],
  [
    "However , even that is not entirely novel since such kernels did exist in the past",
    "NOVELTY"
  ],
  [
    "is a very nice idea with useful properties",
    "NOVELTY"
  ],
  [
    "but provides no real novelty in the approach",
    "NOVELTY"
  ],
  [
    "and contributes strongly to the use of Wasserstein",
    "NOVELTY"
  ],
  [
    "The use of the method in a WASP setting [ 47 ] is particularly appealing and promising .",
    "NOVELTY"
  ],
  [
    "the paper itself does not bring much insightful information .",
    "NOVELTY"
  ],
  [
    "The tiling trick is not something new",
    "NOVELTY"
  ],
  [
    "Although the technical contributions seem to be not quite significant",
    "NOVELTY"
  ],
  [
    "introduces a few new domains which are useful for studying problems in multiagent reinforcement",
    "NOVELTY"
  ],
  [
    "The framework is nice and appealing .",
    "NOVELTY"
  ],
  [
    "This is a new method for the visual correspondence problem , and addresses quite a few shortcomings or limitations of existing methods .",
    "NOVELTY"
  ],
  [
    "This work does seem to be significantly new , with important results that can advance state-of-the-art research and practice of optical flow estimation .",
    "NOVELTY"
  ],
  [
    "at this point I feel that the theoretical results , which constitute the majority of the paper , are of limited novelty and/or significance .",
    "NOVELTY"
  ],
  [
    "Theorem 2.5 is very related to results already proven for linear networks in earlier work",
    "NOVELTY"
  ],
  [
    ", so there is little novelty here",
    "NOVELTY"
  ],
  [
    "The probabilistic model and variational inference approach is new and interesting . Related work is cited and it differs from previous work through a new adaptation of the temperature of the policies",
    "NOVELTY"
  ],
  [
    "The paper is quite interesting and outperform its baseline by a",
    "NOVELTY"
  ],
  [
    "interesting idea - experiments are interesting cons",
    "NOVELTY"
  ],
  [
    "This paper is clearly original since it provides a new proof of a well-known result ( Catoni 's bound , recovered up to constants ) , a new definition of flatness ( h-flatness ) of the landscape where the posterior concentrates and a new PAC-Bayes bound associated to the notion of flatness . This paper is a nice theoretical contribution to the PAC-Bayesian theory of learning .",
    "NOVELTY"
  ],
  [
    "the new bound of Theorem 4.3 and the definition of flatness provided in Definition 4.1 are interesting and important theoretical contributions , successfully investigating the links between two major lines of research",
    "NOVELTY"
  ],
  [
    "methods in this family and to give better explanations by I vote for rejecting this paper as the contributions to what already exists in the literature are not clear",
    "NOVELTY"
  ],
  [
    "All in all , the true contribution of this work to other existing methods in this family is not enough for this venue .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the 40 billion parallel corpus for the NMT training is the largest reported in the paper published so far .",
    "NOVELTY"
  ],
  [
    "the methodology seems quite incremental over the previous work .",
    "NOVELTY"
  ],
  [
    "The contributions in the paper are clear .",
    "NOVELTY"
  ],
  [
    "I found this paper very original and thought-provoking ,",
    "NOVELTY"
  ],
  [
    "However , there lacks the novelty on the objectives defined in this paper .",
    "NOVELTY"
  ],
  [
    "The novelty of the work is still limited , since the techniques used are well-known and have been applied to other domains already .",
    "NOVELTY"
  ],
  [
    "In the rest of the dimensions , i.e. , theoretical and algorithmic , the paper is not adding anything novel to the literature .",
    "NOVELTY"
  ],
  [
    "The proposed model enables a unique approach to data exploration .",
    "NOVELTY"
  ],
  [
    "The paper is empirical in nature , and do not offer any additional insight .",
    "NOVELTY"
  ],
  [
    "Originality -STREETS differs from previous work in several ways",
    "NOVELTY"
  ],
  [
    "The benefit of only reconstructing a subset of the input dimensions seems very data specific to me and I find it hard to consider this a novel idea by itself . Presenting sequential data in a windowed format is a standard procedure and not a new idea either",
    "NOVELTY"
  ],
  [
    "All in all I do n't think that the paper presents any new ideas or interesting results .",
    "NOVELTY"
  ],
  [
    "No new ideas .",
    "NOVELTY"
  ],
  [
    "This is a very interesting piece of",
    "NOVELTY"
  ],
  [
    "It is worth noting that the idea of using language prediction for navigation in a grounded 3D environment has already been introduced by Hermann et al",
    "NOVELTY"
  ],
  [
    "paper that contributes to the development of language-grounded visual navigation agents Clarity",
    "NOVELTY"
  ],
  [
    "rather incremental work , missing reference on language generation for language-grounded agent Significance",
    "NOVELTY"
  ],
  [
    "this idea is not especially novel",
    "NOVELTY"
  ],
  [
    "Clever end-to-end differentiable rule-based inference method that allows to learn rules via backprop .",
    "NOVELTY"
  ],
  [
    "The novelty is incremental .",
    "NOVELTY"
  ],
  [
    "The main contribution of the paper as I see it is not in presenting novel techniques but rather in a way of combining existing techniques to obtain a more ( empirically ) practical algorithm .",
    "NOVELTY"
  ],
  [
    "This seems to be the first paper to apply non-parametric regression techniques to prove posterior concentration properties for spike-and-slab priors on DNNs . This is relatively novel , even if the results are a natural extension of existing work on spike-and-slab variable selection .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting",
    "NOVELTY"
  ],
  [
    "but the contribution seems quite limited .",
    "NOVELTY"
  ],
  [
    "I believe the perspective of solving for the Nash equilibrium of a bilinear approximation is novel",
    "NOVELTY"
  ],
  [
    "and many of the perspectives are original",
    "NOVELTY"
  ],
  [
    "I think the community would benefit from some of the ideas in this paper .",
    "NOVELTY"
  ],
  [
    "while the paper builds on existing work",
    "NOVELTY"
  ],
  [
    "I believe the contributions to be significant enough for acceptance to NIPS",
    "NOVELTY"
  ],
  [
    "acceptance to NIPS",
    "NOVELTY"
  ],
  [
    "While the idea of using Fano 's inequality to give a complexity score for datasets is interesting",
    "NOVELTY"
  ],
  [
    "The new algorithm fiEM is an interesting extension of the original algorithm iEM [ 1 ] .",
    "NOVELTY"
  ],
  [
    "The global convergence non-asymptotic rate analysis for the incremental EM algorithms is interesting .",
    "NOVELTY"
  ],
  [
    "Although the approach is not too innovative",
    "NOVELTY"
  ],
  [
    "the paper is interesting",
    "NOVELTY"
  ],
  [
    "A seemingly important novel feature of the model is the use of multiple INs at different speeds in the dynamics predictor .",
    "NOVELTY"
  ],
  [
    "and the proposed approach to be interesting",
    "NOVELTY"
  ],
  [
    "though the results are novel and original",
    "NOVELTY"
  ],
  [
    "The proposed Adversarial Dynamics Embedding is entirely novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "While I think",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "thought-provoking .",
    "NOVELTY"
  ],
  [
    "This feature of the considered setting is quite interesting .",
    "NOVELTY"
  ],
  [
    "Both ideas of DPG and DG are novel in preventing catastrophic forgetting . - DG is novel because it does not require storage of data and does not depend on labels .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "The novelty seems to be not sufficient to me , as multi-scale solutions are not new in computer vision and have been applied a lot in pose estimation as well",
    "NOVELTY"
  ],
  [
    "Weighting different scales is not fundamentally new .",
    "NOVELTY"
  ],
  [
    "if the methodological and theoretical contribution of the paper is rather minor ,",
    "NOVELTY"
  ],
  [
    "The idea proposed in the paper is quite interesting",
    "NOVELTY"
  ],
  [
    "This seems to be a valuable and novel analysis of the problem",
    "NOVELTY"
  ],
  [
    "since no works have introduced this idea into this domain as far as I know",
    "NOVELTY"
  ],
  [
    "The authors present a novel algorithm",
    "NOVELTY"
  ],
  [
    "3 .The proposed approach is simply a combination of the existing dropout methods . The contribution of the paper is very limited .",
    "NOVELTY"
  ],
  [
    "The model is technically novel , building up from existing approaches in a progressive way .",
    "NOVELTY"
  ],
  [
    "and also shown in this paper , this paper presents a new perspective to utilize GAN as a successful data-augmentation technique in teacher student paradigm",
    "NOVELTY"
  ],
  [
    "Knowledge distillation , as a classical model compression technique , has been applied in deep convolutional models for several years",
    "NOVELTY"
  ],
  [
    "The proposed TSCScore seems to be similar with [ 1",
    "NOVELTY"
  ],
  [
    "2 .It looks like the idea of stability-span is new to the analysis and that the definition/usage of this quantity is also a contribution of this paper .",
    "NOVELTY"
  ],
  [
    "it is an important contribution",
    "NOVELTY"
  ],
  [
    "As such , I do n't see much novelty in the paper compared with previous work .",
    "NOVELTY"
  ],
  [
    "The use of recurrent BP is probably the most distinction from previous work",
    "NOVELTY"
  ],
  [
    "The use of wFM instead of a convolutional layer is an interesting idea .",
    "NOVELTY"
  ],
  [
    "and proposes a new direction to find a memory efficient representation of symbols .",
    "NOVELTY"
  ],
  [
    "also when taking into account the existing literature the novelty of the work is quite limited . The idea of using backwards updates is quite old and goes back to at least the 1993 paper `` Prioritized Sweeping `` by Moore and Atkeson",
    "NOVELTY"
  ],
  [
    "so my main concern would be with a lack of",
    "NOVELTY"
  ],
  [
    "Based on the above , the authors propose a novel boosting algorithm that minimizes a regularized Rademacher observation loss , showing that learning is computationally efficient .",
    "NOVELTY"
  ],
  [
    "it does not seem to have influenced the work of many other researchers in ensemble learning or other fields .",
    "NOVELTY"
  ],
  [
    "and the framework presented seems new and useful",
    "NOVELTY"
  ],
  [
    "The manuscript appears to be a straightforward extension of NAM to include a variational autoencoder and the work appears somewhat incremental",
    "NOVELTY"
  ],
  [
    "The relationship between causal inference and biologically plausible learning is very interesting .",
    "NOVELTY"
  ],
  [
    "Application of the RDD method to spiking neural net training is novel .",
    "NOVELTY"
  ],
  [
    "and the suggested algorithm original and interesting .",
    "NOVELTY"
  ],
  [
    "The architecture seems novel and is well motivated",
    "NOVELTY"
  ],
  [
    "and shows a promising future direction",
    "NOVELTY"
  ],
  [
    "I think this paper lack novelty",
    "NOVELTY"
  ],
  [
    "and this is not new",
    "NOVELTY"
  ],
  [
    "doubts about the interest and originality The authors provided detailed and convincing answers to my questions",
    "NOVELTY"
  ],
  [
    "The idea is interesting , novel , and formalizes issues with interchanging integration and differentiation that might not be evident to most of the NIPS community .",
    "NOVELTY"
  ],
  [
    "I like this paper a lot - the idea of defining tuning functions using the embedding is clever",
    "NOVELTY"
  ],
  [
    "presents results that are novel",
    "NOVELTY"
  ],
  [
    "appear to be really insightful",
    "NOVELTY"
  ],
  [
    "The proposed idea is not particularly novel",
    "NOVELTY"
  ],
  [
    "The first term is bounded using a random walk type of analysis , which to the best of my knowledge is novel . I find this",
    "NOVELTY"
  ],
  [
    "I think the idea is quite interesting .",
    "NOVELTY"
  ],
  [
    "Toward the actual goal of unsupervised learning of landmark points I think the idea is rather neat and creative .",
    "NOVELTY"
  ],
  [
    "Within this area of work , the paper is original and significant",
    "NOVELTY"
  ],
  [
    "This paper is largely building off of prior research in hierarchical RL and transfer learning .",
    "NOVELTY"
  ],
  [
    "The core ideas of this paper are shared by many other works transfer learning to guide hiearchical RL",
    "NOVELTY"
  ],
  [
    "The paper demonstrates novel ways of combining hierarchical RL and transfer learning",
    "NOVELTY"
  ],
  [
    "but this is not a unique approach towards that",
    "NOVELTY"
  ],
  [
    "I like the idea of using a linear combination of the Q-values ( and cumulants ) in a generalized policy improvement framework .",
    "NOVELTY"
  ],
  [
    "idea",
    "NOVELTY"
  ],
  [
    "Overall , I like this paper and the proposed approach , and think this is a thoughtful and encouraging work .",
    "NOVELTY"
  ],
  [
    "The high-level idea is quite interesting",
    "NOVELTY"
  ],
  [
    "due to fact that the core idea is simple and original",
    "NOVELTY"
  ],
  [
    "interesting one",
    "NOVELTY"
  ],
  [
    "This submission provides interesting facts that are omitted in previous research works .",
    "NOVELTY"
  ],
  [
    "This makes the novelty of this submission relatively weak .",
    "NOVELTY"
  ],
  [
    "Although I 'm not an expert in the field , I feel this paper is well written and pushes the boundaries of what is known .",
    "NOVELTY"
  ],
  [
    "The novelty is relatively low since the compilation algorithm presented here is very similar to the compilation algorithm for AND/OR Multi-Valued Decision Diagrams ( AOMDDs ) , which are a special case of PSDDs .",
    "NOVELTY"
  ],
  [
    "The general idea of being able to better control the behavior of neural networks by better leveraging known structure ( e.g. , algorithms ) is appealing .",
    "NOVELTY"
  ],
  [
    "The innovation is a bit on the incremental level , especially given the results from WAE",
    "NOVELTY"
  ],
  [
    "Although there 's not much originality in algorithmic proposals",
    "NOVELTY"
  ],
  [
    "Overall , the approach presented is not",
    "NOVELTY"
  ],
  [
    "Although the contributions of the work are mostly on the theoretical side",
    "NOVELTY"
  ],
  [
    "it seems to me that this work is incremental in terms of understanding the He initialization .",
    "NOVELTY"
  ],
  [
    "Without those claims the contribution of this paper is incremental and does not warrant publication at this time .",
    "NOVELTY"
  ],
  [
    "Principled and quite original modeling based on variational inference",
    "NOVELTY"
  ],
  [
    "and I am not sure if analyzing RMSProp/Adam in this setting should be considered a significant contributions of the paper .",
    "NOVELTY"
  ],
  [
    "2 .The proposed algorithm AvaGrad is a simple but interesting idea .",
    "NOVELTY"
  ],
  [
    "I think decoupling the learning rate and the damping parameter by normalizing the preconditioner is a simple but interesting idea",
    "NOVELTY"
  ],
  [
    "We are also concerned about the novelty of the results",
    "NOVELTY"
  ],
  [
    "The paper is incremental and does n't really provide improvements to learning parameters",
    "NOVELTY"
  ],
  [
    "This paper is one of the first",
    "NOVELTY"
  ],
  [
    "and do provide novel insights",
    "NOVELTY"
  ],
  [
    "Overall I really like the paper , it appears crisp , insightful and polished .",
    "NOVELTY"
  ],
  [
    "and it is a natural extension of the recent literature of theoretical deep learning",
    "NOVELTY"
  ],
  [
    "As far as I know this is the first analysis to shed light on the stability and smoothness effect of batch normalization as its most important feature for helping optimization .",
    "NOVELTY"
  ],
  [
    "The idea of learning from a compressed representation is a very interesting and beneficial idea for large-scale image understanding tasks .",
    "NOVELTY"
  ],
  [
    "As it is mentioned in the paper , solving a Vision problem directly from a compressed image , is not a novel method",
    "NOVELTY"
  ],
  [
    "However , applying a deep representation for the compression and then directly solving a vision task ( classification and segmentation ) can be considered as a novel idea .",
    "NOVELTY"
  ],
  [
    "The proposed approach to solve catastrophic forgetting is new ( to my knowledge",
    "NOVELTY"
  ],
  [
    ") yet also straightforward , replacing experience replay with a replay mechanism based on a generative model",
    "NOVELTY"
  ],
  [
    "the paper has a compelling and promising idea ( graph transfer",
    "NOVELTY"
  ],
  [
    "My feeling from reading the paper is that it is rather incremental over Cai et al .I am impressed by the results of the three experiments that have been shown here",
    "NOVELTY"
  ],
  [
    "there is not much novel insight or really exciting new ideas presented .",
    "NOVELTY"
  ],
  [
    "The idea in this paper is moderately interesting , well-founded",
    "NOVELTY"
  ],
  [
    "has plenty of precedent in the literature ( while still being reasonably novel",
    "NOVELTY"
  ],
  [
    "While I think the idea is interesting",
    "NOVELTY"
  ],
  [
    "the",
    "NOVELTY"
  ],
  [
    "All in all a good paper that pushes the boundaries of image denoising and super-resolution",
    "NOVELTY"
  ],
  [
    "The simplicity and generality of the method are appealing .",
    "NOVELTY"
  ],
  [
    "but to my knowledge the broad applicability to non-decomposable and non-differentiable metrics expressible in terms of the confusion matrix is new",
    "NOVELTY"
  ],
  [
    "I think this paper is a strong contribution",
    "NOVELTY"
  ],
  [
    "Overall , the idea is clever",
    "NOVELTY"
  ],
  [
    "The most appealing aspect of this work is that the developed YASS system outperforms relative",
    "NOVELTY"
  ],
  [
    "2 .Many of the components in the Yass pipeline are derivative of previous work .",
    "NOVELTY"
  ],
  [
    "The claims of `` probabilistic completeness `` are not particularly insightful",
    "NOVELTY"
  ],
  [
    "The computational evaluations are not particularly insightful , in that they seems to not give much insight into exactly what is happening .",
    "NOVELTY"
  ],
  [
    "Idea is quite intriguing .",
    "NOVELTY"
  ],
  [
    "author provides an interesting modification to the PoWER algorithm",
    "NOVELTY"
  ],
  [
    "with variational bounds on the value function",
    "NOVELTY"
  ],
  [
    "it is hard to say if this contribution is enough for NeurIPS .",
    "NOVELTY"
  ],
  [
    "My concern was that , most of the hard works are already done in the previous papers , and the matrix-tensor model may not be interesting",
    "NOVELTY"
  ],
  [
    "the paper has not enough insights to constitute a significant theoretical contribution",
    "NOVELTY"
  ],
  [
    "The idea of learning generic shared common and latent implicit patterns across different graph structure is brilliant .",
    "NOVELTY"
  ],
  [
    "Novelty is not enough .",
    "NOVELTY"
  ],
  [
    "The idea is very interesting and novel .",
    "NOVELTY"
  ],
  [
    "I believe the paper is novel . The differentiable wireframe rendering is new and very interesting .",
    "NOVELTY"
  ],
  [
    "The idea of trying to move in the function space rather than in the parameter space is definitely not new",
    "NOVELTY"
  ],
  [
    "the proposed HCGD seems quite new",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel algorithm that penalizes movement in the function space .",
    "NOVELTY"
  ],
  [
    "The origins of the HCGD algorithm is extremely similar to the origins of Natural Gradient",
    "NOVELTY"
  ],
  [
    "but I do not understand the advantage of the max-component compared to this , so it seems to me that the max-component trick is a fairly limited contribution in itself . - the main novelty seems to be the regularizer",
    "NOVELTY"
  ],
  [
    "I think the technical contribution of this paper is a bit weak in that they mostly followed the original IBP and the only novelties are the random patch training and guided patch training .",
    "NOVELTY"
  ],
  [
    "Psychologists have long been plagued by vague definitions of saliency , and the authors propose a novel and innovative model ( as far as I am aware ) that could aid the development of better understanding how what makes something salient and a formal model for eye movements ( within the bottom-up tradition ) .",
    "NOVELTY"
  ],
  [
    "and the proposed application is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The degree of novelty is not very high . While the task is new , I believe the technical innovation is not profound .",
    "NOVELTY"
  ],
  [
    "I like the general approach of explicitly putting desired equivariance in the convolutional networks . Using a hexagonal lattice is elegant , even if it is not new in computer vision",
    "NOVELTY"
  ],
  [
    "rather modest originality",
    "NOVELTY"
  ],
  [
    "but this method is just not that novel",
    "NOVELTY"
  ],
  [
    "The idea of iteratively refining an adjacency matrix A to obtain sparsity and smoothness is interesting",
    "NOVELTY"
  ],
  [
    "Other parts in the paper such as using similarity between nodes",
    "NOVELTY"
  ],
  [
    "to compute adjacency matrix or using the learned adjacency matrix with graph neural network is not new and have been done by many other works .",
    "NOVELTY"
  ],
  [
    "The observations of the impact of the graph properties on the filter choice are interesting",
    "NOVELTY"
  ],
  [
    "limited",
    "NOVELTY"
  ],
  [
    "After so much recent work in image generation using Generative Adversarial Networks it is nice to see a novel proposal for videos .",
    "NOVELTY"
  ],
  [
    "The examples considered seem a bit too simple to be insightful",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is also not strong . The only novel part",
    "NOVELTY"
  ],
  [
    "in this paper is the parametrization of the",
    "NOVELTY"
  ],
  [
    "task relationship matrix",
    "NOVELTY"
  ],
  [
    "the Unfocused update of the proposed method is quite similar to SPL",
    "NOVELTY"
  ],
  [
    "Good results - Method appears largely novel",
    "NOVELTY"
  ],
  [
    "( although bears some resemblance to https",
    "NOVELTY"
  ],
  [
    "The contributions are incremental",
    "NOVELTY"
  ],
  [
    "but clearly novel",
    "NOVELTY"
  ],
  [
    "Again , the paper 's contributions seem genuinely new and interesting .",
    "NOVELTY"
  ],
  [
    "the contributions are useful but do n't constitute any paradigm shift",
    "NOVELTY"
  ],
  [
    "I think overall this paper is a good contribution . The Bayesian and the frequentist analysis for the TS-MNL algorithm is novel .",
    "NOVELTY"
  ],
  [
    "The approach is original .",
    "NOVELTY"
  ],
  [
    "and the idea proposed is expected to be of practival interest to the bayesian optimizaiton",
    "NOVELTY"
  ],
  [
    "the paper also introduces various new one-shot learning tasks",
    "NOVELTY"
  ],
  [
    "this paper introduces a simple and interesting method to train one-shot learning classifiers .",
    "NOVELTY"
  ],
  [
    "More critically , the idea of taking the gradient of a model w.r.t.its parameters over an example to encode geometric relationship of the example in the data manifold is by no means novel at the conceptual level .",
    "NOVELTY"
  ],
  [
    "I don \u2019 t see any novelty here by doing this to a new model ( deep neural networks",
    "NOVELTY"
  ],
  [
    "contribution is also vague and trivial compared to literature , plus",
    "NOVELTY"
  ],
  [
    "While I found the general approach of the paper interesting",
    "NOVELTY"
  ],
  [
    "I have serious concerns about its originality and clarity .",
    "NOVELTY"
  ],
  [
    "To me , the released dataset is one of the key contributions of this work .",
    "NOVELTY"
  ],
  [
    "While the theorems proved in the paper are original and novel",
    "NOVELTY"
  ],
  [
    ", they are a refinement of the already known results regarding approximation theorems for PointNet and DeepSets , respectively , hence only a marginal improvement in understanding these function classes .",
    "NOVELTY"
  ],
  [
    "The idea of never training over the ground-truth sequence , but training on sampled prefix and an optimized suffix is very novel .",
    "NOVELTY"
  ],
  [
    "The paper proposed a very interesting training algorithm for auto-regressive models especially it does not require any MLE pre-training and can directly optimize from the sampling",
    "NOVELTY"
  ],
  [
    "I like the ideas in this paper",
    "NOVELTY"
  ],
  [
    "The paper seems the first to introduce Bloomier filter into the network compression problem . I think its contribution is novel and original .",
    "NOVELTY"
  ],
  [
    "The idea is certainly elegant and",
    "NOVELTY"
  ],
  [
    "I also find that the paper is a little light on the technical side .",
    "NOVELTY"
  ],
  [
    "I think the overall approach is interesting and a novel way to address the growing concern of how to access coordination between agents in multi-agent systems .",
    "NOVELTY"
  ],
  [
    "I also like the idea to use the Gumbel-softmax trick to make the entire model differentiable",
    "NOVELTY"
  ],
  [
    "The existence of this previous work also reduces the novelty of the proposed approach",
    "NOVELTY"
  ],
  [
    "To me , this class of algorithm sounds very appealing as it is very natural and could realistically be implemented in practice",
    "NOVELTY"
  ],
  [
    "In terms of novelty , the proposed modification of SQAIR ( separating object detection and latent dynamics prediction ) is novel and likely leads to a speed-up in training and evaluation",
    "NOVELTY"
  ],
  [
    "On a final note , gradient based sampling , is not in itself a novel idea .",
    "NOVELTY"
  ],
  [
    "This work uses the idea of generative adversarial models and applies it in a novel and clever way to learn identity discriminative feature representations that are robust to pose and background variations -- probably the two most significant challenges in person re-identification .",
    "NOVELTY"
  ],
  [
    "Though the proposed system is based on multiple known techniques , the combination is novel and well thought-out .",
    "NOVELTY"
  ],
  [
    "mean that",
    "NOVELTY"
  ],
  [
    "but that on its own , it does not contribute a significant contribution .",
    "NOVELTY"
  ],
  [
    "The second idea , of learning which variables to ignore , seems original and is interesting .",
    "NOVELTY"
  ],
  [
    "The idea to put attention into zero shot learning task , especially first regresses global image feature to textual representation , then use it to guide attention , is new .",
    "NOVELTY"
  ],
  [
    "While I believe",
    "NOVELTY"
  ],
  [
    "this idea has not specifically been tried in previous literature and the vague intuition that NF leads to more exploration that helps learning a better policy , the novelty of combining these two seems limited ,",
    "NOVELTY"
  ],
  [
    "the paper 's strengths are ( to the best of this reviewer 's knowledge ) its originality and potential significance . The insight that Groebner bases can be used as a rich language to encode algebraic constraints and highlighting the connection to this vast background theory opens an entirely new approach in modelling capacities for Gaussian processes",
    "NOVELTY"
  ],
  [
    "I think the theory presented therein is highly original and significant",
    "NOVELTY"
  ],
  [
    "I think that adding computer-algebra code sounds like a good idea .",
    "NOVELTY"
  ],
  [
    "but the novelty might be limited since the theoretical result has been established for IHT under standard unstructured sparsity assumption in",
    "NOVELTY"
  ],
  [
    "The technical contribution seems a bit incremental compared to MPO .",
    "NOVELTY"
  ],
  [
    "In my opinion , the marginal contribution of the paper beyond prior work on adaptive submodularity and the submodular secretary problem is too weak to warrant inclusion in NIPS . The streaming setting is well-motivated for this type of",
    "NOVELTY"
  ],
  [
    "but paper 's technical contribution strikes me as too incremental .",
    "NOVELTY"
  ],
  [
    "The originality is not high as most of theoretical discussion is based on the existing work and the resulting hierarchical clustering algorithm is a straightforward extension of the average linkage method .",
    "NOVELTY"
  ],
  [
    "The proposed formulation of hierarchical clustering is interesting .",
    "NOVELTY"
  ],
  [
    "The idea is novel",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel and principled way of using and constructing GNNs for a wide variety of tasks .",
    "NOVELTY"
  ],
  [
    "the techniques used in this work seem to be of a different nature",
    "NOVELTY"
  ],
  [
    "I think the framework proposed by this paper is still novel given the fact that there are several existing RL based approaches solving similar problems",
    "NOVELTY"
  ],
  [
    "Overall , I find the idea of the paper quite interesting and I \u2019 m excited to use the datasets they have created .",
    "NOVELTY"
  ],
  [
    "I think the relative novelty of the paper does not meet ICLR standards",
    "NOVELTY"
  ],
  [
    "In that sense , this study has sufficient novelty .",
    "NOVELTY"
  ],
  [
    "In my view , this is an idea that would interest the NIPS audience .",
    "NOVELTY"
  ],
  [
    "The general idea of multi-scale generation is not new",
    "NOVELTY"
  ],
  [
    "Training both the templates and the deformations of a registration procedure end-to-end is novel and very useful .",
    "NOVELTY"
  ],
  [
    "I think the idea is interesting and novel .",
    "NOVELTY"
  ],
  [
    "The idea is novel and practical in the scenario of DNN .",
    "NOVELTY"
  ],
  [
    "Even though there is not that",
    "NOVELTY"
  ],
  [
    "novel method proposed",
    "NOVELTY"
  ],
  [
    "The population-based S2P seems to be a bit incremental and unrelated to the main theme of the paper .",
    "NOVELTY"
  ],
  [
    "the motivation of adding POP into S2P based on the policy variability is somewhat different from the original claim about the combination of supervised and selfplay",
    "NOVELTY"
  ],
  [
    "the improvements on IBR in Figure 7 are incremental , making the major claim of this work little divergent .",
    "NOVELTY"
  ],
  [
    "While there 's nothing really new in terms of machine learning , this work merges different novelties to create an efficient framework that will create new perspectives in NLP.A general remark",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , these contributions are novel ,",
    "NOVELTY"
  ],
  [
    "and contributions are good",
    "NOVELTY"
  ],
  [
    "The idea of the paper is very interesting .",
    "NOVELTY"
  ],
  [
    "the degree of novelty on offer seems minimal and",
    "NOVELTY"
  ],
  [
    ", and appears to be original",
    "NOVELTY"
  ],
  [
    "While this paper made a nice contribution which successfully modifies the correspondence LDA model for brain image modeling",
    "NOVELTY"
  ],
  [
    "neither the problem or the method is novel .",
    "NOVELTY"
  ],
  [
    "the proposed method is incremental variant of the correspondence LDA , whose technical value is limited .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel way of how to train a multi-view stereo system .",
    "NOVELTY"
  ],
  [
    "I think the proposed idea is interesting and potentially promising",
    "NOVELTY"
  ],
  [
    "The proposed SPA-based algorithms are novel and have theoretic guarantees but only use second-order statistics unlike other tensor-based algorithms which requires three-order statistics",
    "NOVELTY"
  ],
  [
    "The connection to multi-particle ODEs is genuinely interesting .",
    "NOVELTY"
  ],
  [
    "it is not sufficiently fleshed out to count as a contribution ( yet ) .",
    "NOVELTY"
  ],
  [
    "The proposed method named MetaGrad is promising , and the derived upper bounds interesting .",
    "NOVELTY"
  ],
  [
    "I think the sample complexity results are new for LQR setting",
    "NOVELTY"
  ],
  [
    "I still think the actual contributions of the paper are minor .",
    "NOVELTY"
  ],
  [
    "I like the idea . The construction of the input layer from persistence diagrams is novel and well-thought .",
    "NOVELTY"
  ],
  [
    "This work is , as far as I can tell , original work .",
    "NOVELTY"
  ],
  [
    "This is a highly specialized contribution building up novel results on two main fronts",
    "NOVELTY"
  ],
  [
    "surprising",
    "NOVELTY"
  ],
  [
    "Data collection part itself seems to be the biggest contribution to this work",
    "NOVELTY"
  ],
  [
    "To my knowledge this is an original approach to the unsupervised learning of object segmentation .",
    "NOVELTY"
  ],
  [
    "If this is the case , I find the whole idea limited as it",
    "NOVELTY"
  ],
  [
    "with a mix of different categories .",
    "NOVELTY"
  ],
  [
    "The idea of using that particular gradient as a guide to selecting which parameters to prune is actually not new and has been previously proposed at [ 1 ] .",
    "NOVELTY"
  ],
  [
    "the idea of parameterizing sine functions is novel and interesting .",
    "NOVELTY"
  ],
  [
    "This regime has been considered in prior work",
    "NOVELTY"
  ],
  [
    "I have the impression that this paper contains interesting ideas",
    "NOVELTY"
  ],
  [
    "the paper does not make its contribution clear .",
    "NOVELTY"
  ],
  [
    "and I find the idea rather interesting , despite not having a huge gap in raw performance",
    "NOVELTY"
  ],
  [
    "I also should note that this paper is not the first to propose conducting online meta-learning over a replay buffer",
    "NOVELTY"
  ],
  [
    "While there is a concern raised above , the paper still contributes a good solution for solving CPOMDPs online with another MCTS-based approach .",
    "NOVELTY"
  ],
  [
    "My main concern is the limited technical novelty and evaluation",
    "NOVELTY"
  ],
  [
    "This paper is novel and impactful .",
    "NOVELTY"
  ],
  [
    "Overall , I think this is an interesting , novel contribution",
    "NOVELTY"
  ],
  [
    "The method proposed , while interesting , well-conceived and potentially novel",
    "NOVELTY"
  ],
  [
    "Overall this is a nice idea that works on using black box models to amortize the residuals from doing inference assuming a linearized approximation to the model .",
    "NOVELTY"
  ],
  [
    "While this idea in itself is n't new",
    "NOVELTY"
  ],
  [
    "Pros 1 .The degenerate embedding problem is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The present paper describes an interesting approach",
    "NOVELTY"
  ],
  [
    "is a new way of building cognitive aspects into a learning algorithm",
    "NOVELTY"
  ],
  [
    "Although the the application of density ratio estimation to variational inference seems to be an idea 'in the air ' and building blocks of this paper have appeared elsewhere",
    "NOVELTY"
  ],
  [
    "This is not a big surprise , but I like the simple but clever idea of reset that the paper exploits .",
    "NOVELTY"
  ],
  [
    "The idea of using a closed family of functions induced by pgfs for representing intermediate factors in inference is novel ( as far as there is ever anything new under the sun",
    "NOVELTY"
  ],
  [
    "The algorithm , even if a simple modification of ADAM , is new , and the proofs seem to be new as well .",
    "NOVELTY"
  ],
  [
    "The work is highly original and I believe it could lead to novel RL algorithms in the future .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution of this paper is nice and valuable .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is intriguing",
    "NOVELTY"
  ],
  [
    "This by itself is a neat contribution",
    "NOVELTY"
  ],
  [
    "I find this aspect of the paper narrowing its contribution",
    "NOVELTY"
  ],
  [
    "While the idea is interesting and might be a good alternative to standard CNNs",
    "NOVELTY"
  ],
  [
    "The feature extraction network seems to be similar",
    "NOVELTY"
  ],
  [
    "The GAN-based feature generation seems to be new in this paper .",
    "NOVELTY"
  ],
  [
    "I think the idea of using GANs to generate features that can help with the classification + taking advantage of the relationship/structure among the ICD codes are both interesting ideas .",
    "NOVELTY"
  ],
  [
    ".The work is rather incremental",
    "NOVELTY"
  ],
  [
    "but",
    "NOVELTY"
  ],
  [
    "contains stimulating insights",
    "NOVELTY"
  ],
  [
    "They propose a smart modification of the previous approach by evaluating the sign of the gradient rather than the gradient itself",
    "NOVELTY"
  ],
  [
    "and propose an interesting modification of a previous algorithm",
    "NOVELTY"
  ],
  [
    "The novelty of each proposed trick is limited",
    "NOVELTY"
  ],
  [
    "However , the combination is novel , well-motivated",
    "NOVELTY"
  ],
  [
    "I like this paper : it is a intuitive idea",
    "NOVELTY"
  ],
  [
    "While I really like the ideas in this paper",
    "NOVELTY"
  ],
  [
    "The idea is fresh ,",
    "NOVELTY"
  ],
  [
    "1 ) potentially a good idea ,",
    "NOVELTY"
  ],
  [
    "I feel that this method provides a nice contribution to work on Bayesian DP , and extends where one can use these methods to data-distributed",
    "NOVELTY"
  ],
  [
    "which seems",
    "NOVELTY"
  ],
  [
    "Each of the above contributions is highly original .",
    "NOVELTY"
  ],
  [
    "does not seem to contain any striking new ideas",
    "NOVELTY"
  ],
  [
    "Learning sample-reweighting from data is not a new thing .",
    "NOVELTY"
  ],
  [
    "The optimization framework (",
    "NOVELTY"
  ],
  [
    ") is novel and neat",
    "NOVELTY"
  ],
  [
    ", and the approach is unique in this reviewer 's knowledge .",
    "NOVELTY"
  ],
  [
    "the novelty of this work is not enough .",
    "NOVELTY"
  ],
  [
    "The introduced technique is interesting .",
    "NOVELTY"
  ],
  [
    "But the stochastic alignment and policy space constraint seem novel and important .",
    "NOVELTY"
  ],
  [
    "2 .The idea is interesting .",
    "NOVELTY"
  ],
  [
    "1 .Originality The novel formulation of model competence is conceptually simple and straightforward , yet original . Although the proposed method depends largely on the state-of-the-art anomaly detector ( Lee et al .2018 ) for modeling distributional uncertainty and the simple transfer classifiers for data uncertainty , the novel formulation of delta competence enables simple yet effective modeling of model uncertainty for any classifier with any error function . As a combination , the proposed method is original as well as conceptually appealing .",
    "NOVELTY"
  ],
  [
    "there is really very little in this paper that is new relative to the original paper by Cohen et al",
    "NOVELTY"
  ],
  [
    "The idea of using unlabeled data for continual learning is interesting and to the best of my knowledge this is the first work that suggests using delayed feedback for continual learning but unfortunately they do not consider measuring forgetting and this work seems an online learning method using delayed feedback",
    "NOVELTY"
  ],
  [
    "the authors introduce a novel layer-wise objective that pushes the binary activations to match the real activations , which are given by a teacher model ( real-to-binary ) .",
    "NOVELTY"
  ],
  [
    "B `` for multi-fidelity BO and parallel BO , it is an incremental contribution to combine them ,",
    "NOVELTY"
  ],
  [
    "I believe the paper does contain interesting results that are novel and useful to the community .",
    "NOVELTY"
  ],
  [
    "Adversarial fairness methods are not new",
    "NOVELTY"
  ],
  [
    "The proposed method is certainly novel and the contribution is original enough",
    "NOVELTY"
  ],
  [
    "Overall , the paper proposes a novel approach to zero-shot learning .",
    "NOVELTY"
  ],
  [
    "heuristic",
    "NOVELTY"
  ],
  [
    "I liked the overall ideas",
    "NOVELTY"
  ],
  [
    "However , this formulation has barely any novelty .",
    "NOVELTY"
  ],
  [
    "and I think it is indeed innovative to extend the simulator for the purpose of learning as a synthesis of two different fields . This submission",
    "NOVELTY"
  ],
  [
    "the paper suffers from lacking algorithmic contributions",
    "NOVELTY"
  ],
  [
    "Lacking algorithmic contribution : this paper applies existing tools/methods to solve the problem rather than developing something new or extending them",
    "NOVELTY"
  ],
  [
    "The sandwich bound is novel in and of itself",
    "NOVELTY"
  ],
  [
    "but it is not incredibly insightful on its own .",
    "NOVELTY"
  ],
  [
    "none of which are novel . The quality of this paper 's contribution is mixed .",
    "NOVELTY"
  ],
  [
    "While the idea is natural",
    "NOVELTY"
  ],
  [
    "My main concern is if bringing together this collection of earlier tools is a sufficient novel contribution for this conference .",
    "NOVELTY"
  ],
  [
    "I\u00e2\u0080\u0099m not an expert in this specific area and I do have some difficulties appreciating the originality and importance of this paper",
    "NOVELTY"
  ],
  [
    "The casting of the problem as domain adaptation is original",
    "NOVELTY"
  ],
  [
    "The paper is somewhat incremental considering that Li et al",
    "NOVELTY"
  ],
  [
    "2017 ) and Balaji et al",
    "NOVELTY"
  ],
  [
    "have already proposed meta-learning parameter-wise learning rates and parameter-wise regularization coefficient respectively",
    "NOVELTY"
  ],
  [
    "For this , it also introduces a novel multivariate generalization of quantile functions .",
    "NOVELTY"
  ],
  [
    "While the authors tend to sell the idea for both zero-shot",
    "NOVELTY"
  ],
  [
    "and few-shot learning , the novelty to ZSL is actually much small .",
    "NOVELTY"
  ],
  [
    "The authors propose a novel task and experimental framework for considering their method , and show",
    "NOVELTY"
  ],
  [
    "To my knowledge there is little prior work on unsupervised/self-supervised learning on remote sensing/satellite data and this data suits the contrastive/multiview framework very well",
    "NOVELTY"
  ],
  [
    "The idea of showing that causal reasoning naturally emerges from certain decision-making tasks and that modern ( meta-learning ) RL agents can become attuned to causal structure of the world without being explicitly trained to answer causal questions is an attractive one . I also find much about the specific paper elegant and creative .",
    "NOVELTY"
  ],
  [
    "I am optimistic that a future version of this paper will be a wonderful contribution",
    "NOVELTY"
  ],
  [
    "Overall this is significant and original work for learning 3D keypoints from images .",
    "NOVELTY"
  ],
  [
    "bayesian inference approach to active learning , the various approximations",
    "NOVELTY"
  ],
  [
    "Overall I like the idea of estimating kernel functions from ordinal data . To best of my knowledge this has not been done before and I believe that the intuitive idea proposed in this paper can help practitioners do standard kernel-based learning tasks from ordinal data",
    "NOVELTY"
  ],
  [
    "The results seem novel and interesting .",
    "NOVELTY"
  ],
  [
    "novelty is somehow weak .",
    "NOVELTY"
  ],
  [
    "The goal of the paper , which is to design an algorithm to find highly-desired items in a large pool , seems very natural to me .",
    "NOVELTY"
  ],
  [
    "but I am not convinced that it brings enough novelty to the RL software landscape for a published ICLR paper",
    "NOVELTY"
  ],
  [
    "but still leaning towards rejection due to the fact I am still not convinced that this library brings that much novelty compared to existing other libraries",
    "NOVELTY"
  ],
  [
    "but I do not find these results particularly insightful",
    "NOVELTY"
  ],
  [
    "and makes a clear contribution to the field",
    "NOVELTY"
  ],
  [
    "The paper takes an interesting idea , and does a",
    "NOVELTY"
  ],
  [
    "exploring the solution .",
    "NOVELTY"
  ],
  [
    "Overall , this work represents a significant but incremental step forwards for this `` hybrid `` -RL class of algorithms .",
    "NOVELTY"
  ],
  [
    "The theoretical result given in Theorem 3 of the paper is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Originality The novel aspect of the paper is the way distance is measured by converting the weights ( and activations ) to probability distributions and using KL divergence to measure distance",
    "NOVELTY"
  ],
  [
    "Their novel improvements to the existing segmentation and LSTM techniques produces a reliable path to exploiting context",
    "NOVELTY"
  ],
  [
    "the authors expand on the existing techniques and propose novel extensions to LSTM and use of context",
    "NOVELTY"
  ],
  [
    "Given how simple the modification is , the novelty is also limited , and not sufficient relative to the low significance .",
    "NOVELTY"
  ],
  [
    "and presents an interesting method for structure learning",
    "NOVELTY"
  ],
  [
    "Usig the spherical projection representation is interesting",
    "NOVELTY"
  ],
  [
    "it presents a simple and nice method through spherical projection .",
    "NOVELTY"
  ],
  [
    "The technical contributions of the paper is not very strong though .",
    "NOVELTY"
  ],
  [
    "I note that this idea is not new",
    "NOVELTY"
  ],
  [
    "The idea of constructing these as separate Gamma likelihoods is novel as far as I am aware",
    "NOVELTY"
  ],
  [
    "although it is not groundbreaking",
    "NOVELTY"
  ],
  [
    "It provides a new experimental approach .",
    "NOVELTY"
  ],
  [
    "one could argue that the paper does not provide a new method which outperforms previous methods in a general sense and that no novel theoretical tools are introduced",
    "NOVELTY"
  ],
  [
    "It is mainly a combination of existing tools , but",
    "NOVELTY"
  ],
  [
    "the combination seems to be novel .",
    "NOVELTY"
  ],
  [
    "the algorithms and all the analysis are too similar to that in MAI .",
    "NOVELTY"
  ],
  [
    "However , there does n't seem to be a lot of novel content in the paper",
    "NOVELTY"
  ],
  [
    "the contribution seems to be theorem 1 , but this is basically a restatement of a do-calculus result from ( Pearl , 2009 ) .",
    "NOVELTY"
  ],
  [
    "The paper seems to basically be a combination of these two methods",
    "NOVELTY"
  ],
  [
    "it 's difficult to determine whether there is any significantly novelty here and whether this might be relevant to the potential impact of the paper",
    "NOVELTY"
  ],
  [
    "there does not seem to be enough novelty to warrant acceptance for this paper .",
    "NOVELTY"
  ],
  [
    "The proposed methodology builds on prior work ( citations [ 3 ] and [",
    "NOVELTY"
  ],
  [
    "and the contribution of the paper is incremental and somehow similar in nature to the aforementioned work .",
    "NOVELTY"
  ],
  [
    "All contributions seem novel .",
    "NOVELTY"
  ],
  [
    "the issue identified in this paper , however , seems novel",
    "NOVELTY"
  ],
  [
    "I believe the",
    "NOVELTY"
  ],
  [
    "form , is marginal at best",
    "NOVELTY"
  ],
  [
    "The methods in this paper are adequately novel and original , nicely combining various elements from previous work .",
    "NOVELTY"
  ],
  [
    "This is the only contribution of the paper , and I believe it is insufficient .",
    "NOVELTY"
  ],
  [
    "the novelty and distinctiveness of the modularization approach was not apparent",
    "NOVELTY"
  ],
  [
    "I am not sure whether it has been done before",
    "NOVELTY"
  ],
  [
    "The proposed feature smoothing method seems less novel to me .",
    "NOVELTY"
  ],
  [
    "The idea of introducing the confusion term to disentanglement private and public information seems novel .",
    "NOVELTY"
  ],
  [
    "Nonetheless , the contributions are novel albeit straight-forward",
    "NOVELTY"
  ],
  [
    "This paper also seems to be the first to outline a trust-region fitted-q iteration algorithm .",
    "NOVELTY"
  ],
  [
    "However , in the context of this conference , I find the contribution specifically on the `` representation `` problem to be limited .",
    "NOVELTY"
  ],
  [
    "The ideas presented here are somewhat novel",
    "NOVELTY"
  ],
  [
    "The theoretical analysis outlined in the beginning of this paper in terms of behavior of eigenvalues under diffusion and sparsification is interesting , relevant",
    "NOVELTY"
  ],
  [
    "I find the distillation based learning to be a clever alternative to the computationally heavy optimizing over past performance .",
    "NOVELTY"
  ],
  [
    "The model is moderately novel .",
    "NOVELTY"
  ],
  [
    "Originality The method is new and",
    "NOVELTY"
  ],
  [
    "differs from previous contributions",
    "NOVELTY"
  ],
  [
    "and present a new idea",
    "NOVELTY"
  ],
  [
    "2 .The sensor probing layer is somewhat novel",
    "NOVELTY"
  ],
  [
    "The idea is nice",
    "NOVELTY"
  ],
  [
    "the idea of using the Bloomier filter is new to me .",
    "NOVELTY"
  ],
  [
    "Novel result for RNN learnability with generalization bound polynomial in input length .",
    "NOVELTY"
  ],
  [
    "not sure which of these are novel when compared to",
    "NOVELTY"
  ],
  [
    "However the contribution of the paper is interesting and worth the ICLR audience to know about",
    "NOVELTY"
  ],
  [
    "the paper presents some interesting ideas but",
    "NOVELTY"
  ],
  [
    "1 .It is not clear what is the novelty in sections 2 and 3.1 except the combination of all the results to get a generalization bound which does not increase with network size",
    "NOVELTY"
  ],
  [
    "The idea of this paper is quite interesting to me",
    "NOVELTY"
  ],
  [
    "Overall , the idea of this paper is interesting and it is a great incremental advance in the field of densification one permutation hashing .",
    "NOVELTY"
  ],
  [
    "general , I find this paper rather interesting",
    "NOVELTY"
  ],
  [
    "Task of reducing computation by skipping inputs is interesting - Model is novel and interesting",
    "NOVELTY"
  ],
  [
    "The task of reducing computation by skipping RNN inputs is interesting , and the proposed method is novel , interesting , and clearly explained",
    "NOVELTY"
  ],
  [
    "On the whole I believe that the task and method are interesting",
    "NOVELTY"
  ],
  [
    "Overall , the SGR layer is a simple and interesting idea .",
    "NOVELTY"
  ],
  [
    "Although gating is not novel",
    "NOVELTY"
  ],
  [
    "Other than that , not much is contributed , as their differentiability trick , as mentioned , has already been done .",
    "NOVELTY"
  ],
  [
    "but the technique ( the linear classifier as the probe ) is not novel and more",
    "NOVELTY"
  ],
  [
    "This is a promising approach .",
    "NOVELTY"
  ],
  [
    "domains",
    "NOVELTY"
  ],
  [
    "There is little by way of theoretical development of the ideas using MDP",
    "NOVELTY"
  ],
  [
    "The approach is novel .",
    "NOVELTY"
  ],
  [
    "the approach is novel",
    "NOVELTY"
  ],
  [
    "The paper , while presenting a quite novel algorithm",
    "NOVELTY"
  ],
  [
    "My main issue with the work in its current form is that the method is too light in terms of technical contribution .",
    "NOVELTY"
  ],
  [
    "Computing novelty with respect to a state \u2019 s nearest neighbors is problematic at scale .",
    "NOVELTY"
  ],
  [
    "I have concerns about its novelty .",
    "NOVELTY"
  ],
  [
    "The idea of CondConvs is interesting",
    "NOVELTY"
  ],
  [
    "the updated version could eliminate one of the unrealistic assumptions and the analysis further provides novel dynamic ensemble results and the connection to Batch Normalization that gives more insightful results about the structure of Res Nets",
    "NOVELTY"
  ],
  [
    "the perspective is interesting",
    "NOVELTY"
  ],
  [
    "It 's not the most novel or surprising paper",
    "NOVELTY"
  ],
  [
    "My main concern lies on the novelty of the idea .",
    "NOVELTY"
  ],
  [
    "The joint analysis of node representations and community structure is an interesting and original avenue for analyzing networks .",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "I really enjoyed the paper .",
    "NOVELTY"
  ],
  [
    "Building upon the intuition , the author proposes a novel architecture based on a numerical ODE solver method .",
    "NOVELTY"
  ],
  [
    "As far as I know , these loss functions are novel",
    "NOVELTY"
  ],
  [
    "But I found the contribution of this work to be not significant enough .",
    "NOVELTY"
  ],
  [
    "An interesting approach to policy-gradient , to be sure .",
    "NOVELTY"
  ],
  [
    "That message is novel , albeit a minor modification to a well-known algorithm",
    "NOVELTY"
  ],
  [
    "and presents an elegant approach for modeling complex , richly-structured data using hierarchical representation .",
    "NOVELTY"
  ],
  [
    "and seems novel to me",
    "NOVELTY"
  ],
  [
    "Although the idea of generating contrastive explanations is quite interesting",
    "NOVELTY"
  ],
  [
    ", it is not that novel .",
    "NOVELTY"
  ],
  [
    "Use of error correcting output codes to improve robustness with empirical results is very novel ( although explored in Machine learning in some other context before ) .",
    "NOVELTY"
  ],
  [
    "I find the paper interesting",
    "NOVELTY"
  ],
  [
    "I have n't never seen this idea of operator view of VB and it is technically interesting",
    "NOVELTY"
  ],
  [
    "I still like the overall idea of the paper as optimizing connectivity patterns in architectures has so far mostly been ignored while it is actually straight-forward to do",
    "NOVELTY"
  ],
  [
    "the novelty and significance of this work is still limited in my option and therefore I do not argue heavily in favor of accepting this submission",
    "NOVELTY"
  ],
  [
    "Knowing [ 4 ] and DARTS , the proposed method seems to be rather incremental and straightforward rather than ground breaking .",
    "NOVELTY"
  ],
  [
    "However , the proposed optimization method is , in my opinion , rather incremental ( with respect to DARTS and [ 4 ] ) and therefore of limited novelty and significance .",
    "NOVELTY"
  ],
  [
    "This work provides a novel unsupervised method on a traditional computational task",
    "NOVELTY"
  ],
  [
    "Although this idea is not new",
    "NOVELTY"
  ],
  [
    ", the proposed mechanism for relaxing the assumption does seem to be original . The variational inference algorithm for this model also seems to be new .",
    "NOVELTY"
  ],
  [
    "The idea is novel to the best of my knowledge ,",
    "NOVELTY"
  ],
  [
    "It is original , to my understanding : I have not seen similar ideas being published elsewhere .",
    "NOVELTY"
  ],
  [
    "The authors combine traditional models with deep learning approaches",
    "NOVELTY"
  ],
  [
    "testing on extrapolating data is not a new method .",
    "NOVELTY"
  ],
  [
    "interesting idea",
    "NOVELTY"
  ],
  [
    "so not exactly new",
    "NOVELTY"
  ],
  [
    "The paper seems to make two interesting contributions",
    "NOVELTY"
  ],
  [
    "based on a novel differentiable variant of the Needleman-Wunsch algorithm",
    "NOVELTY"
  ],
  [
    "However , the novelty of introducing a new idea like this makes it , in my opinions , worth publishing , despite not having stunning results",
    "NOVELTY"
  ],
  [
    "I recommend the paper to be accepted since they have an innovative",
    "NOVELTY"
  ],
  [
    "contribution that pushes the needle on the transfer RL literature although I do not think the contribution is substantial",
    "NOVELTY"
  ],
  [
    "the model of the paper is n't very excitingly different .",
    "NOVELTY"
  ],
  [
    "The idea of using a positional encoding so that you can generate rare words by position has previously been used in NMT",
    "NOVELTY"
  ],
  [
    "An interesting attempt to learn a controllable generative model of states to analyze deep RL agents .",
    "NOVELTY"
  ],
  [
    "The proposed regularizer for VAE and gradient descent approach for generating particular types of states are novel and interesting .",
    "NOVELTY"
  ],
  [
    "It \u2019 s technically incremental : the paper doesn \u2019 t propose a new model",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting for the ICLR",
    "NOVELTY"
  ],
  [
    "This paper is reasonably interesting -- -it joins an effort to produce non-Euclidean models in a tractable way",
    "NOVELTY"
  ],
  [
    "everything here is an extension of existing work",
    "NOVELTY"
  ],
  [
    "quite interesting",
    "NOVELTY"
  ],
  [
    "but my main concern is the originality",
    "NOVELTY"
  ],
  [
    "I like the simplicity of the approach in this paper ( especially compared to",
    "NOVELTY"
  ],
  [
    "The insight to study the generalization of GAN from the view of privacy protection is very interesting .",
    "NOVELTY"
  ],
  [
    "2 .The theoretical analysis that employs differential privacy and the stability based theory is insightful 3",
    "NOVELTY"
  ],
  [
    "the idea of using curiosity is not originated from this paper",
    "NOVELTY"
  ],
  [
    "Transforming sets into fixed size vectors is not new .",
    "NOVELTY"
  ],
  [
    "I think that using Forth ( a very simple stack-based language ) as the sketch definition language is interesting in itself",
    "NOVELTY"
  ],
  [
    "it is not clear if the novelties introduced in this paper are important for the task or if they are they are tackling the core problem of catastrophic forgetting",
    "NOVELTY"
  ],
  [
    "Although the approach is somewhat incremental",
    "NOVELTY"
  ],
  [
    ", I believe this is an interesting contribution",
    "NOVELTY"
  ],
  [
    "This result is obtained by relying on a metric learning procedure based on approximated average precision , which seems novel .",
    "NOVELTY"
  ],
  [
    "The one shortcoming of the paper is that it takes a simple idea and",
    "NOVELTY"
  ],
  [
    "and uses novel techniques",
    "NOVELTY"
  ],
  [
    "the proposal can be regarded as a straightforward combination of compressed sensing and the DIP , so that the main contribution of this paper should be considered rather marginal .",
    "NOVELTY"
  ],
  [
    "The comparisons with and without the agent embedding , different policies , and different perception modules ( all across datasets ) are all quite insightful",
    "NOVELTY"
  ],
  [
    "2 .The finding that there are center-surround or asymmetric ( non-gabor ) RFs in mouse V1 is not novel and not specific to this model",
    "NOVELTY"
  ],
  [
    "While I find this idea interesting and",
    "NOVELTY"
  ],
  [
    "Method At a high level , the idea of imposing a mixture of gaussian structure in the feature space of a deep neural network classifier is not new .",
    "NOVELTY"
  ],
  [
    ", presents a novel method of some interest to the community",
    "NOVELTY"
  ],
  [
    "The paper combines essentially two existing methods . In that sense the originality is low .",
    "NOVELTY"
  ],
  [
    "Also the white noise model and its analysis , and the factored model are original and practically useful extensions .",
    "NOVELTY"
  ],
  [
    "I find there is a lack of novelty on the machine learning part . The authors combine well established methods in a straight-forward manner and while the resulting increase in performance for some datasets may be relevant in the domain , the conceptual advances are too incremental for a machine learning audience .",
    "NOVELTY"
  ],
  [
    "I have read the response and am still think there is a lack of novelty here",
    "NOVELTY"
  ],
  [
    "and seems novel",
    "NOVELTY"
  ],
  [
    "The overall novelty however is a bit limited compared to the existing work ,",
    "NOVELTY"
  ],
  [
    "But , the technical contribution feels incremental over previous approaches , especially Huang ( 2019 ) .",
    "NOVELTY"
  ],
  [
    ", the idea is creative ,",
    "NOVELTY"
  ],
  [
    "It is quite evident to me that this approach has a big advantage over the other incremental classification methods .",
    "NOVELTY"
  ],
  [
    "using a pretrained feature extractor could be practically useful but has limited insight for future research",
    "NOVELTY"
  ],
  [
    "The theoretical results , i.e. , gradient dynamics sequentially learn the solutions , on the reduced-rank regression problem are novel and interesting .",
    "NOVELTY"
  ],
  [
    "The idea is quite novel and evokes interesting thoughts .",
    "NOVELTY"
  ],
  [
    "The general idea is interesting",
    "NOVELTY"
  ],
  [
    "I think there are several limitations regarding the novelty and significance of the proposed model .",
    "NOVELTY"
  ],
  [
    ".Such a simple combination is a good attempt to incorporate both node features and edge features but the novelty is quite limited",
    "NOVELTY"
  ],
  [
    "Although its goal is different from this paper , just applying such multi-head architectures seems to be incremental .",
    "NOVELTY"
  ],
  [
    "Despite such a large number of parameters , the performance gain seems to be incremental .",
    "NOVELTY"
  ],
  [
    "but is incremental",
    "NOVELTY"
  ],
  [
    "This paper provide no novelty with respect to deep learning method .",
    "NOVELTY"
  ],
  [
    "The algorithm is somewhat novel though its individual components are well known .",
    "NOVELTY"
  ],
  [
    "So spectral embedding analysis has limited novelty . 1 .2 .The bipartite model is interesting , but not entirely new .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the method and its analysis are new .",
    "NOVELTY"
  ],
  [
    "Originality The identification of noise issues and the proposed solutions appear original . The idea of selective noise injection is new to me , and it addresses the issue with noisy gradients . Although an information bottleneck has been proposed in the past , its evaluation in this setting seems novel .",
    "NOVELTY"
  ],
  [
    "Even though motivated from graph convolutions",
    "NOVELTY"
  ],
  [
    "Overall , the novelty in this paper is not strong and their",
    "NOVELTY"
  ],
  [
    "Interesting and novel application of eyeblink conditioning model to smooth pursuit .",
    "NOVELTY"
  ],
  [
    "which the title does not do justice",
    "NOVELTY"
  ],
  [
    "While I like the paper and think I can see and appreciate its novelty",
    "NOVELTY"
  ],
  [
    "I am not sure that it does a good job in expressing its novelty and interest",
    "NOVELTY"
  ],
  [
    "The paper is a nice combination of incomplete mmd and post selection inference technique .",
    "NOVELTY"
  ],
  [
    "Novel form of measuring uncertainty through counts .",
    "NOVELTY"
  ],
  [
    "The proposed environment is , to my knowledge , novel as well the task formulation in section 2 .",
    "NOVELTY"
  ],
  [
    "it provide a new one completely",
    "NOVELTY"
  ],
  [
    "but not too much novelty",
    "NOVELTY"
  ],
  [
    "I have no idea about the originality and significance of the theoretical results and proof techniques",
    "NOVELTY"
  ],
  [
    "Still this paper makes a lot of interesting observations and analyses and represents a first methodological study of this phenomenon",
    "NOVELTY"
  ],
  [
    "A novelty of this work is that it is the first paper that methodologically analyses FRIs for DNNs a reasearch area which might shed new light on the understanding of how vision systems work and the source of misrecognitions and the limitations of recognition systems",
    "NOVELTY"
  ],
  [
    "I suggest this paper to be accepted as it constitutes novel research in understanding how DNNs recognize image content and its similarities and differences to human vision",
    "NOVELTY"
  ],
  [
    "I don \u2019 t really see any significant contribution here except",
    "NOVELTY"
  ],
  [
    "I like the idea",
    "NOVELTY"
  ],
  [
    "The problem author focused on is unique and",
    "NOVELTY"
  ],
  [
    "This seems quite novel ,",
    "NOVELTY"
  ],
  [
    "the proposed GAN allowing to estimate the SR kernel is new and tailored for the blind SR problem .",
    "NOVELTY"
  ],
  [
    "The paper looks novel",
    "NOVELTY"
  ],
  [
    "I think both the considered setting ( learning ReLUs in the Gaussian setting with noise ) and connections to learning parities and halfspaces are very appealing .",
    "NOVELTY"
  ],
  [
    "The approach ( of using subgraph connectivity patterns as features ) is clever , novel ( at least in my knowledge ) and neatly sidesteps the need for extra metadata/features .",
    "NOVELTY"
  ],
  [
    "The novelty of the main idea is limited and may provide a limited contribution to the research community .",
    "NOVELTY"
  ],
  [
    "Although this paper presents interesting insights",
    "NOVELTY"
  ],
  [
    "The proposed model , HybridNet is a fairly straightforward variation of WaveNet and thus the paper offers a relatively low novelty .",
    "NOVELTY"
  ],
  [
    "The introduction of a local LSTM is perhaps not a sufficiently significant innovation .",
    "NOVELTY"
  ],
  [
    "However the theoretical contribution is poor .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is somewhat limited",
    "NOVELTY"
  ],
  [
    "The model provided may be slightly original but is quite similar to the model of Dong and Lapata 2018 .",
    "NOVELTY"
  ],
  [
    "compared to the paper that introduces this",
    "NOVELTY"
  ],
  [
    "the current work seems to be too incremental to warrant acceptance to Neurips",
    "NOVELTY"
  ],
  [
    "The main weakness is the limited novelty of this paper .",
    "NOVELTY"
  ],
  [
    "The idea is neat and novel .",
    "NOVELTY"
  ],
  [
    "Bayesian regret through the",
    "NOVELTY"
  ],
  [
    "The use of information planes to study the training behavior of networks is not new .",
    "NOVELTY"
  ],
  [
    "The techniques used in this paper are quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "The paper presents novel results and is applicable to a wide range of multifidelity engineering optimization problems .",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "I do n't think the contributions in the manuscript are enough for NIPS but",
    "NOVELTY"
  ],
  [
    "The solutions are not novel but straightforward to the problem .",
    "NOVELTY"
  ],
  [
    "and the method proposed in this paper is nice . In particular , the idea of the selective proposal distribution is interesting and provides an effective solution to deal with the problem of missing modality in conventional multimodal learning",
    "NOVELTY"
  ],
  [
    "but its limited level of novelty and achieved gain are hardly supporting acceptance .",
    "NOVELTY"
  ],
  [
    "This reviewer believes the idea of the paper is interesting .",
    "NOVELTY"
  ],
  [
    "In my opinion , the work is quite original , both because of the foundational nature of the problem and also because of the new technical contributions",
    "NOVELTY"
  ],
  [
    "I think that the paper displays some appealing empirical and methodological contributions",
    "NOVELTY"
  ],
  [
    "However , the idea behind their approach , which is based on first reaching an already visited state and then exploring randomly from that state , is not all dissimilar from the two-phase exploration scheme of novelty-pursuit .",
    "NOVELTY"
  ],
  [
    "the paper seems to contribute not only new results , but also new approaches possibly extendable to larger K 's",
    "NOVELTY"
  ],
  [
    "This is a very strong contribution .",
    "NOVELTY"
  ],
  [
    "and the authors make several non-trivial contributions that clearly improve the state of the art in this area",
    "NOVELTY"
  ],
  [
    "area of \u00e2\u0080\u009cinverse protein folding\u00e2\u0080\u009d , but the paper did a great job at introducing",
    "NOVELTY"
  ],
  [
    "Originality The use of self supervision for this particular application is novel as far as I know . The idea of incorporating the self supervised transformations during inference ( outlier scoring ) adds additional novelty .",
    "NOVELTY"
  ],
  [
    "Significance I think this is an interesting new application of self supervision",
    "NOVELTY"
  ],
  [
    "The proposed method is very similar in spirit to the approach in [ 10 ] .",
    "NOVELTY"
  ],
  [
    "and the proposed method is interesting and novel .",
    "NOVELTY"
  ],
  [
    "an interesting and new way to transfer knowledge learned for recognition to a the quite different task of correspondance search",
    "NOVELTY"
  ],
  [
    "Little novelty This paper could be a good fit for an applied conference such as the International Symposium on Biomedical Imaging",
    "NOVELTY"
  ],
  [
    "this paper",
    "NOVELTY"
  ],
  [
    "This type of contribution may not match the scope of ICLR",
    "NOVELTY"
  ],
  [
    "The positioning of the paper relative to existing approaches is unclear",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is more limited",
    "NOVELTY"
  ],
  [
    "The idea of using stochastic lower bounds given by Bidirectional Monte Carlo to perform MCMC convergence diagnostic is interesting .",
    "NOVELTY"
  ],
  [
    "Methodology of the paper is very incremental compared with previous models .",
    "NOVELTY"
  ],
  [
    "The main originality of paper is the block style .",
    "NOVELTY"
  ],
  [
    "In light of these existing models , the novelty of the QRNN is somewhat diminished , however in my opinion their is still sufficient novelty to justify publication .",
    "NOVELTY"
  ],
  [
    "While I feel that the contribution is somewhat incremental",
    "NOVELTY"
  ],
  [
    "the proven statements are novel and extend/fix the claims of [ 14 ]",
    "NOVELTY"
  ],
  [
    "Seems more incremental than novel While the proposed model gives a new , clean approach on how to construct coresets",
    "NOVELTY"
  ],
  [
    "In that case it looks rather incremental and is lacking a strong motivation as to why it should be used compared to prior work in the area of coreset construction .",
    "NOVELTY"
  ],
  [
    "The idea of building a differentially private GAN and generating differentially private synthetic data is very interesting .",
    "NOVELTY"
  ],
  [
    "I think the idea proposed by this paper is of novel interest",
    "NOVELTY"
  ],
  [
    "an interesting approach",
    "NOVELTY"
  ],
  [
    "The use of word segmentation data was quite clever",
    "NOVELTY"
  ],
  [
    "The idea of customising the smoothing function is very interesting and novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "I do not believe the paper showed novel competitive bounds for interesting problems .",
    "NOVELTY"
  ],
  [
    "al .2016 and seems very incremental .",
    "NOVELTY"
  ],
  [
    "As the work is similar to the one of Morris et al",
    "NOVELTY"
  ],
  [
    "I find this paper very exciting .",
    "NOVELTY"
  ],
  [
    "-The proposed idea is a bit incremental , which is a combination of sparsity-constrained Gated Module [ 32 ] and SR-SOP [ 26 ] .",
    "NOVELTY"
  ],
  [
    "the maze",
    "NOVELTY"
  ],
  [
    "From my point of view , the article clearly lacks of maturity and does not bring yet a strong contribution to the field .",
    "NOVELTY"
  ],
  [
    "The paper proposed a novel regularization methods for continual learning .",
    "NOVELTY"
  ],
  [
    "it is less clear to what degree the results are novel and required new insight over previous work",
    "NOVELTY"
  ],
  [
    "and I like that it doesn",
    "NOVELTY"
  ],
  [
    "I don \u2019 t think the contribution of this work in its current state is sufficiently well-developed \u2014 and would lean toward rejecting in its current form",
    "NOVELTY"
  ],
  [
    "opinion the right ideas",
    "NOVELTY"
  ],
  [
    "I strongly believe that the results of the submission are sufficiently original and significant",
    "NOVELTY"
  ],
  [
    "given the recent advancements in self-attention and message-passing graph modeling under various supervised settings",
    "NOVELTY"
  ],
  [
    "graph2seq and graph2graph ) , the methodological novelty is somewhat limited .",
    "NOVELTY"
  ],
  [
    "3 .Over-fitting is not new for these datasets",
    "NOVELTY"
  ],
  [
    "but both seem to be from off-the-shelf solutions from literature with slight variation",
    "NOVELTY"
  ],
  [
    "I had a hard time getting the novelty here",
    "NOVELTY"
  ],
  [
    "I think this paper has contributed to a deeper understanding of graph NNs and sufficiently significant",
    "NOVELTY"
  ],
  [
    "the originality is limited .",
    "NOVELTY"
  ],
  [
    "Conditioning on that work , the methodological novelty of the proposed approach is little .",
    "NOVELTY"
  ],
  [
    "The problem setting is novel .",
    "NOVELTY"
  ],
  [
    "I think the Stein operator perspective on variational inference is exciting and new , and this paper",
    "NOVELTY"
  ],
  [
    "it represents a significant enough contribution",
    "NOVELTY"
  ],
  [
    "publication",
    "NOVELTY"
  ],
  [
    "-The method is novel .",
    "NOVELTY"
  ],
  [
    "The contributions of the study are limited",
    "NOVELTY"
  ],
  [
    "There is no methodological contribution .",
    "NOVELTY"
  ],
  [
    "The technical part and the idea of using higher moment estimation to approximate the first moment is very interesting .",
    "NOVELTY"
  ],
  [
    "The authors introduced a novel self-contained model that decides what to write to the external memory and making use of the external memory for different tasks .",
    "NOVELTY"
  ],
  [
    "2 .This is an interesting paper that combines a novel technique for writing to external memory based on surprisal and using it for more difficult tasks such as deductive reasoning .",
    "NOVELTY"
  ],
  [
    "I see why the contribution can be viewed as minor",
    "NOVELTY"
  ],
  [
    "I think there are some interesting ideas in the paper",
    "NOVELTY"
  ],
  [
    "The technical contribution seems not enough .",
    "NOVELTY"
  ],
  [
    "The proposed model is mainly based on monotonic networks and technical novelty is a bit incremental as it is more like an application of monotonic networks to point processes",
    "NOVELTY"
  ],
  [
    "The use of the decision-theoretic influence is novel as far as I can tell",
    "NOVELTY"
  ],
  [
    "I believe the quantization approach proposed in this paper is novel , and provides a new general framework to quantize sparse CNNs .",
    "NOVELTY"
  ],
  [
    "The main contribution of this paper ( a variant of the semi-supervised VAE model ) is quite far from these .",
    "NOVELTY"
  ],
  [
    "Although the idea is quite simple if one is familiar with spectral learning of WFAs , I am quite confident it is novel . I believe this is a nice contribution .",
    "NOVELTY"
  ],
  [
    "This extension and the associated algorithmic modifications are very interesting",
    "NOVELTY"
  ],
  [
    "this paper proposes no significant methodological developments",
    "NOVELTY"
  ],
  [
    "seems a bit preliminary and , in its current state , does not make a significant enough contribution to be accepted at this venue .",
    "NOVELTY"
  ],
  [
    "this is the first paper to demonstrate frequentist regret guarantees for perturbation induced exploration",
    "NOVELTY"
  ],
  [
    "This is an incremental change of an existing method .",
    "NOVELTY"
  ],
  [
    "The novelty is a little weak .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed architecture is limited .",
    "NOVELTY"
  ],
  [
    "The authors \u2019 add a manifold regularization penalty to GAN discriminator \u2019 s loss function .",
    "NOVELTY"
  ],
  [
    "while I don \u2019 t think their algorithm is super novel",
    "NOVELTY"
  ],
  [
    ", it is significant and thus novel enough .",
    "NOVELTY"
  ],
  [
    "While the idea itself is not extremely novel",
    "NOVELTY"
  ],
  [
    "so the impression is that the marginal technical contribution is very minor",
    "NOVELTY"
  ],
  [
    "I am unsure what this paper contributes beyond these works",
    "NOVELTY"
  ],
  [
    "I am unsure this paper represents a significant contribution over existing work .",
    "NOVELTY"
  ],
  [
    "Quality Although the idea is pretty straight forward",
    "NOVELTY"
  ],
  [
    "Originality The idea of using a whitening layer together with the slowness objective has not",
    "NOVELTY"
  ],
  [
    "been explored before .",
    "NOVELTY"
  ],
  [
    "I find the idea interesting .",
    "NOVELTY"
  ],
  [
    "the mechanics of the proposed approach are not new",
    "NOVELTY"
  ],
  [
    "but the findings about the transfer of similarity judgement to novel object classes are interesting .",
    "NOVELTY"
  ],
  [
    "Given these previous work , I think the proposed method lacks sufficient novelty for acceptance .",
    "NOVELTY"
  ],
  [
    "The paper introduces new fundamental objects , Kantorovich and Sinkhorn sorting operators ( as well as CDFs and quantile functions ) , in a very insightful and",
    "NOVELTY"
  ],
  [
    "despite a number of typos",
    "NOVELTY"
  ],
  [
    "Nevertheless , the main contribution is of a conceptual nature",
    "NOVELTY"
  ],
  [
    "they are clearly of interest on their own right , and very innovative",
    "NOVELTY"
  ],
  [
    "Overall I find the proposed manuscript to be very exciting . It is very original and very clear thanks",
    "NOVELTY"
  ],
  [
    "Some ideas in the paper are promising and I recommend the authors submit this paper to a workshop",
    "NOVELTY"
  ],
  [
    "The idea of generalizing an interpretable model into a more complex one is interesting and to my knowledge novel .",
    "NOVELTY"
  ],
  [
    "The paper introduces several novel variants of existing approaches that seem to be of high relevance to me . The description of the novel approaches",
    "NOVELTY"
  ],
  [
    "since the technical contribution is rather limited",
    "NOVELTY"
  ],
  [
    "While the variational formulation for the given image denoising is new",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of the paper is solid in terms of technical novelty and problem formulations .",
    "NOVELTY"
  ],
  [
    "The approach is not brand-new",
    "NOVELTY"
  ],
  [
    "but it manages to put all the pieces together .",
    "NOVELTY"
  ],
  [
    "This proposed approach , along with proofs for convergence and KKT-optimality are a a novel contribution for this graph matching formulation .",
    "NOVELTY"
  ],
  [
    "The novelty is relatively limited .",
    "NOVELTY"
  ],
  [
    "While the idea is interesting",
    "NOVELTY"
  ],
  [
    "intriguing",
    "NOVELTY"
  ],
  [
    "while the idea of using ALE ram state as ground truth is not new",
    "NOVELTY"
  ],
  [
    "This paper provides a simple but novel coaching method for teacher-student based semi-supervised learning framework .",
    "NOVELTY"
  ],
  [
    "The main concern is the technical novelty .",
    "NOVELTY"
  ],
  [
    "and relatively new",
    "NOVELTY"
  ],
  [
    "The major issue in this paper is that the `` new direction `` in this paper has been explored before",
    "NOVELTY"
  ],
  [
    "Thus far this is not super-novel , as this idea has been studied before .",
    "NOVELTY"
  ],
  [
    "The main selling point of this paper is that the ideas have been proven before independently",
    "NOVELTY"
  ],
  [
    "The section on confidence based surrogates is standard , and can not be considered an original contribution .",
    "NOVELTY"
  ],
  [
    "but these are not particularly original and such bounds can be derived using previously known techniques",
    "NOVELTY"
  ],
  [
    "The empirical results are not particularly impressive ( or original",
    "NOVELTY"
  ],
  [
    "While it does not propose any novel algorithms",
    "NOVELTY"
  ],
  [
    "AC-GAN model itself is of limited novelty relative to other GAN approaches that condition on class .",
    "NOVELTY"
  ],
  [
    "Though the model is not very novel and",
    "NOVELTY"
  ],
  [
    "The innovativeness seems low given the several previous proposals for sparse attention , the results are not dramatic enough to compensate for the lack of originality",
    "NOVELTY"
  ],
  [
    "but the work is nonetheless original in proving a theoretical basis for this .",
    "NOVELTY"
  ],
  [
    "the excellent technical contribution is somewhat lacking in discussion",
    "NOVELTY"
  ],
  [
    "but overall I think this would be a fantastic contribution to NIPS",
    "NOVELTY"
  ],
  [
    "Novelty is limited",
    "NOVELTY"
  ],
  [
    "I think the main weakness of this paper is its lack of any significant novelty ,",
    "NOVELTY"
  ],
  [
    "The decorrelation idea is original and well motivated by an extensive analysis of a pathological examples .",
    "NOVELTY"
  ],
  [
    "In terms of image classification , it is not very novel .",
    "NOVELTY"
  ],
  [
    "the proposed model is very interesting .",
    "NOVELTY"
  ],
  [
    "The experimental results are incremental .",
    "NOVELTY"
  ],
  [
    "Regarding originality and significance , I found the results of UCB-M novel .",
    "NOVELTY"
  ],
  [
    "Hence I would consider the novelty to be very low",
    "NOVELTY"
  ],
  [
    "Overall , the novelty of the paper seems to be low and it is difficult to",
    "NOVELTY"
  ],
  [
    "The results are novel , sound , and theoretically interesting .",
    "NOVELTY"
  ],
  [
    "Their method improves over prior deep learning approaches to this problem .",
    "NOVELTY"
  ],
  [
    "The approach is interesting and novel , as far as I\u00e2\u0080\u0099m aware .",
    "NOVELTY"
  ],
  [
    "The proposed approach is novel .",
    "NOVELTY"
  ],
  [
    "2 .The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "Although the techniques employed are not new",
    "NOVELTY"
  ],
  [
    "the modelling is quite intuitive",
    "NOVELTY"
  ],
  [
    "it can be seen as incremental for PNL but does not offer new insights .",
    "NOVELTY"
  ],
  [
    "but in the light of the work above , the novelty is unclear .",
    "NOVELTY"
  ],
  [
    "To my knowledge this is the first application of implicit depth ideas to sequence modeling ) .",
    "NOVELTY"
  ],
  [
    "the proposed method is a bit trivial",
    "NOVELTY"
  ],
  [
    "-- Originality and Quality -- To the best of my knowledge , the proposed NMBM algorithm is new .",
    "NOVELTY"
  ],
  [
    "Insufficient novelty for algorithm design .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the derived result is the first statistical result for Distributed Gradient Descent in the context of multi-agent decentralized non-parametric least-squares regression , making an important contribution for understanding the generalization properties of decentralized distributed gradient descent .",
    "NOVELTY"
  ],
  [
    "This is a pretty original approach , as far as this reviewer knows",
    "NOVELTY"
  ],
  [
    "The contribution of the paper seem quite significant , and the technique very novel",
    "NOVELTY"
  ],
  [
    "I think overall is a good paper as it contains interesting new ideas",
    "NOVELTY"
  ],
  [
    "the contributions are clear",
    "NOVELTY"
  ],
  [
    "The proposed model architecture is incremental",
    "NOVELTY"
  ],
  [
    ", but the theoretical study is original and refreshing .",
    "NOVELTY"
  ],
  [
    "The submission is rather incremental in the sense that the framework is practically a combination of useful existing techniques : parameter sharing/reuse , knowledge distillation and retrospection and model plasticity .",
    "NOVELTY"
  ],
  [
    "The novelty , however , is weak , and the framework is the composition of existing components .",
    "NOVELTY"
  ],
  [
    "Overall I think this is a good contribution",
    "NOVELTY"
  ],
  [
    "albeit a somewhat incremental one )",
    "NOVELTY"
  ],
  [
    "and the idea in this paper is interesting , and , to the best of my knowledge , seems novel .",
    "NOVELTY"
  ],
  [
    "I really enjoyed this paper .",
    "NOVELTY"
  ],
  [
    "The general idea is interesting , to reformulate any QA task as a ranking task Cons",
    "NOVELTY"
  ],
  [
    "The novelty : The novelty is not significant .",
    "NOVELTY"
  ],
  [
    "2 .Intuitive and excellent idea The idea presented is both intuitive and excellent .",
    "NOVELTY"
  ],
  [
    "The author propose a novel and general architecture that , to the best of my knowledge , has not been described before . Thus the idea of the `` shallow `` two layer RNN architecture as well as the accompanying theoretical analysis and experimental results are all novel .",
    "NOVELTY"
  ],
  [
    "The idea of approximating a binary linear program solver using neural network is new .",
    "NOVELTY"
  ],
  [
    "The problem considered in this paper is new ,",
    "NOVELTY"
  ],
  [
    "The novelty of the approach is also called into question since there are clear similarities with MLNs",
    "NOVELTY"
  ],
  [
    "I think it has a nice idea and demonstrates an interesting phenomenon .",
    "NOVELTY"
  ],
  [
    "The main idea of this paper is interesting",
    "NOVELTY"
  ],
  [
    "but my main concerts are on the limited novelty compared to the previous work .",
    "NOVELTY"
  ],
  [
    "There is a lack of novelty and no significant results .",
    "NOVELTY"
  ],
  [
    "No real novelty .",
    "NOVELTY"
  ],
  [
    "I think the idea of designing a preconditioner based on considerations of gradient noise and as well as the Hessian is interesting .",
    "NOVELTY"
  ],
  [
    "The model and the corresponding inference scheme , despite is laborious derivation , is by itself not very novel .",
    "NOVELTY"
  ],
  [
    "This paper is a nice contribution to the theory of SDP algorithms for clustering , inspired by some of the techniques arising in SDP algorithms for community detection in the stochastic block model .",
    "NOVELTY"
  ],
  [
    "The reviewer finds this work very interesting",
    "NOVELTY"
  ],
  [
    "The main idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "Given that the theoretical contribution of the paper is not outstanding , I would 've expected the experiments to provide more insight about the algorithm",
    "NOVELTY"
  ],
  [
    "originality This is a good tun-able",
    "NOVELTY"
  ],
  [
    "This appears to be a novel application of persistent homology for a segmentation loss .",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed algorithm is limited in that it mainly applies existing mulit-head self-attention .",
    "NOVELTY"
  ],
  [
    "the nature of these changes seems more incremental",
    "NOVELTY"
  ],
  [
    "The ideas presented in the paper are original ,",
    "NOVELTY"
  ],
  [
    "but the contribution does not appear more substantial than a standard 8-page submission",
    "NOVELTY"
  ],
  [
    "The paper also needs to be more clear in terms of contributions",
    "NOVELTY"
  ],
  [
    "The parer is interesting",
    "NOVELTY"
  ],
  [
    "The proof technique seems to be novel , i.e. , different from the popular techniques used for alternating minimization of matrix completion or the tensor methods .",
    "NOVELTY"
  ],
  [
    "While the paper makes conceptual contribution",
    "NOVELTY"
  ],
  [
    "Novel and interesting direction to approach novel image object captioning - Evaluation which",
    "NOVELTY"
  ],
  [
    "The paper presents an interesting approach for novel object image captioning with strong experimental validation which I advocate to accept .",
    "NOVELTY"
  ],
  [
    "Positives -- -- -- -- -- -- 1.I liked the intuition behind the proposed method",
    "NOVELTY"
  ],
  [
    "I believe this is the core contribution of the paper",
    "NOVELTY"
  ],
  [
    "Outlier detection and anomaly/novelty detection are two very different problems",
    "NOVELTY"
  ],
  [
    "Low on the technical novelty .",
    "NOVELTY"
  ],
  [
    "but unfortunately , the paper is low on the technical novelty aspect .",
    "NOVELTY"
  ],
  [
    "works",
    "NOVELTY"
  ],
  [
    "This type of framework of crude to fine hierarchical generative model has already been successfully introduced by StackGAN and it 's recent variants",
    "NOVELTY"
  ],
  [
    "I find there is no novelty involved apart from combining the already existing SOTA model in disentangled feature learning",
    "NOVELTY"
  ],
  [
    "I found the new architecture of the neural programmer-interpreter very interesting .",
    "NOVELTY"
  ],
  [
    "-- -This paper presents some original results in terms of giving a different spin on the routing algorithms for CapsNets",
    "NOVELTY"
  ],
  [
    "-- -CapsNets are a very promising area of research therefore new",
    "NOVELTY"
  ],
  [
    "The extend to which the methods presented in this paper are significant or novel is limited",
    "NOVELTY"
  ],
  [
    "The findings are in general interesting and inspiring",
    "NOVELTY"
  ],
  [
    "The new proposed method improves in terms of compressing the teacher network with just a small drop in accuracy upon an existing neural architecture search method based on reinforcement learning and random sampling",
    "NOVELTY"
  ],
  [
    "-Presentation of new application of representation learning models",
    "NOVELTY"
  ],
  [
    "while it is a significant contribution",
    "NOVELTY"
  ],
  [
    "authors , it seems to be an extension of an existing dataset for source code vulnerability detection",
    "NOVELTY"
  ],
  [
    "-The proposed architecture is reasonable and maybe new",
    "NOVELTY"
  ],
  [
    "The use of timestamps is a clever addition as well .",
    "NOVELTY"
  ],
  [
    "The results are somewhat novel",
    "NOVELTY"
  ],
  [
    "but not quite deep",
    "NOVELTY"
  ],
  [
    "I think it is a rather marginal contribution",
    "NOVELTY"
  ],
  [
    "This paper introduces such a method .",
    "NOVELTY"
  ],
  [
    "originality , quality , clarity , and significance .",
    "NOVELTY"
  ],
  [
    "The minimax method looks trivial",
    "NOVELTY"
  ],
  [
    "The proposed approach with adversarial negative sampling using an auxilary model seems interesting 2",
    "NOVELTY"
  ],
  [
    "The proposal provides an easy-to-implement drop-in regularizer framework , so that it can straightforwardly be combined",
    "NOVELTY"
  ],
  [
    "Providing justification to the proximal operator approach in GAN learning via natural gradient with respect to the Riemannian structure seems original .",
    "NOVELTY"
  ],
  [
    "Overall I think this is a great idea and a very nice contribution to the fast growing meta-learning literature .",
    "NOVELTY"
  ],
  [
    "Overall I think this a really interesting paper with a great methodological contribution .",
    "NOVELTY"
  ],
  [
    "the overall observation that gradient descent in latent space for GANs might lead to local minima is interesting",
    "NOVELTY"
  ],
  [
    "The main advantage of the proposed approach is that by only introducing a few model parameters , the proposed approach could quickly adapt to new domains .",
    "NOVELTY"
  ],
  [
    "the approach seems rather incremental with respect to ( Hadsell et al .2006 ) , the way the neighbors are chosen being the main difference",
    "NOVELTY"
  ],
  [
    "The proposed method is novel",
    "NOVELTY"
  ],
  [
    "the GNN has the advantage of being a data-driven approach that does not rely on knowing the specific random model",
    "NOVELTY"
  ],
  [
    ".At this point , the contribution of this paper is very limited",
    "NOVELTY"
  ],
  [
    "the idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "The proposed method is not very original ,",
    "NOVELTY"
  ],
  [
    "The main contribution of this work is not significant enough .",
    "NOVELTY"
  ],
  [
    "Strengths -The idea of learning elementary structures from data is novel .",
    "NOVELTY"
  ],
  [
    "It is not by itself novel .",
    "NOVELTY"
  ],
  [
    "The main idea of first unlabeled parsing then predicting labels is hardly novel ,",
    "NOVELTY"
  ],
  [
    "I think this idea of viewing protected attributes as privileged is interesting .",
    "NOVELTY"
  ],
  [
    "I believe this idea is quite similar to the idea of Learning using Privileged Information",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge this problem formulation is new and it would actually be interesting to see this line of work being further explored",
    "NOVELTY"
  ],
  [
    "-- Comments after the authors ' response -- This paper has a simple and interesting",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is limited .",
    "NOVELTY"
  ],
  [
    "However , the proposed approach isn \u2019 t very novel",
    "NOVELTY"
  ],
  [
    "Originality The originality of this paper is not very high since the proposed algorithm and its components are not novel",
    "NOVELTY"
  ],
  [
    "The problem proposed , Unsupervised Progressive Learning ( UPL ) problem , is novel .",
    "NOVELTY"
  ],
  [
    "paper",
    "NOVELTY"
  ],
  [
    "The new proof provides new insights into the universal approximation property .",
    "NOVELTY"
  ],
  [
    "This paper provides a novel post-processing method that can relieve isotropy condition",
    "NOVELTY"
  ],
  [
    "on word embedding vectors",
    "NOVELTY"
  ],
  [
    "as the method itself is quite incremental ( replacing a VAE with an AE ) .",
    "NOVELTY"
  ],
  [
    "My main concern is the lack of novelty in the proposed method .",
    "NOVELTY"
  ],
  [
    "The main idea of defining orbits is interesting .",
    "NOVELTY"
  ],
  [
    "I do n't think it takes away any novelty from this submission",
    "NOVELTY"
  ],
  [
    "I do n't think there is much novelty in the `` generic `` approach",
    "NOVELTY"
  ],
  [
    "I like the paper and the idea of treating all the filters simultaneously .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the ratio model is obtained by minimizing the distance between true ratio function and its ratio model ( Something similar to ( 4 ) ) .",
    "NOVELTY"
  ],
  [
    "advances",
    "NOVELTY"
  ],
  [
    ", there is a potentially interesting contribution here",
    "NOVELTY"
  ],
  [
    "Summary The paper proposes a novel -- fairly straightforward -- network architecture to learn image rendering .",
    "NOVELTY"
  ],
  [
    "It makes a strong contribution towards inverse rendering .",
    "NOVELTY"
  ],
  [
    "originality The theoretical results seem to be an improvement over existing results",
    "NOVELTY"
  ],
  [
    "The proposed setting seems new to me",
    "NOVELTY"
  ],
  [
    "the idea is interesting",
    "NOVELTY"
  ],
  [
    "the analysis follows the usual template per Borkar or Konda in actor-critic methods and is not new",
    "NOVELTY"
  ],
  [
    ", the contribution of this paper is insufficient for the main conference .",
    "NOVELTY"
  ],
  [
    "The above idea is interesting and novel",
    "NOVELTY"
  ],
  [
    "Interesting and novel idea CONS",
    "NOVELTY"
  ],
  [
    "The idea of having a separate class for out-distribution is a very interesting idea",
    "NOVELTY"
  ],
  [
    "but unfortunately previously explored",
    "NOVELTY"
  ],
  [
    "This appears to be a novel , if minor contribution .",
    "NOVELTY"
  ],
  [
    "All in all , I think that the paper provides a nice contribution to the art of volatility modelling .",
    "NOVELTY"
  ],
  [
    "The overall idea is interesting and novel to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Unfortunately the contribution is too minor , and the work too incremental , to be worthy of a place at a top-tier international conference such as ICLR .",
    "NOVELTY"
  ],
  [
    "the method for predicting mechanisms seems to be new",
    "NOVELTY"
  ],
  [
    "The idea of unsupervised exploration has been visited before .",
    "NOVELTY"
  ],
  [
    "However , the paper presents a novel way to frame the problem ,",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper presents a novel and unique idea that would be interesting to the wider research community .",
    "NOVELTY"
  ],
  [
    "I really enjoyed this paper . It is very original and full of insight .",
    "NOVELTY"
  ],
  [
    "The authors propose a novel approach to domain adaption the relaxes many of the standard assumptions .",
    "NOVELTY"
  ],
  [
    "A nice idea combining universal MDP formulation and Hindsight experience replay for HRL that can deal with hierarchies with more than two levels of policies in continuous tasks .",
    "NOVELTY"
  ],
  [
    "The analysis of maximum likelihood performed for Gaussian and Bernoulli DLVM provide some interesting and potentially actionable insights",
    "NOVELTY"
  ],
  [
    "2 .The task is novel ( to my knowledge ) and has various practical applications .",
    "NOVELTY"
  ],
  [
    "Although the technical novelty of the paper is not high",
    "NOVELTY"
  ],
  [
    "the goal subsampling idea is a nice contribution",
    "NOVELTY"
  ],
  [
    "and the experiments are extensive and insightful",
    "NOVELTY"
  ],
  [
    "The proof technique of interpreting saddle point problems as finding zeros of a monotone operator is interesting , and",
    "NOVELTY"
  ],
  [
    "and the analysis approach is interesting",
    "NOVELTY"
  ],
  [
    "This learning formulation is to my mind is both very innovative and extremely effective",
    "NOVELTY"
  ],
  [
    "the paper is original .",
    "NOVELTY"
  ],
  [
    "The paper is novel , well-written and",
    "NOVELTY"
  ],
  [
    "The idea of self-supervised feature learning from videos are not novel .",
    "NOVELTY"
  ],
  [
    "There is not much that 's technically new in the paper -- at least not much that 's really understandable",
    "NOVELTY"
  ],
  [
    "the reviewer is concerned about the modeling contribution made in this paper is somewhat incremental given existing literature",
    "NOVELTY"
  ],
  [
    "and though I am not an expert I found it interesting and",
    "NOVELTY"
  ],
  [
    "The proposed algorithm seems new and promising .",
    "NOVELTY"
  ],
  [
    "The proposed model is not very innovative but works fine for the DQA task",
    "NOVELTY"
  ],
  [
    "find the general idea very interesting",
    "NOVELTY"
  ],
  [
    "so considering multi-agent policies with no communication is by itself not new at all",
    "NOVELTY"
  ],
  [
    "The idea to regularize entropy of the latent representation of images is interesting .",
    "NOVELTY"
  ],
  [
    "I believe it is an interesting contribution",
    "NOVELTY"
  ],
  [
    "The paper shows how to effectively use residual connections in the spatio-termporal setting needed for action recognition",
    "NOVELTY"
  ],
  [
    "The overall novelty is only incremental .",
    "NOVELTY"
  ],
  [
    "The proposed work is competitive with other recent NAS methods but does not clearly advance the state-of-the-art in terms of search time , test error , number of parameters of the network , or other dimensions .",
    "NOVELTY"
  ],
  [
    "Overall , the work introduces an approach for NAS which is novel and presented clearly .",
    "NOVELTY"
  ],
  [
    "The contribution of PDDM mechanism shows a novel local similarity metric which combines feature difference and absolute position information from",
    "NOVELTY"
  ],
  [
    "and presents surprising fast training convergence and better performance",
    "NOVELTY"
  ],
  [
    "I thought this was an impressive paper that looked at theoretical properties of CNNs",
    "NOVELTY"
  ],
  [
    "The paper",
    "NOVELTY"
  ],
  [
    "\u2019",
    "NOVELTY"
  ],
  [
    ", but do not reach a level of generality , originality , or depth justifying presentation at ICLR .",
    "NOVELTY"
  ],
  [
    "I like the method proposed in this paper .",
    "NOVELTY"
  ],
  [
    "but I still think the contribution as it is already meets the NIPS bar , and certainly has some neat ideas",
    "NOVELTY"
  ],
  [
    "I think the main contributions in Section 3.1 ( described more below ) are very illuminating on a number of levels .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , previous work only gave 1-Wasserstein bounds",
    "NOVELTY"
  ],
  [
    "In terms of implementation the concatenation in Eq 6 seems to be the only major change to GAT . I \u2019 m not sure if this is a major advance",
    "NOVELTY"
  ],
  [
    "The paper presents a , to my knowledge , novel approach , to avoid the leakage of meta-data in the embedding , effectively debiasing it from this information",
    "NOVELTY"
  ],
  [
    "While restricted to a specific kind of temporal abstraction model , this paper offers the first ( to my knowledge ) clear formulation of `` goal-conditioned `` ( which I believe is an expression proposed by the authors ) HRL fleshed out of architectural and algorithmic considerations . The template of analysis is also novel and may even be useful in the more general SMDP/options perspective .",
    "NOVELTY"
  ],
  [
    "There are some interesting novel concepts introduced in the UDA framework proposed by the authors .",
    "NOVELTY"
  ],
  [
    "The ideas look original and the",
    "NOVELTY"
  ],
  [
    "The proposed solution is interesting",
    "NOVELTY"
  ],
  [
    "The contribution in terms of ( un ) -supervised MT is limited at best compared to ( Artetxe et al 2017,2018 ) or ( Lample et al , 2017 , 2018 ) .",
    "NOVELTY"
  ],
  [
    "the contribution is limited",
    "NOVELTY"
  ],
  [
    "-- Even if there are technical novelties in the analyses above",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper is rather interesting and original : I like the idea of explicitly learned transformations and its adaptation for the task .",
    "NOVELTY"
  ],
  [
    "The use of a relativistic loss in training GANs is not novel",
    "NOVELTY"
  ],
  [
    "but this is the first time it has been applied to generating adversarial examples , and",
    "NOVELTY"
  ],
  [
    "This submission is low in originality , but high in significance . Although the contribution has relatively low technical novelty",
    "NOVELTY"
  ],
  [
    "paper propose a novel visual planning approach which constructs explicit plans from `` hallucinated `` states of the environment",
    "NOVELTY"
  ],
  [
    "Although the techniques are not novel",
    "NOVELTY"
  ],
  [
    "I\u00e2\u0080\u0099m a bit out",
    "NOVELTY"
  ],
  [
    "and I\u00e2\u0080\u0099m not 100 % sure the proofs are novel",
    "NOVELTY"
  ],
  [
    "My best guess is that the proofs are novel , and I\u00e2\u0080\u0099m fairly confident they\u00e2\u0080\u0099re novel to the machine learning or at least deep learning community .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach seems limited in light of the related paper that is concurrently under review at ICLR2018",
    "NOVELTY"
  ],
  [
    "The sampling approaches proposed seem pretty straightforward adaptations of existing methods and not novel enough .",
    "NOVELTY"
  ],
  [
    "While the claim of the paper sounds very ambitious",
    "NOVELTY"
  ],
  [
    "The idea of applying trainable mask to weights and regularizing toward masking out is quite interesting and new to my knowledge .",
    "NOVELTY"
  ],
  [
    "This paper proposes an interesting idea ( trainable mask )",
    "NOVELTY"
  ],
  [
    "The idea of using randomized tensor factorization for dense is novel 2",
    "NOVELTY"
  ],
  [
    "I want to re-iterate that I think that the submitted work by the authors is impressive and can provide valuable insights",
    "NOVELTY"
  ],
  [
    "The infinite DEP model is novel .",
    "NOVELTY"
  ],
  [
    "So while the introduction of the collapsed sampler is novel , the derivation of the same may not be considered that novel .",
    "NOVELTY"
  ],
  [
    "I do n't see how the proposed method is different from exactly doing regularized gauss newton , so to me the algorithm is not novel in itself .",
    "NOVELTY"
  ],
  [
    "but overall the paper lacks novelty and potential impact and stays firmly within the realm of deep learning framework whitepapers such as",
    "NOVELTY"
  ],
  [
    "My overall assessment is that the method is still quite limited and the method itself is not novel",
    "NOVELTY"
  ],
  [
    "The method is not novel .",
    "NOVELTY"
  ],
  [
    "Although the approach is not very novel by itself",
    "NOVELTY"
  ],
  [
    ", the adaption and combination of existing methods for the proposed solution is interesting .",
    "NOVELTY"
  ],
  [
    "The work seems quite original to me and represents a substantial move beyond other spectral method of moments recovery algorithms in the literature .",
    "NOVELTY"
  ],
  [
    "The empirical evaluation is interesting and novel .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge ( although I am not an expert on the topic ) , the results are novel and constitute a qualitative advance . In particular , the paper presents a novel connection between min-sum algorithms and lifted Markov chain techniques .",
    "NOVELTY"
  ],
  [
    "From a theoretical point of view , the contribution seems very incremental .",
    "NOVELTY"
  ],
  [
    "Using self-attention in autoregressive models is an intriguing idea .",
    "NOVELTY"
  ],
  [
    "In term of novelty , the analysis seems pretty classical to me .",
    "NOVELTY"
  ],
  [
    "I think this is a good , well-written paper that presents a good contribution .",
    "NOVELTY"
  ],
  [
    "This paper brings an novel perspective on probabilistic frameworks for new reinforcement learning algorithms",
    "NOVELTY"
  ],
  [
    "the approach is interesting and I",
    "NOVELTY"
  ],
  [
    "I found the paper very interesting",
    "NOVELTY"
  ],
  [
    "and I found that turning the insights developed by the theoretical section of the paper into an actionable algorithm for clustering was a nice contribution .",
    "NOVELTY"
  ],
  [
    "since the novelty is somehow limited",
    "NOVELTY"
  ],
  [
    "1 .Adding noise on x",
    "NOVELTY"
  ],
  [
    ") is not new",
    "NOVELTY"
  ],
  [
    "Unfortunately , as state tacking can be formulated as one special case of sequence decoding , there is not much of innovation that can be claimed in this paper considering the `` fertility `` idea was already been proposed .",
    "NOVELTY"
  ],
  [
    "is missing some related work and lacks a clear statement of innovation . The first issue is that augmenting reward by adding an entropy term to the original RL objective is not clearly innovative .",
    "NOVELTY"
  ],
  [
    "The setup is original",
    "NOVELTY"
  ],
  [
    "The idea is very creative and interesting .",
    "NOVELTY"
  ],
  [
    "I \u2019 m",
    "NOVELTY"
  ],
  [
    "This paper introduces a neat new bound .",
    "NOVELTY"
  ],
  [
    "Major comments I found the novelty of the proposed approach rather limited .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "And even though some of the techniques used by the authors can be construed new applications , the overall contribution appears incremental .",
    "NOVELTY"
  ],
  [
    "While the general idea is interesting",
    "NOVELTY"
  ],
  [
    "The formulation of the locally-optimal max-margin constraints is an interesting notion .",
    "NOVELTY"
  ],
  [
    "off-course , exploration and actor-critic architectures are not new in reinforcement learning",
    "NOVELTY"
  ],
  [
    "I can see no contribution which is general enough to be interesting for the broader readership .",
    "NOVELTY"
  ],
  [
    "My major concern is about the method novelty , the idea that apply two stages or multiple stages and utilize human parsing is not completely new (",
    "NOVELTY"
  ],
  [
    "the idea of Warping-GAN is also not completely new",
    "NOVELTY"
  ],
  [
    "All these individual modules seem to be utilized in various papers",
    "NOVELTY"
  ],
  [
    "but the combination , to my knowledge , is new .",
    "NOVELTY"
  ],
  [
    ", the novelty is somehow incremental but I think it\u00e2\u0080\u0099s still a good submission",
    "NOVELTY"
  ],
  [
    "Given the significant empirical improvement , I think this paper has made a valid contribution to the area .",
    "NOVELTY"
  ],
  [
    "The theory appears to be important ( if somewhat straightforward-looking ) contributions of existing k-NN theory to the corrupted labels setting",
    "NOVELTY"
  ],
  [
    "The model presented deals with the missing values in a novel , ML-type way ( learn new dampening parameters ) .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper seems incremental",
    "NOVELTY"
  ],
  [
    "The approach is novel .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "The theoretical content is not novel .",
    "NOVELTY"
  ],
  [
    "at the end of the day it feels rather incremental .",
    "NOVELTY"
  ],
  [
    "This paper falls under the vein of applying existing techniques to a novel domain . While the idea of introducing Anderson acceleration to the context of RL is not new",
    "NOVELTY"
  ],
  [
    "it has not been applied to deep RL methods . While the originality is somewhat limited in this aspect , developing a practical and functional improvement for deep RL algorithms is not trivial .",
    "NOVELTY"
  ],
  [
    ", with certain novelties",
    "NOVELTY"
  ],
  [
    "The paper presents a highly original theory and derives a novel training method from it .",
    "NOVELTY"
  ],
  [
    "This paper deals with early stopping but the contributions are limited .",
    "NOVELTY"
  ],
  [
    "The presented empirical study follows the steps of others",
    "NOVELTY"
  ],
  [
    "as cited by the authors ) , but studying the DTM-based models is original .",
    "NOVELTY"
  ],
  [
    "While this is probably not",
    "NOVELTY"
  ],
  [
    "a breakthrough",
    "NOVELTY"
  ],
  [
    "The problem formulation and the solution are novel enough .",
    "NOVELTY"
  ],
  [
    "This work presents interesting and novel ideas in deriving the proposed algorithm together with strong and significant theoretical results .",
    "NOVELTY"
  ],
  [
    "and there are a great many prior works on zero-shot and few-shot learning , the proposed technique is novel to my knowledge , and achieves state-of-the-art results on several benchmark datasets .",
    "NOVELTY"
  ],
  [
    "but I still think it is innovative and significant",
    "NOVELTY"
  ],
  [
    "This paper is highly original , combining two very different efforts in a novel way .",
    "NOVELTY"
  ],
  [
    "And the use is quite clever",
    "NOVELTY"
  ],
  [
    "this paper \u00e2\u0080\u009cprovides a first attempt in using predictive-map-generated task relationships to answer broader questions of neural information processing .",
    "NOVELTY"
  ],
  [
    "The proposed method is novel up to my knowledge .",
    "NOVELTY"
  ],
  [
    "The methodological contributions do not seem very sophisticated",
    "NOVELTY"
  ],
  [
    "Utilizing text is an interesting direction for NTP in terms of integrating it with past work on KG completion",
    "NOVELTY"
  ],
  [
    "I think the paper makes an interesting contribution and I would like to see this work being published",
    "NOVELTY"
  ],
  [
    "I think the paper presents an interesting and novel solution to the important problem of learning generalizable behaviours in multi-agent environments .",
    "NOVELTY"
  ],
  [
    "However , I still consider that the contribution of the paper is limited ,",
    "NOVELTY"
  ],
  [
    "As far as I know , the idea of applying GAN for triplet discrimination has not been tried before , and it is a novel contribution of the authors",
    "NOVELTY"
  ],
  [
    "While the idea of applying adversarial approaches is new in the context of KG alignment , the technical novelty of each component is limited , and borrowed directly from existing literature with minor modifications .",
    "NOVELTY"
  ],
  [
    "This work builds primarily on the work of Kirillov but feels a bit incremental in some ways as the main theoretical result is very reminiscent of previous work .",
    "NOVELTY"
  ],
  [
    "I do like the idea of performing parallel hyperparameter optimization to allow the efficient use of multi-core environments",
    "NOVELTY"
  ],
  [
    "Both methods themselves are not new and the paper refers to `` Parallel Bayesian global optimization of expensive functions ``",
    "NOVELTY"
  ],
  [
    "I think it is definitely original",
    "NOVELTY"
  ],
  [
    "but all the theoretical contributions seem to me a bit marginal",
    "NOVELTY"
  ],
  [
    "The idea of concept learning considered here is novel and satisfying .",
    "NOVELTY"
  ],
  [
    "This clear and well written paper describes an interesting and novel way of learning a model of hierarchical concepts .",
    "NOVELTY"
  ],
  [
    ", since this form of hierarchical disentangling seems novel .",
    "NOVELTY"
  ],
  [
    "I worry that the proposed approach only incrementally contributes to the topic",
    "NOVELTY"
  ],
  [
    "From this perspective , the empirical contribution does not stand out .",
    "NOVELTY"
  ],
  [
    "it only incrementally contributes to the literature",
    "NOVELTY"
  ],
  [
    "This",
    "NOVELTY"
  ],
  [
    "The paper lacks a little bit in novelty since it is basically a variante of GAN-GCL",
    "NOVELTY"
  ],
  [
    "and these practical techniques have already been adopted by the community in addition to spurring novel research",
    "NOVELTY"
  ],
  [
    "From a technical perspective , it 's not clear that there 's much novelty in this approach .",
    "NOVELTY"
  ],
  [
    "From an applications perspective , there might be some novelty here but it 's not clear . The application of imitation learning to sports data is not new ,",
    "NOVELTY"
  ],
  [
    "the technical contributions are new and solid",
    "NOVELTY"
  ],
  [
    "The algorithmic modification itself is insightful and non-trivial",
    "NOVELTY"
  ],
  [
    "As far as I know this work is original .",
    "NOVELTY"
  ],
  [
    "this seems to be an interesting paper proposing an interesting idea",
    "NOVELTY"
  ],
  [
    "Overall , I am not sure that this paper provided enough fundamental new insight to be published in ICLR .",
    "NOVELTY"
  ],
  [
    "maximum likelihood training for structured prediction problems",
    "NOVELTY"
  ],
  [
    "The paper provides a nice unified point of view for several learning objectives in terms of the KL divergence .",
    "NOVELTY"
  ],
  [
    "The specific questions tackled in this paper are original",
    "NOVELTY"
  ],
  [
    "It seems to me that this particular use of `` learnability `` is original , even though PAC learnability was defined a while ago .",
    "NOVELTY"
  ],
  [
    "its contributions",
    "NOVELTY"
  ],
  [
    "It has thus limited originality .",
    "NOVELTY"
  ],
  [
    "This technique has been used before but only with limited success .",
    "NOVELTY"
  ],
  [
    "Even if the idea is very simple , I think it is a very interesting idea which can clearly contribute to the field .",
    "NOVELTY"
  ],
  [
    "since as far as I know this paper gives a novel insight to the overfitting problem in meta learning , and has formulated the problem formally with theoretical insight",
    "NOVELTY"
  ],
  [
    "the paper should provide new insight to meta-learning .",
    "NOVELTY"
  ],
  [
    "Novel view into meta-learning 's overfitting problem (",
    "NOVELTY"
  ],
  [
    "I 'm still skeptical of the novelty of the paper",
    "NOVELTY"
  ],
  [
    "It seems that reviewers agree that the contributions are novel",
    "NOVELTY"
  ],
  [
    "I think the contributions are novel enough since it gives theoretical guidance as well .",
    "NOVELTY"
  ],
  [
    "The ideas to use the PEGE framework to completely get rid of dependency on the number of arms and to allocate samples to the gap estimation to get rid of the square in the problem dependent regret bound are interesting .",
    "NOVELTY"
  ],
  [
    "3 .The paper proposed the new architecture RIN , but it is not much different than a simple RNN with identity initialization . Not much novelty .",
    "NOVELTY"
  ],
  [
    "to be novel and insightful",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is very limited",
    "NOVELTY"
  ],
  [
    "The novelty is low as similar attention mechanisms have been used before .",
    "NOVELTY"
  ],
  [
    "None of the improvements seem close to state of the art though",
    "NOVELTY"
  ],
  [
    "The proposed approach is very interesting .",
    "NOVELTY"
  ],
  [
    "My primary concern is with novelty .",
    "NOVELTY"
  ],
  [
    "the insight of this paper is somehow shortcoming",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited",
    "NOVELTY"
  ],
  [
    "The cost analysis of ring-based Allreduce is already provided in the existing literature",
    "NOVELTY"
  ],
  [
    "The overlap of communication of computation is an already applied technique in systems such as TensorFlow and MXNet",
    "NOVELTY"
  ],
  [
    "Since the main contribution is not very novel from a technical perspective",
    "NOVELTY"
  ],
  [
    "this is a significant limitation",
    "NOVELTY"
  ],
  [
    "the major weakness of this paper is the lack of technical novelty and detailed analysis of the proposed method .",
    "NOVELTY"
  ],
  [
    "Generally I think this is a solid work to tackle a challenging and novel task . Understanding and quantify the feedback loop has not been studied by too many , and this work is a pioneer in this direction .",
    "NOVELTY"
  ],
  [
    "This",
    "NOVELTY"
  ],
  [
    "and while the idea is motivated from word2vec and derivatives , the application to kmers is original .",
    "NOVELTY"
  ],
  [
    "The introduction of Rainbow-IQN in this paper feels a little random and out of place given the context created by the rest of the paper 's contributions- I feel it might be more appropriate for a benchmarking paper to focus on a representative set of `` standard `` or relatively simple/trivial algorithms",
    "NOVELTY"
  ],
  [
    "The work has been in the public domain for some time thereby limiting the apparent novelty .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm , KIV , is novel , to my knowledge and according to the well detailed bibliography",
    "NOVELTY"
  ],
  [
    "but it is a nice piece of work",
    "NOVELTY"
  ],
  [
    "It is original in the sense that a generative adversarial network is used as the model for doing the tree search",
    "NOVELTY"
  ],
  [
    "The paper provides little novelty in terms of model or algorithmic design , as using a CNN to parametrize the latent variables is the only model detail unique to this paper .",
    "NOVELTY"
  ],
  [
    "Conclusion While the paper 's conceptual novelty is low",
    "NOVELTY"
  ],
  [
    "I find the approach rather interesting",
    "NOVELTY"
  ],
  [
    "I think the general idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "This work is original in the sense that no previous work has tackled the this specific problem using replay generated from GAN .",
    "NOVELTY"
  ],
  [
    "However , the novelty is limited in that using GAN generator to store rehearsal examples is not new .",
    "NOVELTY"
  ],
  [
    "the idea itself is not very novel",
    "NOVELTY"
  ],
  [
    "So the idea is not that much new .",
    "NOVELTY"
  ],
  [
    "So for this work , GAN 's application to sound generation is not new",
    "NOVELTY"
  ],
  [
    "represents a significant piece of work",
    "NOVELTY"
  ],
  [
    "The contributions are mostly extensions of previous work , though the new upper bound is original .",
    "NOVELTY"
  ],
  [
    "But from my knowledge , its application in causal inference is novel .",
    "NOVELTY"
  ],
  [
    "The experiments on setting curriculum training schedule to improve convergence on LSTMs are insightful .",
    "NOVELTY"
  ],
  [
    "The presented method is novel .",
    "NOVELTY"
  ],
  [
    "This was the most interesting paper I reviewed at NIPS this year",
    "NOVELTY"
  ],
  [
    "the ideas in the paper were quite intriguing",
    "NOVELTY"
  ],
  [
    "The idea to perform improper unsupervised learning is an interesting one , which allows one to circumvent certain NP hardness results in the unsupervised learning setting .",
    "NOVELTY"
  ],
  [
    "2 .I thought that the introduction was a bit grandiose in comparing itself to PAC learning",
    "NOVELTY"
  ],
  [
    "Although there is little novelty in the paper",
    "NOVELTY"
  ],
  [
    "There is a novel contribution , though .",
    "NOVELTY"
  ],
  [
    "The observation that deictic predicates can yield some of the benefits of a first-order framework without incurring its costs is not entirely novel in the history of logic-based systems of course ,",
    "NOVELTY"
  ],
  [
    "but it is , as far as I know , novel in the context of OOMDPs",
    "NOVELTY"
  ],
  [
    "ways",
    "NOVELTY"
  ],
  [
    "Its contributions are largely conceptual and theoretical and not likely to",
    "NOVELTY"
  ],
  [
    "I still feel that this paper offers a novel and worthwhile contribution in formalizing the deictic setting as a middle ground between fully propositional and fully relational representations .",
    "NOVELTY"
  ],
  [
    "The first contribution seems rather straightforward and appears to have been done previously , while the second is interesting",
    "NOVELTY"
  ],
  [
    "I have found the paper to be interesting , and , although I am not an expert in MFGs , novel and well-articulated .",
    "NOVELTY"
  ],
  [
    "The proposed LCO is novel and seems sound , serving as a way to transfer the general knowledge of what a cluster is without requiring advance knowledge of the specific clusters of interest .",
    "NOVELTY"
  ],
  [
    "Overall , the paper seems to have both a novel contribution and strong technical merit .",
    "NOVELTY"
  ],
  [
    "This idea is very attractive from a computational point of view",
    "NOVELTY"
  ],
  [
    "to my knowledge , it is not the first work to use this kind of techniques",
    "NOVELTY"
  ],
  [
    "It is fairly new and not very well-known so not surprising that the authors missed it",
    "NOVELTY"
  ],
  [
    "A review paper , which does n't add much new to the existing suite of techniques .",
    "NOVELTY"
  ],
  [
    "Novelty : The idea is incremental .",
    "NOVELTY"
  ],
  [
    "Numerous claims/ideas put forth in this paper are abstract and intuitive",
    "NOVELTY"
  ],
  [
    "The tackled setting is a new problem .",
    "NOVELTY"
  ],
  [
    "The algorithms are based on known bandit-strategies , but",
    "NOVELTY"
  ],
  [
    "their application for solving the problem is new",
    "NOVELTY"
  ],
  [
    "Though the theoretical contribution seems rather low given existing work on pure exploration",
    "NOVELTY"
  ],
  [
    "I do not think the presented scheme is new .",
    "NOVELTY"
  ],
  [
    "The idea is not entirely new but the particular approach with Algorithm 1 and formal theoretical analysis is",
    "NOVELTY"
  ],
  [
    "this paper presents an interesting theoretical result on providing stochastic robustness guarantees for Lipschitz constrained neural networks .",
    "NOVELTY"
  ],
  [
    "This is the first paper to study the implicit regularization of large learning rate training theoretically and rigorously .",
    "NOVELTY"
  ],
  [
    "In my opinion , this is a very novel theory paper .",
    "NOVELTY"
  ],
  [
    "In this sense , the technical contribution is not novel enough ,",
    "NOVELTY"
  ],
  [
    "but I am not convinced that these really constitute a novel contribution",
    "NOVELTY"
  ],
  [
    "I would argue that the paper novelty is limited .",
    "NOVELTY"
  ],
  [
    "I believe this is a nice contribution",
    "NOVELTY"
  ],
  [
    "The paper is novel in that it is the first to work with the Overcooked environment .",
    "NOVELTY"
  ],
  [
    "but not a breakthrough",
    "NOVELTY"
  ],
  [
    "It does not present enough novelty .",
    "NOVELTY"
  ],
  [
    "The method is not novel .",
    "NOVELTY"
  ],
  [
    "The method proposed is not very original .",
    "NOVELTY"
  ],
  [
    "The work is interesting",
    "NOVELTY"
  ],
  [
    "as far as I can tell , the paper presents original analysis in this new setting , which is interesting and valuable .",
    "NOVELTY"
  ],
  [
    "But I would maintain my score as 7 since I do think the theoretical contribution is novel and interesting",
    "NOVELTY"
  ],
  [
    "Understanding bias from images seems unique and interesting",
    "NOVELTY"
  ],
  [
    "I think this paper presents an interesting take on feature pooling .",
    "NOVELTY"
  ],
  [
    "I like the idea and it seems novel it may lead to some promising research directions related to lossy pooling methods/channel aggregation .",
    "NOVELTY"
  ],
  [
    "The paper lacks the technical novelty as it does not propose any novel technique .",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea of the paper .",
    "NOVELTY"
  ],
  [
    "However , the paper lacks the technical novelty and",
    "NOVELTY"
  ],
  [
    "The idea of pairwise interactions is very natural",
    "NOVELTY"
  ],
  [
    "Originality The proposed approach nicely combines statistical sampling with robust control",
    "NOVELTY"
  ],
  [
    "The conditioning of the z-space has originality in it and may provide interesting to the audience .",
    "NOVELTY"
  ],
  [
    "to the problem of exploration",
    "NOVELTY"
  ],
  [
    "ideas are rather new",
    "NOVELTY"
  ],
  [
    "I think the idea of viewing the divergence in WAE as a relaxed WS distance and then minimising it with another WAE structure is interesting , intuitive and straightforward .",
    "NOVELTY"
  ],
  [
    "The idea seems novel .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "contribution of your paper",
    "NOVELTY"
  ],
  [
    "This in and of itself is not novel",
    "NOVELTY"
  ],
  [
    "Given that neither the model nor the training strategy is novel",
    "NOVELTY"
  ],
  [
    "The proposed methodology for denoising largely relies on the Ambient GAN model and hence the technical contribution of the paper in this task appears to be limited .",
    "NOVELTY"
  ],
  [
    "The idea is appropriately novel and the authors are using state of the art inference and modeling approaches",
    "NOVELTY"
  ],
  [
    "I would have liked to score this paper higher as I appreciate the idea",
    "NOVELTY"
  ],
  [
    "The main technical ideas are largely inspired by prior work such as Bernstein and Sheldon",
    "NOVELTY"
  ],
  [
    "The empirical results here are interesting but not particularly striking",
    "NOVELTY"
  ],
  [
    "The novelty is somewhat small , given the fact that a number of other methods have been proposed to address the explored challenge in other domains .",
    "NOVELTY"
  ],
  [
    "This is an interesting paper and the result is novel .",
    "NOVELTY"
  ],
  [
    "and contains some clearly interesting ideas in handling the problem .",
    "NOVELTY"
  ],
  [
    "I really like the spirit of the paper and appreciate the efforts to organize rather chaotic recent literature into two unified themes",
    "NOVELTY"
  ],
  [
    "Novelty/originality This work introduces the compositional kernel and includes several novel and interesting behavioral experiments .",
    "NOVELTY"
  ],
  [
    "and contains notable contributions",
    "NOVELTY"
  ],
  [
    "This method is essentially an extension of",
    "NOVELTY"
  ],
  [
    "Overall , the paper is about a problem interesting for the NeurIPS community and the authors propose a novel setting to use the Gromov-Wasserstein distance in the graph matching and graph partitioning tasks in a scalable way .",
    "NOVELTY"
  ],
  [
    "But I do feel it is a bit incremental over the GAIN approach . The overall GAN architecture is very similar to GAIN 's and although stochastic prediction shows clear improvements it is a bit straightforward",
    "NOVELTY"
  ],
  [
    "uncertainty of the",
    "NOVELTY"
  ],
  [
    "The proposed model is novel as far as I can tell .",
    "NOVELTY"
  ],
  [
    "The new benchmark is a good addition .",
    "NOVELTY"
  ],
  [
    "is not very insightful",
    "NOVELTY"
  ],
  [
    "I believe the paper should be rejected because it does not have significant technical novelty for a first-tier conference , and the results do not show much aesthetic or technical advance . In terms of technical novelty , the paper seems to be applying a standard RL agent to an existing problem space , to optimize existing losses",
    "NOVELTY"
  ],
  [
    "The paper itself fails to articulate a compelling statement of novelty",
    "NOVELTY"
  ],
  [
    "t even be mentioned ; the control mechanism is not particularly novel",
    "NOVELTY"
  ],
  [
    "Learning surrogate loss functions for different tasks is somewhat novel",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "it provides a novel analysis of an algorithmic task which sheds light on how and when the network fails to learn the algorithm , and in particular the role which initialization plays .",
    "NOVELTY"
  ],
  [
    "Significance Although the method is not very novel in light of Paper 1253",
    "NOVELTY"
  ],
  [
    "The idea of matching local image features to word-level embeddings and matching global image features to sentence level embeddings is intuitive and",
    "NOVELTY"
  ],
  [
    "clever",
    "NOVELTY"
  ],
  [
    "the proposed model is quite intuitive",
    "NOVELTY"
  ],
  [
    "The paper proposes",
    "NOVELTY"
  ],
  [
    "that is a nice and straightforward idea",
    "NOVELTY"
  ],
  [
    "the paper is based on a very smart and interesting idea and a straightforward use of GANs .",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting , the writing is easy to",
    "NOVELTY"
  ],
  [
    "-- The aversion concept is theoretically interesting and",
    "NOVELTY"
  ],
  [
    "I still think the work is somewhat incremental",
    "NOVELTY"
  ],
  [
    ", but they have done a good job of exploring the idea ( which is nice ) .",
    "NOVELTY"
  ],
  [
    "It \u2019 s a",
    "NOVELTY"
  ],
  [
    "idea",
    "NOVELTY"
  ],
  [
    "Unfortunately , this seems to be a simple idea that does n't work as well as the simpler idea ( ResNets ) that inspired it .",
    "NOVELTY"
  ],
  [
    "the extension is a natural one",
    "NOVELTY"
  ],
  [
    "Nonetheless , the elegant mathematical exposition alone makes the paper a worthwhile contribution to the literature .",
    "NOVELTY"
  ],
  [
    "It is a novel approach which trains the placement end to end .",
    "NOVELTY"
  ],
  [
    "It has some elements of novelty but not yet there",
    "NOVELTY"
  ],
  [
    "Therefore the novelty is limited .",
    "NOVELTY"
  ],
  [
    "While the applicability of this model may represent an advance in the particular field of the authors , the technical contribution of this paper is far from the level expected in this conference .",
    "NOVELTY"
  ],
  [
    "this can not be considered a contribution",
    "NOVELTY"
  ],
  [
    "the key idea is very similar to that of DistanceGAN",
    "NOVELTY"
  ],
  [
    "Thus , the technical novelty is very limited in my opinion .",
    "NOVELTY"
  ],
  [
    "Using Random Masks in neural network is not a new idea since it was already proposed for DropOut or DropConnect",
    "NOVELTY"
  ],
  [
    "This is nice but it is not argued that this is highly novel .",
    "NOVELTY"
  ],
  [
    "it is also not clear from the paper that such VAE using the additional flow-based layes is new or not .",
    "NOVELTY"
  ],
  [
    "The sequential fusing ( GRU-like ) of the multiple layers of attention is interesting and novel .",
    "NOVELTY"
  ],
  [
    "Using different embedding for computing attention weights and getting attended vector is not entirely novel but rather an expected practice for many memory-based models",
    "NOVELTY"
  ],
  [
    "the main contribution of the paper is 1.1 % improvement over previous state of the art",
    "NOVELTY"
  ],
  [
    "1- The level of contributions is limited .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper should be rejected as the contributions are limited and are not aligned with the experiments .",
    "NOVELTY"
  ],
  [
    "The three properties of visual concepts described in the paper are interesting .",
    "NOVELTY"
  ],
  [
    "The novelty of the paper is limited .",
    "NOVELTY"
  ],
  [
    "This paper is one of the first studies tries to incorporate the phase information to DNN based speech enhancement",
    "NOVELTY"
  ],
  [
    "The main idea of this paper is novel . Based on my knowledge , this is the first work on bilevel metric learning .",
    "NOVELTY"
  ],
  [
    "This is a good and interesting idea .",
    "NOVELTY"
  ],
  [
    "I generally find the work interesting and I do not have any major criticism",
    "NOVELTY"
  ],
  [
    "the current version of the paper seems to have issues regarding methodology and novelty .",
    "NOVELTY"
  ],
  [
    "The short-comings of TransE and improvements to the loss have been discussed quite extensively in prior work",
    "NOVELTY"
  ],
  [
    "the main novelty would lie in the experimental results which",
    "NOVELTY"
  ],
  [
    "The paper lacks novelty and at the same time , it",
    "NOVELTY"
  ],
  [
    "Originality The setting and proposed solution is novel to reflection separation .",
    "NOVELTY"
  ],
  [
    "While the overall idea of using logic in this way to help with skill composition is interesting and exciting",
    "NOVELTY"
  ],
  [
    "At the best of my knowledge , the training method proposed in this paper is not explored before and the experimental results suggests that the method might be an effective way to training such modules",
    "NOVELTY"
  ],
  [
    "novel way to find loop invariants for a program",
    "NOVELTY"
  ],
  [
    "This",
    "NOVELTY"
  ],
  [
    "If the claims made by the paper are true they constitute a significant contribution to the field of program synthesis and program",
    "NOVELTY"
  ],
  [
    "Not enough of this paper concentrates on the novel aspects of the approach .",
    "NOVELTY"
  ],
  [
    "My concern , which is not major , is that the proposed method might be a bit incremental based on Xie et al . ( 2017 ) and Gal and Ghahramani ( 2016 ) .",
    "NOVELTY"
  ],
  [
    "Novel meta-learning approach that is different than the previous learning to learn approach Cons",
    "NOVELTY"
  ],
  [
    "The core idea is related to",
    "NOVELTY"
  ],
  [
    "While the idea is not groundbreaking",
    "NOVELTY"
  ],
  [
    "contribution is",
    "NOVELTY"
  ],
  [
    ".The results seem original",
    "NOVELTY"
  ],
  [
    "this is in my opinion a quite strong point of the paper , that nicely bridges two different theories and brings an interesting interpretation to rejection samples and their nature within the learning theory .",
    "NOVELTY"
  ],
  [
    "For the aforementioned contributions , I believe this work provides a creative , unique approach to this problem .",
    "NOVELTY"
  ],
  [
    "I believe the work introduces novel methodology and a creative approach in a relatively unexplored space of gradient-based methods for hierarchical clustering .",
    "NOVELTY"
  ],
  [
    "The effort and results are very original in attacking the problem of generalization using place-cell , grid cell network interactions .",
    "NOVELTY"
  ],
  [
    "The results of this paper include some clever use of existing results and techniques along with some novel algorithmic elements .",
    "NOVELTY"
  ],
  [
    "First , this paper may lack deeper innovation ,",
    "NOVELTY"
  ],
  [
    "The idea is original to the best of my knowledge and is presented clearly . I especially like the idea of \u201c soft unitary constraint \u201d which can be applied very efficiently in this factorized setup .",
    "NOVELTY"
  ],
  [
    "The approach seems to be quiet novel , as well as the convergence results .",
    "NOVELTY"
  ],
  [
    "In general , the idea is very intuitive and",
    "NOVELTY"
  ],
  [
    "The theoretical contribution is very limited . The work is rather incremental from current state-of-the-art methods .",
    "NOVELTY"
  ],
  [
    "Provides fresh theoretical results in sample complexity and limiting distribution that improve upon previously known results .",
    "NOVELTY"
  ],
  [
    "However , I think the paper is lacking in innovation",
    "NOVELTY"
  ],
  [
    "The application of alpha-approximate Bayesian oracle is a novel approach .",
    "NOVELTY"
  ],
  [
    "This is a nice idea",
    "NOVELTY"
  ],
  [
    "the idea here is novel ( as far as I know ) and innovative , going beyond an incremental contribution .",
    "NOVELTY"
  ],
  [
    "interesting idea , advances the state of the art , likely to be interesting for others working in the area .",
    "NOVELTY"
  ],
  [
    "This is a really nice trick",
    "NOVELTY"
  ],
  [
    "I think that this is an elegant idea and I",
    "NOVELTY"
  ],
  [
    "The proposal of learning a hierarchical representation is not new .",
    "NOVELTY"
  ],
  [
    "Lack of novelty",
    "NOVELTY"
  ],
  [
    "It 's results are , to my non-expert judgement , original .",
    "NOVELTY"
  ],
  [
    "I have found the hypothesis that the paper puts forth to be very appealing , as it articulates the essence of many ideas that have been floating around for quite a while .",
    "NOVELTY"
  ],
  [
    "the hypothesis and experiments presented in this paper gave me a new perspective on both the generalization and optimization problem , which as a theoretician gave me new ideas on how to approach analyzing them rigorously",
    "NOVELTY"
  ],
  [
    "insights",
    "NOVELTY"
  ],
  [
    "and novel to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "To me , the core idea of this algorithm is very similar to the line of works such as Info-GAN [ 1 ] which learns a conditional GAN by auto-encoding the latent variable using an additional decoder network .",
    "NOVELTY"
  ],
  [
    "In short , this paper",
    "NOVELTY"
  ],
  [
    "However , I did n't find the ideas of the paper significantly original .",
    "NOVELTY"
  ],
  [
    "Theorem 2 presents an interesting and surprising result",
    "NOVELTY"
  ],
  [
    "I do think the paper already contains significant contribution",
    "NOVELTY"
  ],
  [
    "I found the paper to be generally well-written and the core idea to be interesting",
    "NOVELTY"
  ],
  [
    "The novelty is a little thin",
    "NOVELTY"
  ],
  [
    "I am not an expert in this field and the paper seems interesting .",
    "NOVELTY"
  ],
  [
    "The paper is the first paper that uses knowledge distillation for object detection .",
    "NOVELTY"
  ],
  [
    "The paper is a bit incremental .",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting",
    "NOVELTY"
  ],
  [
    "Strengths Method advances state-of-the-art on several benchmarks .",
    "NOVELTY"
  ],
  [
    "This is an interesting and natural idea",
    "NOVELTY"
  ],
  [
    "its contribution",
    "NOVELTY"
  ],
  [
    "Solid contribution to the literature on Gumbels .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is interesting",
    "NOVELTY"
  ],
  [
    "The work seems to me to be very related to LwF .",
    "NOVELTY"
  ],
  [
    "I find the architecture appealing and I think it has features that intuitively should help with the type of settings they consider",
    "NOVELTY"
  ],
  [
    "Dynamic computational graph is not new either . In this sense , the technical novelty of this work is somehow limited .",
    "NOVELTY"
  ],
  [
    "while the application scenario is interesting",
    "NOVELTY"
  ],
  [
    "the novelty of the paper is rather mild . Using pretrain VGG for audio classification has already been proposed by several other papers",
    "NOVELTY"
  ],
  [
    "the proposed method for graph sparsification lacks novelty",
    "NOVELTY"
  ],
  [
    "but the method proposed in this paper is not realistic and lacks novelty .",
    "NOVELTY"
  ],
  [
    "As to the technical contribution itself , the DeepState method of incorporating deep neural networks within a SSM appears novel , and worthy of study within the important topic of time series forecasting .",
    "NOVELTY"
  ],
  [
    "The paper 's overall method is a novel one , unifying NAS on det/seg tasks , while prior works mostly only focus on one task .",
    "NOVELTY"
  ],
  [
    "2 .The concrete parameter remapping scheme is not entirely novel .",
    "NOVELTY"
  ],
  [
    "I do n't follow this area closely , but from what I can tell it 's a novel idea .",
    "NOVELTY"
  ],
  [
    "The idea of learning a compact and hardware-friendly structure is very interesting .",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "The paper comprises of multiple small contributions . However for adaptive sampling techniques for kmeans , these small contributions are interesting .",
    "NOVELTY"
  ],
  [
    "The dependence of the learning dynamics on the spectral properties of the input data is not new and was previously studies by Saxe et al",
    "NOVELTY"
  ],
  [
    "I agree with reviewer # 2 that the work is interesting , original , and should be published .",
    "NOVELTY"
  ],
  [
    "because the contribution is strong",
    "NOVELTY"
  ],
  [
    "But the",
    "NOVELTY"
  ],
  [
    "and appears to oversell the contribution .",
    "NOVELTY"
  ],
  [
    "but the contribution of the paper appears to be over claimed",
    "NOVELTY"
  ],
  [
    "and the task-wise procedure seems like an improvement over the original IDP proposal",
    "NOVELTY"
  ],
  [
    "The idea itself is interesting",
    "NOVELTY"
  ],
  [
    "to entirely miss the main contribution of the paper",
    "NOVELTY"
  ],
  [
    "lack of novelty",
    "NOVELTY"
  ],
  [
    "The technical contribution of this paper is limited .",
    "NOVELTY"
  ],
  [
    "There does n't seem to be a significant contribution on the algorithmic side .",
    "NOVELTY"
  ],
  [
    "The idea of having the discriminator to work as active interrogator to influence the generator is novel and makes perfect sense .",
    "NOVELTY"
  ],
  [
    "Summary In sum , the paper presents a novel and interesting idea that can generalize and potentially improve the existing generative adversarial learning .",
    "NOVELTY"
  ],
  [
    "the paper is original in many aspects : definition of classwise-calibrated vs. confidence calibrated",
    "NOVELTY"
  ],
  [
    "while I find the perspective and results interesting and worth highlighting",
    "NOVELTY"
  ],
  [
    "However , in light of previous work in captioning , the contribution and resulting insights is too incremental for a conference paper at ICLR .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , there already exist some inductive/recursive wFM estimation methods like [ 1,2 ] .",
    "NOVELTY"
  ],
  [
    "The classical weight update scheme is clearly simplistic",
    "NOVELTY"
  ],
  [
    "-While a",
    "NOVELTY"
  ],
  [
    "the improvement over competing KD methods is marginal",
    "NOVELTY"
  ],
  [
    "-The novelty is limited .",
    "NOVELTY"
  ],
  [
    "Positives A new approach on how to employ Machine learning techniques to Automated reasoning problems",
    "NOVELTY"
  ],
  [
    "Conclusion The proposed framework is an interesting addition to existing techniques in the field and the idea",
    "NOVELTY"
  ],
  [
    "some of the foundations and overall nature of the work needs some improvement and maturity",
    "NOVELTY"
  ],
  [
    "So while the theorems in this paper are interesting and went far beyond existing perceptron-style theorems",
    "NOVELTY"
  ],
  [
    "Decision I vote for weak rejection because the core modification proposed to Adam is minor and is mostly supported by intuition and preliminary experiments",
    "NOVELTY"
  ],
  [
    "Bringing these together is original and an interesting avenue of research",
    "NOVELTY"
  ],
  [
    "This however appears very incremental seeing that integrating the mutation component into existing system is straight-forward and that mutation is not even a new concept -- it has always been a vital component in genetic programming paradigm",
    "NOVELTY"
  ],
  [
    "I also find the contribution of this paper too incremental",
    "NOVELTY"
  ],
  [
    "this does n't necessarily seem like a substantially new algorithmic development",
    "NOVELTY"
  ],
  [
    "as well as the fair NN formulation the main originality of the paper",
    "NOVELTY"
  ],
  [
    "The model itself is by no means novel , and in that sense , not very significant .",
    "NOVELTY"
  ],
  [
    "but the selection method for imputation is not particularly novel as an algorithm",
    "NOVELTY"
  ],
  [
    "I am unsure if the proposed conditional MI has been suggested before",
    "NOVELTY"
  ],
  [
    "so it is impossible to fully determine the significance for this acquisition function",
    "NOVELTY"
  ],
  [
    "as you do not claim it to be a novel contribution",
    "NOVELTY"
  ],
  [
    ", discusses some interesting insides about clustering , which is new to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "Though the Bayesian inference using GAN is a natural idea",
    "NOVELTY"
  ],
  [
    "The method is novel , the recursive divide and conquer formulation is well-suited for capturing long-term dependencies .",
    "NOVELTY"
  ],
  [
    "The main concern is that the two contributions are rather orthogonal to each other and each of them is not that significant . The first contribution",
    "NOVELTY"
  ],
  [
    "is not very surprising",
    "NOVELTY"
  ],
  [
    "Strength There are some interesting observations in terms of transfer learning",
    "NOVELTY"
  ],
  [
    "Also , given Cycle-WGAN , the technical contribution seems small .",
    "NOVELTY"
  ],
  [
    "The main technical contribution is the linear convergence guarantee which appears novel . This is an interesting work that presents the perhaps first theoretical guarantee for a widely used optimization technique of the problem of robust PCA .",
    "NOVELTY"
  ],
  [
    "I was a bit let down that there is no novel practical tricks presented",
    "NOVELTY"
  ],
  [
    "Showing oscillatory-like behavior in training is not very novel .",
    "NOVELTY"
  ],
  [
    "Freezing layers , especially the last one , is also not novel .",
    "NOVELTY"
  ],
  [
    "Although I believe the authors present an intriguing idea",
    "NOVELTY"
  ],
  [
    "I believe that the algorithm presented in the paper is novel and would lead to significant follow-up work .",
    "NOVELTY"
  ],
  [
    "but I found it somewhat incremental .",
    "NOVELTY"
  ],
  [
    "In terms of originality/significance , they do seem to strongly build on previous work in this direction , but seem to have enough interesting own contributions .",
    "NOVELTY"
  ],
  [
    "The paper is a bit low in technicality .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge the proposed approach is original .",
    "NOVELTY"
  ],
  [
    "The novelty is limited .",
    "NOVELTY"
  ],
  [
    "The optimization algorithm is not novel either .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel technique to improve model robustness against L-infinity adversarial attacks .",
    "NOVELTY"
  ],
  [
    "but it does provide an interesting idea and improved metrics",
    "NOVELTY"
  ],
  [
    "The main concern with the paper is a lack of originality and novelty .",
    "NOVELTY"
  ],
  [
    "Regarding the second contribution : a dedicated CNN structure with diverse training corpus ( historical scripts ) and multi-task learning scenario is novel and seems to be effective",
    "NOVELTY"
  ],
  [
    "The objective is new and might give some researchers new ideas in practice when solving RPCA problem .",
    "NOVELTY"
  ],
  [
    "Summary of paper The authors provide a novel analysis of a minor variant of the variance reduced algorithm ( SVRG ) for the composite setting -- proxSVRG+",
    "NOVELTY"
  ],
  [
    "The problem considered in this paper seems new",
    "NOVELTY"
  ],
  [
    "The proof strategies are very similar and there are differences in the technicalities though . So",
    "NOVELTY"
  ],
  [
    "while the results presented are novel",
    "NOVELTY"
  ],
  [
    "it is also incremental in view of the above points .",
    "NOVELTY"
  ],
  [
    "The idea is interesting , and to the best of my knowledge has n't been tested before .",
    "NOVELTY"
  ],
  [
    "However , applying gradient descent to update parameters is not very original .",
    "NOVELTY"
  ],
  [
    "This indeed appears to an interesting insight about ResNet training",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is unclear . From the text , the proposed method seems to be a combination of previous contributions .",
    "NOVELTY"
  ],
  [
    "The optimization procedure seems to be \u00e2\u0080\u009cinspired\u00e2\u0080\u009d by previous works also",
    "NOVELTY"
  ],
  [
    "Pros The paper presents interesting ideas regarding unsupervised object discovery Cons",
    "NOVELTY"
  ],
  [
    "3 .The idea of using different compositions of color and figure during train and test is interesting .",
    "NOVELTY"
  ],
  [
    "Novel and original , especially considering that most papers on this subject do not contain much theory",
    "NOVELTY"
  ],
  [
    "From a strictly AI point of view , I could imagine arguments that this is not sufficiently \u201c novel",
    "NOVELTY"
  ],
  [
    "This article brings novel understanding into random feature-based techniques ,",
    "NOVELTY"
  ],
  [
    "Although changing stochastic into greedy is not that big innovation and the O ( l ) algorithm for coordinate selection based on maintaining the gradient is also not new",
    "NOVELTY"
  ],
  [
    "What I like about the paper is that is provides a unifying theory for various stability notions that have been discussed in the literature .",
    "NOVELTY"
  ],
  [
    "Overall I think the paper gives some interesting theoretical insights .",
    "NOVELTY"
  ],
  [
    "I think this paper makes a good theoretical contribution and I still recommend acceptance",
    "NOVELTY"
  ],
  [
    "The scientific contribution ( improving KL-type bounds on best-arm identification problem ) is incremental but",
    "NOVELTY"
  ],
  [
    "The novelty of the work is rather limited and",
    "NOVELTY"
  ],
  [
    "these claims bring a marginal novelty and still `` how and why `` should be central in this work",
    "NOVELTY"
  ],
  [
    "While your proposal of a robust Kalman filter is quite appealing",
    "NOVELTY"
  ],
  [
    "To the best of my understanding the derivation of your filter is heuristic and meant to combine your robust MSE estimation formulation with the efficient recursive structure of the classical Kalman filter",
    "NOVELTY"
  ],
  [
    "The paper is novel",
    "NOVELTY"
  ],
  [
    "and that it is new and interesting to explore it in continuous games",
    "NOVELTY"
  ],
  [
    "The idea of identifying pressure points is new in the context of nonlinear dimension reduction .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well written and provides an interesting combination of sparse variational GP approximations and methods for armotised inference in state space models .",
    "NOVELTY"
  ],
  [
    "This is a set up that has been used in a large amount of previous work",
    "NOVELTY"
  ],
  [
    "and the novelty is relatively limited ,",
    "NOVELTY"
  ],
  [
    "The approach is novel and is clearly differentiated from prior work .",
    "NOVELTY"
  ],
  [
    "They have original contribution ,",
    "NOVELTY"
  ],
  [
    "To my knowledge , using a variational approach to embedding robot skills is novel .",
    "NOVELTY"
  ],
  [
    "there 's not much new",
    "NOVELTY"
  ],
  [
    "the article gradually builds its contribution and is reasonably easy to",
    "NOVELTY"
  ],
  [
    "However , the innovation beyond related work is limited ( averaging over agents is added ) .",
    "NOVELTY"
  ],
  [
    "The idea of reinterpreting the traditional classifier is very interesting ,",
    "NOVELTY"
  ],
  [
    "general , I think this paper is very interesting and enlightening .",
    "NOVELTY"
  ],
  [
    "Nothing is novel in the deep models ( CNN and TreeLSTM ) .",
    "NOVELTY"
  ],
  [
    "is relatively a new concept",
    "NOVELTY"
  ],
  [
    "However , the contribution of this paper is questionable .",
    "NOVELTY"
  ],
  [
    "The problem tackled and the proposed solution are moderately novel",
    "NOVELTY"
  ],
  [
    "being a reasonably straightforward combination of past work on meta-learning and inverse reinforcement learning",
    "NOVELTY"
  ],
  [
    "Personally , I quite like the idea of decomposing the world into important states -- it is closely related to the concept of empowerment",
    "NOVELTY"
  ],
  [
    "But the novelty of the results , in the context of automatic differentiation , is not very clear .",
    "NOVELTY"
  ],
  [
    "by taking into account the related work as presented by the authors , the proposed model seems to be novel enough .",
    "NOVELTY"
  ],
  [
    "The idea of integrating a meaningful feature extractor in the metric learning task , is very interesting and makes a lot of",
    "NOVELTY"
  ],
  [
    "The general idea of bilevel models is pretty appealing .",
    "NOVELTY"
  ],
  [
    "This fact has made me to think that the originality of this paper is marginal .",
    "NOVELTY"
  ],
  [
    "the methodological contributions are limited and I have some important concerns about their evaluation",
    "NOVELTY"
  ],
  [
    "The methodological contributions are limited .",
    "NOVELTY"
  ],
  [
    "Performing hyper-parameter optimization is in my eyes not novel , but common practice in the field",
    "NOVELTY"
  ],
  [
    "This appears to be the first study comprehensively comparing different units in terms of the representation quality",
    "NOVELTY"
  ],
  [
    "It is thorough and original .",
    "NOVELTY"
  ],
  [
    "and contains some new ideas",
    "NOVELTY"
  ],
  [
    "the paper falls short on two particular aspects that needs further development",
    "NOVELTY"
  ],
  [
    "The proposed model contains some novelty inside",
    "NOVELTY"
  ],
  [
    "this idea is wrapped up in a nice framework .",
    "NOVELTY"
  ],
  [
    "However , the novelty is limited as similar ideas have been undertaken by [ Hein and Maier 2007 ] although in different contexts .",
    "NOVELTY"
  ],
  [
    "the techniques seem to be original",
    "NOVELTY"
  ],
  [
    "Despite having good experimental results , the proposed approach is rather a mix of previous works and hence not novel .",
    "NOVELTY"
  ],
  [
    "This is an original observation/contribution .",
    "NOVELTY"
  ],
  [
    "I think the formulation and use of the block structure is certainly novel for this problem",
    "NOVELTY"
  ],
  [
    "I think the ideas of using structure could be used in other interior point methods for LPs",
    "NOVELTY"
  ],
  [
    "I would point out that the paper provides an incremental contribution and/or that the novelty is not well sold .",
    "NOVELTY"
  ],
  [
    "the incrementality of the contribution",
    "NOVELTY"
  ],
  [
    "It is an interesting and to my knowledge novel idea , which may contribute towards a better understanding of neuropsychological and computational processes underlying memory .",
    "NOVELTY"
  ],
  [
    "The idea of applying additional structural constraints on the sparsity structure induced by Sparsemax is a cool idea",
    "NOVELTY"
  ],
  [
    "Introducing cubic regularization",
    "NOVELTY"
  ],
  [
    "The idea of using reinforcement learning for crowdsourcing incentive mechanism design is interesting and novel .",
    "NOVELTY"
  ],
  [
    "this is the first work that deals with situations that a point can belong to multiple clusters",
    "NOVELTY"
  ],
  [
    "and the setting is very interesting",
    "NOVELTY"
  ],
  [
    "The proposed method is new up to my knowledge . This is one of the first methods to do Bayesian meta-learning .",
    "NOVELTY"
  ],
  [
    "Although the idea sounds interesting",
    "NOVELTY"
  ],
  [
    "the novelty of the paper seems to be limited .",
    "NOVELTY"
  ],
  [
    "1 .It seems to be an extension of Learning without Forgetting",
    "NOVELTY"
  ],
  [
    "This methodology is original",
    "NOVELTY"
  ],
  [
    "The paper presents a strong theoretical contribution",
    "NOVELTY"
  ],
  [
    "even though the algorithmic suggestion is somewhat incremental",
    "NOVELTY"
  ],
  [
    "and the learning methods itself are not new .",
    "NOVELTY"
  ],
  [
    "but the contribution to the field of neural learning itself is small",
    "NOVELTY"
  ],
  [
    "As someone who has worked a lot with Bregman divergences , I do find the main result to be quite appealing and intriguing",
    "NOVELTY"
  ],
  [
    "My overall impression is positive , the idea seems interesting from a practical point of view .",
    "NOVELTY"
  ],
  [
    "What I like is that the idea is super simple and as the authors even mention",
    "NOVELTY"
  ],
  [
    "The deterministic result does not seem very novel and uses the idea of one-point strong convexity which has been studied in various prior works",
    "NOVELTY"
  ],
  [
    "Overall , I find this paper an interesting and significant contribution to the state of the art .",
    "NOVELTY"
  ],
  [
    "nor it introduces new which can be properly quantified",
    "NOVELTY"
  ],
  [
    "the paper has a novel idea I like",
    "NOVELTY"
  ],
  [
    "but the work has to mature a bit more in terms of empirical work and",
    "NOVELTY"
  ],
  [
    "and the idea is interesting and novel",
    "NOVELTY"
  ],
  [
    "I think the technical novel is a bit limited .",
    "NOVELTY"
  ],
  [
    "In general , the observations in this paper are quite novel ,",
    "NOVELTY"
  ],
  [
    "although I still have concern on its technical novelty",
    "NOVELTY"
  ],
  [
    "Considering the originality of the proposed objective , the strong theoretical treatment , the empirical validation",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is an original approach .",
    "NOVELTY"
  ],
  [
    "While the individual components of this model have been explored in other structured regression",
    "NOVELTY"
  ],
  [
    "I think this is a nice combination and application of these techniques to a real-world , scientific problem",
    "NOVELTY"
  ],
  [
    "The main idea of the paper is interesting and original",
    "NOVELTY"
  ],
  [
    "I enjoyed the main idea of the paper .",
    "NOVELTY"
  ],
  [
    "it seems like the theorem is a novel contribution of this paper",
    "NOVELTY"
  ],
  [
    "from my reading of the text , it is not",
    "NOVELTY"
  ],
  [
    "It 's very unclear however what the contributions of the paper are",
    "NOVELTY"
  ],
  [
    "The contributions of the paper are unfortunately minimal .",
    "NOVELTY"
  ],
  [
    "However , my major concern is about the novelty of this work , given the fact that the theoretical contribution is quite limited .",
    "NOVELTY"
  ],
  [
    "Overall , the proposed VPSS method is a promising solution to the video prediction problem .",
    "NOVELTY"
  ],
  [
    "The paper is very incremental",
    "NOVELTY"
  ],
  [
    "The contribution of the paper seems to be the combination of these ideas and the way in which they are applied to RL",
    "NOVELTY"
  ],
  [
    "The derivation of the dual network is novel and intuitively more efficient in computation .",
    "NOVELTY"
  ],
  [
    "It is an incremental work with very considerable novelty .",
    "NOVELTY"
  ],
  [
    "Theoretical proofs are novel",
    "NOVELTY"
  ],
  [
    "I believe that the contribution of the work is original and significant to the field .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first paper which proposes continues neural representation which is compatible with multi view / projective geometry toolbox and at the same time does not require dense 3D ground-truth data .",
    "NOVELTY"
  ],
  [
    "I am also not convinced about the novelty and importance of this work .",
    "NOVELTY"
  ],
  [
    "Dealing with the additive noise is new ,",
    "NOVELTY"
  ],
  [
    "but somehow incremental",
    "NOVELTY"
  ],
  [
    "The contribution of this paper thus seems to mostly be in the supervised learning domain",
    "NOVELTY"
  ],
  [
    "The proposed method seems interesting and novel",
    "NOVELTY"
  ],
  [
    "and the ideas from privileged learning and distribution matching have not been employed in designing fair classifiers so far .",
    "NOVELTY"
  ],
  [
    "The idea of proposing a generalized framework which can handle multiple notions of fairness is quite appealing .",
    "NOVELTY"
  ],
  [
    "The proposed objective is interesting and utilizes ideas from two well studied lines of research",
    "NOVELTY"
  ],
  [
    "particularly in the way it is implemented in autodiff software , this does not appear to be a sufficiently novel contribution .",
    "NOVELTY"
  ],
  [
    "It is a very interesting set up , and a novel idea .",
    "NOVELTY"
  ],
  [
    "I think this paper should be accepted as it is interesting and novel",
    "NOVELTY"
  ],
  [
    "Interesting idea",
    "NOVELTY"
  ],
  [
    "The idea , while interesting , is similar to that used in the Salimans et .",
    "NOVELTY"
  ],
  [
    "The main strength of this paper is the introduction of an interesting new idea that interprets annealing as part of the variational objective .",
    "NOVELTY"
  ],
  [
    "From a technical standpoint , the work does not see too much improvement in learning compared to the work by Salimans et .",
    "NOVELTY"
  ],
  [
    "I liked the paper and the idea of using the discriminator of the GAN to detect novelty .",
    "NOVELTY"
  ],
  [
    "The recurrent GAN architecture does not appear particularly novel --",
    "NOVELTY"
  ],
  [
    "The work is extremely creative and packed with interesting experiments .",
    "NOVELTY"
  ],
  [
    "I think that the present paper is therefore only incremental .",
    "NOVELTY"
  ],
  [
    "3 .The techniques developed in this paper are new and significantly depart from previous works .",
    "NOVELTY"
  ],
  [
    "the paper presents a nice collection of results that significantly improves our understanding on overcomplete HMMs",
    "NOVELTY"
  ],
  [
    "However , this is not new idea",
    "NOVELTY"
  ],
  [
    "The summary in Table 1 and 2 may be noteworthy but falls somewhat on the border of novelty",
    "NOVELTY"
  ],
  [
    "I believe that this article is interesting and the original .",
    "NOVELTY"
  ],
  [
    "Overall , the idea in the paper is pretty intuitive and makes",
    "NOVELTY"
  ],
  [
    "From the machine learning perspective , the proposed `` attacking `` method is standard without any technical novelty",
    "NOVELTY"
  ],
  [
    "Since both approaches have been published before (",
    "NOVELTY"
  ],
  [
    ", the novelty seems to be limited .",
    "NOVELTY"
  ],
  [
    "This is original and novel and creative",
    "NOVELTY"
  ],
  [
    "this",
    "NOVELTY"
  ],
  [
    "Using insights from information geometry opens up a very interesting and ( to my knowledge ) new approach for analysing the generalisation ability of ML models .",
    "NOVELTY"
  ],
  [
    "After surveying previous work , I am not sure if the paper is really novel : First of all , adding KL-based constrains to alleviate model forgetting has already been widely explored in prior arts",
    "NOVELTY"
  ],
  [
    "The techniques applied , although not commonly used in the context of ride sharing / hailing , have been used extensively in other literature",
    "NOVELTY"
  ],
  [
    "The conversion of data to heat-maps has been used extensively in prior research",
    "NOVELTY"
  ],
  [
    "While the idea is quite simple , it seems to work well empirically and , to the best of my knowledge , is novel .",
    "NOVELTY"
  ],
  [
    "While the idea of exploring a novel fairness measure in counterfactual semantics and enforcing it over multiple candidate models is interesting",
    "NOVELTY"
  ],
  [
    "3 .The contribution of this paper seems to be incremental unless I am missing something .",
    "NOVELTY"
  ],
  [
    "The contributions of this paper are to the best of my knowledge original .",
    "NOVELTY"
  ],
  [
    "The idea of self-normalisation , however , has been introduced with Self-Normalizing Neural Networks",
    "NOVELTY"
  ],
  [
    "The benefit of inherent normalisation with this method , makes this an especially interesting approach .",
    "NOVELTY"
  ],
  [
    "The paper has some nice contributions and",
    "NOVELTY"
  ],
  [
    "but the paper is not matured enough",
    "NOVELTY"
  ],
  [
    "Although not dramatically novel given cited work by Salimans",
    "NOVELTY"
  ],
  [
    "Searching both the partitioning + weight values with ENAS and ES provides a nice way to do learning & compact architecture search simultaneously .",
    "NOVELTY"
  ],
  [
    "Both model compression and lifelong learning are active domains of research and proposing an approach which somehow bridges the two problems and proposes a dual view on these problems is great",
    "NOVELTY"
  ],
  [
    "My major concern with this paper is that their 's nothing new in it .",
    "NOVELTY"
  ],
  [
    "The main benefit of this proposed algorithm is that it escapes doing sparse-eigenvector computations , which was a bottleneck in previous works",
    "NOVELTY"
  ],
  [
    "While the use of such convex combination ( mixing features ) is not new",
    "NOVELTY"
  ],
  [
    "While the idea of mixing not only features but also labels is new and interesting",
    "NOVELTY"
  ],
  [
    "\u00e2\u0080\u00a2 Key-point learning without any external labels appears to be a novel addition .",
    "NOVELTY"
  ],
  [
    "and I am not aware of existing work on meta-learning the AF for BO",
    "NOVELTY"
  ],
  [
    "The presented approach is very similar to Chen et al , which is discussed in the related work section but not used as a baseline",
    "NOVELTY"
  ],
  [
    "Using VAEs to model the conditional class distributions is a nice idea",
    "NOVELTY"
  ],
  [
    "`` To our knowledge our results provide the first demonstration of end-to-end learning for a complex manipulation problem involving multiple freely moving objects ``",
    "NOVELTY"
  ],
  [
    "I had difficulties to see which parts of this work could be sufficiently novel .",
    "NOVELTY"
  ],
  [
    "+The unsupervised learning method for sparse representation expansion seems to be novel .",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea of this paper .",
    "NOVELTY"
  ],
  [
    "Studying the Granger causality in Wold point processes is novel and can be interesting to several disciplines .",
    "NOVELTY"
  ],
  [
    "The idea of using neural networks ( in general ) for NIDS is old [ 1 ] .",
    "NOVELTY"
  ],
  [
    "To my knowledge , this is the first work enforcing this particular minimum group coverage constraint in the context of graph covering .",
    "NOVELTY"
  ],
  [
    "In terms of the connection between the the problem and Bayesian filtering as well as smoothing , the paper has novelty there .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed ( combined ) method is unclear , given that it is a relatively straightforward combination of relatively simple and battle-tested techniques",
    "NOVELTY"
  ],
  [
    "novel /original proposal justified both theoretically and empirically + well",
    "NOVELTY"
  ],
  [
    "This is a really nice and natural idea .",
    "NOVELTY"
  ],
  [
    "Interesting topic but lacks of novelty",
    "NOVELTY"
  ],
  [
    "The idea of the proposed method is related to the classic Dyna methods from Sutton",
    "NOVELTY"
  ],
  [
    "The main idea of the proposed method",
    "NOVELTY"
  ],
  [
    "I think this paper is interesting",
    "NOVELTY"
  ],
  [
    "Overall , the work is perhaps a bit incremental , but it seems",
    "NOVELTY"
  ],
  [
    "to",
    "NOVELTY"
  ],
  [
    "The method is new and somehow theoretically guaranteed by the proof of the Proposition 1",
    "NOVELTY"
  ],
  [
    "the paper is an incremental effort in revisiting previous results and previous algorithms ;",
    "NOVELTY"
  ],
  [
    "The proposed method has certain advantages over previous methods",
    "NOVELTY"
  ],
  [
    "Also , the idea of using uniform noise to emulate quantization is interesting .",
    "NOVELTY"
  ],
  [
    "The added novelty is limited and unclear .",
    "NOVELTY"
  ],
  [
    "The technical novelty is also limited .",
    "NOVELTY"
  ],
  [
    "each component in isolation is not novel",
    "NOVELTY"
  ],
  [
    ", this paper presents a novel contribution with an idea for more efficient BNNs and experimentally verifies the success of their proposed changes",
    "NOVELTY"
  ],
  [
    "Originality The proposed method is original up to my knowledge .",
    "NOVELTY"
  ],
  [
    "In my opinion it is one of the most relevant advances in the area of scalable Gaussian processes in the last years .",
    "NOVELTY"
  ],
  [
    "The paper proposes a very interesting approach .",
    "NOVELTY"
  ],
  [
    "The paper 's two contributions are too minor to merit publication",
    "NOVELTY"
  ],
  [
    "this is simply too minor to be considered a contribution",
    "NOVELTY"
  ],
  [
    "The authors claim this paradigm towards specifying ML models is novel .",
    "NOVELTY"
  ],
  [
    "but I am inclined to agree that their approach seems new and interesting",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "originality of this paper is moderate",
    "NOVELTY"
  ],
  [
    "The work puts together ideas and formulations from various areas . I believe that this work is an interesting extension of the seminal work on CVaR-based RL by Chow and Ghavamzadeh",
    "NOVELTY"
  ],
  [
    "but I would not consider it as particularly novel .",
    "NOVELTY"
  ],
  [
    ".Even though I do not feel that the present work advances the theory of robust options in some major way",
    "NOVELTY"
  ],
  [
    "the experiments",
    "NOVELTY"
  ],
  [
    "all reviewers agreed that the novelty over Chow and Ghavamzadeh is not so significant",
    "NOVELTY"
  ],
  [
    "Overall I found novelty low and also there are several recent papers already published before this submission which provide results which are at least as good or even better Details Specifically the rules are",
    "NOVELTY"
  ],
  [
    "However the contributions were not really very novel in my opinion .",
    "NOVELTY"
  ],
  [
    "and the approach of moving the computationally intensive operations from real values to binary looks promising",
    "NOVELTY"
  ],
  [
    "The contribution is rather incremental",
    "NOVELTY"
  ],
  [
    "which requires a rather minor change in the algorithm",
    "NOVELTY"
  ],
  [
    "This work combines existing techniques in a meaningful way .",
    "NOVELTY"
  ],
  [
    "however , technical novelty of the paper is not significant",
    "NOVELTY"
  ],
  [
    "Interesting approach : Trying to develop an external observer based on information theoretic perspective .",
    "NOVELTY"
  ],
  [
    "I like the idea very much",
    "NOVELTY"
  ],
  [
    "The model is interesting , well defined and well explained . As far as I know , the UREX model is an original model which will certainly be useful for the RL community .",
    "NOVELTY"
  ],
  [
    "since the statements seem relatively powerful and the corresponding proofs seem very technical",
    "NOVELTY"
  ],
  [
    "I believe these results are original .",
    "NOVELTY"
  ],
  [
    "The adaptivity of the algorithm to the curvature and L0 sparsity is interesting . I think the analysis of the algorithm of section 3.3 had some interesting techniques",
    "NOVELTY"
  ],
  [
    "Comments -- -- -- -- Scaling RL agents to high-dimensional partially-observable domains with sparse rewards is a fundamental open problem and this work provides a nice contribution",
    "NOVELTY"
  ],
  [
    "The proposed methodology seems to be a simple combination of existing algorithms and (",
    "NOVELTY"
  ],
  [
    "`` GNN is a low-pass filter `` is not a new observation .",
    "NOVELTY"
  ],
  [
    "then the technical contribution of gfNN is trivial .",
    "NOVELTY"
  ],
  [
    "Invertible constraint is a nice idea for using inverse of the decoder as the encoder .",
    "NOVELTY"
  ],
  [
    "I feel this paper does not give sufficient novelty to be accepted at ICLR .",
    "NOVELTY"
  ],
  [
    "The paper involves some interesting ideas and experimental results .",
    "NOVELTY"
  ],
  [
    ", and to the best of my knowledge , original .",
    "NOVELTY"
  ],
  [
    "The main idea is novel and fresh ,",
    "NOVELTY"
  ],
  [
    "Some reviewers could argue that the contribution is minimal with respect to the `` learning `` state-of-the-art",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel supervised binary hashing method . Instead of optimizing over all bits of a binary code as the final objective , the proposed method learns hash functions independently for each bit . To avoid a trivial solution it borrows ideas from ensemble learning and introduces a notion of diversity ( instead of orthogonality common in classical hashing literature ) among bits by a bootstrapping type mechanism . The final algorithm can be optimized more efficiently since it is more amenable to parallelization and outperforms similar supervised hashing algorithm such as KSH.The proposed scheme seems to be novel in hashing literature despite similarities to ensemble learning",
    "NOVELTY"
  ],
  [
    "The idea is well thought",
    "NOVELTY"
  ],
  [
    "but the innovation is indeed low .",
    "NOVELTY"
  ],
  [
    "Another major concern is that the technical contributions of the proposed model is quite limited .",
    "NOVELTY"
  ],
  [
    "However , such contributions are quite minor , and technically heuristic .",
    "NOVELTY"
  ],
  [
    "a novel transition revision ( T-Revision ) method is proposed , which does not require anchor points",
    "NOVELTY"
  ],
  [
    "The arguments are similar to those appearing in most such papers , and as such are not particularly novel or technically interesting .",
    "NOVELTY"
  ],
  [
    ", and the idea of using two agents for better exploration is interesting and novel .",
    "NOVELTY"
  ],
  [
    "- a simple and novel idea tackling a hard problem",
    "NOVELTY"
  ],
  [
    "The contribution of SELF is not clear .",
    "NOVELTY"
  ],
  [
    "The proposed change to the MPNN network architecture is rather simple and hardly physics inspired",
    "NOVELTY"
  ],
  [
    "so this too is a nice contribution",
    "NOVELTY"
  ],
  [
    "the idea of using bond-type information was already in Gilmer et al .Also",
    "NOVELTY"
  ],
  [
    "I especially like the idea of formalizing the dissimilarity between tasks using RDM .",
    "NOVELTY"
  ],
  [
    "but the formalism of the approach is welcomed",
    "NOVELTY"
  ],
  [
    "Novelty-wise , I consider that the proposed solution to be satisfactorily innovative and on a different vein than the existing methods .",
    "NOVELTY"
  ],
  [
    "The idea of formalizing code completion as structured language modeling and extending Alon et al. , 2019a for the task is natural and",
    "NOVELTY"
  ],
  [
    "I have a very mixed feeling with this paper , while the model registers high empirical performance , the technical contribution is a bit limited",
    "NOVELTY"
  ],
  [
    "Section 7 ) , applying the model to a different task without significant task-specific adaptation or in-depth analysis might not sound technically novel .",
    "NOVELTY"
  ],
  [
    "This paper presents an interesting approach to this problem that leverages recent developments in applied mathematics",
    "NOVELTY"
  ],
  [
    "I think this is an interesting contribution",
    "NOVELTY"
  ],
  [
    "This contribution is remarkable in this sense .",
    "NOVELTY"
  ],
  [
    "and the derivation of the joint training seems original idea",
    "NOVELTY"
  ],
  [
    "While the idea of using chirplet transform is interesting",
    "NOVELTY"
  ],
  [
    "The proposed pooling function is novel .",
    "NOVELTY"
  ],
  [
    "Interesting paper with very novel applications .",
    "NOVELTY"
  ],
  [
    "I find the application exciting and novel",
    "NOVELTY"
  ],
  [
    "While I found the initial motivation of the paper quite interesting ( and novel as far as I can tell )",
    "NOVELTY"
  ],
  [
    "Multi-task baseline in the paper is naive",
    "NOVELTY"
  ],
  [
    "which is beautiful and enlightening",
    "NOVELTY"
  ],
  [
    "but somewhat abstract",
    "NOVELTY"
  ],
  [
    "I found it very enlightening .",
    "NOVELTY"
  ],
  [
    "My biggest concern with the paper is novelty .",
    "NOVELTY"
  ],
  [
    "the differences being quite incremental",
    "NOVELTY"
  ],
  [
    "I am not totally sure whether the contribution of the paper should be considered as a new method or as architectural optimizations of an existing one .",
    "NOVELTY"
  ],
  [
    "and that this contribution is a nice addition to the spectral learning literature",
    "NOVELTY"
  ],
  [
    "and the results are technically non-trivial",
    "NOVELTY"
  ],
  [
    "1 .Although the gated fusion of visual and semantic representation is simple , but the idea is interesting and effective .",
    "NOVELTY"
  ],
  [
    "I have not see similar idea in few-shot learning",
    "NOVELTY"
  ],
  [
    "I like this idea and the proposed model a",
    "NOVELTY"
  ],
  [
    "This work is a novel combination of existing techniques , combining variational autoencoders , joint training , and sequence models .",
    "NOVELTY"
  ],
  [
    "I found that this paper did little to extend the work of [ 11 ]",
    "NOVELTY"
  ],
  [
    "I like the idea of the ablation studies presented",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel trial to alleviate the catastrophic forgetting for continual learning which is kind a mixture model of on and off-policy .",
    "NOVELTY"
  ],
  [
    "The paper presents a novel solution to an incremental classification problem based on a dual memory system .",
    "NOVELTY"
  ],
  [
    "The solution proposed is a novel one based on a dual memory system inspired by the memory storage mechanism in brain .",
    "NOVELTY"
  ],
  [
    "Hence , the proposed work provides a novel and scalable solution to the existing problem .",
    "NOVELTY"
  ],
  [
    "The new Greedy Sinkhorn algorithm is very interesting",
    "NOVELTY"
  ],
  [
    "what is so novel about this",
    "NOVELTY"
  ],
  [
    "the contributions are less clear",
    "NOVELTY"
  ],
  [
    "This is could be enough as a contribution",
    "NOVELTY"
  ],
  [
    "I really like the idea of trying to fuse neuroethology and animal behavior research in general with deep learning methods .",
    "NOVELTY"
  ],
  [
    "The learning of a network that can perform these four independent tasks is quite impressive in its own right",
    "NOVELTY"
  ],
  [
    "Nevertheless , the proposed representation is new in the particular context of learning the kernels for DPP .",
    "NOVELTY"
  ],
  [
    "The idea of increasing robustness by maximizing inter-class margins and minimizing intra-class variance is fairly natural",
    "NOVELTY"
  ],
  [
    "The proposed technique seems to be a fairly small extension to existing work , but",
    "NOVELTY"
  ],
  [
    "together with its analysis and experiments it is sufficiently novel",
    "NOVELTY"
  ],
  [
    "This work risks being underappreciated as proposing but a simple addition of artificial structured-label noise",
    "NOVELTY"
  ],
  [
    "but I think the specific link with structured output task reward is sufficiently original , and the paper also uncovers important theoretical insight by revealing the formal relationship between the proposed reward augmented ML and RL-based regularized expected reward objectives .",
    "NOVELTY"
  ],
  [
    "I am not aware of anyone having attempted something similar , clearly a very original submission .",
    "NOVELTY"
  ],
  [
    "I think this is a very interesting idea",
    "NOVELTY"
  ],
  [
    "and the approach leverages existing source of visual grounding in a exciting way .",
    "NOVELTY"
  ],
  [
    "Compared with Nagarajan and Kolter , the contribution of this paper seems to be minor , although technically involved .",
    "NOVELTY"
  ],
  [
    "The paper is interesting and has some great ideas",
    "NOVELTY"
  ],
  [
    "introducing BP , FA and DFA in the paper .",
    "NOVELTY"
  ],
  [
    "proposed model is elegant",
    "NOVELTY"
  ],
  [
    "While",
    "NOVELTY"
  ],
  [
    "I think its assumptions are too simplistic for real-world interaction data and the model itself is not novel enough to justify this . The novelty of the model stems mostly from the combination of two previously introduced components\u00e2\u0080\u0094namely",
    "NOVELTY"
  ],
  [
    "The paper come across to me as an extension of known results for the SBM .",
    "NOVELTY"
  ],
  [
    "Exploiting compositionality in model design is not novel per se",
    "NOVELTY"
  ],
  [
    ", but it is to the best of my knowledge the first explicit application of this idea in neural architecture search .",
    "NOVELTY"
  ],
  [
    "while the idea behind the proposed approach is definitely interesting",
    "NOVELTY"
  ],
  [
    "Overall , this is a good piece of work .",
    "NOVELTY"
  ],
  [
    "The idea of generalizing verifications to a convex-relaxable set is interesting",
    "NOVELTY"
  ],
  [
    "The idea is new ( to me ) and appears both elegant and effective .",
    "NOVELTY"
  ],
  [
    "Introducing analysis tools from game theory to the community - entertaining video",
    "NOVELTY"
  ],
  [
    "From the technical point of view , some proof techniques are not so novel .",
    "NOVELTY"
  ],
  [
    "3 .The idea of using quantization for neural network model compression is not novel ( even for language model ) , although it is listed as one of the main contributions in Section 1 . So in general , I think the paper is insufficient in novelty and missing competitive baselines .",
    "NOVELTY"
  ],
  [
    "The phenomena of effective sample size amplification is technically interesting .",
    "NOVELTY"
  ],
  [
    "Meantime , style transfer via iterative refinement is not a novel idea as it has been applied by the WCT method [ 17 ] .",
    "NOVELTY"
  ],
  [
    "The framework is novel compared to other style transfer methods .",
    "NOVELTY"
  ],
  [
    "Originality and significance Overall it looks a nice contribution .",
    "NOVELTY"
  ],
  [
    "The paper is interesting , and adds considerably to the increasing body of research in hierarchical reinforcement learning ( HRL ) .",
    "NOVELTY"
  ],
  [
    "This paper offers some good ideas that are moderately novel and may advance the field",
    "NOVELTY"
  ],
  [
    "It may or may not be as interesting or novel .",
    "NOVELTY"
  ],
  [
    "While the paper contains some interesting ideas",
    "NOVELTY"
  ],
  [
    "The idea of transferring abstract knowledge learned from one modality to other in the student teacher network is interesting and looks appealing .",
    "NOVELTY"
  ],
  [
    "Although the methodology used is not very novel it facilitate learning of much deeper sound-net",
    "NOVELTY"
  ],
  [
    "Over all a well presented paper with incremental novelty but",
    "NOVELTY"
  ],
  [
    "I 'd highly recommend this paper get accepted since I believe the analysis carried out here and the conclusions reached are quite novel and",
    "NOVELTY"
  ],
  [
    "The model is moderately novel",
    "NOVELTY"
  ],
  [
    "I found the trellis construction to be novel , and an interesting approach to dealing with the difficulty of finding good architectures .",
    "NOVELTY"
  ],
  [
    "I think that there are valuable ideas and insights to be presented",
    "NOVELTY"
  ],
  [
    "From a high-level perspective , the methodological innovation ( a pointer-network trained on sequence loss from logged data ) , setting ( re-ranking a slate to consider interactions ) , and empirical analyses are largely \u2018 incremental \u2019 \u2014",
    "NOVELTY"
  ],
  [
    "This is the weakest aspect of the paper from a methodological perspective",
    "NOVELTY"
  ],
  [
    "Non-trivial and complete , but not particularly innovative .",
    "NOVELTY"
  ],
  [
    "and this work introduces some interesting ideas in this domain .",
    "NOVELTY"
  ],
  [
    "Interesting new modeling approach , joint constraint networks",
    "NOVELTY"
  ],
  [
    "I consider the paper significant and original",
    "NOVELTY"
  ],
  [
    "All in all , I like the idea , the way the work is presented ,",
    "NOVELTY"
  ],
  [
    "Lack of novelty The paper has very limited novelty since the proposed method is a straightforward combination of two prior works on the same topic",
    "NOVELTY"
  ],
  [
    "Since the ideas are already published in the prior work , the paper does not contribute additional knowledge to the problem .",
    "NOVELTY"
  ],
  [
    "the authors provide an inference algorith I think the paper is promising",
    "NOVELTY"
  ],
  [
    "it is by no means a *new* model",
    "NOVELTY"
  ],
  [
    "2 .I think the approach of [ treating the agent 's learning problem as binary classification ] is very interesting .",
    "NOVELTY"
  ],
  [
    "The proposed objective is novel ,",
    "NOVELTY"
  ],
  [
    "though it is very similar to InfoGAN or GAIL + [ Florensa et al . ]",
    "NOVELTY"
  ],
  [
    ", and the proposed idea of using GAIL with InfoGAN-like objective is novel .",
    "NOVELTY"
  ],
  [
    "The paper describes an interesting approach to the problem",
    "NOVELTY"
  ],
  [
    "Not much technical novelty to be found",
    "NOVELTY"
  ],
  [
    "and they are interesting on their own .",
    "NOVELTY"
  ],
  [
    "Originality This is the first work to give the detailed characterizations of the implicit bias of gradient descent on separable data .",
    "NOVELTY"
  ],
  [
    "I do n't think the intersection of ideas in structured graphical models and deep generative model is particularly novel at this point",
    "NOVELTY"
  ],
  [
    "Generally , methodologically the papers appears somewhat incremental",
    "NOVELTY"
  ],
  [
    "The auxiliary bound introduced in ( 4 ) - ( 5 ) is novel and and allows the posterior in the semi-supervised case to force learning over the classification network",
    "NOVELTY"
  ],
  [
    "I have only limited knowledge of the field , so it is hard for me to assess originality of the results .",
    "NOVELTY"
  ],
  [
    "Even with this overlap with the preceding study , the main claim of this paper about the quantization effect in activation function is surely new and important",
    "NOVELTY"
  ],
  [
    "Application of MFT to studying the effect of quantization is clearly new and important .",
    "NOVELTY"
  ],
  [
    "The paper is quite interesting",
    "NOVELTY"
  ],
  [
    "The proof techniques are classical",
    "NOVELTY"
  ],
  [
    "but the results seem novel as far as I know .",
    "NOVELTY"
  ],
  [
    "Ideas are simple and incremental , even if i rely upon literature overview provided by the authors in the related work section",
    "NOVELTY"
  ],
  [
    "The proposed solution does n't seem generic to be applied in other NLP or ML problems",
    "NOVELTY"
  ],
  [
    "This work is a novel combination of well-known techniques .",
    "NOVELTY"
  ],
  [
    "it is original enough to provide better results",
    "NOVELTY"
  ],
  [
    "The originality is further enhanced by the proposed source counting module",
    "NOVELTY"
  ],
  [
    "Overall , this paper presents a significant advancement of the deep learning-ification of a classic problem in signal processing .",
    "NOVELTY"
  ],
  [
    "It is novel",
    "NOVELTY"
  ],
  [
    "The idea is simple and carries over from ( image-based ) supervised learning .",
    "NOVELTY"
  ],
  [
    "Still , I am really unsure about the technical contribution as the paper is not very clear on this point . The approach appears to be very similar to others such as Balntas 16 that also used triplet losses and deep nets to learn patch descriptors .",
    "NOVELTY"
  ],
  [
    "The approach seems novel and original ,",
    "NOVELTY"
  ],
  [
    "though there is some novelty in the method",
    "NOVELTY"
  ],
  [
    "However there are a variety of concerns that the authors need to address : The technical contributions in this paper are somewhat thin .",
    "NOVELTY"
  ],
  [
    "The novelty is quite low and it \u2019 s not clear if this will transfer to another domain .",
    "NOVELTY"
  ],
  [
    "Using deep learning to this application area is also not novel .",
    "NOVELTY"
  ],
  [
    "The primary concern with this submission is the novelty .",
    "NOVELTY"
  ],
  [
    "I do not find any novelty in this paper",
    "NOVELTY"
  ],
  [
    "Overall , I find the novelty and the experimental analysis of the",
    "NOVELTY"
  ],
  [
    "While none of the individual components proposed in this paper are new",
    "NOVELTY"
  ],
  [
    "The idea is interesting and trendy .",
    "NOVELTY"
  ],
  [
    "The proposed approach is very simple and intuitive .",
    "NOVELTY"
  ],
  [
    "Novelty and presentation .",
    "NOVELTY"
  ],
  [
    "it introduces a simple idea",
    "NOVELTY"
  ],
  [
    "The idea of generating passage graph is novel .",
    "NOVELTY"
  ],
  [
    "al .The 2 techniques , although simple , do n't make up for technical novelty .",
    "NOVELTY"
  ],
  [
    "This paper presents a novel model to decompose the latent code in a semantic manner .",
    "NOVELTY"
  ],
  [
    "DR .I find the manuscript to contain interesting ideas",
    "NOVELTY"
  ],
  [
    "novel training methodology for GANs to improve stability",
    "NOVELTY"
  ],
  [
    "2 .The paper proposes novel strategies to update the latent distributions ' parameters .",
    "NOVELTY"
  ],
  [
    "The idea is an incremental extension of MAML and DARTS .",
    "NOVELTY"
  ],
  [
    "However , the idea is creative",
    "NOVELTY"
  ],
  [
    "and while the fast-weights are not new , the details of the presented method are original .",
    "NOVELTY"
  ],
  [
    "and this paper continues this line of work for MMAP.In terms of novelty",
    "NOVELTY"
  ],
  [
    "the paper 's discussion on leveraging the analysis of hashing-based counting approaches was good",
    "NOVELTY"
  ],
  [
    "The insight of using multi-step prediction models is certainly appealing",
    "NOVELTY"
  ],
  [
    "The contribution in this paper limited as the proposed approach as well as the experimental comparison is restricted to a relatively specific class of problems and no attempts to generalize are made",
    "NOVELTY"
  ],
  [
    "All in all , I think the paper makes a small contribution demonstrating that multi-step models are useful for model-based RL in specific domains -- which is interesting but certainly not surprising",
    "NOVELTY"
  ],
  [
    "I feel that",
    "NOVELTY"
  ],
  [
    "while the proposed solution is very intuitive ,",
    "NOVELTY"
  ],
  [
    "by",
    "NOVELTY"
  ],
  [
    "The model is new .",
    "NOVELTY"
  ],
  [
    "I find that the insights provided in the paper",
    "NOVELTY"
  ],
  [
    "and the lossy decoding are well-written",
    "NOVELTY"
  ],
  [
    "but are not novel",
    "NOVELTY"
  ],
  [
    "The difference between an auto-regressive prior and the inverse auto-regressive posterior is new and interesting though .",
    "NOVELTY"
  ],
  [
    "the observations on expressiveness of composition functions in SRL are not new .",
    "NOVELTY"
  ],
  [
    "The proposed method boils down to combining relatively simple components in a straightforward manner , little innovation in terms of methodology .",
    "NOVELTY"
  ],
  [
    "is a very interesting paper",
    "NOVELTY"
  ],
  [
    "Moderate novelty",
    "NOVELTY"
  ],
  [
    "Comments The theoretical contribution is quite small since the connection to RD theory is well established by now",
    "NOVELTY"
  ],
  [
    "The formulation for the problem of unsupervised translation is insightful .",
    "NOVELTY"
  ],
  [
    "The contribution to the GAN model of this paper is to add the mutual information penalty",
    "NOVELTY"
  ],
  [
    "to the GAN loss , which seems incremental",
    "NOVELTY"
  ],
  [
    "this paper proposes a nice formulation for the problem of unsupervised translation",
    "NOVELTY"
  ],
  [
    "But the contribution to the GAN model seems incremental and comparisons to other methods are not enough .",
    "NOVELTY"
  ],
  [
    "I like the idea of using node-level embedding instead of pairwise weights to learn a low-rank weight representation .",
    "NOVELTY"
  ],
  [
    "This is not a new idea by itself and is used e.g .as a baseline in Kingma and Welling 's original VAE paper",
    "NOVELTY"
  ],
  [
    "The method to estimate gradients by \u201c shaking \u201d in a probabilistic way by fitting a GP to noisy trajectories is clever and interesting .",
    "NOVELTY"
  ],
  [
    "the paper",
    "NOVELTY"
  ],
  [
    "the 3D CNN architecture ( which is one of the the core novelties of this work compared to past efforts",
    "NOVELTY"
  ],
  [
    "The MHP model adopted in the paper has been applied to this problem by varied social network papers",
    "NOVELTY"
  ],
  [
    "Limited technical novelty .",
    "NOVELTY"
  ],
  [
    "Implementing such a hybrid system is nontrivial due to the reality gap .",
    "NOVELTY"
  ],
  [
    "I like the idea , the application and the result of this paper .",
    "NOVELTY"
  ],
  [
    "The proposed AGEM algorithm for simultaneously solving linear inverse problem and estimating noise level is novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "The way tackling the information asymmetry , or untie weights , between domains is novel and interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the idea as such is not that novel (",
    "NOVELTY"
  ],
  [
    "it does n't offer any new insights",
    "NOVELTY"
  ],
  [
    "existing method",
    "NOVELTY"
  ],
  [
    "I like the method very much and think it \u2019 s a clever and well-executed algorithm",
    "NOVELTY"
  ],
  [
    "The method is interesting and clever .",
    "NOVELTY"
  ],
  [
    "In general , I liked this approach . It is a new an interesting take on the problem and one that seems obvious in retrospect ( which is often a sign of a good idea",
    "NOVELTY"
  ],
  [
    "-The Bayesian analysis with different noise models is interesting .",
    "NOVELTY"
  ],
  [
    "-The new convolutional architecture with receptive fields restricted to a half plane is also a nice contribution",
    "NOVELTY"
  ],
  [
    ", the proposed method is original",
    "NOVELTY"
  ],
  [
    "However , it is not clear whether the findings are novel",
    "NOVELTY"
  ],
  [
    "I am convinced that the contribution of this paper is novel ( compared to [ 21 ] )",
    "NOVELTY"
  ],
  [
    "Therefore , the novelty of the paper seems not enough .",
    "NOVELTY"
  ],
  [
    "but nevertheless I feel that this paper already represents a worthwhile contribution",
    "NOVELTY"
  ],
  [
    "I think this paper has some very interesting ideas .",
    "NOVELTY"
  ],
  [
    "This paper presents some interesting theoretical results along this direction .",
    "NOVELTY"
  ],
  [
    "The work is highly original .",
    "NOVELTY"
  ],
  [
    "This submission is of high quality .",
    "NOVELTY"
  ],
  [
    "The authors proposed to exploit the structure relationships between point clouds from both global and local perspectives are very enlightening .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is a modest contribution to the field ,",
    "NOVELTY"
  ],
  [
    "Semi-supervised learning for dependency parsing is both important and difficult and this paper presents a novel approach using variational auto-encoders .",
    "NOVELTY"
  ],
  [
    "it is very impressive to reveal the connection between HMC and slice sampling , the two seemingly quite different samplers .",
    "NOVELTY"
  ],
  [
    "The algorithms proposed are simple , clever variants of the perceptron method .",
    "NOVELTY"
  ],
  [
    "Novel recurrent neural network architecture to model structured dynamics of agents in an environment .",
    "NOVELTY"
  ],
  [
    "New dataset for partially observable prediction",
    "NOVELTY"
  ],
  [
    "The transfer learning of spoken language understanding is very interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the novelty of this paper is incremental and",
    "NOVELTY"
  ],
  [
    "improvement over SVCCA .",
    "NOVELTY"
  ],
  [
    "In general , the novelty of the paper is a little bit limited",
    "NOVELTY"
  ],
  [
    "-Use of unlabeled data to help facilitate fairness along with better accuracy is novel .",
    "NOVELTY"
  ],
  [
    "and to the best of my knowledge , this has not been shown in prior work",
    "NOVELTY"
  ],
  [
    "Fluid dynamics isn \u2019 t exactly a field that was introduced 5 years ago",
    "NOVELTY"
  ],
  [
    "I generally like the idea of including physical consistency when training to train a neural network for a respective task where this matters .",
    "NOVELTY"
  ],
  [
    "insights",
    "NOVELTY"
  ],
  [
    "the novelty/originality of this work is somewhat limited",
    "NOVELTY"
  ],
  [
    "I do not think this is enough contribution to be presented at NIPS .",
    "NOVELTY"
  ],
  [
    "Whereas I agree there is novelty on the usage of this methodology , the contribution in this side is limited ( in the nips sense",
    "NOVELTY"
  ],
  [
    "The results presented seem to be",
    "NOVELTY"
  ],
  [
    "on par with EM but the technique is a novel spin on the capsule routing",
    "NOVELTY"
  ],
  [
    "paper explores an interesting avenue involving capsule networks , by bridging attention logic and capsule convolutional nets",
    "NOVELTY"
  ],
  [
    "The idea of using attention in capsule networks in itself is not brand new",
    "NOVELTY"
  ],
  [
    "The novel view-point performance on smallNORB is",
    "NOVELTY"
  ],
  [
    "The paper essentially combines the IDS formulation of Kirschner",
    "NOVELTY"
  ],
  [
    ", and the C51 distributional RL method of Bellemare et al .Most of the novelty is in how to combine these ideas effectively in the deep RL setting",
    "NOVELTY"
  ],
  [
    "This is an interesting",
    "NOVELTY"
  ],
  [
    "with a new thought-provoking perspective on adversarial examples 2",
    "NOVELTY"
  ],
  [
    "In terms of originality , the design proposed in the paper appears to be new and makes intuitive sense .",
    "NOVELTY"
  ],
  [
    "My main criticism of the paper is the novelty of the proposed model .",
    "NOVELTY"
  ],
  [
    "However I think that closely related variants of the main contributions in the paper have been tried elsewhere which somewhat reduces the novelty of the proposed model .",
    "NOVELTY"
  ],
  [
    "novel , and bringing them together is an important contribution .",
    "NOVELTY"
  ],
  [
    "the sampling step , to the best of my knowledge",
    "NOVELTY"
  ],
  [
    "The underlying idea of this paper ( graph regularization ) has been already explored in different papers",
    "NOVELTY"
  ],
  [
    "The submitted paper is the first GAN-based paper on this precise topic I 've seen",
    "NOVELTY"
  ],
  [
    "The use of GANs is a somewhat novel extension of existing conditional GAN methods .",
    "NOVELTY"
  ],
  [
    "While unrolling the inference is not new",
    "NOVELTY"
  ],
  [
    "I have the similar feeling with R1 that the novelty is somewhat limited",
    "NOVELTY"
  ],
  [
    "While there is some interesting and potentially useful novelty in the approach",
    "NOVELTY"
  ],
  [
    "The information-theoretic tools that they use are interesting and new to ML community .",
    "NOVELTY"
  ],
  [
    "2 .The idea of bipartite graph convolution seems different from that of stride convolution",
    "NOVELTY"
  ],
  [
    "Limited novelty . No new reinforcement learning method is introduced .",
    "NOVELTY"
  ],
  [
    "Since this problem has been addressed before using also RL tools [ 13 ] the novelty is very limited .",
    "NOVELTY"
  ],
  [
    "Its contributions are not clear ( in particular its novelty )",
    "NOVELTY"
  ],
  [
    "that are interesting but not really new",
    "NOVELTY"
  ],
  [
    "The architecture is novel compare to recent lines of language model work , which all used variation of BERT or GPT",
    "NOVELTY"
  ],
  [
    "en-fake experiments enlightening",
    "NOVELTY"
  ],
  [
    "The idea of creating a unicode shifted version of English and use it for testing is a first of its kind and quite interesting .",
    "NOVELTY"
  ],
  [
    "The architecture experiments were not that insightful",
    "NOVELTY"
  ],
  [
    "The proposed approach appears to provide a novel , convincing and non-obvious solution to RNA secondary structure prediction",
    "NOVELTY"
  ],
  [
    "The paper does not really introduce new methods",
    "NOVELTY"
  ],
  [
    "As for the technical contribution of the paper , it seems not that significant over Hogwild !",
    "NOVELTY"
  ],
  [
    "The basic methodological contribution of the paper seems somewhat limited .",
    "NOVELTY"
  ],
  [
    "The Dwork et al .paper is one of the original seminal papers of the area",
    "NOVELTY"
  ],
  [
    "The new definitions in this paper are clever and thoughtful",
    "NOVELTY"
  ],
  [
    "The theorems are nontrivial",
    "NOVELTY"
  ],
  [
    "Overall this is a high quality paper with significant novel contributions to the theory of fair learning .",
    "NOVELTY"
  ],
  [
    "The novelty of the method is overstated .",
    "NOVELTY"
  ],
  [
    "The use of empirical Bayes is not novel in the context of neural networks despite the submission 's claim that `` Existing studies on parametric empirical Bayes methods focus on the setting where the likelihood function and the prior are assumed to have specific forms ``",
    "NOVELTY"
  ],
  [
    "3 .Novelty .Although the paper re-uses a lot of existing ideas and works",
    "NOVELTY"
  ],
  [
    ", still the combination is novel and relevant to consider .",
    "NOVELTY"
  ],
  [
    "linked",
    "NOVELTY"
  ],
  [
    "I really like the idea of combining an RNN and using it to guide network structure .",
    "NOVELTY"
  ],
  [
    "-The reward structure and formulating feature ( in this case kernel ) selection as an MDP is not new",
    "NOVELTY"
  ],
  [
    "2 .There is no novelty in the way KG is built , so there is no technical contribution to this paper making it a very weak submission for ICLR standards .",
    "NOVELTY"
  ],
  [
    "While this is an interesting approach",
    "NOVELTY"
  ],
  [
    "So the contribution is limited .",
    "NOVELTY"
  ],
  [
    "and contains stunning contributions . I was",
    "NOVELTY"
  ],
  [
    "and ideas contained in just eight pages",
    "NOVELTY"
  ],
  [
    "approach is presented as an original improvement with respect to the state-of-the-art",
    "NOVELTY"
  ],
  [
    "Moving away from strict holomorphy and using CR calculus to apply complex valued networks to RNNs is interesting as a novel technique .",
    "NOVELTY"
  ],
  [
    "Overall the paper appears original and well",
    "NOVELTY"
  ],
  [
    "The idea itself is rather straight-forward .",
    "NOVELTY"
  ],
  [
    "and is an interesting idea which I have n't seen in recent works combining logic and neural networks",
    "NOVELTY"
  ],
  [
    "The proposed model is novel",
    "NOVELTY"
  ],
  [
    "but incremental comparing to existing frameworks .",
    "NOVELTY"
  ],
  [
    "2 .The discussion comparing the related work/baseline methods is insightful .",
    "NOVELTY"
  ],
  [
    "The study presents some interesting methodological and technical ideas .",
    "NOVELTY"
  ],
  [
    "I vote for weak accept as the proposed is novel",
    "NOVELTY"
  ],
  [
    "The proposed methods seems incremental , given the existence of Ren et al .ICML18 .The idea of self-training is not new either .",
    "NOVELTY"
  ],
  [
    "Overall , it is hard to see substantial contributions of this work given the incremental improvements , limited justifications , and the limited performance gain from the main technical method .",
    "NOVELTY"
  ],
  [
    "Label Sensitive Gate ( LSG )",
    "NOVELTY"
  ],
  [
    "Overall , the novelty of the paper is limited by the scope of the experimental results .",
    "NOVELTY"
  ],
  [
    "The paper appears to provide to novel results",
    "NOVELTY"
  ],
  [
    "content",
    "NOVELTY"
  ],
  [
    "However , the paper is well written and provides two novel ideas relating to gradient flows for MMD , which seem like a worthy contribution to the field .",
    "NOVELTY"
  ],
  [
    "this is a nice paper with a small , incremental idea",
    "NOVELTY"
  ],
  [
    "However , the contribution is very incremental and of interest to a specialized subsegment of the ICLR audience ,",
    "NOVELTY"
  ],
  [
    "Modeling the structure via patches is an interesting idea .",
    "NOVELTY"
  ],
  [
    "The idea of relying on patches to model the structure is not new .",
    "NOVELTY"
  ],
  [
    "There is some novelty in the proposed approach",
    "NOVELTY"
  ],
  [
    "and I found the proposed solution",
    "NOVELTY"
  ],
  [
    "Overall , I liked the idea and tend towards acceptance .",
    "NOVELTY"
  ],
  [
    "I like the paper and I think it contains simple extensions to previous methods referenced in the",
    "NOVELTY"
  ],
  [
    "Especially , the use of RBS seems to be an interesting idea .",
    "NOVELTY"
  ],
  [
    "Despite the nice idea",
    "NOVELTY"
  ],
  [
    "extension of the work of Moreno-Munoz er al",
    "NOVELTY"
  ],
  [
    "This combination is ( to my knowledge ) novel and relevant .",
    "NOVELTY"
  ],
  [
    "although it is not new",
    "NOVELTY"
  ],
  [
    "this is an interesting",
    "NOVELTY"
  ],
  [
    "though not really novel .",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "My biggest concern is whether the algorithm novelty of the paper is not only incremental to this of [ 8 ]",
    "NOVELTY"
  ],
  [
    "I think the `` global optimization `` aspect of the main result and the fast ( i.e. , linear ) convergence rate are very interesting , and",
    "NOVELTY"
  ],
  [
    "I think this result is definitely a beautiful addition to this line of literature also",
    "NOVELTY"
  ],
  [
    "Overall the idea in the paper is interesting and promising",
    "NOVELTY"
  ],
  [
    "1 .The paper introduces an interesting idea to incorporate inter-slice contexts into the framework for 3D image segmentation",
    "NOVELTY"
  ],
  [
    "novel insights and improved performance\u00e2\u0080\u009d",
    "NOVELTY"
  ],
  [
    "Another concern is the novelty in relation to related work .",
    "NOVELTY"
  ],
  [
    "I very much like the idea of the paper",
    "NOVELTY"
  ],
  [
    "the reviewer thinks that the novelty and contribution of the paper are limited .",
    "NOVELTY"
  ],
  [
    "Since the novelty provided by the paper is small",
    "NOVELTY"
  ],
  [
    "There is also a major concern with respect to novelty and related work",
    "NOVELTY"
  ],
  [
    "Novelty is clearly limited in light of this overlooked prior work .",
    "NOVELTY"
  ],
  [
    "The idea of applying IMGEPs to explore parameters of a dynamic system is novel and interesting ,",
    "NOVELTY"
  ],
  [
    "Originality The work is original",
    "NOVELTY"
  ],
  [
    ", as only a few works have added additional unsupervised structure into the latent space . However , the originality is limited by the fact , that there is no clear explanation as to why the proposed structure is superior to other approaches that disentangle attributes from identity .",
    "NOVELTY"
  ],
  [
    "I found the paper interesting",
    "NOVELTY"
  ],
  [
    "This is indeed a relevant and interesting novelty .",
    "NOVELTY"
  ],
  [
    "c/ The theoretical contribution is minor",
    "NOVELTY"
  ],
  [
    "The main drawback of the paper is that most of the techniques used are already proposed in the literature and well-known ( at least to researchers working in this area",
    "NOVELTY"
  ],
  [
    "The proposed method for estimating hypercontractivity coefficient looks interesting .",
    "NOVELTY"
  ],
  [
    "In my opinion , the paper lacks sufficient contributions in itself to be accepted at this conference .",
    "NOVELTY"
  ],
  [
    "Overall : Though the direction of this work is interesting but lacks sufficient technical novelty .",
    "NOVELTY"
  ],
  [
    "there should be more clear novelty in the method",
    "NOVELTY"
  ],
  [
    "but the contribution is somewhat incremental",
    "NOVELTY"
  ],
  [
    "-introduces fast new implementation for homomorphic encrypted neural networks -first paper to implement LSTMs with homomorphic encryption",
    "NOVELTY"
  ],
  [
    "For this reason , I don\u00e2\u0080\u0099t think the result is very original and detracts from the main results",
    "NOVELTY"
  ],
  [
    "The progress is fairly incremental but I can live with that",
    "NOVELTY"
  ],
  [
    "Unlike their claim in the paper , the idea of combining supervised and RL is not new .",
    "NOVELTY"
  ],
  [
    "However , if I understand correctly , it seems that combining supervision of RL at a later fine-tuning phase by considering supervision as a regularization term is an interesting idea that seems novel .",
    "NOVELTY"
  ],
  [
    "but this paper lacks innovation since most techniques are available in the field",
    "NOVELTY"
  ],
  [
    "I do not view the contribution to be significant enough to be published in NIPS , especially the improvement is rather straightforward and incremental compared to [ 15 ] .",
    "NOVELTY"
  ],
  [
    "and as far as I can tell , there are not a lot of works that have proposed this metric before",
    "NOVELTY"
  ],
  [
    "Interesting idea and",
    "NOVELTY"
  ],
  [
    "I would say Theorem 3 does not contain any significant novel ideas .",
    "NOVELTY"
  ],
  [
    "I am not sure if this work provides a sufficient contribution to the literature ( neither in terms of the techniques used",
    "NOVELTY"
  ],
  [
    "Thus I think the contribution of the paper is marginal .",
    "NOVELTY"
  ],
  [
    "to my knowledge the work seems original and its relation to other work in the field",
    "NOVELTY"
  ],
  [
    "The paper then proposes a novel proximal update .",
    "NOVELTY"
  ],
  [
    "I do not see much novelty in the proposed learning objective Eq.4",
    "NOVELTY"
  ],
  [
    "the theory in the paper seems interesting",
    "NOVELTY"
  ],
  [
    "The model and procedure presented in the paper are an original application of variational inference , and represent a more general method for dealing with correlation structures than anything I have encountered before .",
    "NOVELTY"
  ],
  [
    "The idea of mapping the bias term back to the input is interesting as it shows a common behaviour of the network on inputs that choose the same pieces of the piecewise linear functions .",
    "NOVELTY"
  ],
  [
    "Time will tell whether a disease specific signal processing will be the future of medical image analysis , but - to the best of my knowledge - this is one of the first attempts to do this in CT image analysis , a field that is of significance both to researchers dealing with image reconstruction ( denoising",
    "NOVELTY"
  ],
  [
    "The saliency-based VAE objective is new to me as well .",
    "NOVELTY"
  ],
  [
    "the idea of smoothing for structured prediction is interesting",
    "NOVELTY"
  ],
  [
    "In general , I like the idea of guiding synthesis with intermediate executions",
    "NOVELTY"
  ],
  [
    "I have two major concerns with the paper , its presented contribution",
    "NOVELTY"
  ],
  [
    "There is nothing novel about the ensemble proposed , and ensembling , as a standard method that pushes models that extra few percentage points , is present in a lot of other research",
    "NOVELTY"
  ],
  [
    "I can not accept non-novel ensembling as a contribution of the paper .",
    "NOVELTY"
  ],
  [
    "but the idea is interesting and seems to work for the tasks in the paper",
    "NOVELTY"
  ],
  [
    "Although the methodology within the paper appears to be incremental over previous NAS method , the efficiency got improved quite significantly .",
    "NOVELTY"
  ],
  [
    "I like the soft gradient constraint idea introduced in this paper .",
    "NOVELTY"
  ],
  [
    "it presents an approximate fixed-point update rule for autoregressive time-series that can exploit GPU parallelism .",
    "NOVELTY"
  ],
  [
    "Contribution 1 is n't very novel",
    "NOVELTY"
  ],
  [
    "this seems to be the first time SGLD has been applied to such a problem",
    "NOVELTY"
  ],
  [
    "Neither MixUp nor the idea of fixing some number of labeled elements in a minibatch is new",
    "NOVELTY"
  ],
  [
    "There is not much technical contribution .",
    "NOVELTY"
  ],
  [
    "2 .Label embedding learning has been investigated in many previous works",
    "NOVELTY"
  ],
  [
    "The proposed novelty is simple and intuitive , which I think is a strength of the method",
    "NOVELTY"
  ],
  [
    "The paper is interesting and quite a worthwhile contribution that should be highlighted . This is a new perspective on fairness and bias that has not really been discussed before --",
    "NOVELTY"
  ],
  [
    "although similar in spirit to past works on approximating black-box models with interpretable surrogates / performing symbolic regression",
    "NOVELTY"
  ],
  [
    "this work seems to go several steps further and contribute something novel both in framing the problem and solving it .",
    "NOVELTY"
  ],
  [
    "The proofs techniques used to show that polynomial time algorithms do not exist for even epsilon trending towards 0 are very interesting , and show a pretty surprising",
    "NOVELTY"
  ],
  [
    "The formulation of the prototypes and additional learning objectives for UDA are clear and seem novel",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "Establish new time complexity ( to my knowledge ) of general neural-nets .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution is indeed novel and is based on the weak version of Szemer\u00c3\u00a9di\u00e2\u0080\u0099s regularity lemma .",
    "NOVELTY"
  ],
  [
    "Summary .I believe that the algorithm is novel and the theoretical expositions interesting",
    "NOVELTY"
  ],
  [
    "None of these three components is new",
    "NOVELTY"
  ],
  [
    "it is a nice paper with incremental contributions on every dimension the authors claimed",
    "NOVELTY"
  ],
  [
    "It 's not a completely new algorithm",
    "NOVELTY"
  ],
  [
    "are perhaps not entirely surprising , they are novel to me and shed light both on what we can expect of SVGD inference schemes , and more importantly , how to design the features used so that good approximations are obtained on the desired test functions",
    "NOVELTY"
  ],
  [
    "I think this paper is a valuable addition to the body of work on SVGD",
    "NOVELTY"
  ],
  [
    "and its contributions are not clear to me",
    "NOVELTY"
  ],
  [
    "The base idea that divides the learned features into two sets ; the reliable feature set and the less reliable one is very interesting and looks novel .",
    "NOVELTY"
  ],
  [
    "I think this paper is above the standard of ICLR because the idea is interesting and novel",
    "NOVELTY"
  ],
  [
    "this paper proposes a new",
    "NOVELTY"
  ],
  [
    "Figure 1a is not much insightful",
    "NOVELTY"
  ],
  [
    "While the formulation lacks substantial novelty",
    "NOVELTY"
  ],
  [
    "But the novelty is limited .",
    "NOVELTY"
  ],
  [
    "Thus , the novelty is incremental .",
    "NOVELTY"
  ],
  [
    "The idea to use linguistic knowledge in the design of sentence embeddings is attractive .",
    "NOVELTY"
  ],
  [
    "This idea seems promising and provides an interesting methodological development for recommender systems .",
    "NOVELTY"
  ],
  [
    "I find the idea quite interesting",
    "NOVELTY"
  ],
  [
    "I had overlooked the contributions of reconstruction of the topics",
    "NOVELTY"
  ],
  [
    "the use of spherical maps for representing shapes and having a network to inpaint the hidden parts is interesting",
    "NOVELTY"
  ],
  [
    "In the weaknesses , the novelty in terms of network architecture seems limited as the method is using a sequence of standard blocks/losses .",
    "NOVELTY"
  ],
  [
    "The work is more than moderately original .",
    "NOVELTY"
  ],
  [
    "Using stochastic gradient over logistic random variable to avoid the expectation operation in the gradient is a cute idea .",
    "NOVELTY"
  ],
  [
    "The main issue of the paper is lack of technical contributions .",
    "NOVELTY"
  ],
  [
    "Technically , there is nothing new here .",
    "NOVELTY"
  ],
  [
    "I like the idea of hindsight modeling a lot",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is a new quality of result that was achieved",
    "NOVELTY"
  ],
  [
    "There is a incremental nature to the paper",
    "NOVELTY"
  ],
  [
    "Since the technical contribution is limited",
    "NOVELTY"
  ],
  [
    "The paper is quite original and the new assumption on the noise model of SGD leads to a new continuous time limit SDE for the dynamic of SGD under which the exit time properties are fairly different ( polynomial time versus usual exponential time ) .",
    "NOVELTY"
  ],
  [
    "in that many of the results are quite incremental with respect to previous observations in the field .",
    "NOVELTY"
  ],
  [
    "it does not provide pure machine learning contributions in the form of new techniques of generally applicable insights",
    "NOVELTY"
  ],
  [
    "I do like the idea of combining static and dynamic pruning",
    "NOVELTY"
  ],
  [
    "The method of initializing LMN using a linear RNN is natural and simple .",
    "NOVELTY"
  ],
  [
    "Moreover , the proposed approach is fairly incremental , compared to existing work on RWS , VIMCO , etc .",
    "NOVELTY"
  ],
  [
    "the current submission is incomplete",
    "NOVELTY"
  ],
  [
    "and I love this kind of paper ; with a simple idea , making a huge impact on the field",
    "NOVELTY"
  ],
  [
    "This seems to be the most important contribution of this paper , of which I don \u2019 t understand",
    "NOVELTY"
  ],
  [
    "yet",
    "NOVELTY"
  ],
  [
    "I believe that this work is a nice addition to the existing literature on Stein discrepancies and goodness-of-fit testing .",
    "NOVELTY"
  ],
  [
    "The architecture presented is a natural and important extension of",
    "NOVELTY"
  ],
  [
    "the proposed edge-exchangeability is an application of the de Finetti 's theorem to an exchangeable sequence conditioned on W , which is not novel",
    "NOVELTY"
  ],
  [
    "This is an observation made upon through exploratory analysis and is not a technical novelty .",
    "NOVELTY"
  ],
  [
    "The paper lack technical novelty .",
    "NOVELTY"
  ],
  [
    "The inverse saliency map idea is already proposed in",
    "NOVELTY"
  ],
  [
    "There are contributions but I would not term them as significant .",
    "NOVELTY"
  ],
  [
    "the methodological contribution is rather straightforward",
    "NOVELTY"
  ],
  [
    "Originality To my knowledge the idea of using the Monge-Ampere equation for continuous normalizing flows is new .",
    "NOVELTY"
  ],
  [
    "The technical contribution is strong .",
    "NOVELTY"
  ],
  [
    "The construction and use of the super-graph structure to model relations between graph classes is interesting and novel to me",
    "NOVELTY"
  ],
  [
    "The architecture itself , which combines GINs and GATs , is also novel to me",
    "NOVELTY"
  ],
  [
    "The approach is interesting",
    "NOVELTY"
  ],
  [
    "They present a novel model that seems",
    "NOVELTY"
  ],
  [
    "I like the idea a lot .",
    "NOVELTY"
  ],
  [
    "I like this idea",
    "NOVELTY"
  ],
  [
    "This work appears to be a novel application of ABC to the problem of vesicle release modelling",
    "NOVELTY"
  ],
  [
    "Technically speaking , the proposed self-supervised scheme with two conv nets is very interesting .",
    "NOVELTY"
  ],
  [
    "interesting self-supervised framework provided for highlighting relevant substructures for a given prediction task",
    "NOVELTY"
  ],
  [
    "The novelties are n't very well-justified",
    "NOVELTY"
  ],
  [
    "I think the proposed approach , using spherical latent space , is interesting",
    "NOVELTY"
  ],
  [
    "The paper is not so novel .",
    "NOVELTY"
  ],
  [
    "The work advances the state of the art on differentially-private deep learning ,",
    "NOVELTY"
  ],
  [
    "The results seem novel and interesting .",
    "NOVELTY"
  ],
  [
    "The lower bound seems to be new for the considered class of problems and stochastic algorithms .",
    "NOVELTY"
  ],
  [
    "and the novelty of NBP is not clearly claimed",
    "NOVELTY"
  ],
  [
    "I believe that the idea and approach of the paper are interesting and contribute to the multiagent learning literature .",
    "NOVELTY"
  ],
  [
    "the novelty is rather limited . The first method seems to be slightly more novel , although it is unclear whether the contribution by combining different models",
    "NOVELTY"
  ],
  [
    "All in all , the paper has some interesting ideas .",
    "NOVELTY"
  ],
  [
    "this particular semi-ring variant of belief propagation has not been investigated before",
    "NOVELTY"
  ],
  [
    "But the novelty of the algorithm is relatively limited .",
    "NOVELTY"
  ],
  [
    "The MCU target is new for architecture search .",
    "NOVELTY"
  ],
  [
    "However , the constrained search problem is not new to architecture search researchers .",
    "NOVELTY"
  ],
  [
    "This work definitely advances the state of the art for MCUs .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "but the novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the idea is novel , although I am not completely sure",
    "NOVELTY"
  ],
  [
    "I think that it is interesting to think more carefully about how sparse reward states and state similarities can be used more efficiently but the ideas in the paper are not original or theoretically founded enough to have a lot of impact without the company of stronger empirical results",
    "NOVELTY"
  ],
  [
    "I find the theorem in the paper quite interesting",
    "NOVELTY"
  ],
  [
    "This Lemma appears to be quite novel to me .",
    "NOVELTY"
  ],
  [
    "Clearly the methods employed are , by themselves , not novel and have been used for a range of other ML problem formulations .",
    "NOVELTY"
  ],
  [
    "Though the PushSum idea is n't new",
    "NOVELTY"
  ],
  [
    "The idea of learning word-embeddings in hyperbolic space with the proposed approach is novel and relevant .",
    "NOVELTY"
  ],
  [
    "Overall I find the idea appealing .",
    "NOVELTY"
  ],
  [
    "As far as I know , this approach to meta-learning in the context of deep-RL is novel .",
    "NOVELTY"
  ],
  [
    ", I think the originality of the approach is significant and could spark further work on learning parameterised loss functions .",
    "NOVELTY"
  ],
  [
    "The contribution from the RL perspective is limited",
    "NOVELTY"
  ],
  [
    "The method is not very novel , especially given",
    "NOVELTY"
  ],
  [
    "but it does introduce some nice new ideas",
    "NOVELTY"
  ],
  [
    "the proposed method seems to work Weakness",
    "NOVELTY"
  ],
  [
    "the novelty of the proposed method seems to be very marginal",
    "NOVELTY"
  ],
  [
    "multiple sets of neighborhoods must be sampled for each node",
    "NOVELTY"
  ],
  [
    "This is the first work that studies probability calibration for knowledge graph embedding models .",
    "NOVELTY"
  ],
  [
    "NOVELTY Thresholding gradients to induce sparsity and improve efficiency in RNN training is a novel result to my knowledge .",
    "NOVELTY"
  ],
  [
    "SUMMARY The",
    "NOVELTY"
  ],
  [
    "bit incremental",
    "NOVELTY"
  ],
  [
    "A new dataset for evaluating learning causal arrows ( with accessible ground-truths ) . I think these are interesting contributions .",
    "NOVELTY"
  ],
  [
    "interesting contribution",
    "NOVELTY"
  ],
  [
    "The use of LSTM for prediction is not really new .",
    "NOVELTY"
  ],
  [
    "The technical novelty is on the low end .",
    "NOVELTY"
  ],
  [
    "but I feel it does not make a significant contribution to the state of knowledge in machine learning .",
    "NOVELTY"
  ],
  [
    "The idea is interesting and the performance of the proposed method seem to be capable of finding adversarial examples with smaller distortions and less queries compared with other hard-label attack algorithms",
    "NOVELTY"
  ],
  [
    "I believe that the article presents the synthesis of notions introduced in two very distinct research areas , and introduces an interesting line of research for future enquiry .",
    "NOVELTY"
  ],
  [
    ".The novelty of the proposed approach is limited .",
    "NOVELTY"
  ],
  [
    "though it is a trivial extension of a previous method .",
    "NOVELTY"
  ],
  [
    "The proposed idea is interesting .",
    "NOVELTY"
  ],
  [
    "The use of movement in this state embedding as an intrinsic reward is importantly novel and valuable .",
    "NOVELTY"
  ],
  [
    "SUMMARY I believe the manuscript is definitely interesting and has a",
    "NOVELTY"
  ],
  [
    "Lack of novelty .",
    "NOVELTY"
  ],
  [
    "It is not new to use batch normalization in CNNs for object / pedestrian detection .",
    "NOVELTY"
  ],
  [
    "the contribution of this paper is minor .",
    "NOVELTY"
  ],
  [
    "While the general method doesn \u2019 t appear to be particularly novel",
    "NOVELTY"
  ],
  [
    "but this paper lacks novelty in general",
    "NOVELTY"
  ],
  [
    "In my opinion , the novelty of the proposed approach is not high and the improvements are incremental .",
    "NOVELTY"
  ],
  [
    "but to me , it seems these ideas are not new and have been proposed before [ 1,2,3,4 ] . I could not find a strong contribution of this paper .",
    "NOVELTY"
  ],
  [
    "This is not novel enough to serve as a contribution .",
    "NOVELTY"
  ],
  [
    "The observation that typical real-world datasets are concentrated on a lower-dimensional manifold is not novel",
    "NOVELTY"
  ],
  [
    "The other observation that in real-world learning tasks one rarely encounters plateaux is not novel either .",
    "NOVELTY"
  ],
  [
    "I would judge possible contributions of this paper rather weak , so that I would not be able to recommend acceptance of this paper .",
    "NOVELTY"
  ],
  [
    "This work contains interesting derivations and a different parameterization , with enough contributions to potentially be interesting in its own right .",
    "NOVELTY"
  ],
  [
    "The potential function and the resulting gradient flow parameterization is interesting .",
    "NOVELTY"
  ],
  [
    "-The originality of this paper is good , which gives the definition of \u00e2\u0080\u009ctiny cluster\u00e2\u0080\u009d and points out the importance of clustering these tiny clusters .",
    "NOVELTY"
  ],
  [
    "Overall , the idea of object relation is interesting .",
    "NOVELTY"
  ],
  [
    "However , the proposed method is incremental from Relation Network ( Learning2Compare Sun te al .2017 ) and",
    "NOVELTY"
  ],
  [
    "Interesting idea to improve the performance of few-shot learning .",
    "NOVELTY"
  ],
  [
    "when actually the idea of having the V-function depending on a slowly changing network is also not novel in RL",
    "NOVELTY"
  ],
  [
    "Even though the novelty is not great",
    "NOVELTY"
  ],
  [
    "A novel technique to minimize the normalized cut for this problem .",
    "NOVELTY"
  ],
  [
    "the paper presents an approach to OPE that is a departure from classic approaches . As far as I am aware this is a very novel way to address this issue Clarity",
    "NOVELTY"
  ],
  [
    "It 's an interesting and novel paper which makes a new link between two previously unconnected areas and I think it could inspire more new thinking between them",
    "NOVELTY"
  ],
  [
    "Thus the novelty of the proposed method is limited .",
    "NOVELTY"
  ],
  [
    "Their randomized CD algorithm is novel , as they",
    "NOVELTY"
  ],
  [
    "I think the paper is interesting",
    "NOVELTY"
  ],
  [
    "This paper gives an interesting idea for the pruning techniques . I think the idea is novel .",
    "NOVELTY"
  ],
  [
    "while the novelty of the paper is not exceptional",
    "NOVELTY"
  ],
  [
    "Originality== The work is original .",
    "NOVELTY"
  ],
  [
    "The originality of the method stems from the combination of a number of known reasonable techniques",
    "NOVELTY"
  ],
  [
    "The proposed idea is novel and interesting .",
    "NOVELTY"
  ],
  [
    "The algorithm seems a significant improvement on prior works",
    "NOVELTY"
  ],
  [
    "and provides an interesting combination of reinforcement learning with imagined goals ( RIG ) and entropy maximization .",
    "NOVELTY"
  ],
  [
    "the work is too incremental 2",
    "NOVELTY"
  ],
  [
    "I also believe that the proposed method is quite intuitive , and is a good addition to the field",
    "NOVELTY"
  ],
  [
    "I find that this paper makes only incremental forward progress from the Pang 2018 paper and the Konyushkova 2017 paper . The methodology here looks very similar to the SingleRL method ,",
    "NOVELTY"
  ],
  [
    "I believe the task , and the setup created by the authors is very interesting and novel , and",
    "NOVELTY"
  ],
  [
    "I still think this is a very interesting contribution .",
    "NOVELTY"
  ],
  [
    "the solution put forward in the paper strikes us as a curious but a hardly useful toy",
    "NOVELTY"
  ],
  [
    "My main concern is that the practical contribution on top of Liu et al . ( 2017 ) might be somewhat limited .",
    "NOVELTY"
  ],
  [
    "Overall , I think the paper presents a really nice idea of how to improve modeling of agents .",
    "NOVELTY"
  ],
  [
    "This work sounds novel to me from a reinforcement learning perspective",
    "NOVELTY"
  ],
  [
    "The idea of learning compositional representations inside of a VAE framework is very appealing .",
    "NOVELTY"
  ],
  [
    "However , the novelty of this algorithm is not strong , given that the similar idea of 'predicting the behavior of other agents ' can be found in related work with discrete action spaces",
    "NOVELTY"
  ],
  [
    "The novelty of this approach is not strong .",
    "NOVELTY"
  ],
  [
    "Although it is not a",
    "NOVELTY"
  ],
  [
    "I have seen several papers fusing EBMs and GAN training together and to the best of my knowledge section 4 is novel (",
    "NOVELTY"
  ],
  [
    "The idea of estimating of the entropy term for the implicit distribution p_G with adversarial mutual information estimation is something new ,",
    "NOVELTY"
  ],
  [
    "although quite straight-forward",
    "NOVELTY"
  ],
  [
    "My main concern is about the technical novelty of the paper .",
    "NOVELTY"
  ],
  [
    "Originality The method appears to be novel and the approach is well embedded into the related",
    "NOVELTY"
  ],
  [
    "The algorithmic and theoretical extension from [ Chen 2014 ] is non-trivial",
    "NOVELTY"
  ],
  [
    "Although the proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "is a very interesting finding .",
    "NOVELTY"
  ],
  [
    "Therefore , the key idea in this paper is not new to Bayesian nonparametric community .",
    "NOVELTY"
  ],
  [
    "I think that 's a very clever way to approach the problem of combining control variates",
    "NOVELTY"
  ],
  [
    "I think this paper presents an interesting idea , and points to a way to use a bunch of existing estimators to get the most out of a stochastic optimization procedure .",
    "NOVELTY"
  ],
  [
    "The regularization and running average of the control variate parameter is an interesting extension",
    "NOVELTY"
  ],
  [
    "It seems that the proposed model is the first deep learning model for graph sequence prediction .",
    "NOVELTY"
  ],
  [
    "These are practical but perhaps simple / incremental ideas",
    "NOVELTY"
  ],
  [
    "Perhaps the greatest argument against the paper could be that the results are only incremental on the ResNet and ReLU results in the literature .",
    "NOVELTY"
  ],
  [
    "Cons The contributions seem incremental , not properly enunciated , or",
    "NOVELTY"
  ],
  [
    "c ) A novel reconstruction DNN as a component of the above pipeline . ( d ) A novel detection network as a component of the above pipeline .",
    "NOVELTY"
  ],
  [
    "this clearly is not the main contribution of the paper .",
    "NOVELTY"
  ],
  [
    "there is nothing particularly novel about the detection network nor the way it is used .",
    "NOVELTY"
  ],
  [
    "The proposed approach to solve this problem may indeed by novel",
    "NOVELTY"
  ],
  [
    "the contributions seem incremental ,",
    "NOVELTY"
  ],
  [
    "The top-K implementation is interesting .",
    "NOVELTY"
  ],
  [
    "I found the case considered here of modest interest",
    "NOVELTY"
  ],
  [
    "Overall I think the idea is new and useful",
    "NOVELTY"
  ],
  [
    "The propositions presented in the paper are quite standard results derived from the original GAN paper , so for that part the contribution is incremental and less interesting .",
    "NOVELTY"
  ],
  [
    "the proposed idea is new",
    "NOVELTY"
  ],
  [
    "but straight-forward",
    "NOVELTY"
  ],
  [
    "The idea of the paper is interesting , which mimic the human 's behavior .",
    "NOVELTY"
  ],
  [
    "The proposed framework is novel and based on the Riemannian Geometry",
    "NOVELTY"
  ],
  [
    "the novelty and contribution is relatively low .",
    "NOVELTY"
  ],
  [
    "The ideas presented in",
    "NOVELTY"
  ],
  [
    "The combination of continuous flows and graph structured data is new in the literature ( as far as I know ) .",
    "NOVELTY"
  ],
  [
    "The way of incorporating relational structure into flows are very similar to the GraphNVP and Graph Normalizing Flow : using neighboring nodes \u2019 hidden vectors as parameters ( or input to parameter inference networks ) .",
    "NOVELTY"
  ],
  [
    "I think technical contribution of this paper is somewhat limited .",
    "NOVELTY"
  ],
  [
    "But at the same time , technological advancement is limited .",
    "NOVELTY"
  ],
  [
    "The ideas and the presented results are interesting and are clearly of interest to the deep learning",
    "NOVELTY"
  ],
  [
    "The approach builds upon prior work with the same general thrust",
    "NOVELTY"
  ],
  [
    "The proposal of learning with a probabilistic memory is interesting",
    "NOVELTY"
  ],
  [
    "The model appears novel and is interesting",
    "NOVELTY"
  ],
  [
    "* The combination of compressed sensing and GANs for image reconstruction is novel Cons",
    "NOVELTY"
  ],
  [
    "The idea of multi-stage communication is great",
    "NOVELTY"
  ],
  [
    "The key idea of using Bi-LSTM to compute global context for attention is actually not novel ,",
    "NOVELTY"
  ],
  [
    "however it is not clear what the main contribution of the paper is as the authors fail to",
    "NOVELTY"
  ],
  [
    "The contribution is very interesting and original enough .",
    "NOVELTY"
  ],
  [
    "it would be nice to acknowledge that the idea is not totally new",
    "NOVELTY"
  ],
  [
    "high - both with respect to presentation of the facts and the method Quality",
    "NOVELTY"
  ],
  [
    "The tasks or methods are not new exactly ,",
    "NOVELTY"
  ],
  [
    "but",
    "NOVELTY"
  ],
  [
    "they are new as applied to fMRI",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , this is the first work to propose or at least to carefully analyze the properties of sending only approximate Newton directions .",
    "NOVELTY"
  ],
  [
    "The main downside of this paper is uses a lot of previously known results in a rather straightforward manner to achieve this .",
    "NOVELTY"
  ],
  [
    "=Quality= The authors seem to be experts in their field .",
    "NOVELTY"
  ],
  [
    "=Originality= This is an interesting problem that will be novel to most member of the ICLR community .",
    "NOVELTY"
  ],
  [
    "The paper provides a novel insight on the effect of pruning at the class and the example level , which could lead to a more effective pruning approach that exploit this findings .",
    "NOVELTY"
  ],
  [
    "The paper only provides a novel finding but not the solution on how to tackle this problem , and thus the paper looks incomplete",
    "NOVELTY"
  ],
  [
    "the paper provides a novel insight on how pruning affects the",
    "NOVELTY"
  ],
  [
    "The contribution seems to be novel and significant .",
    "NOVELTY"
  ],
  [
    "1 .The idea of adding temporal dynamics in the latent user intent is fairly natural given the flexible model setup in ExpoMF .",
    "NOVELTY"
  ],
  [
    "I find the exponential family view on the Bayesian coreset construction quite interesting .",
    "NOVELTY"
  ],
  [
    "The proposed method is an interesting contribution and provides new insights on the construction of Bayesian coresets .",
    "NOVELTY"
  ],
  [
    "Overall I find the goal to be interesting and novel .",
    "NOVELTY"
  ],
  [
    "1 .The idea of weighting different pairs is not new and can be found in [ 1",
    "NOVELTY"
  ],
  [
    "Not very novel ( compared to [ 47 ] ) and just a mild variation over [ 47 ] including the analysis",
    "NOVELTY"
  ],
  [
    "This is an nice extension of current mixture models where samples are usually considered as independent .",
    "NOVELTY"
  ],
  [
    "As much as I love the ideas behind the paper",
    "NOVELTY"
  ],
  [
    "Overall , I like the ideas behind this paper very much .",
    "NOVELTY"
  ],
  [
    "These results are substantially novel .",
    "NOVELTY"
  ],
  [
    "The idea of training on data from varying quartiles , with the goal of preventing overly-conservative models , is quite intriguing and inspiring .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm looks promising and interesting .",
    "NOVELTY"
  ],
  [
    "Overall , the paper is well-written and I think the algorithm is novel .",
    "NOVELTY"
  ],
  [
    "The proposed adaptive weight generation module could be considered new .",
    "NOVELTY"
  ],
  [
    "Although attention-based encoding of image sets is not new",
    "NOVELTY"
  ],
  [
    "The novelties of the approach are the problem setting ( no access to optimal policies , immediate deployment at test-time ) , the joint training of a probing policy and VAE model , and a universal policy conditioned on the estimated hidden parameters .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is promising and attempts to directly address limitations in previous literature",
    "NOVELTY"
  ],
  [
    "The approach is closely related to existing methods , most prominently SAGA .",
    "NOVELTY"
  ],
  [
    "It is obvious that there is a strong connection between PCA and linear regression",
    "NOVELTY"
  ],
  [
    "thus the originality of the general idea is limited .",
    "NOVELTY"
  ],
  [
    "I think idea in the paper is potentially interesting",
    "NOVELTY"
  ],
  [
    "If not , it should not be regarded as a novel contribution of this paper",
    "NOVELTY"
  ],
  [
    "but without a practical upside to the work it remains a novelty",
    "NOVELTY"
  ],
  [
    "The choice of the architecture is interesting .",
    "NOVELTY"
  ],
  [
    "The idea of predicting video using state-space models is interesting and promising .",
    "NOVELTY"
  ],
  [
    "the paper overstates its novelty and falls short of showing the advantages of the method beyond incremental improvements on frame-wise image quality metrics",
    "NOVELTY"
  ],
  [
    "The idea to use fully latent models for video prediction , to untie frame synthesis and dynamics , is not new and the paper does not fully cite this literature",
    "NOVELTY"
  ],
  [
    "Proposes a novel ( to my knowledge ) exploration method for RL which intuitively seems like it should work better than \\epsilon-greedy exploration",
    "NOVELTY"
  ],
  [
    "the paper proposes a novel yet relatively simple and intuitive approach with strong empirical performance gains over comparable",
    "NOVELTY"
  ],
  [
    "The paper introduces a novel notion of fairness .",
    "NOVELTY"
  ],
  [
    "nontrivial",
    "NOVELTY"
  ],
  [
    "the authors present , what I believe to be an elegant ,",
    "NOVELTY"
  ],
  [
    "I found the additional extensions presented in the appendix to be interesting ideas as well",
    "NOVELTY"
  ],
  [
    "This approach of finite rate of innovation solutions to impulse estimation has recently been applied to other problems , but as far as I can tell has not been applied to impulse response estimation before .",
    "NOVELTY"
  ],
  [
    "The proposed approach addresses a difficult task in a better way than previous work , thus advancing the state-of-the-art in a demonstrable way .",
    "NOVELTY"
  ],
  [
    "ORIGINALITY The CEB method is an original ( but minor ) modification of a well known method .",
    "NOVELTY"
  ],
  [
    "and the ideas are not much novel",
    "NOVELTY"
  ],
  [
    "Further from experimental improvements , the paper introduces new insights in terms of utilizing barycentric mappings , along with a novel method that accommodates out-of-sample data .",
    "NOVELTY"
  ],
  [
    "and introduces an interesting application of the Neural ODE . The approach of embedding the Neural ODE within other approaches is particularly appealing and seems like a strong way of encoding inductive bias into the model .",
    "NOVELTY"
  ],
  [
    "While the idea to use an ensemble of deep neural networks to estimate their uncertainty is not new",
    "NOVELTY"
  ],
  [
    "As far as I can tell , none of the fundamental ideas are new .",
    "NOVELTY"
  ],
  [
    "However , they are combined in an interesting , novel way that shows significant performance improvements .",
    "NOVELTY"
  ],
  [
    "The paper is",
    "NOVELTY"
  ],
  [
    "The paper addresses a novel problem which is inherent in the wildly used word embedding model .",
    "NOVELTY"
  ],
  [
    "Although the idea is quite novel",
    "NOVELTY"
  ],
  [
    ", the technical contributions in this work are limited .",
    "NOVELTY"
  ],
  [
    "although I am not fully convinced by the great novelty of the presented work , as the proposals appear to me as rather straightforward applications of DRQN to the setting of multi-agents .",
    "NOVELTY"
  ],
  [
    "I enjoyed reading this paper .",
    "NOVELTY"
  ],
  [
    "Some part of the analysis also provides some novel techniques that may be independently useful for other purpose",
    "NOVELTY"
  ],
  [
    "The proposed randomized algorithm is natural and somewhat unsurprising",
    "NOVELTY"
  ],
  [
    "The strength of this paper is that 1 ) the proposed method is new in the sense that it invents an automatic way for exploration .",
    "NOVELTY"
  ],
  [
    "the SRU is a superbly elegant architecture with a fair bit of originality in its structure",
    "NOVELTY"
  ],
  [
    "the novelty of this paper is limited since it only combines SARAH estimator with SGD .",
    "NOVELTY"
  ],
  [
    "The proposed algorithm and analyses within the submission are variants of work done in the area in a new combination",
    "NOVELTY"
  ],
  [
    "the work is not groundbreaking in terms of its novelty .",
    "NOVELTY"
  ],
  [
    "Although the novelty of the submission is n't groundbreaking",
    "NOVELTY"
  ],
  [
    "The authors put together interesting current ideas together in a manner that is new and seems to",
    "NOVELTY"
  ],
  [
    "given that I do not know whether the claim of originality is true",
    "NOVELTY"
  ],
  [
    "then the work is a significant and interesting advance",
    "NOVELTY"
  ],
  [
    "Though the contribution is quite limited",
    "NOVELTY"
  ],
  [
    "The rest of the results appear to expand on other results that have already appeared in the literature and the authors",
    "NOVELTY"
  ],
  [
    "The proposed model is simple but also novel .",
    "NOVELTY"
  ],
  [
    "it seems novel to use a product-of-experts inference network to do the posterior inference of latent variables .",
    "NOVELTY"
  ],
  [
    "the proposed sub-sampled training paradigm is also intuitive and interesting",
    "NOVELTY"
  ],
  [
    "I think the paper proposes a nice approach",
    "NOVELTY"
  ],
  [
    "instead of only two .",
    "NOVELTY"
  ],
  [
    "this work has some novelty inside , and",
    "NOVELTY"
  ],
  [
    "and that this is not a contribution of this paper",
    "NOVELTY"
  ],
  [
    "feels a bit disingenious",
    "NOVELTY"
  ],
  [
    "this paper appears very interesting",
    "NOVELTY"
  ],
  [
    "The linear approximation with respect to input parameter space is also interesting",
    "NOVELTY"
  ],
  [
    "However there is no significant and concrete novel insight that could be derived from these connections .",
    "NOVELTY"
  ],
  [
    "Therefore , the paper does not really advance our understanding of GNN .",
    "NOVELTY"
  ],
  [
    "My main concern is that some of the contributions claimed were already shown in previous work",
    "NOVELTY"
  ],
  [
    ", and the novelty feels a bit limited .",
    "NOVELTY"
  ],
  [
    "Ensembling on unlabeled data for robustness does seem novel to me",
    "NOVELTY"
  ],
  [
    "The idea to use sampling is nice",
    "NOVELTY"
  ],
  [
    "The claimed contributions are also appealing",
    "NOVELTY"
  ],
  [
    "The development of the paper is a bit disappointing since the above contributions",
    "NOVELTY"
  ],
  [
    "The approach is interesting",
    "NOVELTY"
  ],
  [
    "The idea is quite novel .",
    "NOVELTY"
  ],
  [
    "Significance The work presented in this paper appears to be sufficiently novel within the context of GP optimization .",
    "NOVELTY"
  ],
  [
    "This paper is indeed not the first to consider robust optimisation",
    "NOVELTY"
  ],
  [
    "and the main idea is simple and elegant",
    "NOVELTY"
  ],
  [
    "Although the approach does not seem to improve significantly , if at all , over Sobolev training of these modules",
    "NOVELTY"
  ],
  [
    "The idea proposed in this paper is interesting",
    "NOVELTY"
  ],
  [
    "The multi-scale point feature encoder is novel .",
    "NOVELTY"
  ],
  [
    "I do not understand the contribution of the batched modular meta-learning section",
    "NOVELTY"
  ],
  [
    "This work is a natural follow up on previous work that used group lasso for CNNs",
    "NOVELTY"
  ],
  [
    "Not very original ,",
    "NOVELTY"
  ],
  [
    "I like the idea of adaptive sampling in MRI",
    "NOVELTY"
  ],
  [
    ".Making the methodological contribution to be rather limited",
    "NOVELTY"
  ],
  [
    "However , this is a small modification of FastGCN since for a mini-batch training",
    "NOVELTY"
  ],
  [
    "this is just a trick in the coding implementation of FastGCN in terms of this point claimed by the authors , and can not be considered as a novel improvement in the level of NeurIPS although you have conducted the corresponding experiments",
    "NOVELTY"
  ],
  [
    "I do n't really see the novelty of your work",
    "NOVELTY"
  ],
  [
    "but nearly all of this work seems to be rather dated",
    "NOVELTY"
  ],
  [
    "As this paper looks to me as an simple application of an existing approach in literature to a real-world problem , novelty is the main concern here .",
    "NOVELTY"
  ],
  [
    "I generally like this article , as it contains a neat solution to a common problem that builds on and extends prior work .",
    "NOVELTY"
  ],
  [
    "the true contributions of the paper are somewhat muddied by presenting CRL as more general than what is actually supported by the experiments",
    "NOVELTY"
  ],
  [
    "mostly because the core method is novel , clearly explained ,",
    "NOVELTY"
  ],
  [
    "Overall , this paper could be a great contribution for the",
    "NOVELTY"
  ],
  [
    "Originality The paper builds on a large corpus of previous research , but",
    "NOVELTY"
  ],
  [
    "the novelties are clearly outlined in section 3 .",
    "NOVELTY"
  ],
  [
    "the presented method is very far from my own field of research",
    "NOVELTY"
  ],
  [
    "It provides an elegant and novel approach to combine planning and learning in a single end-to-end neural network system .",
    "NOVELTY"
  ],
  [
    "The paper has an interesting idea at the core .",
    "NOVELTY"
  ],
  [
    "there are arguably no revolutionary ideas",
    "NOVELTY"
  ],
  [
    "Despite the claim , the novelty of the paper is limited .",
    "NOVELTY"
  ],
  [
    "and this work proposes nice ideas towards its solution",
    "NOVELTY"
  ],
  [
    "The idea of reducing meta-rl to a task identification problem is not completely novel since some recent works have been proposed in this direction ( see later ) .",
    "NOVELTY"
  ],
  [
    "the proposed approach is interesting",
    "NOVELTY"
  ],
  [
    "The novelty may not be enough .",
    "NOVELTY"
  ],
  [
    "Novelty : Their usage of context early in the network seems novel .",
    "NOVELTY"
  ],
  [
    "I think the introduction of the tensor kernels for mutual information estimation is the key contribution of this paper .",
    "NOVELTY"
  ],
  [
    "However , I think this contribution is a little bit incremental , compared to the multivariate matrix-based version introduced by Yu et.al .",
    "NOVELTY"
  ],
  [
    "This approach does not capture the special structure of tensor and seems incremental .",
    "NOVELTY"
  ],
  [
    "So an incremental change on computing such a questionable phenomenon make the contribution of this paper not very strong .",
    "NOVELTY"
  ],
  [
    "This paper is very interesting .",
    "NOVELTY"
  ],
  [
    "This paper could open a novel area of temporal regularization that received inadequate attention before .",
    "NOVELTY"
  ],
  [
    "After reading the paper I am not convinced that there \u2019 s anything substantially new in this paper .",
    "NOVELTY"
  ],
  [
    "I am not convinced that the proposed formulation is any different than what is in Hindsight Experience Replay ( HER ) paper .",
    "NOVELTY"
  ],
  [
    "Unless the authors can convince me that the method is not equivalent to existing work I don \u2019 t see enough novelty or significance for an ICLR paper",
    "NOVELTY"
  ],
  [
    "The methods of the paper are inspiring .",
    "NOVELTY"
  ],
  [
    "There are some very interesting and strong contributions of this manuscript .",
    "NOVELTY"
  ],
  [
    "I am not sure that it adds a lot to the manuscript",
    "NOVELTY"
  ],
  [
    "The use of pointer network is interesting as it enables generalization to arbitrary input size .",
    "NOVELTY"
  ],
  [
    "It elegantly combines several ideas that have been recently been investigated in the literature , though not yet put together .",
    "NOVELTY"
  ],
  [
    "Other novelties include the introduction of wildcard denoising and beta-pooling which make a lot of sense and prevent the system from overfitting e.g",
    "NOVELTY"
  ],
  [
    "The idea of the paper is natural and interesting .",
    "NOVELTY"
  ],
  [
    "the paper contains nice ideas and experimental results are promising",
    "NOVELTY"
  ],
  [
    "presenting an interesting algorithm",
    "NOVELTY"
  ],
  [
    "The analysis is original to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "A nice paper with some interesting observations .",
    "NOVELTY"
  ],
  [
    "Its approach to fitting Bayesian neural networks with \\alpha divergence is interesting and appears novel in this context .",
    "NOVELTY"
  ],
  [
    "I think that the paper brings a valuable contribution to the literature .",
    "NOVELTY"
  ],
  [
    "2 .I am not convinced this method is sufficiently new , given that there are other methods that try to directly reward visiting new states .",
    "NOVELTY"
  ],
  [
    "From this viewpoint , the actor-critic component in Dreamer is an incremental contribution . Since the latent models are learned based on existing techniques , the paper presents an incremental contribution .",
    "NOVELTY"
  ],
  [
    "Though , I still think the contribution is incremental , since back-propagating gradients through values and dynamics has been studied in prior works (",
    "NOVELTY"
  ],
  [
    "This paper proposed a novel architecture to tackle the match prediction problem",
    "NOVELTY"
  ],
  [
    "2 .The proposed method to some extent is not that novel .",
    "NOVELTY"
  ],
  [
    "the idea of greedily guiding the agglomeration of",
    "NOVELTY"
  ],
  [
    "voxels by evaluating energies pretty much resembles many bottom-up graph-theoretic merging in early segmentation methods",
    "NOVELTY"
  ],
  [
    "The reviewer finds that the proposed method interesting .",
    "NOVELTY"
  ],
  [
    "The main originality of the work is to use the initial state as a key information about the features that translate many desired state of background objects in a scene",
    "NOVELTY"
  ],
  [
    "1 ) a novel problem of subtask graph execution .",
    "NOVELTY"
  ],
  [
    "The idea of using time series model for regularization is also interesting .",
    "NOVELTY"
  ],
  [
    "interesting ( and possibly",
    "NOVELTY"
  ],
  [
    "Sec 2 seems a bit long compared to the new insight presented in Sec 3",
    "NOVELTY"
  ],
  [
    "These techniques seem novel and widely applicable .",
    "NOVELTY"
  ],
  [
    "While the method based on sliced Wasserstein distances sounds new , the novelty seems limited since the idea of whitening the activation distribution to unit Gaussian was introduced before as mentioned by the authors",
    "NOVELTY"
  ],
  [
    "The application to adversarial training is somehow a novel selling point",
    "NOVELTY"
  ],
  [
    "1 .The computational-statistical tradeoff shown in this paper is novel , which seems a significant contribution to understanding the single index models .",
    "NOVELTY"
  ],
  [
    "The technical depth of the paper is shallow .",
    "NOVELTY"
  ],
  [
    "It does not represent a major breakthrough .",
    "NOVELTY"
  ],
  [
    "I have seen this before for SGD",
    "NOVELTY"
  ],
  [
    "the authors do not claim that the basic idea is novel )",
    "NOVELTY"
  ],
  [
    ", but I believe that the application to other algorithms",
    "NOVELTY"
  ],
  [
    "are novel",
    "NOVELTY"
  ],
  [
    "This appears to be a promising approach",
    "NOVELTY"
  ],
  [
    "the approach is original , gives improvements over strong baselines .",
    "NOVELTY"
  ],
  [
    "For several of the GBDT features , the approach chosen is unusual or perhaps outdated .",
    "NOVELTY"
  ],
  [
    "Besides , those extensions are not really novel .",
    "NOVELTY"
  ],
  [
    "The proposed group sparsity inducing priors are a natural extension of existing work interpreting Gaussian dropout as variational inference in BNNs .",
    "NOVELTY"
  ],
  [
    "these techniques themselves are very standard and hence come with limited technical novelty . * The proposed workflow seems to involve a nontrivial amount of additional hyperparameters",
    "NOVELTY"
  ],
  [
    "I find the idea of learning in environments with modular morphologies as well as the proposed tasks interesting .",
    "NOVELTY"
  ],
  [
    "despite potentially interesting ideas and",
    "NOVELTY"
  ],
  [
    "the authors propose a novel approach and include it in the evaluation",
    "NOVELTY"
  ],
  [
    "To my best knowledge , the idea of applying the meta-learning to the automatic generation of auxiliary tasks is novel .",
    "NOVELTY"
  ],
  [
    "In summary , the paper propose few applications to the original ( Weston et al , 2008 ) paper . It rebrands the algorithm under a new name , and does not bring any scientific novelty",
    "NOVELTY"
  ],
  [
    "The approach is new , the",
    "NOVELTY"
  ],
  [
    "Apart from that , this paper doesn \u2019 t have an obvious technical innovation that can inspire future work .",
    "NOVELTY"
  ],
  [
    "so the technical contribution of the proposed model is not too impressive",
    "NOVELTY"
  ],
  [
    "and the proposed innovation has been explored in various forms in other papers",
    "NOVELTY"
  ],
  [
    "the use of Levenshtein edit distance ( and more specifically , decomposing it with dynamic programming , and using it as the oracle policy ) is not new .",
    "NOVELTY"
  ],
  [
    "The ideas in the paper are sufficiently novel and is a good contribution to the community .",
    "NOVELTY"
  ],
  [
    "it is a novel and well-explained idea",
    "NOVELTY"
  ],
  [
    "I really like the intuition behind optimizing for the anchors via gradient descent",
    "NOVELTY"
  ],
  [
    "The contributions are clear",
    "NOVELTY"
  ],
  [
    "but as a standard application of attention lacks novelty .",
    "NOVELTY"
  ],
  [
    "the paper lacks novelty wrt technique , and as an \u201c application-of-attention \u201d paper fails to be even close to competitive with the state-of-the-art approaches on the problems being addressed .",
    "NOVELTY"
  ],
  [
    "but the actual execution perhaps is n't mature enough the way it has been presented",
    "NOVELTY"
  ],
  [
    "The procedure for generating SAT instances is original as far as the reviewer knows",
    "NOVELTY"
  ],
  [
    "this paper studies a very new problem , which is quite novel",
    "NOVELTY"
  ],
  [
    "2 .The proposed approach is quite intuitive .",
    "NOVELTY"
  ],
  [
    "The novelty of the proposed approach is limited .",
    "NOVELTY"
  ],
  [
    "although the proposed approach studies a new problem , the major idea is the same as the existing studies",
    "NOVELTY"
  ],
  [
    "this paper combines several existing ideas , but does not provide new insights or techniques , so the contribution is quite limited .",
    "NOVELTY"
  ],
  [
    "I like the idea of hyperparameters changing dynamically during the training which allows to explore a much larger space than one value \\\\",
    "NOVELTY"
  ],
  [
    "This is definitely a good contribution to the conference .",
    "NOVELTY"
  ],
  [
    "This is a minor contribution",
    "NOVELTY"
  ],
  [
    ", and the main result seems original and technically interesting .",
    "NOVELTY"
  ],
  [
    "But the novel work in the paper is limited to",
    "NOVELTY"
  ],
  [
    "I enjoyed reading the",
    "NOVELTY"
  ],
  [
    "and found them interesting for their own sake .",
    "NOVELTY"
  ],
  [
    "This work is original ; the idea of restricting to calibrated distributions and subsequently finding a condition to obtain properness is new AFAIK .",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is incremental .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is clear to me",
    "NOVELTY"
  ],
  [
    "The main idea of this paper is indeed novel and interesting .",
    "NOVELTY"
  ],
  [
    "1- While the idea introduced in this paper is novel for modern deep learning",
    "NOVELTY"
  ],
  [
    ", the general idea of sensitivity-based regularization for neural networks has been previously studied .",
    "NOVELTY"
  ],
  [
    "The high-level idea of guiding model capacity by rewarding high-entropy activations is interesting and novel to my knowledge",
    "NOVELTY"
  ],
  [
    "From a theoretical perspective , I see the main contribution of the paper as making this statement precise .",
    "NOVELTY"
  ],
  [
    "I feel that the paper does not contain enough novelty to justify acceptance .",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "and the method appears to be novel .",
    "NOVELTY"
  ],
  [
    "The combination is not necessarily original",
    "NOVELTY"
  ],
  [
    "but happens to bring substantial sample efficiency",
    "NOVELTY"
  ],
  [
    "However , the research contribution of the project is limited to image-space discrete RL tasks , and does not cover the wide-range other RL . In terms of the novelty , the proposed algorithm is not fundamentally different from Rainbow .",
    "NOVELTY"
  ],
  [
    "The main idea of the paper is build upon similar to a previous work by the same group of author",
    "NOVELTY"
  ],
  [
    "and the new model for joint optimization of transport and coupling looks promising",
    "NOVELTY"
  ],
  [
    "It is novel to find that simply combining 1-D conv with SRU substantially improves the quality of SRU",
    "NOVELTY"
  ],
  [
    "The contribution itself is novel and interesting",
    "NOVELTY"
  ],
  [
    "This last idea has been also used on prior work",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , this is the first autoencoder-based music translation method .",
    "NOVELTY"
  ],
  [
    "I think that the contributions in terms of methods are limited ,",
    "NOVELTY"
  ],
  [
    "but the results are",
    "NOVELTY"
  ],
  [
    "However , the paper introduces few new ideas and seems very much like applying an existing framework to new problems .",
    "NOVELTY"
  ],
  [
    "The specific contributions are not quite clear with respect to the existing literature",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "am not an expert in the area but the work seems to be sufficiently novel based on how the paper is situated in the related works .",
    "NOVELTY"
  ],
  [
    "opinion",
    "NOVELTY"
  ],
  [
    "The idea of universality that is independent of input distribution and dimension , depending only on the algorithm is an appealing one .",
    "NOVELTY"
  ],
  [
    "The work is a nice combination of existing works .",
    "NOVELTY"
  ],
  [
    "I like the idea of learning features imbued with the power to perform well on an inherently",
    "NOVELTY"
  ],
  [
    "The main ideas of the paper and the variational inference algorithm are very interesting",
    "NOVELTY"
  ],
  [
    "Overall the approach is interesting from the conceptual point of view",
    "NOVELTY"
  ],
  [
    "But I think the perspective on viewing k-way D-dim approach as product quantization ( which motivate the differentiable learning approach in the paper ) is very interesting .",
    "NOVELTY"
  ],
  [
    "For",
    "NOVELTY"
  ],
  [
    "who 's accustomed to using soft attention without thinking about an underlying graphical model , the paper was a very helpful new perspective",
    "NOVELTY"
  ],
  [
    "The techniques are not completely new",
    "NOVELTY"
  ],
  [
    "The technical contribution seems to be scattered",
    "NOVELTY"
  ],
  [
    "SSE [ Wu et al .2019 ] is existing technique and simply applying it to sequential recommendation is a bit incremental .",
    "NOVELTY"
  ],
  [
    "To summarize , the paper is a bit incremental/scattered in terms of technical contribution but the execution of this paper looks solid .",
    "NOVELTY"
  ],
  [
    "and contains some interesting ideas",
    "NOVELTY"
  ],
  [
    "To the best of the reviewer \u2019 s knowledge , the presented approach is novel for knowledge graph embeddings .",
    "NOVELTY"
  ],
  [
    "The architectures presented are simple and nascent providing pointers for other in further developing in neural network based Premise Selection in the ATP area .",
    "NOVELTY"
  ],
  [
    "The idea of this paper is definitely original .",
    "NOVELTY"
  ],
  [
    "the connection between state-triggered control and optimization design seems new and novel to me",
    "NOVELTY"
  ],
  [
    "Bridging state-triggered control with optimization design is a novel idea that may inspire further research . I think the conceptual novelty of this paper is high",
    "NOVELTY"
  ],
  [
    "although I",
    "NOVELTY"
  ],
  [
    "It is novel to consider the sparsity ( other than low-rankness ) of G . The theocratical results are novel too .",
    "NOVELTY"
  ],
  [
    "But the idea of side information has been studied by many others",
    "NOVELTY"
  ],
  [
    "Up to my knowledge , the idea of estimating the density ratio using kernels is novel .",
    "NOVELTY"
  ],
  [
    "The observation is original to me .",
    "NOVELTY"
  ],
  [
    "and this paper represents a strong advance in this direction",
    "NOVELTY"
  ],
  [
    "The author 's noise model as a superposition of positive sources and lower amplitude normal component is interesting and gives more statistical",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel evaluation scheme that is both fair",
    "NOVELTY"
  ],
  [
    "Overall , I find this paper provides a simple , novel significant method for evaluating GAN models and making better use of their latent space arithmetic editing capabilities .",
    "NOVELTY"
  ],
  [
    "I think it is an important first contribution in this domain",
    "NOVELTY"
  ],
  [
    "I maintain that while the approach is original and potentially interesting",
    "NOVELTY"
  ],
  [
    "to my knowledge , using copulas to solve the global multi-label problem has not been done before , hence the paper can be considered as original .",
    "NOVELTY"
  ],
  [
    "I very much like the approach .",
    "NOVELTY"
  ],
  [
    "This paper clearly presents an obviously good idea : making generative population models composable .",
    "NOVELTY"
  ],
  [
    "Contribution of the paper appears a bit incremental to me .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- OVERALL JUDGMENT The proposed model is simple but interesting .",
    "NOVELTY"
  ],
  [
    "the qualitative evaluation is insightful",
    "NOVELTY"
  ],
  [
    "The proposed algorithm is quite interesting and novel .",
    "NOVELTY"
  ],
  [
    "The adoption of bloom filter on large opaque ids has already been proposed in",
    "NOVELTY"
  ],
  [
    "The approach does seem novel",
    "NOVELTY"
  ],
  [
    "The problem being addressed is a nice twist on a classical combinatorial optimization problem",
    "NOVELTY"
  ],
  [
    ", there might be limited novelty beyond training a sequence to sequence model on pre-collected trajectories .",
    "NOVELTY"
  ],
  [
    "Nice idea for tackling the unbounded action space problem in text-based games .",
    "NOVELTY"
  ],
  [
    "Originality This paper presents a novel way of constructing variational distributions motivated by Sklar 's theorem .",
    "NOVELTY"
  ],
  [
    "but it is not exactly new",
    "NOVELTY"
  ],
  [
    "the resolution limitations suggest the overall contribution is rather incremental .",
    "NOVELTY"
  ],
  [
    "Although the main bounding strategy seems to be a promising idea",
    "NOVELTY"
  ],
  [
    "The main contributions of this paper are not quite clear to me .",
    "NOVELTY"
  ],
  [
    "but this paper also introduces new algorithm",
    "NOVELTY"
  ],
  [
    "Although the model is derived from [ 21 ] , it appears to be the first study that modify the model to address the VQA problem .",
    "NOVELTY"
  ],
  [
    "the paper seems to be closely related to [ 15 ] , where the same technique is used to prove a quite general result",
    "NOVELTY"
  ],
  [
    "think this paper is an interesting extension of probabilistic submodular models",
    "NOVELTY"
  ],
  [
    "Although each element for the development of the framework is not necessarily new",
    "NOVELTY"
  ],
  [
    "and weight sharing is also a commonly used strategy with other deep nets for domain adaptation , the novelty in this paper is moderate",
    "NOVELTY"
  ],
  [
    "I like the model and ideas",
    "NOVELTY"
  ],
  [
    "the model seems very interesting",
    "NOVELTY"
  ],
  [
    "The ideas for the upper and lower bound are also nice in my opinion .",
    "NOVELTY"
  ],
  [
    "and the proofs are interesting",
    "NOVELTY"
  ],
  [
    "I",
    "NOVELTY"
  ],
  [
    "am unfamiliar with prior work in this direction",
    "NOVELTY"
  ],
  [
    "but the idea of DKs seems to be conceptually appealing and as the authors point-out",
    "NOVELTY"
  ],
  [
    "but both conceptually and empirically it seems very close to deformable convolutions",
    "NOVELTY"
  ],
  [
    "Novel method ( as far as I can see",
    "NOVELTY"
  ],
  [
    "So there is nothing new for the community to benefit from",
    "NOVELTY"
  ],
  [
    "I do not think there is anything new in the paper and I vote for rejection",
    "NOVELTY"
  ],
  [
    "It is fair to say that this paper contains almost no novelty .",
    "NOVELTY"
  ],
  [
    "As far as I see it , the present paper introduces a novel approach to compute counting numbers , which could then be used e.g .in Theorem 9 of",
    "NOVELTY"
  ],
  [
    "the contribution and also the particular combination appears to be very interesting",
    "NOVELTY"
  ],
  [
    "see the novel contributions",
    "NOVELTY"
  ],
  [
    "I am not sure about the novelty of the method",
    "NOVELTY"
  ],
  [
    "3 .The relation between the proposed algorithm and the Weisfeiler-Lehman isomorphism test is very interesting and should be explained in more details",
    "NOVELTY"
  ],
  [
    "and at the same time , not significantly novel",
    "NOVELTY"
  ],
  [
    "To my knowledge the method proposed is novel",
    "NOVELTY"
  ],
  [
    "however using implicit posterior to learn the weights is not novel and several other works have looked at it .",
    "NOVELTY"
  ],
  [
    "The approach is interesting and shows promisze .",
    "NOVELTY"
  ],
  [
    "I personally like the main idea of the paper , which is to use previous results from approximating the Koopman operator and combining it with GNNs for more accurate physical modelling of object-object interactions .",
    "NOVELTY"
  ],
  [
    "The task is new to me . Adding noise for GAN training is not new . The guess discriminator seems new to me .",
    "NOVELTY"
  ],
  [
    "So it is hard to say if their method is much better than existing",
    "NOVELTY"
  ],
  [
    "I found the backward proposal network q_",
    "NOVELTY"
  ],
  [
    "to be interesting",
    "NOVELTY"
  ],
  [
    "with a fresh perspective",
    "NOVELTY"
  ],
  [
    "work-from-scratch mathiness that does n't really contribute insight or understanding",
    "NOVELTY"
  ],
  [
    "Pro o There is certainly originality of perspective .",
    "NOVELTY"
  ],
  [
    "Con o There is not really significant originality of method .",
    "NOVELTY"
  ],
  [
    "Overall , I think the ideas presented are interesting and",
    "NOVELTY"
  ],
  [
    "metric learning .",
    "NOVELTY"
  ],
  [
    "Summary I think this is an interesting proposal to combine the useful features of the softmax and triplet losses .",
    "NOVELTY"
  ],
  [
    "I think the contribution of the paper is not sufficient and I tend to reject the paper",
    "NOVELTY"
  ],
  [
    "The idea of precision highway , however , is quite similar to the skip connections used in Bi-Real Net .",
    "NOVELTY"
  ],
  [
    "I very much like the direction this paper",
    "NOVELTY"
  ],
  [
    "presents both a natural and interesting extension of previous work in this setting",
    "NOVELTY"
  ],
  [
    "however , the proposed method is of arguably low novelty .",
    "NOVELTY"
  ],
  [
    "One could argue that the novelty of this paper is incremental",
    "NOVELTY"
  ],
  [
    "The algorithm has a limited novelty with a simple modification of the DDPG algorithm to add the PER component .",
    "NOVELTY"
  ],
  [
    "Per se , the model is incrementally new",
    "NOVELTY"
  ],
  [
    "there is no other paper providing a large scale study of networks capacity on the task of video prediction",
    "NOVELTY"
  ],
  [
    "As far as the reviewer is aware , this is a novel application of HVM to this task and well motivated under the MGD interpretation of the problem .",
    "NOVELTY"
  ],
  [
    "as noted above , this does appear to be an interesting and rather original idea , at least for neural MT .",
    "NOVELTY"
  ],
  [
    "While",
    "NOVELTY"
  ],
  [
    "this is a new and interesting task",
    "NOVELTY"
  ],
  [
    "the contribution (",
    "NOVELTY"
  ],
  [
    "above ) is somewhat limited .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution extends the seminal work of Ben-David et al. , the idea of using adversarial learning is not new , the novelty is mediaum Significance : The theoretical analysis is interested but for me limited , the idea of the algorithm is not new but as far as I know the first explicitly presented for multi-source",
    "NOVELTY"
  ],
  [
    "-new theoretical analysis for multisource problem -paper clear -smoothed version is interesting Cons -Learning bounds with worst case standpoint is probably not the best analysis for multisource learning -experimental evaluation limited in the sense that similar algorithms in the literature are not compared -Extension a bit direct from the seminal work of Ben-David et al .Summary",
    "NOVELTY"
  ],
  [
    "contribution appears quite narrow",
    "NOVELTY"
  ],
  [
    "making good use of existing technology developed in the cited work",
    "NOVELTY"
  ],
  [
    "but the estimator is novel",
    "NOVELTY"
  ],
  [
    "The idea of incorporating two distributions into the cost function looks exciting .",
    "NOVELTY"
  ],
  [
    "Probably the most important contribution of this work is that it proposes a new operation that can summarize/generalize the existing depthwise separable convolution and reveal the relationship with the standard convolution .",
    "NOVELTY"
  ],
  [
    "The ( almost ) parameter free method is very appealing and have its benefits .",
    "NOVELTY"
  ],
  [
    "The proposed method is too simplistic",
    "NOVELTY"
  ],
  [
    "The HSVI-like algorithm exploiting Lipschitz continuity is a first of a kind",
    "NOVELTY"
  ],
  [
    "Considers an interesting dataset subsampling variant of the sample weighting meta-learning problem . * Novel application of meta-learning for improving locally-linear models .",
    "NOVELTY"
  ],
  [
    "Down/Up methodology with Co-Attention is new , and beautifully illustrated , showing an exact interaction between question elements",
    "NOVELTY"
  ],
  [
    "The attention unit is novel ,",
    "NOVELTY"
  ],
  [
    "but incremental from common co-attention practice .",
    "NOVELTY"
  ],
  [
    "The proposed low rank bilinear operation is not new ,",
    "NOVELTY"
  ],
  [
    "I think the insights and empirical results presented in this paper are quite interesting and certainly sufficient for acceptance to ICLR",
    "NOVELTY"
  ],
  [
    "Overall , I 'm just not convinced this paper is novel enough to merit publication .",
    "NOVELTY"
  ],
  [
    "The proposed method is simple and lacks technical contributions .",
    "NOVELTY"
  ],
  [
    "The paper is interesting",
    "NOVELTY"
  ],
  [
    "I liked the idea that the authors have set out to address",
    "NOVELTY"
  ],
  [
    "I appreciate again the novel idea that the authors are trying to tackle",
    "NOVELTY"
  ],
  [
    "I found the concept for the paper exciting and",
    "NOVELTY"
  ],
  [
    "My main concern is wrt the novelty of this work : the novelty of the proposed model seems limited compared to code2vec (",
    "NOVELTY"
  ],
  [
    ". To my understanding the core idea of both code2vec and code2seq is similar in many respects",
    "NOVELTY"
  ],
  [
    "The contributions seem incremental as well in addition to the concerns mentioned below",
    "NOVELTY"
  ],
  [
    "There are indeed some innovations in this work .",
    "NOVELTY"
  ],
  [
    "The bounding box association layer and the multi-criteria loss function are original designs , which might have a high impact on the research community .",
    "NOVELTY"
  ],
  [
    "The framework is novel and efficient",
    "NOVELTY"
  ],
  [
    "The proposed method is not novel .",
    "NOVELTY"
  ],
  [
    "the only contribution of the paper seems to be the ad-hoc modification to Adam in Eq . ( 9",
    "NOVELTY"
  ],
  [
    "the authors develop a novel GAN-based approach to denoising , demixing , and in the process train generators for the various components ( not just inference ) .",
    "NOVELTY"
  ],
  [
    "On one hand this paper seems novel and clearly contributes to the field .",
    "NOVELTY"
  ],
  [
    "and proposes what seems to be novel strategy of choosing a subtrees by using PAC-Bayesian framework .",
    "NOVELTY"
  ],
  [
    "The paper proposes",
    "NOVELTY"
  ],
  [
    "The proposed approach and the HDP have conceptually different ideas behind",
    "NOVELTY"
  ],
  [
    "There is some novelty of using neural network to learn anchor function .",
    "NOVELTY"
  ],
  [
    "The novelty is very limited . The use of nouns to enforce content preservation was already explored by Melnyk et al",
    "NOVELTY"
  ],
  [
    "and the idea of using language models was already proposed by Yang et al",
    "NOVELTY"
  ],
  [
    "The authors must clarify which parts of their approach constitute novel contributions as opposed to existing technology .",
    "NOVELTY"
  ],
  [
    "really good step",
    "NOVELTY"
  ],
  [
    "Perliminary Evaluation The paper is a really nice contribution towards leveraging traditional vision tasks for visual question answering .",
    "NOVELTY"
  ],
  [
    "improving beam search is an important direction , and to the best of my knowledge the idea of looking at beam search through the lens of search discrepancies is novel .",
    "NOVELTY"
  ],
  [
    "we find the paper interesting since it provides a new approach for designing online algorithms",
    "NOVELTY"
  ],
  [
    "and contains very interesting theoretical contributions",
    "NOVELTY"
  ],
  [
    "_______________________ Overall this is a good paper which solves an interesting problem in a novel but principled way , and along the way solves a general subproblem . It seems to be an original work , with clear significance to certain forms of network analysis .",
    "NOVELTY"
  ],
  [
    "The new algorithm using the approach advances the state of the art for that class of problems",
    "NOVELTY"
  ],
  [
    "It 's great to consider learning from more than a single type of human feedback and the combination of human demonstrations with preferences is a promising one",
    "NOVELTY"
  ],
  [
    "I find the work interesting",
    "NOVELTY"
  ],
  [
    "Overall , the submission forms a complete and novel contribution in the area of graph embeddings .",
    "NOVELTY"
  ],
  [
    "and the idea is novel ( to me ) and worthy of exploration .",
    "NOVELTY"
  ],
  [
    "The",
    "NOVELTY"
  ],
  [
    "They propose an approach that , assuming that the complementary label is selected uniformly at random",
    "NOVELTY"
  ],
  [
    "The model generalizes well in terms of link and node classification The proposed method is novel and the incorporated ideas are quite interesting",
    "NOVELTY"
  ],
  [
    "The solution proposed here in novel - combining meta-learning on tasks to alleviate a key problem with IRL based approaches .",
    "NOVELTY"
  ],
  [
    "Although the current formulation is novel , there is a close resemblance to other similar approaches -",
    "NOVELTY"
  ],
  [
    "imitation learning",
    "NOVELTY"
  ],
  [
    "provides an interesting insight with the concept of locality of the prior and establishes the connection with Bayesian approaches .",
    "NOVELTY"
  ],
  [
    "the novelty is limited .",
    "NOVELTY"
  ],
  [
    "The main contributions of this work are pulling these ideas together into a practical framework",
    "NOVELTY"
  ],
  [
    "The attack formulation as an optimization problem is novel and interesting .",
    "NOVELTY"
  ],
  [
    "proposed approach is very interesting and novel . The idea of using random features to speed up kernel alignment is brilliant .",
    "NOVELTY"
  ],
  [
    "The proofs techniques used in the paper look quite standard",
    "NOVELTY"
  ],
  [
    "I think that the paper is an interesting contribution in",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , analysis of discrete dynamics is novel .",
    "NOVELTY"
  ],
  [
    "While previous work has considered the problem of visual imitation learning , the approach taken here is novel in its architecture and loss function , and significantly outperforms the baselines in terms of the similarity between the resulting behavior and the expert behavior .",
    "NOVELTY"
  ],
  [
    "Comparison between standard RL and hippocampal representations : The idea to compare hippocampal representations and standard RL implementations is original and interesting .",
    "NOVELTY"
  ],
  [
    "nature",
    "NOVELTY"
  ],
  [
    "the proposal",
    "NOVELTY"
  ],
  [
    "The idea of `` pruning where it matters `` is great .",
    "NOVELTY"
  ],
  [
    "However , the originality ( or contribution ) sounds not enough",
    "NOVELTY"
  ],
  [
    "The paper is empirical and the techniques are combinations of previous methods",
    "NOVELTY"
  ],
  [
    "So the main contribution of the paper is limited to show RFGSM works well when combined with optimization tricks like cyclic learning rate .",
    "NOVELTY"
  ],
  [
    "The surprising robustness of RFGSM , though the originality",
    "NOVELTY"
  ],
  [
    "is questionable",
    "NOVELTY"
  ],
  [
    "and the",
    "NOVELTY"
  ],
  [
    "technical difference comparing to previous methods are subtle",
    "NOVELTY"
  ],
  [
    "The proposed approach is very similar to the CE method by Rubinstein (",
    "NOVELTY"
  ],
  [
    ", limiting the contributions of this paper .",
    "NOVELTY"
  ],
  [
    "The idea of leveraging local information to avoid redundant communication is novel .",
    "NOVELTY"
  ],
  [
    "In general , the algorithm is novel and can have many applications .",
    "NOVELTY"
  ],
  [
    "interest",
    "NOVELTY"
  ],
  [
    "However , the approach in the paper seems to be heavily inspired by the work on MetaGrad by van Erven and Koolen and overall does not look very novel or surprising .",
    "NOVELTY"
  ],
  [
    "while i found this idea interesting",
    "NOVELTY"
  ],
  [
    "The idea is close to many other proposed in the literature ,",
    "NOVELTY"
  ],
  [
    "but to my knowledge it is the first time this exact procedure is studied in detail",
    "NOVELTY"
  ],
  [
    "although it lacks some novelty and a few more",
    "NOVELTY"
  ],
  [
    "The unification of core parts of the sparse neural network literature combined with the neural architecture search problem is very nice",
    "NOVELTY"
  ],
  [
    "Originality The main contributions are all original .",
    "NOVELTY"
  ],
  [
    ", the paper provides an original analysis that explains and justifies this modification of the computation of MDI importances",
    "NOVELTY"
  ],
  [
    "and unique",
    "NOVELTY"
  ],
  [
    "Therefore the paper has limited contributions .",
    "NOVELTY"
  ],
  [
    "The paper proposed a novel image classifier comparison approach that went beyond one fixed testing set for all .",
    "NOVELTY"
  ],
  [
    "The ideas in general based on distributions of weights have been around",
    "NOVELTY"
  ],
  [
    "but the proposed methods is novel in the way it uses the weight distributions in the sparse CNNs to get optimal quantization strategies . This work is novel and grounded to the best of my knowledge .",
    "NOVELTY"
  ],
  [
    "The proposed model lacks novelty \u2013 there seems to be only one non-trivial contribution and I \u2019 m not entirely sure how",
    "NOVELTY"
  ],
  [
    "I failed to see any significantly novel aspects of the proposed system",
    "NOVELTY"
  ],
  [
    "This is a neat idea",
    "NOVELTY"
  ],
  [
    "I think this approach is somewhat novel since it introduces new direction in the field where the model assists PDE solver to improve performance with learned correction function",
    "NOVELTY"
  ],
  [
    "I like the idea of matching the resulting target distribution instead of minimizing a loss over the ratio .",
    "NOVELTY"
  ],
  [
    "the technique used in this paper is not that much different from Liu et al 2018",
    "NOVELTY"
  ],
  [
    "All the ideas mentioned in this paper are existing ones ( although properly attributed ) , so the novelty of this work is relatively low",
    "NOVELTY"
  ],
  [
    "in general , I would consider this paper to be an uninspired combination of pre-existing ideas with weak and inconclusive experimental",
    "NOVELTY"
  ],
  [
    "The proposed algorithm looks interesting",
    "NOVELTY"
  ],
  [
    "Comments I think this is a paper that presents several interesting ideas .",
    "NOVELTY"
  ],
  [
    "I think that the way they authors integrate a likelihood-free generative model with an inference model is something of a contribution in its own right . I particularly like the idea of the intermediate representation .",
    "NOVELTY"
  ],
  [
    "The theoretical contribution is interesting",
    "NOVELTY"
  ],
  [
    "paper with a novel idea",
    "NOVELTY"
  ],
  [
    "the paper is outstanding",
    "NOVELTY"
  ],
  [
    ", but it lacks novelty in terms of new ideas .",
    "NOVELTY"
  ],
  [
    "However , I do not find much novelty compared to the original paper .",
    "NOVELTY"
  ],
  [
    "My point is that the paper presents exactly the same idea as the original paper of CPC , but",
    "NOVELTY"
  ],
  [
    "with new , very interesting results",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge , the findings of this paper are new and not predictable by the current theory .",
    "NOVELTY"
  ],
  [
    "Applying NN to counting a subgraph is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "The used Visual Concepts ( VCs ) were already introduced by other works ( Wangt'15 ) , and is not a novelty .",
    "NOVELTY"
  ],
  [
    "I am not sure if there are any new machine learning based frequency estimation algorithms .",
    "NOVELTY"
  ],
  [
    "and this paper is the first to propose successful neural models that explicitly models the tree structure in both the input and output .",
    "NOVELTY"
  ],
  [
    "paper makes a strong contribution and I would like to see it accepted",
    "NOVELTY"
  ],
  [
    "It makes an original approach to this problem .",
    "NOVELTY"
  ],
  [
    "Overall , the contribution of the paper seems incremental .",
    "NOVELTY"
  ],
  [
    "The proposal to use ensemble uncertainty estimates to drive model-based MCTS is interesting , natural , and I think it 's a good one .",
    "NOVELTY"
  ],
  [
    "it still contains many novel and interesting aspects",
    "NOVELTY"
  ],
  [
    "The edge factorization-based modeling is not new .",
    "NOVELTY"
  ],
  [
    "SUMMARY While I am not heavily familiar with the literature on adaptive online learning , this paper seems to be a breakthrough",
    "NOVELTY"
  ],
  [
    "The idea of applying SVI to Wisharts is good",
    "NOVELTY"
  ],
  [
    ", but of little novelty since this work represents combining two well known techniques .",
    "NOVELTY"
  ],
  [
    "The paper uses inverse light transport to recover a video of hidden scene without any calibration , which seems novel . + The idea of using deep image prior to model the light transport coefficients and hidden scene is also interesting .",
    "NOVELTY"
  ],
  [
    "but I think that the paper is a good contribution even for Neurips",
    "NOVELTY"
  ],
  [
    "The idea of combining bit-serial arithmetic with the DaDN architecture is a small one .",
    "NOVELTY"
  ],
  [
    "The Tartan and Stripes architectures are interesting but the incremental contribution of this paper ( adding support for fully-connected layers ) over the three previous publications on this topic , and in particular Judd ( 2016b ) is very small .",
    "NOVELTY"
  ],
  [
    "It seems to me after reading the response that although the analysis for `` arbitrary sampling `` may not be that innovative , the analysis of mini-batch is new and different from previous works .",
    "NOVELTY"
  ],
  [
    "I do agree the paper has its unique contribution",
    "NOVELTY"
  ],
  [
    "Results and technics are not super innovative",
    "NOVELTY"
  ],
  [
    "In this sense , I do not view the theoretical contribution of this paper as significant .",
    "NOVELTY"
  ],
  [
    "The novelty is incremental though .",
    "NOVELTY"
  ],
  [
    "This paper tried to make a new insight of GAN from theories and I think their approach is a good first step to build theories for GAN",
    "NOVELTY"
  ],
  [
    "I liked the simplicity of the core idea , and appreciated the exposition being generally easy to follow . The application of upper bounds to general f-divergences for training generative models is novel as far as I know .",
    "NOVELTY"
  ],
  [
    "a",
    "NOVELTY"
  ],
  [
    "the paper does not actually present a novel solution method",
    "NOVELTY"
  ],
  [
    ", combining existing tools from style transfer in a novel way .",
    "NOVELTY"
  ],
  [
    "Compared with earlier work , an additional fudge parameter ( alpha ) is introduced",
    "NOVELTY"
  ],
  [
    "Although the novelty is not that significant ( combining existing techniques",
    "NOVELTY"
  ],
  [
    "Overall , the proposed methodology is intuitive and distinctive to the state-of-the-art interpretability methods .",
    "NOVELTY"
  ],
  [
    "The methods themselves are not novel .",
    "NOVELTY"
  ],
  [
    "This represents a compelling convergence of ideas from the programming languages and machine learning communities",
    "NOVELTY"
  ],
  [
    "The use of continuations for AD in deep learning , while new to the literature , is not new to the practice .",
    "NOVELTY"
  ],
  [
    "To my knowledge , the idea is novel , and well motivated .",
    "NOVELTY"
  ],
  [
    "While the RSVRG algorithm is quite natural , its analysis , especially Lemma 2 , seems quite original .",
    "NOVELTY"
  ],
  [
    "this work is an interesting and important progress ( both theoretically and practically )",
    "NOVELTY"
  ],
  [
    "and I \u2019 m therefore not convinced the final result brings any new insight",
    "NOVELTY"
  ],
  [
    "and seems novel",
    "NOVELTY"
  ],
  [
    "but since it stops at image registration , which is a well-known existing model I can not qualify the paper as novel .",
    "NOVELTY"
  ],
  [
    "2 .The proposed regularization terms seem to be novel and",
    "NOVELTY"
  ],
  [
    "However , I find the paper not novel enough for NIPS . The idea of combining two working ideas into a single technique can barely be considered novel .",
    "NOVELTY"
  ],
  [
    "but pointing out the flaw of a dataset or the model alone does not seem to have enough contribution for ICLR",
    "NOVELTY"
  ],
  [
    "The idea of this paper is novel , which uses reject sampling to construct a hash map .",
    "NOVELTY"
  ],
  [
    "While the particular algorithmic contribution is not a major departure from the state of the art",
    "NOVELTY"
  ],
  [
    "The idea is interesting to me",
    "NOVELTY"
  ],
  [
    "I believe that the idea is novel .",
    "NOVELTY"
  ],
  [
    "This makes the technical contribution rather shallow .",
    "NOVELTY"
  ],
  [
    "The originality lies in introducing the mini-batching on top of MSG and R-MSG . Also , the paper introduces a novel sufficiency condition for rank control of the iterates of MB-MSG and MB-RMSG",
    "NOVELTY"
  ],
  [
    "The authors honestly present which ideas are existing and which ideas are new .",
    "NOVELTY"
  ],
  [
    ".This is potentially a groundbreaking paper",
    "NOVELTY"
  ],
  [
    "To this end , slighly novel .",
    "NOVELTY"
  ],
  [
    "I like the idea this paper proposes",
    "NOVELTY"
  ],
  [
    "novel utility analysis by taking the noise into account",
    "NOVELTY"
  ],
  [
    "they obtain a better utility which is an interesting contribution",
    "NOVELTY"
  ],
  [
    "I kinda like the idea and welcome this line of research .",
    "NOVELTY"
  ],
  [
    "This paper lacks innovation and insightful analysis .",
    "NOVELTY"
  ],
  [
    "and definitely an interesting work",
    "NOVELTY"
  ],
  [
    "given the fact that methodologically we have not learned anything new from this paper and in combination with the not satisfying experimental evaluation I warrant for rejection",
    "NOVELTY"
  ],
  [
    "While this is an interesting insight",
    "NOVELTY"
  ],
  [
    "The idea of disentangling the marginal and conditional factors to reduce the sample complexity and thus achieve fast adaptation is novel and insightful .",
    "NOVELTY"
  ],
  [
    "It is a new method compared with previous bound where the paper use a non-uniform sampling scheme",
    "NOVELTY"
  ],
  [
    "But I still think this paper is above borderline because of its theoretical quality and the idea of non-uniform sample would be inspiring for other policy optimization algorithm",
    "NOVELTY"
  ],
  [
    "Even though the basic idea is not particularly innovative",
    "NOVELTY"
  ],
  [
    "I like the basic idea of the paper",
    "NOVELTY"
  ],
  [
    "but the paper lacks a substantial contribution at this time .",
    "NOVELTY"
  ],
  [
    "I think the idea of the paper is quite interesting",
    "NOVELTY"
  ],
  [
    "While the technique is novel as far as I know",
    "NOVELTY"
  ],
  [
    "While the core idea is to some extent an observation , I like the paper because it is a nice , cute idea that one could actually teach in a class .",
    "NOVELTY"
  ],
  [
    "While the proposed model is very interesting",
    "NOVELTY"
  ],
  [
    "The originality of this work is in the approach of the problem , the paper tries to explain the reasons why CNNs are vulnerable .",
    "NOVELTY"
  ],
  [
    "as the paper points out earlier this is not a novel finding",
    "NOVELTY"
  ],
  [
    "This means of computing the LCB seems technically novel",
    "NOVELTY"
  ],
  [
    "to this paper since this paper proposes an interesting concept and it looks promising",
    "NOVELTY"
  ],
  [
    "Pros .The authors introduce a very useful metric \u201c Ricci curvature \u201d CurvGN-1 and CurvGN-2 outperforms existing graph convolution algorithms .",
    "NOVELTY"
  ],
  [
    "The authors develop a new probabilistic theory that helps give some insights into why CNNs work .",
    "NOVELTY"
  ],
  [
    "The paper presents an original and novel contribution that is of interest to the field .",
    "NOVELTY"
  ],
  [
    "The idea of `` Explore-Verify Frame `` is very good .",
    "NOVELTY"
  ],
  [
    "I 'm not convinced that the work is hugely original .",
    "NOVELTY"
  ],
  [
    "The two novelties are",
    "NOVELTY"
  ],
  [
    "hierarchical priors and",
    "NOVELTY"
  ],
  [
    "reduced floating point precision",
    "NOVELTY"
  ],
  [
    "which are certainly useful but they are unsurprising extensions of the previous work .",
    "NOVELTY"
  ],
  [
    "Idea is not that novel relative to all the recent work on learning to supplement training data for few-shot learning (",
    "NOVELTY"
  ],
  [
    "However , the contribution is rather limited . The proposed taxonomy is not new .",
    "NOVELTY"
  ],
  [
    "the technique as such as very similar to Cheng et al , and Liu et al",
    "NOVELTY"
  ],
  [
    ", the results are new",
    "NOVELTY"
  ],
  [
    "Although the novelty of the paper is limited and have been shown for transfer learning with SVM classifiers prior to resurgence of deep learning",
    "NOVELTY"
  ],
  [
    "It 's simple with no technical novelty",
    "NOVELTY"
  ],
  [
    "It is a novel point of view to aim to find all feature subsets for which a statistical association test rejects the null hypothesis",
    "NOVELTY"
  ],
  [
    "The introduction of the branch-and-bound algorithm for conditional statistical association tests is novel and well-explained .",
    "NOVELTY"
  ],
  [
    "The proposes a novel approximation for ( possibly high dimensional ) integrals .",
    "NOVELTY"
  ],
  [
    "The use of ancestral models rather than Bayesian networks is sensible and novel to my knowledge",
    "NOVELTY"
  ],
  [
    "seems technically solid and novel",
    "NOVELTY"
  ],
  [
    "However , this idea is too incremental and applying the classification function to graph filter is very trivial .",
    "NOVELTY"
  ],
  [
    "it is not clear which contribution actually improves the",
    "NOVELTY"
  ],
  [
    "but the contribution is modest",
    "NOVELTY"
  ],
  [
    "I like the idea of introducing the operator concepts to save much time in the variable binding problems in the common logic inference domain .",
    "NOVELTY"
  ],
  [
    "This hierarchy structure solves the inductive problem efficiently by decomposing it into subproblems , which seems novel to me .",
    "NOVELTY"
  ],
  [
    "the proposed IVE-GAN algorithm is quite novel .",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "While this paper might be not significantly novel in both topic modelling and reinforcement learning area",
    "NOVELTY"
  ],
  [
    ", the seamless combination of two approaches is still interesting and novel",
    "NOVELTY"
  ],
  [
    "The general idea is quite interesting",
    "NOVELTY"
  ],
  [
    "but the novelty is quite limited .",
    "NOVELTY"
  ],
  [
    "The idea of an attention policy that takes advantage of expert knowledge is a nice contribution ,",
    "NOVELTY"
  ],
  [
    "but perhaps if limited novelty --",
    "NOVELTY"
  ],
  [
    "But the contribution of this work seems incremental .",
    "NOVELTY"
  ],
  [
    "While I don\u00e2\u0080\u0099t claim to have a deep knowledge of the literature , this work seems to be original and significant .",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is very relevant to ICLR and , as far as I know , novel .",
    "NOVELTY"
  ],
  [
    "In this view , none of these algorithms contributed in any meaningful way to our understanding of the optimization of deep networks * nor* they advanced in any way the state-of-the-art for optimizing convex Lipschitz functions .",
    "NOVELTY"
  ],
  [
    "Highly original",
    "NOVELTY"
  ],
  [
    "and the improvements are somewhat incremental",
    "NOVELTY"
  ],
  [
    "these contributions were somewhat muted by other shortcomings of the approach which make me doubt the robustness and generality of the",
    "NOVELTY"
  ],
  [
    "In overall , this paper is very nice work as it adopts a novel idea for fast and efficient computations and shows better practical speedup and accuracy than the state-of-the-art algorithm .",
    "NOVELTY"
  ],
  [
    "This observation is not new",
    "NOVELTY"
  ],
  [
    "While the main idea is not new to machine learning ( or deep learning )",
    "NOVELTY"
  ],
  [
    ", to the best of my knowledge it has not been applied on GANs . The paper is overall",
    "NOVELTY"
  ],
  [
    "and it includes an insightful discussion about the importance of high rank models .",
    "NOVELTY"
  ],
  [
    "My main concern about this paper is that is has conceptual overlap with other approaches .",
    "NOVELTY"
  ],
  [
    "The general idea behind the paper seems pretty novel and potentially quite cool .",
    "NOVELTY"
  ],
  [
    "I think the proposed graphical model is interesting and novel .",
    "NOVELTY"
  ],
  [
    "I believe that the theoretic contributions developed in this paper are only of",
    "NOVELTY"
  ],
  [
    "Their methodology combines multiple different ideas in causal inference ( multi-headed deep learning models and targeted learning ) in a novel way",
    "NOVELTY"
  ],
  [
    "The paper contains the germ of a powerful idea .",
    "NOVELTY"
  ],
  [
    "it feels as if the authors have n't yet come to grip with their own idea and architecture .",
    "NOVELTY"
  ],
  [
    "The idea of converting a set of data points to one point and rehearse at a meta level is a smart and novel idea .",
    "NOVELTY"
  ],
  [
    "This paper puts forward a not entirely new , but also not sufficiently understood interpretation of dropout regularization",
    "NOVELTY"
  ],
  [
    "The idea of using the Lipschitz continuity of the value seems interesting",
    "NOVELTY"
  ],
  [
    "although rather straightforward and the advance from previous studies like [ 7 ] appears to be quite small .",
    "NOVELTY"
  ],
  [
    "Some specific modeling and algorithmic details",
    "NOVELTY"
  ],
  [
    "are likely new and useful",
    "NOVELTY"
  ],
  [
    "The idea of splitting latent codes into two separate components -- one supervised , the other more general -- is interesting .",
    "NOVELTY"
  ],
  [
    "I understand that the paper is proposing the first method that combines CNFs with conditional modeling",
    "NOVELTY"
  ],
  [
    "The paper is the first paper , in my knowledge , that introduces the problem of identifying anomalous ( or corrupted ) subset of data input to a neural network .",
    "NOVELTY"
  ],
  [
    "The work has incremental novelty as it seems to be largely based on prior art ( not on DNNs ) .",
    "NOVELTY"
  ],
  [
    "The idea of using DNN to approximately unfold the IHT iteration procedure is interesting and novel as far as I am aware of .",
    "NOVELTY"
  ],
  [
    "There is a clear gap between theory and applications",
    "NOVELTY"
  ],
  [
    "Novelty : The sensitivity bound in this paper seems very similar to the one presented in [ 1 ] which is not cited in the manuscript",
    "NOVELTY"
  ],
  [
    "The computational hardness results presented in this paper are interesting and novel to my knowledge .",
    "NOVELTY"
  ],
  [
    "I liked how this idea allows us to conceptualize learning beam search policies and I",
    "NOVELTY"
  ],
  [
    "which is in my opinion a promising combination",
    "NOVELTY"
  ],
  [
    "Overall",
    "NOVELTY"
  ],
  [
    "; the proposed approach is novel and makes an important contribution to the field of machine learning . It is nice to build a connection between tensor networks and feature selection .",
    "NOVELTY"
  ],
  [
    "so it 's not some new contribution in addition to the clustering part",
    "NOVELTY"
  ],
  [
    "technical novelty is limited",
    "NOVELTY"
  ],
  [
    "The `` novelty `` of this paper is a bit hard to assess",
    "NOVELTY"
  ],
  [
    "The submission is clearly building upon the observations made in [ 5 ] , and extends /complements them in meaningful ways .",
    "NOVELTY"
  ],
  [
    "The paper however does not seem to have a standout technical idea or contribution . The results feel incremental and for a theoretical paper lacks the required technical novelty expected for NeurIPS .",
    "NOVELTY"
  ],
  [
    "Therefore , the novelty of the proposed method is somewhat weak .",
    "NOVELTY"
  ],
  [
    "The adaptive sketch approach is particularly appealing",
    "NOVELTY"
  ],
  [
    "I think the overall idea is interesting .",
    "NOVELTY"
  ],
  [
    "this work interestingly proposes a theoretical model that supports the idea .",
    "NOVELTY"
  ],
  [
    "good , originality : good , significance : good Pros",
    "NOVELTY"
  ],
  [
    "To the best of my knowledge",
    "NOVELTY"
  ],
  [
    "this work is the first one that provides theoretical explanation for the tradeoff between accuracy and robustness",
    "NOVELTY"
  ],
  [
    "The proposed method is novel",
    "NOVELTY"
  ],
  [
    "The search function set and method is not novel .",
    "NOVELTY"
  ],
  [
    "Overall , I think this paper is not meeting ICLR novelty standard .",
    "NOVELTY"
  ],
  [
    "The practical implementation of your algorithm looks very similar to theirs too",
    "NOVELTY"
  ],
  [
    "the analysis techniques using in the paper are novel .",
    "NOVELTY"
  ],
  [
    "The analysis techniques are novel and led to improved analysis for the problem .",
    "NOVELTY"
  ],
  [
    "The results are also novel",
    "NOVELTY"
  ],
  [
    "This paper does not seem to offer any major fundamental or applied contributions .",
    "NOVELTY"
  ],
  [
    "The proposed loss functions seem novel and theoretical analysis are well presented to support their",
    "NOVELTY"
  ],
  [
    "Interesting new idea .",
    "NOVELTY"
  ],
  [
    "Pros The zeroth-order stochastic condition gradient algorithm is the first algorithm that explore the stochastic condition gradient by merely using the zeroth-order information of objective .",
    "NOVELTY"
  ],
  [
    "The paper is already a useful technical contribution",
    "NOVELTY"
  ],
  [
    "The contribution of this paper is not very significant .",
    "NOVELTY"
  ],
  [
    "The idea is novel .",
    "NOVELTY"
  ],
  [
    "While the idea is novel and the paper is clear",
    "NOVELTY"
  ],
  [
    "The idea of using disentangled blocks , rather than injecting noise or using dropout and a softmax bottleneck as in [ Banino et al , 2018 ] , is interesting .",
    "NOVELTY"
  ],
  [
    "the authors have introduced an interesting and elegant model for grid cells that suffers from simplifications",
    "NOVELTY"
  ],
  [
    "Overall the paper seems weak in originality given the amount of previous work on similar problems .",
    "NOVELTY"
  ],
  [
    "the paper seems relatively incremental since many others have explored the general problem of learning multiple graphical models together including some theoretical results",
    "NOVELTY"
  ],
  [
    "The scoring function called TransGaussian is an novel take on ( or a generalization of ) the well-known TransE scoring function .",
    "NOVELTY"
  ],
  [
    "-- -- -- -- -- OVERALL JUDGMENT While I think this proposed work is very interesting",
    "NOVELTY"
  ],
  [
    "separating common semantic latent variables with language-specific latent variables",
    "NOVELTY"
  ],
  [
    "The method is simple , yet original .",
    "NOVELTY"
  ],
  [
    "Though the novelty of the model is limited , learning and inference with the proposed model is non-trivial .",
    "NOVELTY"
  ],
  [
    "The idea is insightful and proposed models are straight-forward .",
    "NOVELTY"
  ],
  [
    "Overall , this paper has a novel contribution .",
    "NOVELTY"
  ],
  [
    "And since it puts together a bunch of well-understood ideas , it seems rather incremental .",
    "NOVELTY"
  ],
  [
    "The contribution of the paper seems to be two-fold",
    "NOVELTY"
  ],
  [
    "The authors present a novel algorithm",
    "NOVELTY"
  ],
  [
    "Extensions to non-Gaussian likelihoods seem non-trivial as computing the expected log likelihood would decouple the variational parameters",
    "NOVELTY"
  ],
  [
    "I like this idea",
    "NOVELTY"
  ],
  [
    "Good , relevant idea",
    "NOVELTY"
  ],
  [
    "Originality I am not aware of other studies on this topic , the proposed approach seems original .",
    "NOVELTY"
  ],
  [
    "I do not see a major technological innovation is needed to get around this issue",
    "NOVELTY"
  ],
  [
    "the analysis and algorithm in this paper are very similar to that of Jin et al 2018",
    "NOVELTY"
  ],
  [
    "this Q-function itself is not a new concept in this paper .",
    "NOVELTY"
  ],
  [
    "There is nothing interesting or novel about the paper .",
    "NOVELTY"
  ],
  [
    "The paper does not provide any theoretical contribution",
    "NOVELTY"
  ],
  [
    "but other than that I fail to find any novelty in the paper .",
    "NOVELTY"
  ],
  [
    "My strongest criticism for this paper is against the claim that Tumblr post represent self-reported emotions and that this method sheds new insight on emotion representation and my secondary criticism is a lack of novelty in the method , which seems to be simply a combination of previously published sentiment analysis module and previously published image analysis module , fused in an output layer",
    "NOVELTY"
  ],
  [
    "With respect to the rest of the paper , the level of novelty and impact is `` ok , but not good enough",
    "NOVELTY"
  ],
  [
    "The authors algorithm also seems to be essentially a combination of two other , previously published algorithms .",
    "NOVELTY"
  ],
  [
    "but I do not feel there is a contribution here .",
    "NOVELTY"
  ],
  [
    "The biggest concern that I have is its technical novelty .",
    "NOVELTY"
  ],
  [
    "So , I would say the novelty is indeed limited .",
    "NOVELTY"
  ],
  [
    "The result of Theorem 1 sounds rather a straightforward application of classical results",
    "NOVELTY"
  ],
  [
    "Overall , I like the idea in this paper that we can put together a unified framework for stochastic optimization algorithms and incorporate things like momentums and regularizations that were previously treated separately .",
    "NOVELTY"
  ],
  [
    "However , beyond proposing such a framework , it seems that contributions on both the theoretical and empirical side are a bit limited at this point .",
    "NOVELTY"
  ],
  [
    "My main concern is with the paper ` s novelty .",
    "NOVELTY"
  ],
  [
    "Little model novelty is required to solve this additional requirement on these tasks beyond using epsilon greedy exploration",
    "NOVELTY"
  ],
  [
    "The missing part , to me , is the most important part of this paper in terms of technical",
    "NOVELTY"
  ],
  [
    "contribution",
    "NOVELTY"
  ],
  [
    "the variational autoencoder to arbitrary tree-structured outputs",
    "NOVELTY"
  ],
  [
    "The use of IWAE to obtain a better estimate of log likelihoods is a particularly nice touch",
    "NOVELTY"
  ],
  [
    "Somehow novel .",
    "NOVELTY"
  ],
  [
    "The idea is intuitive and seems can work .",
    "NOVELTY"
  ],
  [
    "While the fact that these covariates are strongly associated to face images and audio recordings had already been discussed in",
    "NOVELTY"
  ],
  [
    "2 ] , the idea of actually using them to drive the learning process is novel in this particular task .",
    "NOVELTY"
  ],
  [
    "While the article does not present substantial , general-purpose methodological innovations in machine learning",
    "NOVELTY"
  ],
  [
    "I believe it constitutes a solid application of existing techniques",
    "NOVELTY"
  ],
  [
    "The idea is interesting",
    "NOVELTY"
  ],
  [
    "The introduction of the budget constraint is an interesting twist on this problem , which I had not seen before ( though other methods apply other constraints .",
    "NOVELTY"
  ],
  [
    "The proposed method makes an interesting contribution , distinct from the existing literature as far as I know .",
    "NOVELTY"
  ],
  [
    "Combining textual and non-textual features is not a new concept , and combining a RNN layer and a CNN layer is not novel .",
    "NOVELTY"
  ],
  [
    "The paper is clearly original",
    "NOVELTY"
  ],
  [
    "As acknowledged by the authors this formulation is not new and has been described in",
    "NOVELTY"
  ],
  [
    "The proposed algorithm does not seem to do better than a 5 years old DQN algorithm",
    "NOVELTY"
  ],
  [
    "and I think there are several interesting contributions .",
    "NOVELTY"
  ],
  [
    "I find the idea of learning to infer embeddings of the opponent policies from the agent 's own local observations quite interesting .",
    "NOVELTY"
  ],
  [
    "and the results are insightful . The theoretical results rely on non-trivial combinations of several recent techniques . I enjoy reading the paper and appreciate the contribution .",
    "NOVELTY"
  ],
  [
    "This result is novel and interesting .",
    "NOVELTY"
  ],
  [
    "This is a simple idea , but a good one .",
    "NOVELTY"
  ],
  [
    "and a nice contribution to the study of importance sampling techniques",
    "NOVELTY"
  ],
  [
    "The core proposal is a simple modification of Hariharan and Girshick 2016",
    "NOVELTY"
  ],
  [
    "The work is a somewhat novel extension and analysis of Hariharan and Girshick 2016",
    "NOVELTY"
  ],
  [
    "There are two novelties as far as I can see",
    "NOVELTY"
  ],
  [
    "these may or may not be novel",
    "NOVELTY"
  ],
  [
    "- but they were novel to me ) .",
    "NOVELTY"
  ],
  [
    "I thought the MSRE idea was interesting .",
    "NOVELTY"
  ],
  [
    "The large-scale analysis of overfitting in machine learning studies , implemented based on public competition platforms , seems to be a new idea .",
    "NOVELTY"
  ],
  [
    "The work does not include substantially new theoretical or methodological ideas ; the originality is mainly empirical .",
    "NOVELTY"
  ],
  [
    "The idea of learning prototypes to improve interpretation is interesting",
    "NOVELTY"
  ],
  [
    "=========================== I like the idea of this paper",
    "NOVELTY"
  ],
  [
    "Both Theorems 1",
    "NOVELTY"
  ],
  [
    "and 2 are new",
    "NOVELTY"
  ],
  [
    "very similar to row sampling for low-rank graph matrix approximation , with extension to the dynamic setting or on-line setting",
    "NOVELTY"
  ],
  [
    "-The novelty of this paper is somewhat limited .",
    "NOVELTY"
  ],
  [
    "the paper has some interesting mathematical relationships to other MMDs",
    "NOVELTY"
  ],
  [
    "and original",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is limited .",
    "NOVELTY"
  ],
  [
    "On a technical level this paper introduces new ideas that go far beyond simple generalizations of the work of [ 3 ] for OLS regression .",
    "NOVELTY"
  ],
  [
    "The estimates of the loss differences are based on an extra randomly chosen observation , which seems to be a novel approach .",
    "NOVELTY"
  ],
  [
    "Actually , the idea of variable splitting for symmetric NMF is not original ,",
    "NOVELTY"
  ],
  [
    "Originality is limited because the main idea of variable splitting is not new and the algorithm is also not new .",
    "NOVELTY"
  ],
  [
    "Theoretical proofs of existing algorithm might be regarded as some incremental contributions .",
    "NOVELTY"
  ],
  [
    "however it is not new idea that is already being used .",
    "NOVELTY"
  ],
  [
    "but not new in of itself as it was the basis for the prior work of Roberts et al",
    "NOVELTY"
  ],
  [
    ", the proposed algorithm incorporates novel ideas ,",
    "NOVELTY"
  ],
  [
    "In my opinion this takes away from the contribution of the paper",
    "NOVELTY"
  ],
  [
    "However , I found that the contribution of this paper is fairly small .",
    "NOVELTY"
  ],
  [
    "and novel",
    "NOVELTY"
  ],
  [
    "I believe this is the first use of ESS games to study RL algorithms .",
    "NOVELTY"
  ],
  [
    "This paper proposes a novel importance sampling policy search method which accounts for the problem of large variance",
    "NOVELTY"
  ],
  [
    "There are several nice contributions in this paper",
    "NOVELTY"
  ],
  [
    "the contribution is clear",
    "NOVELTY"
  ],
  [
    "knowledge",
    "NOVELTY"
  ],
  [
    "It is clear that this paper stands out in terms of originality and novelty ( at least for the NIPS audience",
    "NOVELTY"
  ],
  [
    "While Grover 's search is not a new",
    "NOVELTY"
  ],
  [
    "algorithm , this application of it and the corresponding interdisciplinary insight certainly are novel by NIPS standards .",
    "NOVELTY"
  ],
  [
    "the most important concepts from quantum mechanics",
    "NOVELTY"
  ],
  [
    "The model is interesting",
    "NOVELTY"
  ],
  [
    "Considering correlations between features from different encoder layers is a good idea",
    "NOVELTY"
  ],
  [
    "OVERALL On the whole I feel that the paper is somewhat incremental .",
    "NOVELTY"
  ],
  [
    "However I don \u2019 t feel that this alone is enough novelty for ICLR ,",
    "NOVELTY"
  ],
  [
    "Overall , I found this paper to be a good submission that provides insight into an increasingly popular family of models .",
    "NOVELTY"
  ],
  [
    "The overall approach is interesting and the experimental results look promising",
    "NOVELTY"
  ],
  [
    "The contribution then seems a bit incremental , as it is mostly weight normalization + straight through estimator to learn the clipping constant by minimizing directly the loss function .",
    "NOVELTY"
  ],
  [
    "the generalization bound for permutation invariance is new to my knowledge",
    "NOVELTY"
  ],
  [
    "While , the proof appears to be novel for permutation invariance per se , however I do not think the main findings in this paper or the proof approach are sufficiently novel .",
    "NOVELTY"
  ],
  [
    ".In the context of this prior work , the contribution of this paper appears incremental .",
    "NOVELTY"
  ],
  [
    "Overall , this paper is technically rigorous , and novel in its very specific context of deriving the generalization bounds for permutation invariant networks .",
    "NOVELTY"
  ],
  [
    ", in the broader context of invariances in general and their bounds , the contribution appears to be marginal .",
    "NOVELTY"
  ],
  [
    "No new ideas are presented ,",
    "NOVELTY"
  ],
  [
    "Idea is interesting .",
    "NOVELTY"
  ],
  [
    "Since from the technical point of view the novelty of the model is limited",
    "NOVELTY"
  ],
  [
    "the comparison makes sense but it also shows that the ideas presented here are less novel than they might initially seem .",
    "NOVELTY"
  ],
  [
    "The paper introduces a novel variant of the multi-armed problem , motivated by practice .",
    "NOVELTY"
  ],
  [
    "I feel the idea of this paper is straightforward , and the contribution is incremental .",
    "NOVELTY"
  ],
  [
    "The work is novel in the sense that most previous multitask works considered only linear relations among the tasks .",
    "NOVELTY"
  ],
  [
    "I find the algorithm interesting",
    "NOVELTY"
  ],
  [
    "I can\u00e2\u0080\u0099t tell which part of the analysis is novel and important .",
    "NOVELTY"
  ],
  [
    "The paper proposes a novel variance based loss to reduce communication overhead in a MARL setting .",
    "NOVELTY"
  ],
  [
    "Definitely a significant contribution to MARL",
    "NOVELTY"
  ],
  [
    "It is novel to use the MC rule to drive the order learning .",
    "NOVELTY"
  ],
  [
    "The updating setting considered in this paper is kind of interesting .",
    "NOVELTY"
  ],
  [
    "the contribution of the current paper is not strong enough",
    "NOVELTY"
  ],
  [
    "in a novel and successful way",
    "NOVELTY"
  ],
  [
    "Overall , this paper seems to be a nice addition to the body of works on network compression .",
    "NOVELTY"
  ],
  [
    "I do think using agent morphology is an under-explored idea and one that is general",
    "NOVELTY"
  ],
  [
    "the contributions are not enough for this venue . Both the introduced method and the metrics are slight modifications",
    "NOVELTY"
  ],
  [
    "I like the basic idea of the paper",
    "NOVELTY"
  ],
  [
    "I do think their idea for a fairness constraint is very interesting",
    "NOVELTY"
  ],
  [
    "while I like the idea of the balanced TPR",
    "NOVELTY"
  ],
  [
    "Admittedly , the idea of this paper is interesting .",
    "NOVELTY"
  ],
  [
    "I think the novelty and rigorousness of this paper is not",
    "NOVELTY"
  ],
  [
    "1 .On the novelty side , characterizing the convergence via the H matrix is not new",
    "NOVELTY"
  ],
  [
    "These facts largely lower the contribution of this paper on a high level",
    "NOVELTY"
  ],
  [
    "However , the VHRNN is constructed by a straight-forward combination of existing techniques and hence the technical contribution of this paper is marginal .",
    "NOVELTY"
  ],
  [
    "3 .The paper proposes a novel ( computationally more efficient ) implementation of the match-LSTM model .",
    "NOVELTY"
  ],
  [
    "2 .NEWSQA dataset is very similar to SQuAD dataset in terms of the size of the dataset",
    "NOVELTY"
  ],
  [
    "ORIGINALITY The originality of the work is somehow limited as it is porting the SSD approach for object detection to action localization . While I understand that the encoding of the sentence with the referring expression and the addition of the temporal dimension is novel , it is not a breakthrough idea either .",
    "NOVELTY"
  ],
  [
    "The proposed approach is more novel than I understood after my original review .",
    "NOVELTY"
  ],
  [
    "i.e .there is nothing architecturally novel about it",
    "NOVELTY"
  ],
  [
    "but even after the clarification round I still do n't understand how it is novel compared to standard attention used in for instance seq2seq models",
    "NOVELTY"
  ],
  [
    "the theory only extends Pentina",
    "NOVELTY"
  ],
  [
    "and the resulting model is novel enough",
    "NOVELTY"
  ],
  [
    "The proposed model is interesting and seems novel . I like the idea of decomposing the latent code into the domain-invariant and domain-specific parts . The idea of using a domain-specific variational information bound to enforce the model disentangle the latent code also seems interesting .",
    "NOVELTY"
  ],
  [
    "I think the idea is novel",
    "NOVELTY"
  ],
  [
    "key contribution of this paper",
    "NOVELTY"
  ],
  [
    "Though the idea is novel",
    "NOVELTY"
  ],
  [
    "Though , the solution is not completely unique",
    "NOVELTY"
  ],
  [
    "I am not sure how novel the technique is .",
    "NOVELTY"
  ],
  [
    "This is an interesting",
    "NOVELTY"
  ],
  [
    "I find the introduction of pruning lengthy and not particularly novel or surprising .",
    "NOVELTY"
  ],
  [
    "in looking for contributions this paper makes",
    "NOVELTY"
  ],
  [
    "there is no essential algorithmic , architectural , or mathematical insight , which I expect out of all but the most heavily experimental papers",
    "NOVELTY"
  ],
  [
    "are impressing",
    "NOVELTY"
  ],
  [
    "The authors propose a sensible approach , which is also novel to be best of our knowledge , using SVM to select support data from old data to be fed to the network along with the new data in the incremental learning framework to avoid catastrophic forgetting .",
    "NOVELTY"
  ],
  [
    "The idea of spectral graph translation and its integration with deep learning is interesting ,",
    "NOVELTY"
  ],
  [
    "but the main idea comes from Kunegis et al",
    "NOVELTY"
  ],
  [
    "Despite of a new designed graph kernel and adding nonlinear activations , the contributions seem not so significant .",
    "NOVELTY"
  ],
  [
    "the speedup AND generalization performance is much better than that of Xgboost and LightGbm I found it an interesting and a refreshing way of thinking about boosting",
    "NOVELTY"
  ],
  [
    "and the formulation is different and interesting 2",
    "NOVELTY"
  ],
  [
    "While using masks is not entirely novel",
    "NOVELTY"
  ],
  [
    ", having auxiliary parameters to decouple the pruning and learning processes is I think quite important and seems to be novel .",
    "NOVELTY"
  ],
  [
    "a new idea and it would be interesting to see larger models",
    "NOVELTY"
  ],
  [
    "it includes new results that were not known previously",
    "NOVELTY"
  ],
  [
    "The technique contribution is limited .",
    "NOVELTY"
  ],
  [
    "The proposed applying attention mechanism in graph operation is nothing new without a comprehensive design .",
    "NOVELTY"
  ],
  [
    "paper proposes a novel way to regularize recurrent neural networks through Bayesian view of dropout",
    "NOVELTY"
  ],
  [
    "the overall novelty of the proposed method is minor .",
    "NOVELTY"
  ],
  [
    "and presents a interesting method of using reasoning engine for VQA .",
    "NOVELTY"
  ],
  [
    "However , the authors do not offer any new innovation on the neural reasoning and",
    "NOVELTY"
  ],
  [
    "There is a lack of novelty of this study .",
    "NOVELTY"
  ],
  [
    "In my opinion , the idea is novel and have potentials in online optimization .",
    "NOVELTY"
  ],
  [
    "The application of adversarial training to text data is a simple but not trivial extension",
    "NOVELTY"
  ],
  [
    "The novelty of this paper is very limited .",
    "NOVELTY"
  ],
  [
    "The idea of applying bi-directional LSTM is also not new for video action segmentation .",
    "NOVELTY"
  ],
  [
    "I believe the novelty , contribution and impact of this work is sub-par to what is expected for publication in ICLR",
    "NOVELTY"
  ],
  [
    "A very interesting problem Weaknesses",
    "NOVELTY"
  ],
  [
    "While there is some prior work in this area",
    "NOVELTY"
  ],
  [
    ", the paper has some very interesting improvements over them",
    "NOVELTY"
  ],
  [
    "The conceptual idea is simple and elegant",
    "NOVELTY"
  ]
]